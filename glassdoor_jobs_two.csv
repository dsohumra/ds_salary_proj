Job Title,Salary Estimate,Job Description,Rating,Company Name,Location,Headquarters,Size,Founded,Type of ownership,Industry,Sector,Revenue,Competitors
Data Scientist,-1,"Job Description – Data Scientist

Location: Chennai or Bengaluru, India


Buckman is a privately held, global specialty chemical company with headquarters in Memphis, TN, USA, committed to safeguarding the environment, maintaining safety in the workplace, and promoting sustainable development. Buckman works proactively and collaboratively with its worldwide customers in pulp and paper, leather, and water treatment to deliver exceptional service and innovative specialty chemical solutions to help boost productivity, reduce risk, improve product quality, and provide a measurable return on investment. Buckman is in the middle of a digital transformation of its businesses and focused on building the capabilities and tools in support of this.

Job Description


Buckman is seeking an experienced Data Scientist to lead the development of a Data Science program. You will work closely with Buckman stakeholders to derive deep industry knowledge across paper, water, leather, and performance chemical industries. You will help develop a data strategy for the company including collection of the right data, creation of the data science project portfolio, partnering with external providers, and augmenting capabilities with additional internal hires. A large part of the job is communicating and developing relationship with key stakeholders and subject matter experts to tee up proofs of concept projects to demonstrate how data science can be used to solve old problems in unique and novel ways. You will not have a large internal team to rely on, at least initially, so individual expertise, breadth of data science knowledge, and ability to partner with external companies will be essential for success. In addition to the pure data science problems, you will be working closely with a multi-disciplinary team consisting of sensor scientists, software engineers, network engineers, mechanical/electrical engineers, and chemical engineers in the development, and deployment of IoT solutions. If you like working for an entrepreneurial company with a Sustainability mission and digital ambitions at the core of its strategy, Buckman is the place for you.

Basic Qualifications
Bachelor’s degree in a quantitative field such as Data Science, Statistics, Applied Mathematics, Physics, Engineering, or Computer Science
5+ years of relevant working experience in an analytical role involving data extraction, analysis, and visualization and expertise in the following areas:
Expertise in one or more programming languages R, Python, MATLAB, JMP, Minitab, Java, C++, Scala
Key libraries such as Sklearn, XgBoost, GLMNet, Dplyr, ggplot, Rshiny
Experience and knowledge of data mining algorithms including supervised and unsupervised machine learning techniques areas such as Gradient Boosting, Decision Trees, Multivariate Regressions, Logistic regressions, Neural Network, Random Forest, Support Vector Machine, Naive Bayes, Time Series, Optimization
Microsoft IoT/data science toolkit: Azure Machine Learning, Datalake, Datalake analytics, Workbench, IoT Hub, Stream Analytics, CosmosDB, Time Series Insights, PowerBI
Data querying languages (e.g. SQL, Hadoop/Hive) and Preferred Qualifications
A demonstrated record of success with a verifiable portfolio of problems tackled
Preferred qualifications
Master’s or PhD degree in a quantitative field such as Data Science, Statistics, Applied Mathematics, Physics, Engineering, or Computer Science
Experience in the specialty chemicals sector or similar industry
Background in engineering, especially Chemical Engineering
Experience starting up a data science program
Experience working with global stakeholders
Experience working in a start-up environment, preferably in an IoT company
Knowledge in quantitative modeling tools and statistical analysis
Personality Traits
A strong business focus, ownership and inner self-drive to data science solutions to real-world customers with tangible impact.
Ability to collaborate effectively with multi-disciplinary and passionate team members.
Ability to communicate with a diverse set of stakeholders
Strong planning and organization skills, with the ability to manage multiple complex projects
A life-long learner who constantly updates skills",3.8,"Buckman
3.8",Chennai,"Memphis, TN",1001 to 5000 employees,1945,Company - Private,Chemical Manufacturing,Manufacturing,₹50 to ₹100 billion (INR),-1
Data Scientist,-1,"About HP

HP is the worlds leading personal systems and printing company, we create technology that makes life better for everyone, everywhere. Our innovation springs from a team of individuals, each collaborating and contributing their own perspectives, knowledge, and experience to advance the way the world works and lives.

We are looking for visionaries, like you, who are ready to make a purposeful impact on the way the world works.

At HP, the future is yours to create!

Purpose

As a Data Scientist, you will join an industry-leading organization and work on developing tools and analytical models to identify optimal marketing, pricing and sales decisions for our Printing & Personal Systems business in EMEA. Working in the Data Science team, you will develop innovative analytical approaches and tools enabling better insights to implement marketing and pricing guidelines for supplies. You will work closely with Product Management, Sales, and Finance teams to drive profitable growth.

Knowledge, Skill and Abilities
Experience building and interpreting machine learning models (e.g. Naïve Bayes, random forest, regression trees, neural networks)
Ability to merge different data sources, create new variables and conduct regression analyses (probit/logit and other GLM)
Develop and implement frameworks and processes for systematic data analysis, as well as reporting capabilities to track key business performance metrics
Very strong analytical skills, with a high level of attention to detail
Solid problem-solving skills and systems thinking, being able to act independently on building analysis models and business cases
Capable of quickly interpreting analysis results and providing strategy recommendations, including presenting to senior leadership
Additional Qualifications
3+ years of advanced analytics experience
Proficient in R and/or Python programming languages
Good understanding of financial metrics and ability to leverage pricing decision using financials
Strong understanding of data structures, data management and statistical methods
Strong presentation skills
Must be a team player, who is passionate and able to build strong relationships across different functions
University degree in a quantitative discipline (e.g. economics, statistics, econometrics, mathematics, physics), with a postgraduate degree preferred
Analytics experience in Finance, Marketing or Pricing is a plus",4.0,"HP Inc.
4.0",Bengaluru,"Palo Alto, CA",10000+ employees,1939,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"At Amazon, we strive to be most customer-centric company on the earth. To get there, we need exceptionally talented, bright, dynamic and driven people to develop the next-generation technologies.
Are you champion of innovating on behalf of the customer by turning data insights into action? Do you want to be part of Amazons strategic and highly impactful finance and payroll technology projects? Amazons Finance Automation Payroll Tech team has an opportunity for a seasoned Data Scientist whose experience illustrates a clear ability to create world class machine learning systems to meet long-term Payroll needs.

At Finance Automation, we are passionate about building systems and services that deliver a seamless and transparent finance experience for Amazon partners. We build, operate, and scale systems that are responsible for billions of dollars in transactions, and are central to the success of worldwide finance. We ""think globally, act locally"" to revolutionize a worldwide employee and customer experience and fulfill our promise to pay accurately, on-time, with lowest cost to Amazon.

As a Data Scientist at Finance Automation, you are self-driven leader with extensive experience in applying statistics and data science concepts to bring tangible benefits for global finance operations. Finance and Payroll domain knowledge is a plus but not required.

· Work with finance and payroll stakeholders to understand the organization goals, objectives, and pain points. Identify key areas to drive Machine Learning initiatives, define needle-moving business questions and success criteria.
· Collect and analyze finance, HR, and payroll data across multiple isolated systems. Derive actionable insights from large volumes of heterogeneous data.
· Create reliable and maintainable code to build regression, classification, clustering, and anomaly detection systems. Work closely with software engineers to develop data ingestion and visualization, and productionize your models.
· Partner with finance analysts, and payroll managers to deploy and test machine learning systems with your statistical models at the core. Automate feedback loops, tune, and improve the models in production.
· Train non-tech stakeholders and partners to effectively use your machine learning systems. Set the right expectations on model limitations and prove business value.
· Create and maintain business and technical artifacts such as requirements documentation, use cases, performance evaluation, and model metrics.
· Learn and utilize AWS technologies and Amazon machine learning systems to effectively work with terabytes of data.

Being part of Amazon Finance Automation gives you the opportunity to work in a rapidly growing organization with many high performing global technology teams. Come join us in making history!




Basic Qualifications

· Bachelor's or Masters degree in Statistics, Applied Math, Operations Research, Economics, Engineering or a related quantitative field with 5 years of working experience as a Data Scientist.
· In-depth knowledge on supervised and unsupervised machine learning algorithms including classification, clustering, and regression.
· Experience building productions systems with statistical analysis, data modeling, regression modeling and forecasting, time series analysis, and deep learning neural networks.
· Expertise in coding using one or more programming languages such as R, Python, MATLAB, and Spark to build machine learning models. Skilled in manipulating and processing data using libraries such as Scikit-learn, Pandas, and NumPy. Demonstrated experience in SQL and/or NoSQL data modeling.
· Experience processing, filtering, and presenting large quantities of data. Ability to design for performance, scalability, and availability.
· Excellent communication, analytical and problem-solving skills. Ability to distill informal customer requirements into problem definitions, dealing with ambiguity and competing objectives.
· Obsession with quality, operational excellence, and customer experience. Ability to convey rigorous mathematical concepts and considerations to non-experts.

Preferred Qualifications

· Passion to dive deep to resolve problems at their root, looking for failure patterns amenable to long-term solutions via simplification and automation.
· Experience in AWS is a huge plus. Functional knowledge of AWS platforms such as Sagemaker, S3, Glue, Dynamodb, and RedShift.
· Exposure to finance and payments domain is a plus.
· Deep understanding of data, application, server, and network security.
· Experience with agile or scrum methodology.",4.2,"Amazon
4.2",Hyderabad,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Scientist,-1,NA,3.9,"Accenture
3.9",Mumbai,"Dublin, Ireland",10000+ employees,1989,Company - Public,Consulting,Business Services,₹500+ billion (INR),"Cognizant Technology Solutions, EY, McKinsey & Company"
Data Scientist,-1,"Introduction
Software Developers at IBM are the backbone of our strategic initiatives to design, code, test, and provide industry-leading solutions that make the world run today - planes and trains take off on time, bank transactions complete in the blink of an eye and the world remains safe because of the work our software developers do. Whether you are working on projects internally or for a client, software development is critical to the success of IBM and our clients worldwide. At IBM, you will use the latest software development tools, techniques and approaches and work with leading minds in the industry to build solutions you can be proud of.

Your Role and Responsibilities
You and IBM India:
IBM is global technology and innovation company present in India since 1992. It is the largest technology and consulting employer in the world, with approximately 380,000 employees serving clients in 170 countries. In this new era of Cognitive Business, IBM is helping to reshape industries as diverse as healthcare, retail, banking, travel, manufacturing, and many more, by bringing together our expertise in Cloud, Analytics, Security, Mobile, and the Internet of Things. We are changing how we build. How we collaborate. How we analyze. How We engage. IBM is a leader in this global transformation. Distinguishes us from other companies in the industry.

IBM is recognized gold standard for inclusion, reflected in winning, to name few, the 2018 Catalyst Award for advancing women in business, the National Award Best Employer of People with Disabilities and being named one of the top 5 2018 Top Companies for Women Technologists for building an inclusive work environment We advocate for fairness and equality as everyone is, and always has been, welcome at IBM.
Our Culture:
IBM is committed to crafting a diverse environment and is proud to be an equal opportunity employer. You will receive consideration for employment without regard to your race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. We are committed to compliance with all fair employment practices regarding citizenship and immigration status
Business Unit Introduction:
The Chief Information Office (CIO) is a cross-functional organization that provides IT applications and infrastructure services to IBM Business Units and to IBMers worldwide. Our mission is to provide a productive environment for everyone at IBM. We do this by leading with Design to drive simplicity and ease of use, Engineering the systems that own the business, and Innovating to transform the business.
Who you are:
As a Software Developer - Data Scientist, you will evaluate and improve products. You will collaborate with a multi-disciplinary team of engineers and analysts on a wide range of problems. This position will bring analytical rigor and statistical methods to the challenges of measuring quality, improving consumer products, and understanding the behavior of end-users.
What youll do:
As a Data Scientist,
Work with large, complex datasets. Solve difficult, non-routine analysis problems, applying advanced analytical methods as needed. Conduct end-to-end analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables, and presentations
Build and prototype analysis pipelines iteratively to provide insights at scale. Develop a comprehensive understanding of Google data structures and metrics, advocating for changes were needed for both products development and sales activity
Make business recommendations (e.g. cost-benefit, forecasting, experiment analysis) with effective presentations of findings at multiple levels of stakeholders through visual displays of quantitative information
Research and develop analysis, forecasting, and optimization methods to improve the quality of user-facing products
How well help you grow:

Youll have access to all the technical and management training courses you need to become the expert you want to be
Youll learn directly from expert developers in the field; our team leads love to mentor
You have the opportunity to work in many different areas to figure out what really excites you
Required Technical and Professional Expertise
Minimum 3+years of expertise in Data Science assignments
Experience in Data modelling to optimize for performance based on access paths
Solid hands on experience in Design, develop, and maintain pipelines that create search indexes out of data from large databases
Proven expertise in writing complex SQL queries
Excellent in Knowledge of data pre-processing steps uploading, creating master data set, extracting right data from external
Demonstrated ability to independently analyze requirements based on a given specification and come up with a sound and sustainable algorithmic design
Proven knowledge in programming language Python (Pandas library) and R
Able to guide a team of lesser experienced professionals
Preferred Technical and Professional Expertise
Willing to learn new technologies for driving the project
Ambitious individual who can work under their own direction towards agreed targets/goals
Ability to manage change with good time management and focus on strict deliverable with tight deadlines
Proven interpersonal skills while contributing to team effort by accomplishing related results as needed
About Business Unit
The IBM Finance organization is responsible for driving enterprise performance and transformation. We are the financial stewards of IBM, delivering IBMs financial strategy, developing new business models, and mitigating enterprise risk. Do you have a passion for creating business value? Join our team in accounting, financial planning, pricing, business controls, tax, treasury, business development (acquisitions & divestitures), and global financing.

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Scientist,-1,"Provide analytical insights into emerging problems, trends and portfolios
Work closely with business partners and stakeholders to determine how to design analysis and measurement approaches that will significantly improve our ability to understand and address emerging business issues
Bringing data to life and making it actionable and relevant to stakeholders through exploratory analysis of internal and external data sources using advanced and innovative analytical techniques, algorithms, and tools
Identifying present or future gaps in the teams existing reporting and tools suite and managing portfolio monitoring, dashboards and reporting
Providing regular updates to leadership, product and other stakeholders that will simplify and clarify complex concepts and the results of analyses effectively with emphasis on the actionable outcomes and impact to business
Experience with standard statistical techniques and tools a plus
Required Qualifications
Bachelor's Degree in a quantitative discipline (Economics, Engineering, Computer Science, Math, Statistics)
1-2 years experience in analytics or management consulting
Proficiency using SQL and querying relational databases
Experience in at least one statistical programming language (SAS, R, Python)
Experience in at least one data visualization tool (Tableau, Qlikview)
Experience with project management
Preferred Skills:
Strong communication skills
Quick learning
Out-of-box Problem Solving",3.5,"PayPal
3.5",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Data Scientist,-1,"Overview


We have an exciting opportunity for a Data Scientist to join our dynamic AI Development team. This permanent position is well suited to an individual that is looking to advance their career in Python / R / Java Programming and gain hands-on experience in a thriving and supportive workplace.

Responsibilities


Objectives: 
Primary focus on applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.
Ability to manage time and follow guidelines and processes.
Procedures: 
Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
 Selecting features, building and optimizing classifiers using machine learning techniques
 Once the data source has been identified, mine and analyse data to drive optimization and improvement of product development, marketing techniques and business strategies.
 Enhancing data collection procedures to include information that is relevant for building analytic systems
 Design and review data collection procedures for regulatory compliance.
 Develop custom data models and algorithms to apply to data sets.
 Present information using data visualization techniques
 Propose solutions and strategies to business challenges
 Collaborate with SAS programming and Statistics teams
 Develop company A/B testing framework and test model quality.
 Develop processes and tools to monitor and analyse model performance and data accuracy.
 Raise awareness with other team on Data Science techniques and approaches.
 Have a good understanding of ICH/GCP guidelines.
 Follow appropriate Project Management procedures.
 Communicate effectively with project team.
Key Contacts/Relationships (Internal & External):

Internal:Work closely with other project team members, mentor and line manager.

External:Under supervision, may have limited interaction with internal clients to complete various programming activities. To fulfil this role, the Data Scientist supported by AI team members, may be required to participate in project team meetings and be responsive on an ad-hoc basis.

Qualifications
Qualified to degree level or equivalent, preferably in a numerate discipline
Good knowledge on statistics.
5 years of experience on Programming / Data Science Industry and minimum 2 year as Data Scientist",4.0,"Quanticate
4.0",Bengaluru,"Hitchin, United Kingdom",201 to 500 employees,1995,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹1 to ₹5 billion (INR),"GCE Solutions, Parexel, IQVIA"
Data Scientist,-1,"Organizational Level 1 : Amdocs Services
Organizational Level 2 : Amdocs SI Services
Manager : Harjot Singh

Talent Acquisition: [[recruiterName]]
Required Travel : Minimal
Open to Relocation : Relocation - No
Referral Bonus Reward Amount* : ₹25,000.00

* In case this job is open for Amdocs employees only ""Refer Friend to Job"" option is disabled
Who are we?
Every day, billions of transactions, calls and messages that hold the world’s communications fabric together run on systems that Amdocs has helped to create.

Because we work with some of the largest and most innovative companies on the planet, our work makes an impact. Over the past four decades, we have continually reinvented ourselves, and as we keep moving into exciting new areas such as media, gaming, IoT, 5G, cloud services and more, there are always opportunities for us to grow and develop. We will nurture your entrepreneurial instincts with open doors and promote your ability to seize the day. Our company is built of amazing people, a supportive atmosphere and a culture built on mutual support, respect and a “feel good factor” that can only happen in a workplace built by the kind of people that Amdocs employs.

Make your career journey with us.
In one sentence
This is a hands-on position for a motivated and talented innovator. The Data Scientist performs data mining and develops algorithms that provide insight from data.
What will your job look like?
You will oversee and perform end-top-end data based research.
You will design data mining solutions to be implemented and executed with alignment to the planned scope and design coverage and needs/uses, leveraging knowledge and a broad understanding of E2E business processes and requirements.
You will define the data analytics research plan, scope and resources required to meet the objectives of his/her area of ownership.
You will identify and analyze new data analytic directions and their potential business impact to determine the proper prioritization of data analytics activities based on business needs and analytics ROI.
You will identify data sources, oversees the data collection process and designs the data structure in collaboration with data experts (BI or big-data) and subject matter and business experts. Ensures that data used in the data analysis activities are of the highest quality.
You will construct data models (algorithms and formulas) for required business needs and predictions.
You will work closely with content experts and managers to pinpoint queries, map data, and validate results.
You will present results, including the preparation of patents and white papers and facilitating presentations during conferences.
All you need is...
Job Duties and Responsibilities:
2-4 Years of experience in Data Science/Machine Learning role
Deep understanding and experience in the field of Machine Learning, Deep Learning and statistical learning
Experience using statistical computer languages & frameworks (R, Python, PyTorch, Tensorflow, Keras, Scikit etc.)
Experienced on supervised, unsupervised and reinforcement machine learning problems.
Experience creating and using advanced machine learning algorithms: regression, clustering, decision trees, gradient boosting, SVM, anomaly detection, factor analysis, neural networks, etc.
Understand the model lifecycle of cleansing/standardizing raw data, feature creation/selection, writing complex transformation logic to generate independent and dependent variables, model selection, tuning, A/B testing and generating production ready code.
Hands on Experience with data mining & natural language processing
Should be comfortable in going through open source code and reading research papers.
Ability to work independently and drive your own projects
Why you will love this job:
You will be working with dynamic IT Professionals at the back-end in creating content & data with analysis and trends for the business.
You will have respectfully interacts with others throughout the organization
You will across all boundaries with cross regional teams were ever you presence is needed to support the business.",3.8,"Amdocs
3.8",Pune,"Chesterfield, MO",10000+ employees,1982,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 billion (INR),"Netcracker Technology, CSG, Huawei Technologies"
Data Scientist,-1,"Description

SHIFT: Day Job

SCHEDULE: Full-time

Design, develop, troubleshoot and debug software programs for databases, applications, tools, networks etc.

As a member of the software engineering division, you will take an active role in the definition and evolution of standard practices and procedures. You will be responsible for defining and developing software for tasks associated with the developing, designing and debugging of software applications or operating systems.

Work is non-routine and very complex, involving the application of advanced technical/business skills in area of specialization. Leading contributor individually and as a team member, providing direction and mentoring to others. BS or MS degree or equivalent experience relevant to functional area. 7 years of software engineering or related experience.

Qualifications
The
data science team at Oracle Analytics works on diverse data science/ML
problems related to data warehousing such as SLA monitoring and prediction, ensuring
accuracy of ETL data, time series modeling, predicting application metrics and conversational AI(chatbots).

As a member of the Data Science team, you will perform the following tasks
Processing, cleansing and verification of data
Adhoc analysis and visualization using tools such as Python pandas
Develop and deploy machine learning models using scikit-learn, keras, tensorflow, pytorch and Apache Spark/Flink.

Bachelors or Masters degree in Computer science with expertise in data science/machine learning is required. ]]>",3.6,"Oracle
3.6",Bengaluru,"Redwood City, CA",10000+ employees,1977,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹500+ billion (INR),"SAP, Salesforce, Microsoft"
Data Scientist,-1,"OVERVIEW OF THE COMPANY

StarStar India has defined the Indian media landscape for over two decades and today is one of the country’s leading media conglomerates, reaching approximately 650 million viewers a month across India and more than 100 other countries. Star generates 20,000 hours of content every year and broadcasts 40+ channels in 8 different languages, reaching 9 out of 10 C&S TV homes in India. The network’s entertainment channel portfolio includes Star Gold, Channel V, Star World, Star Movies, Star Utsav, Life OK, Movies OK and Star Plus, India's No. 1 Hindi General Entertainment Channel. It has a leading presence in regional broadcasting as well, through a bouquet of affiliate channels which includes Star Jalsha, Jalsha Movies, Star Pravah, Asianet, Asianet Plus, Suvarna, Suvarna Plus, Vijay and now Maa. It is also present in the Indian movie production and distribution space through Fox Star Studios, an affiliate joint venture company.
JOB DESCRIPTION


KEY RESPONSIBILITIES :
Using techniques from supervised and unsupervised machine learning, statistical analysis and predictive modelling to deliver business insights to business units based on data
Working directly with internal customers to educate them on “moving beyond BI” and training their internal resources to execute advanced forms of analytics
Creating reusable implementations of statistical tests and models using cutting edge technologies
Working with the academic and business community to develop new techniques and to contribute to research in the area of advanced analytics in media
Assisting in engagement management, requirements definition, project scoping, timeline management, and results documentation to ensure professional relationship management
PERFORMANCE MEASURES :
As per role KPIs
QUALIFICATION :
2-8 Years plus post qualification
Degree in computer science with a machine learning focus (other technical degrees also accepted e.g. applied mathematics, statistics, physics, operations research). PhD will be desirable.
KNOWLEDGE AND SKILLS :
Advanced knowledge of statistical and machine learning methods, particularly in the areas of modelling and business analytics
Strong programming skills
Experience with statistical languages and packages, such as R, SAS, Mat-Lab, and/or Mahout
Experience working with relational databases and/or distributed computing platforms, and their query interfaces, such as SQL, MapReduce and Hive.
Experience with additional programming languages, such as Python, Java, and C/C++.
Excellent written and verbal communications skills, with a proven ability to translate complex methodologies and analytical results to higher-level business insights and key take-away
A proven passion for generating insights from data, with a strong familiarity with the higher-level trends in data growth, open-source platforms, and public data sets.
Experience working hands-on with large-scale data sets
Familiarity with visualization software and techniques (including Tableau), and business intelligence (BI) software, such as Micro-strategy, Cognos, Pentaho, etc.
PERSONAL ATTRIBUTES :
Creative, gritty, driven by curiosity and comfortable with failure
Strong Data intuition: Talent to identify and visualize patterns
Multi Modal Communication skills
We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, gender identity, disability, protected veteran status, or any other characteristic protected by law. We will consider for employment qualified applicants with criminal histories consistent with applicable law.",3.9,"Star TV Network
3.9",Mumbai,"Mumbai, India",1001 to 5000 employees,1991,Company - Private,TV Broadcasting & Cable Networks,Media,Unknown / Non-Applicable,-1
Data Scientist,-1,"Date: May 12, 2020

Ericsson is one of the leading providers of Information and Communication Technology (ICT) to service providers. We enable the full value of connectivity by creating game-changing technology and services that are easy to use, adopt, and scale, making our customers successful in a fully connected world. Headquartered in Stockholm, Sweden, Ericsson is proud of its global presence across 100+ countries and market areas. With a strong focus on innovation, we possess 49 thousand registered patents and a global strength of over 95 thousand competent professionals. We also take pride in supporting networks that cater to a capacity of 40 percent of the world’s mobile traffic, thereby connecting more than 2.5 billion subscribers and counting. We are a world leader in the rapidly changing environment of communications technology – by providing hardware, software, and services to enable the full value of connectivity.

Data Scientist: Noida



About Ericsson:

Ericsson is one of the leading providers of Information and Communication Technology (ICT) to service providers. We enable the full value of connectivity by creating game-changing technology and services that are easy to use, adopt, and scale, making our customers successful in a fully connected world. Headquartered in Stockholm, Sweden, Ericsson is proud of its global presence across 100+ countries and market areas. With a strong focus on innovation, we possess 49 thousand registered patents and a global strength of over 95 thousand competent professionals. We also take pride in supporting networks that cater to a capacity of 40 percent of the world’s mobile traffic, thereby connecting more than 2.5 billion subscribers and counting. We are a world leader in the rapidly changing environment of communications technology – by providing hardware, software, and services to enable the full value of connectivity.

………………………………………………………………………………………………………………………

If you are someone who has passion towards technology and innovation, here is an opportunity to work with us. As Data Scientist we are looking for future leaders with Entrepreneurial & Service mindset to influence and deliver results.

Job Summary:

As Data Scientist, who will be responsible for developing scientific methods, processes, and systems to extract knowledge or insights to drive the future of applied analytics and Provide thought leadership, perform Advanced Statistical Analytics, and create insights into data to provide to the business actionable insights, identify trends, and measure performance which address business problems.

You will:
Build advanced statistical models, algorithms and trend analysis in order to discover predictive insights related to network and business objectives
Translate data algorithms and complex ideas into actionable management insights and solutions
Translate operator business objectives into business intelligence trough regressive data analytics
Explore and work on Big Data tools and technologies to sustain our continued operational transformation objectives and market leadership
Research and develop approaches on how to improve business processes and customers’ experience by using our vast amounts of data.
To be successful in this role, you must have:

Previous experience on a similar job (at least 5 years)
Good knowledge of statistical analysis, theory of probabilities, design of experiments and machine learning.
Acumen for business flow understanding and expertise in data preparation-data mining and pre-processing.
Strong Knowledge of SQL, PL/SQL, SQL Server, SPSS, SPAS
Good command of programming language and software environment for statistical analysis, graphics representation and reporting i.e. R, Python;
Knowledge of Business Objects, Tableau, Cognos
Distributed computing paradigms such as different distributions of Hadoop, Spark.
Excellent documentation skills


Key Qualifications:

Education: BE/B.Tech.

Minimum years of relevant experience: Min 5 years of relevant work experience.

What’s in it for you?

With over 90,000 employees across 180+ countries, we have a culture that respects and supports your ambitions, in alignment with our values of Respect, Professionalism and Perseverance. Ericsson is extremely focused on learning and development, supports mobility and flexible working hours. We are also committed to diversity and inclusion and to be a responsible and relevant driver of positive change. We also offer some awesome benefits, amazing career development and training programs to provide an empowered career in a connected world.

Next Steps:

What happens next once you apply? Read about the next steps here

For your prep and reference, here is our overall Brand video and some insights about our innovations in 5G

……………………………………………………………………………………………………………………………………

Ericsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetics. Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development. Ericsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetic information

Ericsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetics. Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development. Ericsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetic information.",3.9,"Ericsson-Worldwide
3.9",Noida,"Stockholm, Sweden",10000+ employees,1876,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Huawei Technologies, IBM, Cisco Systems"
Data Scientist,-1,"When everything's connected, how we connect is everything… and we'd like to connect with you too! We are looking for you to help us deliver exceptional customer experiences as a Data Scientist.
At TTEC Digital, we combine human insight and the speed of technology to transform our clients’ interactions with their customers. Advanced analytics of the customer experience and customer interactions is our expertise.
Check out our website below to learn more about what we do and how we help our clients.
What you’ll be doing
This person will be a part of our Global Data Science Center focused on helping our clients find and seize opportunities in their markets.

Support the development of consulting products such as proprietary customer experience scores and marketing optimization solutions
Maintain our stellar reputation with our clients and drive >80 client NPS
Leverage a mixture of data science methods such as SVM, neural nets, decision trees, and regression models to deliver proprietary uplift model solutions
Support the introduction and advancement of decision science throughout our contact center engagement
Recommend and introduce new methods where relevant
Resource Planning
Recommend required resources to managers
Align required resources to client schedules
Mentor data engineers and architects on requirements
Develop requirements and technical specifications documents for use by engineers

Delivery
Recommend project timelines to managers
Drive on-time delivery and identify and escalate risks to managers
Support attainment of annual goals for client satisfaction
Deliver your own solutions while collaborating on other projects

What you’ll bring to the role
Masters in Statistics, Economics, IE/OR, Computer Science, Applied Mathematics or related field is required; PhD is a plus
1-5 years' experience delivering advanced analytics solutions since graduate program
Ability to translate client requests into approach statements and project plans
Ability to work in a highly collaborative, team-oriented environment
Ability to identify effective, relevant statistical and/or mathematical methods to solve complex business problems
Expert at data wrangling both structured and unstructured data
Experience delivering solutions using regression modeling or machine learning techniques; experience with both is desired
Expert in developing and implementing predictive analytics solutions in one or more of the following languages: R or Python experience with SAS is desired
Experience delivering solutions using large datasets (multi-Gb or larger)
Experience in MS Office suite of products, especially Excel and Powerpoint
Ability to work within any modern big data environment (AWS, MS Azure, SAP Hana, etc.) is desired
Experience with text analytic or speech analytic is desired.
Experience with one or more modern social listening tools (Crimson Hexagon, TheySay, etc.) is desired
What skills you’ll need:
Excellent analytic and data-driven thinking skills
Strong communication skills and an ability to work successfully in a distributed workforce
Creative problem solving and an understanding of analytics workflows
Strong background in consulting a plus

About TTEC
We help global brands provide a great experience to their customers, build customer loyalty, and grow their business. We were founded on one guiding principle: customer experiences that are simple, inspired, and more human deliver lasting value for everyone. Your role brings that principle to life.",3.5,"TTEC
3.5",Hyderabad,"Englewood, CO",10000+ employees,1982,Company - Public,Staffing & Outsourcing,Business Services,₹100 to ₹500 billion (INR),"Teleperformance, TaskUs, Convergys"
Data Scientist,-1,"Senior Data Scientist

Responsibilities
Conduct large-scale data analysis and develop fraud prevention predictive models for financial institutions.
Mine and analyze data to drive optimization and improvement of product development and business strategies.
Maintain and analyze information about multiple clients’ models, to derive insights for clients and for enhancing risk model performance.
Help maintain and improve model development tools.
Take part in the formation of a new team and help setup practices and processes.


Qualifications
Advanced degree in a quantitative area (statistics, mathematics, physics, computer science, engineering)
Experience of 4-7 years with statistical model development. Deep and diverse experience with multiple statistical procedures and machine learning algorithms.
Strong general analytical skills, agility with using quantitative tools to solve analytical problems
Good oral and written communications skills, and ability to interact with engineers, software developers, project managers, business analysts, product managers and with clients.
Vast experience using SQL and modeling with Python.
Innovative aptitude and can-do approach.",3.8,"NICE Actimize
3.8",Pune,"Hoboken, NJ",501 to 1000 employees,1999,Subsidiary or Business Segment,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"SAS, Feedzai"
Data Scientists,-1,"Driving Infinite Possibilities Within A Diversified, Global Organization


Data Scientist

Were looking for a new team member who is motivated by cracking tough challenges with data, trained in problem solving, and with an unending thirst for learning.

As a Data Scientist, you will join a high-performing, global team, and assist with designing, developing, and deploying data driven solutions for all Honeywell business groups and functions. You will work closely with application architects to integrate results into operational platforms, including Hadoop and NoSQL architectures.

Additionally, the Data Scientist role is expected to work within Honeywell to identify opportunities for new growth and efficiencies based on data analyses both in adjacencies based on previous engagements, as well as larger industry developments.

Specific Responsibilities

Develop data analytics, data modeling, mining, pattern analysis, data visualization and machine learning solutions to address customer needs

Foster relationships with business team members by being proactive, displaying a thorough understanding of the business processes and by recommending innovative solutions

Communicate project output in terms of customer value, business objectives, and product opportunity

Promote data science methods and processes across functions

Work with our businesses and infrastructure teams to develop a strategy that will clearly outline how our enterprise platforms can enable business growth & productivity and discover efficiencies to drive costs out of the ISC.

CORPIT2020

You must have:

· Bachelors degree in Computer Science, Engineering, Applied Mathematics or related field

· Minimum of 3 years of experience with distributed storage and compute tools (e.g. Hive and Spark)
3-5 years of experience within Analytics
Experience with data visualization, Tableau preferred.
Understanding of machine learning techniques and algorithms, such as k-NN, Logistic/Linear Regression, Naive Bayes, SVM, Decision Forests, etc.
Knowledge of cloud platforms AWS, Google Cloud, Azure, SnowFlake
Strong knowledge of SQL, Python/R, query optimization and DBMS concepts
Advanced knowledge of excel
Strong analytical skills with an inherent ability to find, understand and work with large amounts of data.
We value:

· Experience bringing prototypes to production on Hadoop platforms and/or as containerized services
Experience with SAP HANA, Snowflake, Redshift and Tableau
· Experience with Streaming Analytics (i.e. Spark Streaming)

· Experience with Natural Language Processing

· Experience working with global teams

· Results driven with a positive can-do attitude.

· Thrives in a rapidly changing environment.

Additional Information
JOB ID: HRD94041
Category: Engineering
Location: Devarabisanahalli Village, KR Varturhobli,,East Taluk - Phase I,Bangalore,KARNATAKA,560103,India
Exempt
Business Services",3.8,"Honeywell
3.8",Bengaluru,"Charlotte, NC",10000+ employees,1885,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"GE, Johnson Controls, United Technologies"
Data Scientist,-1,"The Data Sciences team at Flipkart is on a mission to build systemic intelligence across
Flipkart products and the overarching ecosystem. Being India’s largest online
marketplace and the most used e-commerce app in India, places Flipkart in a unique
position and gives this team a distinctive opportunity — to decipher the richest
possible data about Indian consumers. Add the dimension of a vast product selection
and a proliferating seller base to that and what you get is a multitude of disruptive
possibilities.
In a nutshell, the terabytes of daily data compounded in Flipkart’s data centers offer a
dynamic mix of numerical, structured, unstructured, image- and audio-based statistics,
all set to define shopping in the future.

What this job entails:
The pool of data available at Flipkart forms the foundation to solve some present and
predictable challenges for shoppers in India. As a Data Scientist you will be working on:
Product discovery along with personalization and intent modeling
Demand shaping and planning
Heterogeneous networks for consumer, product and seller interactions
Customer insights
Catalog enhancement and product insights
Customer emotion detection and right response matching
Fulfillment automation
Optimization of last mile delivery
Fraud modeling",4.1,"Flipkart
4.1",Bengaluru,"Bengaluru, India",10000+ employees,2007,Company - Private,Internet,Information Technology,₹500+ billion (INR),"eBay, Snapdeal"
Data Scientist,-1,"Data Scientist / Sr. Data scientist

At Razorpay, we rely on insightful data to power our systems and solutions. We’re seeking experienced data scientists to deliver those insights to us on a daily basis. Our ideal team member will have the mathematical and statistical expertise you’d expect, along with natural curiosity and creative mind that’s not so easy to find. As you mine, interpret, and clean the data, we will rely on you to ask questions, connect the dots, and uncover opportunities that lie hidden with the ultimate goal of realizing the data’s full potential. You are expected to bring in a strong experience of using a variety of data mining methods and tools in building models and running simulations. You must have a proven ability to drive business results with data-based insights and more importantly you should be comfortable working with a wide range of stakeholders and functional teams. You will be instrumental in helping the business continue its evolution into an analytical and data-driven culture.

Roles & Responsibilities
Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
Develop a use case roadmap for a problem area or capability for the business. Frame the business problem into a Data Science or modelling problem.
Extract data from multiple sources. Mine and analyze data from company databases to drive optimization and improvement of product.
Work as the data strategist, identifying and integrating new datasets that can be leveraged through our product capabilities and work closely with the engineering team to strategize and execute the development of data products.
Enhance data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Undertake preprocessing of structured and unstructured data.
Run data exploration to understand relationships and patterns within the data, develop data visualisation to represent and be able to demonstrate the relationships identified from data exploration.
Data mining using state-of-the-art methods. Selecting features, building and optimizing classifiers using machine learning techniques.
Refine and deepen understanding of the algorithmic and inferential aspects of statistical analysis. Evaluate new algorithms from latest research and develop intuition about the problems for which they are likely to improve the state of the practice.
Build training pipelines for the production environment. Develop and execute on a plan for continuous iteration and refinement of a new model.
Provide inputs for design, quality assurance parameters and support implementation for the model in online environment.
Provide inputs and determine infra requirements and infra management for model deployment.
Lead debugging of data pipelines and model behaviour in production environment.Develop dashboards to enable easy tracking and communication of model impact.
Desired Skills & Experience
We’re looking for someone with 5-7 years of experience manipulating data sets and building statistical models, with a Bachelor’s/Master’s/PhD degree in Statistics, Mathematics, Computer Science or another quantitative field, from any of the top-tier colleges.
Data-oriented personality. Strong problem solving skills with an emphasis on product development.
Great communication skills. Excellent written and verbal communication skills for coordinating across teams.
Good applied statistics skills such as distributions, statistical testing, regression.
Good scripting and programming skills. Experience using statistical computer languages, Python, R, SQL to manipulate data and draw insights from large data sets. Familiarity with Scala, Golang or Java is an asset.
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, artificial neural networks and their real-world advantages or drawbacks. Knowledge of deep learning techniques is a plus.
Experience with common data science toolkits such as R, NumPy, MatLab, Pandas, Scikit-learn, TensorFlow, Keras etc.
Experience with data visualisation tools such as D3.js, GGplot.
Proficiency in using query languages such as SQL.
Experience with NoSQL databases such as MongoDB, Cassandra, HBase is desired.
Experience with distributed data/computing tools like Map/Reduce, Hadoop, Hive, Spark is a big plus.",4.1,"Razorpay
4.1",Bengaluru,"Bengaluru, India",501 to 1000 employees,2014,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Position: Data Scientist (Intern)
Status: Open
AGNIK is hiring a Data Science Intern with some background in the following areas and strong motivation. Candidates must have:
1) Familiarity with Machine Learning, Data Mining, Statistics, and Signal Processing
2) Some Experience in Programming in C++/Java/Distributed Programming
3) Pursuing a Degree in Electrical Engineering, Math, Physics, Statistics

Positions do not require US citizenship but the candidates should be authorized to work in the United States. If you are interested, please send resume to jobs@agnik.com with ""Application for Data Science Intern"" in the Subject line.",4.8,"Agnik
4.8",India,"Columbia, MD",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,₹10 to ₹50 million (INR),-1
Data Scientist - R/Python,-1,"Location: Chandigarh
Experience Level: 1 year
Vacancies: 2

We are looking for a Data Scientist who will support our product, sales, and leadership and marketing teams with insights gained from analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations.

Responsibilities for Data Scientist

Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.

Qualifications for Data Scientist

Strong problem solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
A drive to learn and master new technologies and techniques.
We’re looking for someone with 2-5 years of experience manipulating data sets and building statistical models or another quantitative field, and is familiar with the following software/tools:
Coding knowledge and experience with several languages: C, C++, Java,
JavaScript, etc.
Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
Experience querying databases and using statistical computer languages: R, Python, SLQ, etc.
Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Core metrics, Ad words, Crimson Hexagon, Facebook Insights, etc.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.

Job Type: Full-time",4.7,"Prepladder
4.7",Chandigarh,"Chandigarh, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"We are looking for a Data Scientist to analyze large amounts of raw information to find patterns that will help improve our company. We will rely on you to build data products to extract valuable business insights. In this role, you should be highly analytical with a knack for analysis, math and statistics. Critical thinking and problem-solving skills are essential for interpreting data. We also want to see a passion for machine-learning and research. Your goal will be to help our company analyze trends to make better decisions.
Responsibilities
Identify valuable data sources and automate collection processes
Undertake preprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns
Build predictive models and machine-learning algorithms
Combine models through ensemble modeling
Present information using data visualization techniques
Propose solutions and strategies to business challenges
Collaborate with engineering and product development teams
Requirements
Proven experience as a Data Scientist
Understanding of machine-learning algorithms and operations research
Hands on experience in R, SQL and Python
Should be familiar with Supervised and Unsupervised algorithms
Should have worked on Anamoly detection, PCA and advanced LTSM
Should be strong in Natural language processing and log analytics
Should have experience in deploying machine learning model preferably on Django framework
Work experience in IT infrastructure operations
Very Good analytical thinking with problem-solving abilities
Work with the Engineering Team to design, code, train, test, deploy and iterate on enterprise-scale machine learning systems
Preferably working on any log monitoring tools
Knowledge on Bigdata, Hadoop, Spark will be an added advantage
Problem-solving aptitude
Excellent communication and presentation skills
Benefits
This position is for our product division, for more details please click the below link on under
https://aiinfinity.com/aiops/",3.6,"Atlas Systems
3.6",Bengaluru,"Princeton, NJ",501 to 1000 employees,2003,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Lab Data Analyst,-1,"Q2 Solutions is a leading clinical trial laboratory services organization with end-to-end laboratory services and secure, enterprise-wide biospecimen and consent management solutions. With a relentless focus on quality and innovation, Q2 Solutions uses its global experience and scientific expertise to transform science and data into actionable medical insights that help customers improve human health. A joint venture of IQVIA (formerly QuintilesIMS) and Quest Diagnostics, Q2 Solutions combines the best of each parent organization’s clinical trials laboratory services capabilities to fulfill its mission of treating each sample as if a life depends on it.

PURPOSE
An Matured level Lab Data Analyst that provides clinical lab data expertise as part of a team to develop and maintain Laboratory Data Management (LDM) for the studies awarded to Quintiles laboratory and meets the external client data reporting needs in the local lab activities

RESPONSIBILITIES
• Serve as Data Team Lead (DTL) for a number of regional or global studies or serve in a leadership role to a specific DM Task.
• Manage delivery of projects through full data management study life-cycle (with minimal guidance)
• With guidance from a more senior DTL or Manager, manage project timelines and quality; identify out-of scope work.
• Serve as back-up for other Data Team Leads (with guidance).
• Perform comprehensive quality control procedures.
• Independently bring project solutions to the LDM team
• Understanding and verification of error logs generated by the QLIMS Data Transmission creation programs and communicate effectively to the programming/support team to resolve if any issues in the Data Transmission.
• Identification of the database set up and programming gaps and Solves issues through using the global issue escalation/communication policy.
• Understand and comply with core standard operating procedures and working instructions
• Meet objectives as assigned
• Develop and maintain good communications and working relationships with LDM team
• Interact with CDM team members to negotiate timelines and responsibilities
• Review own work for accuracy and completeness
• Ensure quality checks performed on data files before transmission and obtain peer-review where required
• Create and/or review of all appropriate data management documents
• Record all evidence of the data transmission process from data file definition to closure of study
• Ensure that all specification and design documentation are filed and stored according to company policy
• Ensure the internal and customer queries are timely addressed and resolved effectively.
• Must be proactive in sharing the knowledge among the team members and conducting knowledge sharing sessions in the areas of expertise.
• Use multiple communication styles and skill to effectively broker, audience specific [peers, senior team members, internal/external customers] business and interpersonal relationships that lead to positive outcomes and successful business results.
• Perform other duties as directed by the functional manager

REQUIRED KNOWLEDGE, SKILLS AND ABILITIES
• Strong customer-focus perspective with skill to guide customer communications and customer management.
• Self-driven; keen attention to detail to anticipate, address and/or escalate issues, with aptitude to embrace and be conduit for change.
• Project and task management capabilities to meet/exceed deliverables.
• Effective problem solving skills as well as ability to proactively identifying process improvements which reduce operational costs and maintain quality.
• Quality conscious with high degree of ethics and integrity carrying out duties in accordance to laws, regulatory standards, and with company policies and procedures.
• Computer proficiency including word processing, spreadsheet and Power Point applications and Base SAS programing hands on experience.
• Good understanding of medical, clinical research, and Lab Data Management process and terminology.
• Knowledge on elicitation of the data requirements and authoring specifications.
• Knowledge on various regulatory requirements such as FDA, ICH, ISO HL7, and GLP (Good Laboratory Practices) will be an added advantage.
Qualification:
• Bachelor’s degree or educational equivalence in computer/life science or related field with 4 years of relevant work experience includes SAS programing.

Apply Now!",2.8,"Q2 Solutions
2.8",Bengaluru,"Morrisville, NC",1001 to 5000 employees,2015,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
Data Scientist,-1,"Data Scientist


You will discover the information hidden in vast amounts of data, and help clients make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.

Responsibilities
– Selecting features, building and optimizing classifiers using machine learning techniques
– Data mining using state-of-the-art methods
– Extending company’s data with third party sources of information when needed
– Enhancing data collection procedures to include information that is relevant for building analytic systems
– Processing, cleansing, and verifying the integrity of data used for analysis
– Doing ad-hoc analysis and presenting results in a clear manner
– Creating automated anomaly detection systems and constant tracking of its performance
Skills And Qualifications
– Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
– Experience with common data science toolkits. Excellence in at least one of these is highly desirable
– Great communication skills
– Experience with data visualisation tools, such as D3.js, GGplot, etc.
– Proficiency in using query languages
– Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
– Good applied statistics skills, such as distributions, statistical testing, regression, etc.
– Good scripting and programming skills
– Data-oriented personality
Education
UG:Any Graduate – Any Specialization
PG:Any Postgraduate – Any Specialization",5.0,"Acies
5.0",Chennai,"Chicago, IL",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"AppZen delivers the world’s leading AI platform for modern finance teams. Starting with business spend, we automate manual process, uncover problems, and optimize decision making for enterprises around the globe, including one-fourth of the Fortune 500. Our platform combines patented deep learning, computer vision, and semantic analysis with intelligence from thousands of online data sources to understand financial transactions in business context and make decisions before those transactions happen. AppZen is a must have for CFOs and their teams to reduce spend, achieve compliance, and streamline process.

We’ve taken off this year! Since we released our platform in 2016, over 1,500 enterprises have standardized on AppZen, including three of the top ten banks, four of the top ten media companies, three of the top ten pharmaceutical manufacturers, two of the top five aerospace companies, and five of the top ten software providers. We were a Gartner Cool Vendor last year, have been recognized as one of the fastest-growing technology companies in the market, and we just announced $50 million in Series C funding.

We are looking for a Data Scientist to come and work on our growing AI stack. You will be working with a team of highly skilled and motivated data scientists and machine learning engineers. If you are excited about natural language understanding and machine translation, AppZen is the right place for you to apply and grow your skills.

Must-Have:
Solid understanding of machine learning fundamentals, and familiar with standard algorithms and techniques.
Ability to analyze a wide variety of data: structured and unstructured, observational and experimental, to drive system designs and product implementations.
Expert knowledge of a statistical computing language such as Python or R Knowledge of probability and statistics, including experimental design, predictive modeling, optimization, and causal inference Experience in design and deployment of real-world, large-scale, user-facing systems.
Ensure data quality throughout all stages of acquisition and processing, including such areas as data sourcing/collection, ground truth generation, normalization, transformation, cross-lingual alignment/mapping, etc.
Manage your own process: identify and execute on high impact projects, triage external requests, and make sure you bring projects to conclusion in time for the results to be useful.
Excellent written and verbal technical communication skills; communicate proposals and results in a clear manner backed by data and coupled with actionable conclusions to drive business decisions.
M.Sc. or M.E. or M.Tech in Computer Science, Engineering, Statistics, or other relevant technical fieldMust have 4-6 years of industry experience.
Able to work onsite in Pune, IN
You are a team player
Come as you are, we do not discriminate! We celebrate, support, and thrive upon our diverse customer and employee base.",3.5,"AppZen
3.5",Pune,"San Jose, CA",51 to 200 employees,2012,Company - Private,Financial Transaction Processing,Finance,₹100 to ₹500 million (INR),-1
Data Scientist I,-1,"Position Title
Data Scientist I

08-May-2020

Job ID
295409BR

Job Description
20 petabytes of data across 30 data domain across the whole bio-pharma value chain waiting for you to unlock the next breakthrough in medicine.
Your responsibilities include, but are not limited to:
•Understand complex and critical business problems from Country/Regional/Global business functions, formulate integrated data science based approaches to mine data sources, employ statistical methods and machine learning algorithms to derive actionable insights. High agility to be able to work across various business domains (commercial, NTO, GDD,NIBR, NBS). Able to use business presentations, smart visualization tools and contextual story-telling to translate findings back to business users with a clear impact.
•Think creatively, conceptualize and lead projects resulting in substantial long-term impact on the company’s vision in many key strategic areas such as drug discovery/manufacturing, product launches, determining optimal treatment plans/courses, expanding patient access, predictive/precision medicine, risk mitigation, business growth, brand management, product life cycle, data strategy etc.
•Design, develop and deliver various data science based insights, outcomes and innovation (using mathematics, computer science, statistics, engineering, management science, technology, economics, etc) and create “proof of concepts & blueprints” to drive faster, timely, highly precise, workable and proactive decision making based on data based insights and science and shape strategic glide path of the company
•Lead successful cross-functional collaborations with significant execution rigor, customer focus and “Data to Decision” thinking.
•Demonstrate a comprehensive view of science and technology and deliver a compelling enterprise vision of how Data, Digital & Artificial Intelligence can contribute to providing quantum in leap in building foundational/groundbreaking capabilities transcending a wide spectrum of areas such as research/science, drug discovery/development, commercial, procurement, technology, product, brand, business, strategy, analytics, operations, risk/compliance, legal, propel growth and performance.
•Design and develop state-of-the-art, data-driven analysis, models and decision strategies to solve science and business problems. Choose and apply appropriate predictive analytic technologies (such as statistical modeling, neural networks, scorecards, machine learning, pattern recognition and artificial intelligence) heavily injected with domain expertise. Appropriately, question the veracity and business relevance of data, assumptions, and results and use of solution at all steps of the process. The outcome is improved performance through the design, development, and deployment of project deliverables.
https://www.youtube-nocookie.com/embed/Mo1vwtVPVA0

Minimum requirements
•M.S/Ph.d in Computer Science, Mathematics, Statistics, Operations Research, Cognitive Sciences, Engineering, Finance, Economics, Medicine, Technology, Management Science, other Quant disciplines
•2-5 years of overall experience with demonstrated track record in data science solutioning & significant research expertise/accomplishment, academic strength, theoretical depth and business experience.
•Create and nurture an environment of innovation to support the agenda of creating a DS&AI team of international repute & Support the “Data to Decision” glidepath end-to-end transcending all products, brands, areas and functions; Improve rigor, depth, strategic outlook, execution focus and patient thinking into workstreams /processes.
•Bring deeper understanding in every stage of the patient journey, interaction & access by helping to build capabilities and resulting meaningful outcomes & Be able to synthesize the right science problem to solve from ambiguous business scenarios. Experience in data intensive industry such as Clinical Research Organizations, Retail/eCommerce, Medical Technology, Financial Services, Technology/Professional Services sectors.

Why consider Novartis?
799 million. That’s how many lives our products touched in 2019. And while we’re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people’s lives?

We believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you’re given opportunities to explore the power of digital and data. Where you’re empowered to risk failure by taking smart risks, and where you’re surrounded by people who share your determination to tackle the world’s toughest medical challenges.

Imagine what you could do at Novartis!

Commitment to Diversity & Inclusion:
Novartis embraces diversity, equal opportunity and inclusion. We are committed to building diverse teams, representative of the patients and communities we serve, and we strive to create an inclusive workplace that cultivates bold innovation through collaboration, and empowers our people to unleash their full potential.

Join our Novartis Network: If this role is not suitable to your experience or career goals but you wish to stay connected to learn more about Novartis and our career opportunities, join the Novartis Network here: https://talentnetwork.novartis.com/network

Job Type
Full Time

Country
India

Work Location
Hyderabad, AP

Functional Area
BD&L & Strategic Planning

Division
CORPORATE

Business Unit
DIGITAL OFFICE

Employment Type
Regular

Company/Legal Entity
Nov Hltcr Shared Services Ind

Shift Work
No",3.9,"Novartis
3.9",Hyderabad,"Basel, Switzerland",10000+ employees,1996,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
Data Scientist,-1,"As a Data Science Associate Manager at PayPal, you will apply your leadership, strategic and analytical skills to major company challenges. You will act as a business consultant to drive recommendations and implement solutions that ultimately impact the bottom line. And you will do it all by collaborating with a global team of colleagues across sales, operations, product, data science, and finance in an environment that values your insight, encourages you to take on new responsibility, promotes continuous learning, and rewards innovation.",3.2,"Stark Inc.
3.2",New Delhi,"Cambridge, MA",1001 to 5000 employees,1972,Non-profit Organisation,Aerospace & Defence,Aerospace & Defence,₹50 to ₹100 billion (INR),"BAE Systems USA, MITRE, Raytheon Technologies"
Data Scientist,-1,"Eyeota is looking for an exceptional Data Scientist who is passionate about data and motivated to build large scale machine learning solutions to shine our data products. This person will be contributing to the analytics of data for insight discovery and development of machine learning pipeline to support modeling of terabytes of daily data for various use cases.

Qualifications:
2+ years relevant working experience
Master/Bachelors in computer science or engineering
Working knowledge of Python and SQL
Experience in time series data, data manipulation, analytics and visualization
Experience working with large-scale data
Proficiency of various ML algorithms for supervised and unsupervised learning
Experience working in Agile/Lean model
Experience with Java and Golang is a plus
Experience with BI toolkit such as Tableau, Superset, Quicksight, etc is a plus
Exposure to building large-scale ML models using one or more of modern tools and libraries such as AWS Sagemaker, Spark ML-Lib, Dask, Tensorflow, PyTorch, Keras, GCP ML Stack
Exposure to modern Big Data tech such as Cassandra/Scylla, Kafka, Ceph, Hadoop, Spark
Exposure to IAAS platforms such as AWS, GCP, Azure
About Eyeota

Eyeota provides a dynamic, fun workplace filled with passionate individuals. We are at the cutting edge of advertising technology and there is never a dull moment at work.

We have a truly global footprint, with our headquarters in Singapore and offices in Australia, United States, United Kingdom and India

At Eyeota you will gain work experience in a global startup. We speak over 20 different languages, from more than 16 different nationalities and over 42% of our staff are multilingual.

Eyeota is an Equal Opportunity Employer.

Powered by JazzHR",3.1,"Eyeota
3.1",Pune,"Singapore, Singapore",51 to 200 employees,2010,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,"Lotame, Krux"
Data Scientist,-1,"Job Description
Managing 2 to 3 business lines Provide end to end analytical support for the given business lines with an objective of increasing marketing efficiencies / customer value Develop predictive models, behavioral segments and event triggers Build predictive models / behavioral segments / event triggers for x-sell / activation / retention / attrition control - models to meet minimum performance benchmark To be done for all product / business lines handled by the analyst Analyse portfolio for solving business problems / identifying new opportunities Work with business / campaign stakeholders to understand objective / problem statement, generate hypothesis to solve the objective / problem and run statistical analysis to validate the same Regular interaction with business / product / campaigns teams Work jointly with campaigns and business team to identify business problem, discuss analytical approach and explain the solution which has been developed Ensuring all new analytical solutions are utilized Work jointly with campaigns and business team to ensure that minimum 60% of analytical solutions developed in the FY are utilized for campaigns / on ground activities.
Seek feedback from campaigns and business which can be plugged back to the analytical solution Monitoring performance of predictive scorecards / solutions Monthly monitoring of performance of predictive scorecards / solutions and ensuring the performance is as per the internal benchmarks through regular enhancements of the solutions.

Skills
Strong logical, analytical & mathematical skills
Banking Product & Process Knowledge
Project Management Skills
Good Communication skills",3.6,"HDFC Bank
3.6",Mumbai,"Mumbai, India",10000+ employees,1995,Company - Public,Banks & Building Societies,Finance,₹500+ billion (INR),"State Bank of India, ICICI Bank, Axis Bank"
Data Scientist,-1,"Data Scientist ( > 4 years experience ) :
Should be highly skilled in using deep learning algorithms and have expertise on tweaking them for Dunzo specific problem statement
Should be able to program in python. Should be highly skilled in this.
Should have experience in formulating problem statement and decide what data can help in solving the problem.
Should have overall idea on how to put machine learning models into production. Although there is no need to work on this directly, it is important to guide data engineering and backend team for getting desired results
Should be able to communicate with business and other stakeholders for understanding problems for producing possible solutions. Should give demos for proof of concepts(poc)
Should be interested in learning about advancements in deep learning field and going through research papers and latest updates of the field.
Should have skills in using pandas,numpy, scipy, sklearn, spacy, nltk, keras/pytorch/tensorflow and familiar in using gpu machines for training purpose
Should have an attitude of owning the problem and generating industry standard solutions and ultimately reach to state of the art solutions to the problems.
It will be really great if presenting at tech conferences is one of the interests. Also, we encourage you to write on tech blog. This part is optional",3.1,"Dunzo
3.1",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"About Flock

Flock is an enterprise messaging and collaboration app. At Flock we believe that synchronous messaging tools, supported with internal and external applications, have the power to smash organisational hierarchies, breakdown silos in the workplace, help companies better capture innovative ideas, support individuals in making faster decisions, and also bring more personable communication style into the workplace.
With 30,000 businesses already using the platform we know that we are onto something big, and are now gearing up for a period of rapid growth.

Flock is founded by Bhavin Turakhia. Serial entrepreneur and billionaire, Bhavin Turakhia is driven by a passion for problem-solving and maximizing efficiency through technology driven innovations. In the last 22 years, he has built 5 successful businesses, all driven by his belief that “it is our moral obligation to make an impact that is proportionate to our potential”. At 17, he co-founded Resellerclub, Logicboxes and BigRock, which he exited in a $160mn transaction in 2014. He is presently heading Flock - a suite of productivity apps, Zeta - a digital payments platform, and Radix - a leading registry for top-level extensions.

Role Overview
We are looking to hire a data scientist who will work with various cross-functional teams such as product, marketing, engineering, sales and customer success to develop and deliver data structures, statistical models, reports and deep-dive analysis that will provide actionable recommendations for Flock business. We are looking for a problem solver with strong analytical and problem-solving skills who has a good understanding of statistics and machine learning, and able to work on projects from conceptualization to execution.
What is the Job like?
Work with a team of high performing data science professionals, and cross-functional business partners to identify business opportunities, optimize marketing campaigns, drive product road map or go to market strategy
Build automated data dashboards and visualizations to deliver business insights to the senior leadership team
Understand business problems and provide data-driven solutions for those problems
Develop statistical models and data-driven solutions to add lift to key performance metrics
Initiate and drive projects to completion with minimal guidance
Who should apply for this role?
Bachelors or Master’s degree in a quantitative discipline - Statistics, Operations Research, Computer Science, Engineering, Economics etc
4+ years of experience working in data science or business analytics role
Experience working with large amounts of data using SQL, SAS, R or other statistical packages
Experience working in a Unix/Linux environment for automating processes with shell scripting
Experience programming in Python, Java or other programming languages
Experience in data dashboarding and visualization tool like Tableau, PowerBI or QuickSight
Experience in machine learning techniques like regression analysis, decision tree etc. a plus
Benefits and Perks
We at Flock love our jobs. And it’s no surprise – we get to work on exciting, new projects with some of the best brains in the industry, and that too in a vibrant atmosphere that is designed to be comfortable and conducive for our personal and professional growth.

And Flock goes the extra mile to make you feel at home. We offer benefits ranging from affordable catered meals and even snacks on the house. Our workspaces are welcoming and fun, complete with bean bag chairs and ping pong tables. You are free to wear what makes you comfortable and choose the hours you keep, as a team. Oh, and we’ve got your family covered too, with great health insurance plans and other benefits. In short, everything you need to be your best self at work!

We are passionate about helping teams move to the next level of communication and collaboration, and believe that happy employees are key to achieving this goal. If you like the idea of working on cutting-edge technologies and solutions that have a truly global impact, get in touch!",4.2,"Directi
4.2",Mumbai,"Mumbai, India",1001 to 5000 employees,1998,Company - Private,Internet,Information Technology,₹100 to ₹500 billion (INR),"Yahoo, Slack"
Data Scientist,-1,"Role: Data Scientist
Location: Bhubaneswar

Key Responsibilities:
Apply Data Mining/ Data Analysis methods using a variety of data tools, building and implementing models using algorithms and creating / running simulations to drive optimization and improvement across business functions.
Assess accuracy of new data sources and data gathering techniques.
Perform Exploratory Data Analysis, detailed analysis of business problems and technical environments in designing the solution.
Apply Supervised, Unsupervised and Reinforcement Learning Algorithms.
Apply advanced Machine Learning Algorithms and Statistics: Regression, Simulation, Scenario Analysis, Time Series Modelling, Classification (Logistic Regression, Decision Trees, SVM, KNN, Naive Bayes, Clustering, K-Means, Apriopri), Ensemble Models (Random Forest, Boosting, Bagging and Neural Networks).
Lead and manage Proof of Concepts and demonstrate the outcomes quickly.
Document use cases, solutions and recommendations.
Work analytically in a problem-solving environment.
Work in a fast-paced agile development environment.
Coordinate with different functional teams to implement models and monitor outcomes.
Work with stakeholders throughout the organization to identify opportunities for leveraging organisation data and apply Predictive Modelling techniques to gain insights across business functions – Operations, Products, Sales, Marketing, HR and Finance teams.
Help program and project managers in the design, planning and governance of implementing Data Science solutions.

Experience and Skills:
2+ years of professional working experience in Analytics.
Experience in Retail, Financial Services and Manufacturing.
Experience using statistical packages of R, Python and Spark ML to work with data and draw insights from large data sets.
Experience with distributed data/ computing tools: Hadoop, Hive, Spark, Python.
Experience with SQL.
Experience visualizing/ presenting data for stakeholders using matplotlib, ggplot or Excel or Tableau.
Excellent written and verbal communication skills for coordinating across teams.

Education qualification:
Bachelors/ Masters in a Quantitative Discipline (Statistics, Econometrics, Mathematics, Engineering and Science)
Reach us on careers@eta-iota.com.",-1,ETAIOTA Systems,Bhubaneswar,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"Location:
Chennai, Mumbai, New Delhi

Geography:
Asia Pacific

Capabilities:
Big data & advanced analytics

Industries:
Technology industries

About Us


Boston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.

To succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.

Practice Area Profile

BCG GAMMA combines innovative skills in computer science, artificial intelligence, statistics, and machine learning with deep industry expertise. The BCG GAMMA team is comprised of world-class data scientists and business consultants who specialize in the use of advanced analytics to get breakthrough business results. Our teams own the full analytics value-chain end to end: framing new business challenges, building fact-bases, designing innovative algorithms, creating scale through designing tools and apps, and training colleagues and clients in new solutions. Here at BCG GAMMA, you’ll have the chance to work with clients in every BCG region and every industry area. We are also a core member of a rapidly growing analytics enterprise at BCG - a constellation of teams focused on driving practical results for BCG clients by applying leading edge analytics approaches, data, and technology.

Role Profile

POSITION PROFILE:
We are seeking a strong candidate with advanced analytics experience to fill an exciting Senior Data
Scientist (SDS) position within BCG Gamma. The SDS is a valuable expert in Data Science and Analytics
and will design and build analytics methodologies, solutions, and products to deliver value to BCG's clients
in collaboration with case teams. Exceptional candidates will also show an analytical curiosity, going
beyond the immediate requirements of the project to find deep insights that others have missed. They will
ask questions about outliers, seek to understand the fundamental drivers of advantage and look for clues
that may change the basis of competition.

As a Senior Data Scientist you design and build analytics solutions for our clients where data and
analytics are at the heart of the question. The team interaction centers on use of statistical programs and
others tools to conduct intensive analysis of objective data and open discussion, complemented by
objective research into the competitive environment. Responsibilities / duties to include: understand
problems from the client’s point of view, build and execute solid analytics work plans, gather and organize
large and complex data assets, perform relevant analyses (data exploration and statistical modeling),
manage priorities and deadlines, foster teamwork in interactions, develop client relationships with client
counterparts, and communicate hypotheses and findings in a structured way.

As the field of advanced analytics is rapidly evolving, the SDS is responsible for staying current on
leading-edge business applications, tools and approaches, proactively working with the Analytics
Leadership to enhance offerings that deliver competitive advantage to BCG.

Your Qualifications

JOB REQUIREMENTS:
PhD and 1-2 years of relevant industry work experience or a Masters Degree with significant relevant experience providing advanced analytics solutions is required. The degree should be in computer science, applied mathematics, statistics, machine learning, or a related data centric field.
Looking for individuals with deep technical and data science expertise, acute strategic and analytical skills, ability to lead and persuade, drive and energy, and desire to work in a project based environment on strategic issues.
Strong record of professional accomplishment and leadership.

Date Posted:
13-Feb-2019

Boston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.
BCG is an E-Verify Employer. Click here for more information on E-Verify.",4.0,"Boston Consulting Group
4.0",Chennai,"Boston, MA",10000+ employees,1963,Company - Private,Consulting,Business Services,₹500 million to ₹1 billion (INR),"McKinsey & Company, Bain & Company, Accenture"
Data Scientist,-1,"About Dasceq
Dasceq is transforming collection industry in USA using AI/ML and Big Data. We are focused to build a best in class Collection AI SaaS Product and have already established our product for $320billion Auto and Short Term Industry. We are expanding our team and looking for next generations data scientist with experience to lead high end AI Product Development. We don’t do lip service and we are committed to solve a $1.6 Trillion collection problem and looking to expand our amazing Data Science team. If you would like to build something high end and push boundaries contact us today!

Job codes: DASDS1

Qualifications :
Masters in Data Science ; Econometrics ; Statistics ; Math; Computer Science preferred with 2 to 3 years experience in Product Experience or Financial Services Experience or Marketing Modelling

Preferred Institutes:
ISI; Delhi School of Economics ; Madras School of Economics; Calcutta University; IITs/ IISc/ NIT’s – Relevant Tier 1 Colleges or Top Tier 2 colleges

Job Description :
The prospective hire would be part of a data Science Implementation team and be able to support independently client requirements, historical retro scoring, benefit analysis and other core financial lending and collections ; Knowledge of product development and implementation is a must for the role

Pay:
As per experience and market standards

Apply at: ritu@dasceq.com

Please send: Latest resume with current Salary and Bonus components mentioned",2.0,"Dasceq
2.0",India,"Irving, TX",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Looking for sharp analytical minds to join Applied Global Service Business intelligence management team. Candidate should be a creative, detail-oriented problem solver with a passion for machine learning and data-driven insights generation.

Manufacturing and Supply chain domain experience preferred, but not mandatory.

Roles and Responsibilities
• Own and execute end to end delivery of one or more than one analytics project − Understand requirements from Product Managers/Business Users
− Translating muddy and fuzzy business needs into clear data science problems through structured problem-solving
− Perform data collection, develop robust and intuitive predictive models using Statistical/ML/deep learning techniques
− Operationalize ML models adhering to model management guidelines on enterprise wide platform for end user’s consumption
− Perform ad-hoc deep dive analysis and generate insights based on the data patterns and recommend actions to be taken by the business
− Create technical documentation and provide post-production support for a time-bound period
− Present results to technical as well as business stakeholders across different hierarchies
What are we looking for?

Educational Background: Candidates from any of the following background with quantitative bent of mind
• B. Tech / M. Tech / M. Sc. in Data Science / Stat / Math / Economics / Ops Research / Other quantitative disciplines
• MBA in Analytics / IT / SCM / Operations / General Management who are comfortable in coding
Experience
• Relevant Data Science experience of 3-6 years in − End to end data science project life cycle (data preparation, EDA, modeling, deployment)
− Proven record of successfully building and operationalizing enterprise wide ML solutions
• Deep expertise in − At least one of the data science programming language (R, Python)
− Hands on implementation knowledge of ML and DL algorithms (Neural Net, Classification, Clustering, Regression, Time series, NLP etc.)
• Working knowledge in − Any one of the query language (SQL, Hive, Spark, Impala etc.). Knowledge of big data is essential
− Any one of the visualization tools (Tableau, QlikView, Power BI etc.)
• Story-telling skills, educating and instilling confidence among business users, motivating stakeholders to evangelize the recommendations
Mindset
• Quick and continuous learner of new business, tools/technologies, algorithms
• Exploratory, self-driven and get-shit-done attitude
• Demonstrates high ownership and goes extra mile to bring customer delight by providing the best possible solution
• Can adapt to different project execution styles (Agile, POC, R&D, Product Development) and take up suitable roles as per team’s need
Qualifications
Education:
Bachelor's Degree
Skills
Certifications:
Languages:
Years of Experience:
4 - 7 Years
Work Experience:
Additional Information
Travel:
Yes, 10% of the Time
Relocation Eligible:
Yes

Applied Materials is committed to diversity in its workforce including Equal Employment Opportunity for Minorities, Females, Protected Veterans and Individuals with Disabilities.",3.7,"Applied Materials
3.7",Bengaluru,"Santa Clara, CA",10000+ employees,1967,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹500+ billion (INR),-1
Data Scientist,-1,"We are looking for strong Data Scientists/Analysts, who will be problem solvers, using predictive modelling techniques and machine learning algorithms, to solve complex business problems in credit and risk domains, and also provide business strategies.

Roles and Responsibilities:
Use of cutting edge machine learning techniques for solving supervised and unsupervised learning problems
Design analytical solutions for complex business problems
Dig deep into data, understand characteristics, evaluate and validate hypotheses through empirical approaches
Recommend and implement best practices around application of statistical modelling
Develop and implement predictive models solving business problems and recommend actionable insights
Mentor and train new recruits
Qualification & Experience
2+ years of experience in the field of analytics, predictive modeling or data science
Strong with programming languages like Python and data processing using SQL or equivalent
Strong with analytical and statistical packages like R, Python Scikit-Learn
Additional familiarity with C/C++ welcome
Experience with the following machine learning algorithms desirable: Gradient Boosting, Decision Trees, Logistic Regression, Random Forests, Deep Neural Networks, Ensemble methods
Experience with NoSQL and distributed data processing technologies such as Hadoop is also desirable
Bachelor or Master in Operations Research, Computer Engineering or in closely related Quantitative Disciplines from a premier institution.
Interested? Please send your resume to careersindia@applieddatafinance.com.",4.5,"Applied Data Finance
4.5",Chennai,"San Diego, CA",51 to 200 employees,2014,Company - Private,Lending,Finance,Unknown / Non-Applicable,Avant
Data Scientist,-1,"Jr. Data Scientist / Data Scientist

Having a strong background in machine learning who are extremely passionate about solving real-world applied problems in the various business domains. A real opportunity to expand skill-sets and a chance to learn and use the latest advances and approaches in machine learning and data mining on real-world datasets.

Working at a fast-paced work environment where one is expected to be self-motivated and are measured on performance.

Job Responsibilities

Ability to understand a problem statement and implement analytical solutions & techniques independently or with minimal supervision

Work and collaborate with other teams to deliver and create value for clients

Fast learner: ability to learn and pick up a new language/tool/ platform quickly

Conceptualize, design and deliver high-quality solutions and insightful analysis

Conduct research and prototyping innovations; data and requirements gathering; solution scoping and architecture; consulting clients and client-facing teams on advanced statistical and machine learning problems.

Ability to deliver AIML based solutions around a host of domains and problems, with some of them being: Customer -Segmentation & Targeting, Propensity Modeling, Churn Modeling, Lifetime Value Estimation, Forecasting, Recommender Systems, Modeling Response to Incentives, Marketing Mix Optimization, Price Optimization

Experience Required:

Intermediate to expert level proficiency in at least one of R and Python

Ability to discover effective solutions to complex problems. Strong skills in data structures and algorithms.

Experience of working on a project end-to-end: problem scoping, data gathering, EDA, modelling, insights, and visualizations

Problem-solving: Ability to break the problem into small problems and think of relevant techniques which can be explored & used to cater to those

Intermediate to advanced knowledge of machine learning, probability theory, statistics, and algorithms. You will be required to discuss and use various algorithms and approaches on a daily basis.

We use regression, Bayesian methods, tree-based learners, SVM, RF, XGBOOST, time series modelling, dimensionality reduction, SEM, GLM, GLMM, clustering etc on a regular basis. If you know a few of them you are good to go.

Experience of working in cloud-based environments such as AWS, GCP, Azure

Good to Have:

Experience in one of the upcoming technologies like deep learning, NLP, image processing, recommender systems

The experience of working in on one or more domains:

CPG: pricing and promotion analytics, marketing analytics, trade promotions, supply chain management

BFSI: cross-sell, up-sell, campaign analytics, treasury analytics, fraud detection

Healthcare: medical adherence, medical risk profiling, EHR data, fraud-waste-abuse

Experience in working with Linux computing environment and use of command-line tools like sed/awk

Grasp at databases including RDBMS, NoSQL, MongoDB etc.

Requirements

Education Qualification

B.Tech / M.Tech in Computer Science / Mathematics / Signal Processing or related fields from one of the premier Institutes (IITs/NITs/BITS)",3.5,"Mastek Limited
3.5",Mumbai,"Reading, United Kingdom",1001 to 5000 employees,1982,Company - Public,IT Services,Information Technology,₹10 to ₹50 billion (INR),"Capgemini, Cognizant Technology Solutions, Mindtree"
Data Scientist,-1,"Location Pune, India – Full Time
…

Position Expectations
Our Data Science & Machine Learning team is looking for a hands-on data scientist who can independently build statistical & mathematical models and can design & develop performant algorithms of the highest quality. Need to have an aspiration to become an exceptional data scientist with a passion for learning new technologies and high inclination towards research.

Responsibilities

You would be responsible for managing, developing, maintaining industry specific analytical models
The role would involve conducting research and prototyping innovations (new product ideas) along with data and requirements gathering.
The role would also involve testing various machine learning and analytical tools to build prototypes and production-grade systems. Familiarity with big data technologies and distributed computing concepts will be an advantage.

Qualification & Experience
Knowledge of designing & developing analytical solutions (Statistical & Machine Learning) for complex business problems. Below qualities are desired

Technical Graduates

Understanding of concepts and algorithms used in design of experiments
Understanding of R or Python’s data science stack
Understanding of business statistical/ML predictive techniques such as Regression, ANN, Bayesian methods, Decision Trees, SVM etc.
Understanding of NLP and related areas.
Thorough understanding of RDBMS,NoSQL and data management concepts , fluency in SQL scripting
Understanding of cloud computing platforms (AWS/ IBM Watson/ Google Analytics/ MS Azure)

Management Graduates

Domain knowledge in Finance (Corporate/Retail/Investment Banking) and/or Operations (Retail/ SCM/Logistics) and/or Marketing
Good understanding of Business Statistics
Knowledge of IT systems & applications in your area of expertise

General Requirements

Ability to formulate a problem statement and implement analytical solutions by understanding data and problem statement
Passionate about solving problems, quality and learning new technologies
Good communication skills
A flexibility required in terms of performing different types of responsibilities from a start-up perspective
Strong sense of team work, ownership, and accountability

Education
B.E/ B.Tech./M. Tech/ MBA in any field with significant knowledge in one or more of the following : Statistics, Mathematics, Machine Learning, Economics, Finance or Marketing.

Note
Training on core and advanced statistical techniques/methods would be provided",-1,Right Steps Consultancy,Pune,"Noida, India",1 to 50 employees,-1,Unknown,Consulting,Business Services,Unknown / Non-Applicable,-1
Data Scientist,-1,"Click to Apply

Company Description

Entytle is at the perfect intersection of big data analysis, predictive analytics, machine learning and sales automation.

We are revolutionizing the way industrial OEM manufacturers can leverage existing information to make highly profitable data driven decisions and increase recurring revenue from their customer installed base.

Our highly satisfied customers have derived tremendous ROI from our cutting edge software.

Mission

Deliver innovative but pragmatic solutions to help our customers drive recurring revenue sales, increase loyalty and capture lifetime value from their customers.

Outcomes

Work collaboratively with Entytle stakeholders to create AI and Machine Learning algorithms that address recurring revenue sales
Utilize our data science platform to research and generate new insights into customer loyalty and lifetime value
Provide our internal teams and customers a clear understanding of the models and research generated

Position Description

The position reports to the Head of Data Science. You will work with other data scientists, engineers and product management team members in developing insights and innovative data science models (e.g. AI, ML) in support of our installed base sales automation application. Your communication skills will allow you to work with internal teams and, as needed, our manufacturing-based customers. You will use your agile experience to work with our geographically dispersed teams.

Responsibilities

Work with, as needed, customers to understand business challenges and propose new modeling and algorithmic solutions that leverage the latest in statistical and machine learning techniques.
Work collaboratively with the rest of the data science team, data engineers, developers and product management to translate business requirements into technical requirements that can be addressed with statistical and machine learning techniques.
Study data sources and find insights/correlation to investigate how data science can be used to solve existing and new business challenges.
Apply statistical analysis and modeling techniques on small and large datasets to solve specific business problems in the installed base sales automation domain.
Use best practices in applying and deploying data science at scale.

Competencies

Strong sense of and an ability to cultivate an environment of teamwork, and a willingness to help others.
Ability to effectively communicate technical concepts to both technical and non-technical staff members and customers.
Proficiency in data analysis and programming languages such as SQL, Python, and R.
2-4 years hands-on experience in machine learning, statistics or experiment design.
Master’s Degree required in Statistics, Mathematics, Econometrics, Operations Research, Computer Science, Physics or a related field with focus on data analysis.
Expertise in machine learning, statistics, data analysis. Must have an excellent knowledge of advanced methods, and experience in applying those methods to a variety of problems.
Solid grasp of probability, statistical or mathematical modeling with analytical and quantitative problem-solving ability. Experience with time-series analysis would be a plus.
Demonstrated experience in applying machine learning to real-world problems
Familiarity with software development cycles, source control systems (including Git), databases, and cloud computing platforms such as AWS.
Knowledge of large equipment manufacturing, installed base sales, recurring revenue, and equipment service would be a plus.",4.6,"Entytle
4.6",Pune,"Palo Alto, CA",1 to 50 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Description :
3+ years of experience as a Data Scientist in delivering building complex ML models and delivering key business insights and metrics for financial or product organizations
One or more analytic software tools or languages (e.g., R, Python, Hadoop)
Experience in applied analytics, descriptive statistics, and predictive analytics on industrial datasets
Demonstrated in modeling techniques, Predictive modeling, Supervised learning, Unsupervised learning, Machine Learning, Statistical Modeling
Experienced in working with large data sets, with big data processing tools like MapReduce, Spark, Hive, etc.
Experience with cloud service providers like AWS, GCP, Azure.
Understanding of how to apply predictive and machine learning techniques like logistic regression, random forest, GBM, Neural Nets, SVM etc is required
Additional Responsibilities
Work with business teams to understand the analytical products/platform being used, asks and identify opportunities to re-design using scalable open-source big data technologies
Work with large datasets to investigate key business trends, behaviours, and metrics
Develop, build and train machine learning models using a wide range of machine learning tools
Key Job Attributes :


Data Science
Data Scientist
Machine learning
Python
Hadoop

Educational Qualifications :


B.E/B.Tech

Key Skills :


Machine learning
Statistical modelling
Python
Predictive modeling
Mapreduce
Big data

Contact Details :


Email Id : anbu@handigital.com",3.6,"Han Digital Solution
3.6",Hyderabad,"Bengaluru, India",51 to 200 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Scientist,-1,"Do you feel passionately about solving problems through data? Have you spent 2+ years solving business problems through data?

Do you aspire to take data science to millions of people out there? Can the leader in you make people follow data science out of sheer passion? Would you enjoy helping people solve problems with out expecting any thing in return?

If the answer to all the questions is yes – look no more. Analytics Vidhya is looking for evangelists who can carry and deliver their baton to the world.

What should you expect?
A team of best data scientists and thought leaders from industry.
Disciplined entrepreneurship within team. Each person is owner of his own work – you set the milestones, the pace and the achievements.
High standards, deep passion for data science and a commitment to find out ways to make things work.

Who can fill in the shoes?

This role is best suited for:
Person with 2+ years of experience in data science. The person should have prior experience with practical data science applications and use cases.
Person who loves problem solving through data. She/He should be able to do things hands on by himself or guide a team of data scientists to solve a problem.
A person with deep experience in tools like SAS / R / Python / Julia / Matlab and machine learning / predictive modeling techniques/ Machine Learning Algorithms.
Strong problem solving and communication skills (English).
An avid reader.

What is the role?

Being a startup, the role would evolve over time. But, here are a few things you can expect:

Creating problems for our hackathons by working closely with the clients
Continuously learning new skills and evangelizing them with in our community
Defining and leading our strategy in making data science easy and accessible to all
Leading industry events, meetups, webinars and competitions
Develop custom data models and algorithms to apply to data problems
Use predictive modeling to increase and optimize customer experiences and other business outcomes.

Where is the role based?

We would love to have you in our office in Gurgaon.

If the role excites you, drop an email to hiring@analyticsvidhya.com with your CV, mentioning “Why do you think you are the perfect fit for this role”.

Share this:
Click to share on LinkedIn (Opens in new window)
Click to share on Facebook (Opens in new window)
Click to share on Twitter (Opens in new window)
Click to share on Pocket (Opens in new window)
Click to share on Reddit (Opens in new window)

Like this:
Loading...",4.0,"Analytics Vidhya
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Experience : 3 – 8 Years

Location : India – Pune
Hands-on experience as a Data Scientist
Through understanding of Machine Learning and Statistical models
Experience in R and Python
Experience in one or more areas of predictive modelling, text mining, time series analysis and unsupervised learning methods
Innovative thinking in building complex learning models
Identify and extract interesting pattern from structured and unstructured data
Experience in building state of the art solutions with structured, semi structured and unstructured data
Collaborate with a cross-functional team including data scientists, business analysts and software engineers
Experience with machine learning frameworks e.g., Theano, KERAS,Tensorflow
Additional programming skills like Java and Scala would be a plus",3.4,"Nitor Infotech
3.4",Pune,"Pune, India",201 to 500 employees,2006,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
MS Data Scientist,-1,"The MS
Data Scientist- Manager

Will be responsible to
define and implement the Client Data Management Strategy, considering the integrity,
governance and curation of the data in order to guarantee a smooth transition
data to EY Service Platform or Client legacy service platform. The role acts as
an interface to other service delivery partner groups (e.g. Business Systems,
Data Center), ensuring effective integration of the Data Management process
with other processes in order to meet service level requirements. Data
scientist will discover the information hidden in vast amounts of data, and make
smarter decisions to deliver even better products. The primary focus will be in
applying data mining techniques, doing statistical analysis, and building high
quality prediction systems integrated with our products
Essential Functions of the Job:
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art method
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Define Client Data Management Strategy
Agree KPIs of the Client Data Transfer Process
Planning the Client Data Transfer activities in the MS project
Define the best transfer and storage tools for the specific client process
Verify client data structure and integrity
Mapping Client Data with the different process
Assess client data framework
Define and build data report to stakeholders
Define measurement and controls of data governance
Define client data transfer process reports
Manages the effective implementation of backup and restore procedures and working practices
Monitors backup and restore information, standards, procedures, measurements, tools and technology.
Ensures compliance with data architecture and data management standards and procedures defined in the Data Management Framework
Works closely with Service Level Management to ensure that data management services remain capable of meeting ongoing and future requirements
Estimates overall storage resource and budget requirements for Asset Management as input to the IT Plan in conjunction with other process owners.
Carries out the Process Manager responsibilities for the Data Management process

Primary Objectives:
Beyond what the person in the position actually does, list the primary goals and objectives of the position for its overall contribution to the MS organization.

The Data Scientist have to meet a number of general objectives:
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits
Experience with data visualisation tools
Proficiency in using query languages such as SQL, Hive, Pig, etc
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase, etc
Good applied statistics skills, such as distributions, statistical testing, regression, etc
Successfully implement the Data Management Strategy in the MS Transition phase
Ensure the integrity of client data during the Data Transfer Process
Implement process and activities accordingly with Data Management Framework

Knowledge and Skills Requirements:

Broad knowledge and experience in:
Data Stores in the Cloud
Service IT Platforms Knowledge

Business Process Modeling

Above average skills in:
Analyze data architecture
Data Base Management
Navigating Data Base SW
Self-starter with strong written and verbal communication skills.
Analytical and problem-solving skills

Excellent skills in:
Data Analytics Software Business
Intelligence SW Applications
Data Analytics Software

Job Requirements:

Education:
BSc/BA in computer science bachelor degree or similar
Master’s degree in computer science or similar is ideal

Experience:
10+/13 + years of experience in Data Management
Expertise in relationship building with different roles and level in the organization",3.8,"EY
3.8",India,"London, United Kingdom",10000+ employees,1989,Company - Private,Accounting,Accounting & Legal,₹500+ billion (INR),"Deloitte, KPMG, PwC"
Data Scientist,-1,"The big picture

Cardlytics makes marketing more relevant and measurable through our Purchase Intelligence™ platform. With purchase data from financial institutions (FIs), Cardlytics has a secure view into where and when consumers are spending their money. By applying advanced analytics to this massive aggregation of purchase data, we make it actionable, helping marketers/ advertisers identify, reach and influence likely buyers at scale, and measure the true sales impact of their marketing spend.

What you will accomplish
The Data Scientist will be a subject-matter expert on various analytical tools such statistical programming languages, graph databases, and machine-learning algorithms and provide this expertise throughout Cardlytics as needed
The Data Scientist will create, test, and deploy models in a development environment that will impact new lines of business for the company
Learn new practices, design iterative learning and development cycles, and deliver prototypes to other groups for deployment into production and operations
Build full scale data science models for production
Skills and experiences that will make you successful
Knowledge of advanced statistical modeling, testing, data mining, and data science techniques
Advanced in modeling frameworks including Scikit-learn, PyTorch, and TensorFlow
Highly proficient in Python and SQL
Proficiency in Linux working in shell
Experience with H2O, Data Robot or other automated AI tools are a plus
Advanced Excel and PowerPoint skills required
Experience with Tableau and other data visualization is preferred
Strong scientific approach to problem-solving
Excellent organizational, analytical and problem-solving skills
Ability to communicate complex results in a simple and concise manner at all levels within the organization
Ability to excel in a fast-paced, startup environment
Experience
2+ years of proven success in a position of similar responsibilities or equivalent research time in an academic environment
Proficient in the use of Python or other leading statistical software/languages
Proficient in scripting processes in a Linux environment
Proficient with Data Sciences frameworks such as SkLearn, Tensorflow, and Pytorch.
Ability with Java a plus.
Experience with Python test automation frameworks a plus",3.7,"Cardlytics
3.7",Visakhapatnam,"Atlanta, GA",201 to 500 employees,2008,Company - Public,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Scientist,-1,"As a Data Scientist at Noodle.ai, you will collaborate with our Enterprise Services team,Software Engineers, Designers, and industry-specific experts from our customers. You willvbuild a deep understanding of the business problems our customers are tackling and then develop, test, and deploy advanced machine learning algorithms. As we grow, you will also develop reusable IP to help us move faster, dive deeper, and work more efficiently by generalizing the algorithms, methodologies, and supporting infrastructure that you build. As one of the early hires to join the Noodle.ai team, you will have a significant impact on the future of Enterprise Artificial Intelligence.

Job responsibilities:
Implement a breadth of different modeling approaches/ techniques in machine learning

Manipulate and prepare large, heterogeneous data sets to support advanced analytics

Iteratively conceptualize, design and build data-driven analytical models

Develop processes and tools to monitor and analyze model performance and data accuracy

Translate deep mathematical concepts and practices into language that non-experts can understand and build upon. And conversely, translate business needs and user needs into language and concepts that other data scientists can understand and work with.

Productionalizing machine learning code and interfacing with industry standardmsoftware systems

Understand and manipulate unstructured data from different platforms.

Demonstrate proficiency at real-world modeling problems/DS problems - getting to a result that demonstrably generate business value

Qualifications:Required:
Graduate degree in a relevant field (Computer Science, Operations Research, Statistics, Applied Math...) or Bachelors degree and 2-4 years applying advanced AI techniques to real-world problems

Good to have:
4 years of experience applying advanced AI techniques to real-world problems

Experience tackling data science problems characterized as high-dimension, low sample size (i.e., lots of potentially predictive features and highly diverse but low quality or highly sparse data.)

Knowledge & understanding of a functional area of focus (i.e. Experience applying advanced analytics to supply chain optimization, demand forecasting, and/or revenue management)

Knowledge & understanding of an industry area of focus (i.e. retail, manufacturing,CPG, 3PL, travel...)

Skills and Competencies:
Experience with common analysis tools (SQL, R, and Python).

Demonstrable familiarity with code and programming concepts.

Knowledge of Spark and/or Hadoop

Knowledge of machine learning areas and techniques - Supervised machine learning,Unsupervised machine learning, Time series, Natural language processing, Outlier detection, Computer vision, Recommendation engines, Survival analysis,
Reinforcement learning, and Adversarial learning

Knowledge of data visualization tools - ggplot, d3.js and Matplottlib, and Tableau

Strong problem solving skills with an emphasis on product development

Focus on delivering value and building lasting relationships through collaboration in an open and respectful working style

Passion for learning and a desire to grow",4.5,"Noodle.ai
4.5",Bengaluru,"San Francisco, CA",201 to 500 employees,2016,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),-1
Data Scientist,-1,"Aktana is looking for an experienced Data Scientist or Senior Data Scientist to join our Data Science team. The Data Science team builds mathematical and behavioral economics models underpinning Aktana's core solutions for actionable analytics and behavioral intelligence. The set of problems that we tackle is incredibly diverse and complex. They cut across optimization, prediction, modeling, inference, and behavioral science. We research and develop the algorithms and models that make our solution intelligent, as well as implementing, scaling and maintaining the code that powers our production systems.

The ideal candidate is a critical thinker with experience and background in commercial life science domain, passionate about solving mathematical and behavioral problems with data, and is excited about working in a fast-paced, innovative and collaborative environment.

LOCATION


RESPONSIBILITIES
Work with Data Scientists, Product Managers, Customer Success and Services teams to frame a problem, both mathematically and within the business context
Write production-level code; collaborate with Engineering team to implement algorithms in production and productize common solutions
Perform exploratory data analysis to gain a deeper understanding of the problem
Construct and fit statistical, machine learning and optimization models
Utilize commonly used computing and database environments to get the data that you need and implement a working prototype of the formulated model.
Learn and apply new methodologies in the intersection of applied math/ probability/statistics/machine learning/computer science.
Make intelligent approximations to the model if required to make it scalable.
Analyze experimental and observational data; communicate findings; facilitate launch decisions
Identify data sources that could be used to test assumptions
REQUIRED SKILLS/EXPERIENCES
5 years+ of Data Science experience
Proven track record of developing algorithms for production-ready recommendation or prediction systems using languages and big data platforms such as Scala, Python, R, Java, Spark, Cassandra, and Hadoop
Experience working in an agile software development environment
Passion for solving unstructured and non-standard mathematical and behavioral problems
End-to-end experience with data, including querying, aggregation, analysis, and visualization
Experience implementing machine learning algorithms
Experience with analytics for commercial life science and pharma-specific analyses a big plus
Excellent communication and presentation skills, being able to explain complex problems and the solutions applied, feeling comfortable in being part of the sales process, supporting the sales team, engaging with customers and presenting technical solutions to a nontechnical audience
Experience in data science and data analytics for life science industry especially in GTM strategy and execution a big plus
High-energy self-starter with a passion for your work, attention to detail, and a positive attitude
Great team player, willingness to collaborate and communicate with others to solve a problem.
EDUCATION


M.S. or Ph.D. in Statistics, Operations Research, Mathematics, Computer Science, or other quantitative disciplines with at least 2 years of experience

About Aktana

Committed to customer success and innovation, Aktana is at the forefront of transforming how life sciences companies share information with healthcare providers (HCPs). Our proprietary platform harnesses machine learning algorithms to enable marketing and sales teams to seamlessly coordinate and optimize multichannel engagement with HCPs. Today, more than half of the top 20 global pharma companies are using Aktana for intelligent engagement.

Aktana is growing fast and looking for exceptional talent to join our team. We value hard work, transparency, and collaboration and we like to have fun too! We are Great Place to Work Certified, an honor given based on validated feedback from employees who report a consistently positive experience working at Aktana.

Headquartered in San Francisco, we also have offices in Philadelphia, London, Barcelona, Tokyo, Osaka, Shanghai, Beijing, Sydney, and Sao Paulo.",4.8,"Aktana
4.8",Pune,"San Francisco, CA",201 to 500 employees,2008,Company - Private,Computer Hardware & Software,Information Technology,₹1 to ₹5 billion (INR),-1
Data scientist,-1,"Are you looking at developing future leaders? Come join us at Siemens.

At our Bengaluru Hub nearly 1100 employees provide various types of services Finance, HR, IT, Supply Chain, Customer Care - to more than 60 Siemens entities across the world, We are global business solutions, that supports Siemens companies worldwide to achieve perfection in their internal process allowing our colleagues to fully focus on their business.

Change the future with us
You will Work with large, complex data sets and applying advanced analytical methods as needed
You will be Developing custom data models and algorithms to apply to data sets.
You will Run PoCs and Pilots projects to investigate and prove the feasibility and benefits of the proposed solutions
You should Interact with multiple partners (from various levels) and optimally present findings by exploiting visual displays of complex quantity information in a simplified way
You will Identify and develop intelligent and innovative data analytics use cases to optimize business processes
You will be the partner of choice regarding technology advisory for advanced analytics
You should Actively and proactively perform market/trend scouting to stay up to date on the state-of-the-art technologies
We dont need superheroes, just super minds
You should have Knowledge in advanced data analytics/data science
You should Know-how on Extract, Transform and Load (ETL) of Big Data in enterprise environments (e.g., SAP, Oracle), cloud infrastructure (e.g., AWS, Azure), as well as familiarity of data architecture requirements and conceptual approaches for deploying algorithmic solutions in Big Data productive environments
You should be Comfortable working in programming languages like SQL, Python and R, as well as with frameworks like Tensorflow and Keras; experience designing solutions in distributed teams using Version Control tools like GIT
You should have Experience with cloud technologies: Amazon Web Services and/or Microsoft Azure
You should have Very good communication and presentation skills
Weve got quite a lot to offer. How about you?

This role is based in Bangalore. But youll also get to visit other locations in India and globe, so youll need to go where this journey takes you. In return, youll get the chance to work with teams impacting entire cities, countries and the shape of things to come.

Were Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we encourage applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and creativity and help us craft tomorrow.

Find out more about Siemens at: www.siemens.com/careers


Organization: Global Business Services

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.0,"Siemens
4.0",Bengaluru,"Munich, Germany",10000+ employees,1843,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹500+ billion (INR),"GE, ABB, Philips"
Data Scientist,-1,"COMPANY OVERVIEW
Tata Group is an Indian multinational conglomerate company headquartered in Mumbai, India. It encompasses seven business sectors: communications and information technology, engineering, materials, services, energy, consumer products and chemicals. Tata Group was founded in 1868 by Jamsetji Tata as a trading company. It has operations in more than 80 countries across six continents. Tata Group has over 100 operating companies with each of them operating independently.
Tata Sons is the promoter of all key Tata companies and holds the bulk of shareholding in these companies.

BACKGROUND The Tata companies together serve over million consumer and commercial customers today across several products and services. In order for the Tata companies to better understand customer and client needs and preferences, action life stages, needs, value, and potential, and enhance value and experience; the Tata companies need to develop robust data and information management capability and customer analytics. The vision is to eventually create the best in-house capability for data analytics amongst any large corporate. To achieve the above aims, it has been decided to establish an independent Tata company focused on building a common data analytics platform and help Tata Group companies. This company is being incubated in the initial phase as a division of Tata Industries and will subsequently be structured as a separate company to build Big Data Analytics and Data Science capabilities catering to but not limited to the ‘Consumer’ brands of the group.

Tata Insights and Quants – Journey to Date
Company: Tata - Insights and Quants – A Newly started division by Tata Industries.
http://www.livemint.com/Companies/PCgvCZILuJKV68UKVHZRJO/With-new-analytics-arm-Tata-aims-to-make-better-sense-of-da.html
Employer Brand: Tata iQ in 18 months of its inception was recognized in the list of Analytics India Magazine’s (AIM)
Top 10 most desirable Analytics Indian Firms to work for in 2016:
http://analyticsindiamag.com/top-10-analytics-firm-wish-worked-2016/
Generating Value for Customer: Fourteen Tata companies are partnering Tata Insights and Quants (Tata iQ), a Big Data firm, to analyse data collected from users, consumers and make sense of it to put changes in place http://www.livemint.com/Companies/5om8ebrv6p02jGCcRB3j3K/Tata-companies-use-Big-Data-to-craft-strategies.html https://cio.economictimes.indiatimes.com/news/strategy-and-management/how-ranjit-satyanath-plugs-into-it-to-power-up-croma-for-the-digital-era/65050926

Contributing to Community through big data:
In line with the Tata group’s philosophy of giving back more to the society than what it takes, Tata iQ, Tata group’s big data and decision Sciences Company.
Okhai partners with Tata iQ to deliver big impact through big data

Company : Tata Insights and Quants
Role : Data Scientist
Level : Analyst – Associate - Senior Associate
Role Type : Individual Contributor
Location : Mumbai | Bangalore | Jamshedpur | Kalinga Nagar – All Options open

Job Description The incumbent will be part of the Predictive Analytics, Digital Analytics, Data Sciences, Advanced Visualization, Insights & Experimentation team and will report to the Manager/Senior Manager. He/she will be an individual contributor working on multiple data sciences, advanced visualization and data management initiatives across multiple companies and industries leveraging traditional and big data. The incumbent will have the unique opportunity to witness the application of analytics across multiple industry verticals. Close partnership with business and the senior leadership of multiple Tata Companies will enable a clear understanding of the business perspectives and the application of analytics for solving real business problems.

Key Responsibilities:
Apply Data Mining/ Data Analysis methods using a variety of data tools, building and implementing models using algorithms and creating/ running simulations to drive optimisation and improvement across business functions
Assess accuracy of new data sources and data gathering techniques
Perform Exploratory Data Analysis, detailed analysis of business problems and technical environments in designing the solution
Apply Supervised, Unsupervised, Reinforcement Learning and Deep Learning algorithms
Apply advanced Machine Learning Algorithms and Statistics:
o Regression, Simulation, Scenario Analysis
o Time Series Modelling
o Classification - Logistic Regression, Decision Trees, SVM, KNN, Naive Bayes
o Clustering, K-Means
o Ensemble Models - Random Forest, Boosting, Bagging
o Neural Networks
Lead and manage Proof of Concepts and demonstrate the outcomes quickly
Document use cases, solutions and recommendations
Work analytically in a problem-solving environment
Work in a fast-paced agile development environment
Coordinate with different functional teams to implement models and monitor outcomes
Work with stakeholders throughout the organization to identify opportunities for leveraging organisation data and apply Predictive Modelling techniques to gain insights across business functions - Operations, Products, Sales, Marketing, HR and Finance teams
Help program and project managers in the design, planning and governance of implementing Data Science solutions
Experience and Skills:
2-7 years of professional working experience in Analytics
Experience in Retail, Financial Services and Manufacturing
Experience using statistical packages of R, Python and Spark ML to work with data and draw insights from large data sets
Experience with distributed data/ computing tools: Hadoop, Hive, Spark, Python
Experience with SQL
Experience visualizing/ presenting data for stakeholders using matplot, ggplot or Excel or Tableau
Excellent written and verbal communication skills for coordinating across teams
Education qualification:
Bachelors/ Masters in a quantitative discipline (Statistics, Econometrics, Mathematics, Engineering and Science)
Reach us on careers@tataiq.com",4.0,"Tata Insights and Quants
4.0",Mumbai,"Zug, Switzerland",10000+ employees,1980,Unknown,Architectural & Engineering Services,Business Services,Unknown / Non-Applicable,-1
"Data Scientist, Smart MFG & AI",-1,"Req. ID: 181176

Micron Technology’s vision is to transform how the world uses information to enrich life and our commitment to people, innovation, tenacity, collaboration, and customer focus allows us to fulfill our mission to be a global leader in memory and storage solutions. This means conducting business with integrity, accountability, and professionalism while supporting our global community.

Do you believe that data provides groundbreaking insight? Do you see data as an asset that builds a competitive advantage? Great…so do we!

Micron Technology operates in a highly competitive industry where innovation depends on hardworking minds extracting fresh insights from an ever-expanding data universe. We are seeking an experienced Data Engineer capable of designing and implementing large data solutions from data streams and intelligent systems, including transforming, supporting, configuring and enhancing existing data solutions. Are you experienced in applying Data Engineering and Machine learning to Big Data, never-before-solved problems for industrial manufacturing at scale? Does this sound like the right team for you? Apply today!

As a Big Data Engineer at Micron Technology Inc., you will be a key member of a multi-functional team responsible for developing and growing Micron’s methods and systems for extracting new insight for our expanding data streams. You will be collaborating with data scientists, engineers, technicians and data mining teams to design and implement systems to extract data from Micron’s business systems, transforming it into an actionable format, and as needed, creating dynamic presentation layers for use by high-level engineers and managers throughout the company. You will be creating new solutions, as well as, supporting, configuring, and improving existing solutions.

Responsibilities and Tasks


Understand the Business Problem and the Relevant Data
Maintain an intimate understanding of company and department strategy
Translate analysis requirements into data requirements
Identify and understand the data sources that are relevant to the business problem
Develop conceptual models that capture the relationships within the data
Define the data-quality objectives for the solution
Be a subject matter expert in data sources and reporting options
Architect Data Management Systems
Use understanding of the business problem and the nature of the data to select appropriate data management system (Big Data, OLTP, OLAP, etc.)
Design and implement optimum data structures in the appropriate data management system (Hadoop, Teradata, SQL Server, etc.) to satisfy the data requirements
Plan methods for archiving/deletion of information
Develop, Automate, and Orchestrate an Ecosystem of ETL Processes for Varying Volumes of Data
Identify and select the optimum methods of access for each data source (real-time/streaming, delayed, static)
Determine transformation requirements and develop processes to bring structured and unstructured data from the source to a new physical data model
Develop processes to efficiently load the transform data into the data management system
Prepare Data to Meet Analysis Requirements
Work with the data scientist to implement strategies for cleaning and preparing data for analysis (e.g., outliers, missing data, etc.)
Develop and code data extracts
Follow standard methodologies to ensure data quality and data integrity
Ensure that the data is fit to use for data science applications
Qualifications and Experience:

0-7 years of experience developing, delivering, and/or supporting data engineering, advanced analytics or business intelligence solutions
Ability to work with multiple operating systems (e.g., MS Office, Unix, Linux, etc.)
Experienced in developing ETL/ELT processes using Apache Ni-Fi and Snowflake
Significant experience with big data processing and/or developing applications and data sources via Hadoop, Yarn, Hive, Pig, Sqoop, MapReduce, HBASE, Flume, etc.
Understanding of how distributed systems work
Familiarity with software architecture (data structures, data schemas, etc.)
Strong working knowledge of databases (Oracle, MSSQL, etc.) including SQL and NoSQL.
Strong mathematics background, analytical, problem solving, and organizational skills
Strong communication skills (written, verbal and presentation)
Experience working in a global, multi-functional environment
Minimum of 2 years’ experience in any of the following: At least one high-level client, object-oriented language (e.g., C#, C++, JAVA, Python, Perl, etc.); at least one or more web programming language (PHP, MySQL, Python, Perl, JavaScript, ASP, etc.); one or more Data Extraction Tools (SSIS, Informatica etc.)
Software development
Ability to travel as needed
Education:


B.S. degree in Computer Science, Software Engineering, Electrical Engineering, Applied Mathematics or related field of study.

M.S. degree preferred.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

For US Sites Only: To request assistance with the application process and/or for reasonable accommodations, please contact Micron’s Human Resources Department at 1-800-336-8918 or 208-368-4748 and/or by completing our General Contact Form

Keywords: Hyderabad || Telangana (IN-TG) || India (IN) || SGA || Experienced || Regular || Manufacturing/Production Operations || #LI-NB1 || Tier 4 ||",3.4,"Micron Technology
3.4",Hyderabad,"Boise, ID",10000+ employees,1978,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Samsung Electronics, SK hynix, Toshiba"
Data Scientist,-1,"Job Description: Data Scientist

Education & Training

• Bachelor’s degree or Masters in Computer Science/Statistics/Mathematics

Experience
• 7 to 9 years of experience in executing data-driven solutions to increase efficiency, accuracy, and utility of internal data processing.
• Experienced at creating data regression models, using predictive data modeling, and analyzing data mining algorithms to deliver insights and implement action-oriented solutions to complex business problems.
• Proficient knowledge in statistics, mathematics and data analysis
• Excellent understanding of business operations and analytics tools for effective analysis of data
• Experience on optimized data collection procedures and generate reports.
• Experience on building predictive models and machine-learning algorithms.
• Experience in designing complex reports such as Drill-down, Drill-through, Cascading, Matrix, cross tab and Map reports using Power BI or Tableau
• Expertise in data storage structures, data mining, and data cleansing
• Systematic problem-solving approach with strong communication skills and a sense of ownership and drive

Skills
• Primary Skills
• Strong hold of concepts in Statistics
• Strong programming skills in R, Python, Java
• Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark.
• Proficient with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data
• Proficient in with SQl Databases like MSSql, Postgres.
• Have a good exposure to Azure Analytics Products like, Data Factory, HD Insights, Azure Data Lake Storage, Data Bricks.
• Experience on different data visualization tools like PowerBI , Tableau.
• Secondary Skills
• Tools - Qliksense , Tableau
• Kusto Query Language
Job Responsibilities

• Supporting the analytics needs of business by analyzing data from multiple sources
• Identify valuable data sources and automate collection processes
• Undertake preprocessing of structured and unstructured data
• Analyze large amounts of information to discover trends and patterns
• Support in collecting, organizing, and interpreting data along with fellow colleagues.
• Build predictive models and machine-learning algorithms
• Use machine learning tools and statistical techniques to produce solutions to problems
• Combine models through ensemble modeling
• Present information using data visualization techniques
• Propose solutions and strategies to business challenges
• Collaborate with engineering and product development teams

Job Responsibilities
Responsible
for installation, maintenance, and providing support for Application
Performance Monitoring and Instrumentation with the primary focus on
AppDynamics and Azure Monitor.
Help
define and implement best practices for Production Application Management
monitoring
Assist
engineers with production Infrastructure Monitoring
Ability
to develop necessary POCs & POVs in sandbox/testing environment
Ability
to support setup and configuration of the APM tool
Assist
in building an APM Centre of Excellence
Operating
system and server architecture knowledge of UNIX/Windows/virtual systems
Assist
development teams with application and server troubleshooting and
diagnostics
Programming
automation (VBA /VB.Net, JAVA or major scripting languages such as Perl
and Python, Unix/Linux shell scripts)",3.5,"Mercedes-Benz Research and Development India Private Limited
3.5",Bengaluru,"Chakan, India",1001 to 5000 employees,1996,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),"Volkswagen, Tata Motors"
Data Scientist,-1,"JOB DESCRIPTION
</b></u></h2>

KEY RESPONSIBILITIES :
Using techniques from supervised and unsupervised machine learning, statistical analysis and predictive modelling to deliver business insights to business units based on data
Working directly with internal customers to educate them on moving beyond BI and training their internal resources to execute advanced forms of analytics
Creating reusable implementations of statistical tests and models using cutting edge technologies
Working with the academic and business community to develop new techniques and to contribute to research in the area of advanced analytics in media
Assisting in engagement management, requirements definition, project scoping, timeline management, and results documentation to ensure professional relationship management
PERFORMANCE MEASURES :
As per role KPIs
QUALIFICATION :
2-8 Years plus post qualification
Degree in computer science with a machine learning focus (other technical degrees also accepted e.g. applied mathematics, statistics, physics, operations research). PhD will be desirable.
KNOWLEDGE AND SKILLS :
Advanced knowledge of statistical and machine learning methods, particularly in the areas of modelling and business analytics
Strong programming skills
Experience with statistical languages and packages, such as R, SAS, Mat-Lab, and/or Mahout
Experience working with relational databases and/or distributed computing platforms, and their query interfaces, such as SQL, MapReduce and Hive.
Experience with additional programming languages, such as Python, Java, and C/C++.
Excellent written and verbal communications skills, with a proven ability to translate complex methodologies and analytical results to higher-level business insights and key take-away
A proven passion for generating insights from data, with a strong familiarity with the higher-level trends in data growth, open-source platforms, and public data sets.
Experience working hands-on with large-scale data sets
Familiarity with visualization software and techniques (including Tableau), and business intelligence (BI) software, such as Micro-strategy, Cognos, Pentaho, etc.
PERSONAL ATTRIBUTES :
Creative, gritty, driven by curiosity and comfortable with failure
Strong Data intuition: Talent to identify and visualize patterns
Multi Modal Communication skills
We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, gender identity, disability, protected veteran status, or any other characteristic protected by law. We will consider for employment qualified applicants with criminal histories consistent with applicable law.",3.9,"Walt Disney Company
3.9",Mumbai,"Burbank, CA",10000+ employees,1923,Company - Public,Film Production & Distribution,Media,₹500+ billion (INR),"News Corp, WarnerMedia, NBCUniversal"
Data Scientist,-1,"JOB DESCRIPTION

Data Scientist

Role : Data Scientist

Experience : 5+ years

Education

Graduation / Post Graduation : Specialization in Computer Science, Software Engineering, Business Analytics etc.

Role Background

Inteliment is looking for people who aspire to solve real and complex business problems with their Data Science expertise. You will be a part of our Data Science Centre of Excellence that implements Inteliment’s Data Science Platform as well as on other industry leading platforms.

Key Responsibilities

Work closely with product engineering, client and project teams and align them with respect to your focus area.

Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner.

Enhancing data collection, processing, cleansing and verifying the integrity of data used for advance analytics

Be a subject matter expert in Data Science Platform Data Science & Analytics products and offerings.

Selecting features, building and optimizing classifiers using machine learning techniques, understand and work around possible limitations in models.

To develop hypothesis and test them with careful experiments.

Aid in project planning to determine effort and time estimations.

Contributing to creation of knowledgebase for Technology platform & practise and related KMS initiatives.

Required Skills

Data-oriented personality with a good scripting and programming skills and hands-on expertise on data science toolkits, such as R, MatLab, SAS, SPSS

Hands-on expertise and exposure in NLP, machine & deep learning algorithms, model building, statistical modelling, predictive modelling environments

Excellent track record of delivery using languages like Python, R, Java and technologies like Hadoop, Git / Stash, JIRA / Rally etc.

Desired Skills

Demonstrated clear and thorough logical and analytical thinking, as well as problem solving skills

Self-directed, ability to work independently and research innovative solutions to business problems

Must be flexible to travel onsite if required.

Effective interpersonal communication across various levels of the organization.

Ability to interpret, evaluate and communicate detailed information in a manner that is appropriate to the audience.

Ability to conduct root cause analysis and performance tuning for complex business processes and functionality.

Ability to interact with IT and business users across the organization to resolve issues and provide solutions in a timely manner.

Should be proactive & transparent in the in the deliverables & critical thinker while designing the solutions.

Team oriented and enjoys working in a collaborative development environment.

Tools & Technologies

Excellent track record of delivery using languages like Python, R, Java and technologies like Hadoop, Git / Stash, JIRA / Rally, SAS, SPSS, Statistic etc.

Experience with NoSQL databases (MongoDB, Cassandra, HBase) and SQL, Hive, Pig.

Experience with data-viz tools to present trends, forecasts, patters Tools & Technologies

If you have got it all.. What are you waiting for?",4.0,"inteliment
4.0",Pune,"Pune, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Data Scientist,-1,"Job Description
What will a 'Data Scientist - Data Analytics' do?
Providing a full range of Data and Analytic services(ML, Data Mining, EDA, Feature Engineering, Statistical modeling for Predictive and Prescriptive enterprise analytics) to clients across multiple sectors.
Applicants will be expected to work with a diverse set of data sources, such as time series data, spatial, graph data, semi-structured and unstructured data, and build statistical/machine-learning models in support of on-demand, real-time analytic services.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation and many other business outcomes.
Develop company A / B testing framework and test model quality.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Work with partners in Data Engineering, Product, Programmatic and business teams, to operationalize integration of analytic models into the production environment(s).
Stay current on relevant academic and industry developments to identify best-in-class algorithms, techniques, libraries, etc.

What we are looking for?

Business-minded data scientist with a demonstrated ability to deliver valuable insights via data analytics and advanced data-driven methods.
Developed intricate algorithms based on deep-dive statistical analysis and predictive data modeling.
Experience using statistical computer languages like R, SAS, Python etc.. to manipulate data and draw insights from large data sets.
Analyze and process complex data sets using advanced querying, visualization andanalytics tools.
Passion for solving unstructured and non-standard mathematical and behavioral problems
End-to-end experience with data, including querying, aggregation, analysis, and visualization.
Experience implementing Machine Learning and Deep Learning Algorithms, Data-Driven Personalization.
Excellent communication and presentation skills, being able to explain complex problems and the solutions applied.
Demonstrating data analysis and visualization with one or more leading COTS analytic and presentation solutions including Tableau, Power BI, Qlik view or Qlik Sense, and MS Excel and other MS Office suite applications.
Experience in an Agile environment (SAFe) and work within the Atlassian suite (Jira, Bitbucket, Confluence) and AWS or other computing environments.
Tools: R, Python, Spark, PySpark, Scala, Tensorflow, Keras, Big Data, AWS",4.0,"MTW LABS
4.0",Hyderabad,"Hyderabad, India",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Data Scientist

Job Description:
Expertise or extensive experience with Python/ R -programming
· A thorough understanding of SQL databases
· Excellent technical abilities
statistics and machine-learning optimization skills;
knowledge of big data
insightful data visualization capability
to use algorithms and programming to efficiently go through large datasets
Define unstructured data needs, evaluate data quality, and extract/transform data
data science programming languages and big data tools including R, Python, Spark, SQL, Hadoop
Development and deployment of an advanced solution in a Big Data

Experience Range:

4 - 8 years

Educational Qualifications:

Any graduation,

Skills Required :

data scientist,

data analyst,

Candidate Attributes :

Should be good at R Python and Big Data",3.0,"Angel Broking
3.0",Andheri,"Mumbai, India",1001 to 5000 employees,1987,Company - Private,Brokerage Services,Finance,Unknown / Non-Applicable,-1
Data Scientist,-1,"This position requires a person to design, implement and processes large data sets used for modeling, data mining.

Responsibilities :
Develop and plan required analytic projects in response to business needs.
In conjunction with data owners and department managers, contribute to the development of data models and protocols for mining production databases.
Develop new analytical methods and/or tools as required.
Contribute to data mining architectures, modeling standards, reporting, and data analysis methodologies.
Conduct research and make recommendations on data mining products, services, protocols, and standards in support of procurement and development efforts.
Work with application developers to extract data relevant for analysis.
Collaborate with unit managers, end users, development staff, and other stakeholders to integrate data mining results with existing systems.
Provide and apply quality assurance best practices for data mining/analysis services.
Adhere to change control and testing processes for modifications to analytical models.
Create data definitions for new database file/table development and/or changes to existing ones as needed for analysis.
Determine required network components to ensure data access, as well as data consistency and integrity.
Respond to and resolve data mining performance issues. Monitor data mining system performance and implement efficiency improvements.
Manage and/or provide guidance to junior members of the team.

Send us the Resume at info@zettamine.com",3.9,"ZettaMine
3.9",Hyderabad,"Hyderabad, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Data Scientist
Job Description


ITS Data Scientist

Job Description Summary

The ITS Data Scientist is responsible for integrating business, information, and technology into analytical models that help drive business performance and competitive advantage and providing the business with answers to questions. The role collaborates with Business, IT Functional Engineers and Platform architects to create value from varied data sources. Creating value from data requires a range of talents: from data integration and preparation, to architecting specialized computing/database environments, to data mining and intelligent algorithm development.

Hiring Requirements

Job Details

Development of analytics to help drive competitive advantage from data with accountabilities across multiple functional and technical areas with wide range of complexity.
The Data Scientist must understand medium/complex data types (integrate, manipulate, prepare), know advanced analytics (appropriate techniques, interpret data and diagnose models, meet business requirements), and focus on the business outcomes (goals, constraints, decisions while communicating outcomes via presentations).
Develop models and algorithms that drive innovation throughout the organization. This may include marketing, supply chain, inventory planning and deployment, network planning, order routing, and order fulfillment and delivery.
Conduct advanced statistical analysis to provide actionable insights, identify trends, and measure performance Build learning systems that monitor data flows and react to changes in customer preferences, network constraints, and business objectives.
Collaborate with engineers to implement and deploy scalable solutions Provide thought leadership by researching best practices, conducting experiments, and collaborating with industry leaders.
Partners as a bridge between the business and the information management teams to make sure that the solution fits within the data management principals.
Coordinates data science implementations while leading design variances based upon business needs while ensuring artifacts and repositories are documented.
Manages engagements with vendors as they relate to evaluation, design and delivery of business capabilities.
Contributes to the evaluation and selection of software product standards.
Leader in industry representation, policy formation, User Groups, and strategic direction
Mentors others to complete Continuous Improvement (CI) initiatives; consults and shares knowledge across org; awareness of industry trends.
Education required/ preferred:
MS/PhD in computer science, statistics, or operations research or related technical discipline.
Experience:
3-5+ years of continuous experience in software engineering, software development, solution architecture
Knowledge of machine learning, statistics, optimization or related field
Experience with R, Python, Matlab is required
Experience building machine learning application in areas like time series forecasting, classification models, clustering models, multivariate regression models etc
Experience in Microsoft Azure Stack in the Cloud with focus on Data Factory, Data Bricks, BLOBs, Data Lake Storage, ML Studio, Azure Analysis Services, Azure Data Warehouse, Power BI etc
Experience working with large data sets and distributed computing tools a plus (Map/Reduce, Hadoop, Hive, Spark, Python, R, Gurobi, MySQL, etc.)
Excellent written and verbal communication skills along with strong desire to work in cross functional teams
Consumer products experience in an online and/or retail/manufacturing environment is preferred
Possess strong leadership skills and exhibit creative thinking to be able to come up with inventive solutions to solve business challenges
Provide thought leadership while keeping up with industry trends and disseminating information across the organization
Experience working with blended teams consisting of employees, vendors, and consultants with both onshore and offshore resources
Strong Technical leadership of advanced analytics teams and vendors
Extensive experience collaborating with Enterprise Architects and infrastructure engineers to identify, design, and implement highly complex, end-to-end solutions
Cultivates networking opportunities within the organization
Broad range of business and IT experiences; Has achieved technical and/or business certification(s).
Global VISA and Relocation Specifications:
K-C requires that an employee have authorization to work in the country in which the role is based. In the event an applicant does not have current work authorization, K-C will determine, in its sole discretion, whether to sponsor an individual for work authorization. However, based on immigration requirements, not all roles are suitable for sponsorship.
This role is available for local candidates already authorized to work in the role’s country only. K-C will not provide relocation support for this role.
Primary Location
IT Centre Bangalore GDTC
Additional Locations
Worker Type
Employee
Worker Sub-Type
Regular
Time Type
Full time",3.9,"Kimberly-Clark
3.9",Bengaluru,"Irving, TX",10000+ employees,1872,Company - Public,Consumer Products Manufacturing,Manufacturing,₹500+ billion (INR),"Procter & Gamble, Georgia-Pacific, Unilever"
Data Scientist,-1,"Technical Skills:
A Ph.D., (or master’s degree plus at least 8 years’ relevant experience), in Computer Science, Statistics, Linguistics, Mathematics, Economics, Physics, or a related scientific discipline.
5+ years of experience working with large datasets for drawing business insights.
Research experience and coursework in Machine Learning
Experience with statistical software (e.g. MLlib, R, pandas) and database languages (e.g., SQL)
Fluency in Scala/Python programming.
Experience identifying business problems and selecting/finding the most appropriate data sets and statistical models to formulate solutions.
Experience with large data sets.
Strong understanding of statistics and modeling techniques.
Desire to work in a highly collaborative environment.
Experience with Natural Language Processing, Information Retrieval, or Recommender Systems.
Experience with distributed computing, such as Hadoop, Spark, or related technologies would also be an added advantage.
Experience with mathematical optimization, control theory, time-series analysis would also be an added advantage.

Additional Skills:
A strong work ethic and the ability to manage yourself and your time
Outstanding teamwork skills
Excellent written and verbal communication skills as well as active listening skills
Demonstrated analytical abilities
Experience managing and/or mentoring junior developers
Experience with Agile/SCRUM development methodologie",4.7,"Firminiq
4.7",Chandigarh,"Buffalo Grove, IL",51 to 200 employees,2018,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
DATA SCIENTIST,-1,"The required skills are :


Post graduate degree in Statistics, Math or any other with strong analytical background .
Must have exposure to Big Data analytics..
Need Strong mathematical background (calculus, linearalgebra, probability and statistics).
Applied Machine Learning experience (regression and classification, supervised, and unsupervised learning) is a plus.
Must be a quick learner and capable to solve complex problems in multiple domains.
Skill Set : Language - C#,C++, Python or R, Scripting - Java script

Position Type : Permanent

Qualification : Any postgraduate degree with analytics

Experience : 0 - 4 Yrs

Salary Package :Best in Industry
Job Location : Calicut, Kerala, India

Recruitment Process : Technical Interview & HR interview",4.0,"Tech27 Systems
4.0",Kozhikode,"Aberdeen, United Kingdom",51 to 200 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"2 positions are available in each location. Title seniority and salary are set to experience level of the applicant.

Role and Responsibilities

Execute data mining projects, training and deploying models over a typical duration of 2 -12 months.
The ideal candidate should be able to innovate, analyze the customer requirement, develop a solution in the time box of the project plan, execute and deploy the solution.
Integrate the data mining projects embedded data mining applications in the FogHorn platform (on Docker or Android).

Core Qualifications

Candidates must meet ALL of the following qualifications:
Have analyzed, trained and deployed at least three data mining models in the past. If the candidate did not directly deploy their own models, they will have worked with others who have put their models into production. The models should have been validated as robust over at least an initial time period.
Three years of industry work experience, developing data mining models which were deployed and used.
Programming experience in Python is core using data mining related libraries like Scikit-Learn. Other relevant Python mining libraries include NumPy, SciPy and Pandas.
Data mining algorithm experience in at least 3 algorithms across: prediction (statistical regression, neural nets, deep learning, decision trees, SVM, ensembles), clustering (k-means, DBSCAN or other) or Bayesian networks

Bonus Qualifications
Any of the following extra qualifications will make a candidate more competitive:

Soft Skills
Sets expectations, develops project plans and meets expectations.
Experience adapting technical dialogue to the right level for the audience (i.e. executives) or specific jargon for a given vertical market and job function.
Technical skills
Commonly, candidates have a MS or Ph.D. in Computer Science, Math, Statistics or an engineering technical discipline. BS candidates with experience are considered.
Have managed past models in production over their full life cycle until model replacement is needed. Have developed automated model refreshing on newer data. Have developed frameworks for model automation as a prototype for product.
Training or experience in Deep Learning, such as TensorFlow, Keras, convolutional neural networks (CNN) or Long Short Term Memory (LSTM) neural network architectures. If you don’t have deep learning experience, we will train you on the job.
Shrinking deep learning models, optimizing to speed up execution time of scoring or inference.
OpenCV or other image processing tools or libraries
Cloud computing: Google Cloud, Amazon AWS or Microsoft Azure. We have integration with Google Cloud and are working on other integrations.
Decision trees like XGBoost or Random Forests is helpful.
Complex Event Processing (CEP) or other streaming data as a data source for data mining analysis
Time series algorithms from ARIMA to LSTM to Digital Signal Processing (DSP).
Bayesian Networks (BN), a.k.a. Bayesian Belief Networks (BBN) or Graphical Belief Networks (GBN)
Experience with PMML is of interest (see www.DMG.org).
Vertical experience in Industrial Internet of Things (IoT) applications:
Energy: Oil and Gas, Wind Turbines
Manufacturing: Motors, chemical processes, tools, automotive
Smart Cities: Elevators, cameras on population or cars, power grid
Transportation: Cars, truck fleets, trains

How To Apply

To apply, submit a resume to careers@foghorn.io, with an email subject: “Greg (Data Scientist) ”.
If you want to be more competitive, address how you meet all the minimum requirements and any bonus qualifications.

About FogHorn Systems
FogHorn is a leading developer of “edge intelligence” software for industrial and commercial IoT application solutions. FogHorn’s Lightning software platform brings the power of advanced analytics and machine learning to the on-premise edge environment enabling a new class of applications for advanced monitoring and diagnostics, machine performance optimization, proactive maintenance and operational intelligence use cases. FogHorn’s technology is ideally suited for OEMs, systems integrators and end customers in manufacturing, power and water, oil and gas, renewable energy, mining, transportation, healthcare, retail, as well as Smart Grid, Smart City, Smart Building and connected vehicle applications.

Press: https://www.foghorn.io/press-room/

Awards: https://www.foghorn.io/awards-and-recognition/

2019 Edge Computing Company of the Year – Compass Intelligence
2019 Internet of Things 50: 10 Coolest Industrial IoT Companies – CRN
2018 IoT Planforms Leadership Award & Edge Computing Excellence – IoT Evolution World Magazine
2018 10 Hot IoT Startups to Watch – Network World. (Gartner estimated 20 billion connected things in use worldwide by 2020)
2018 Winner in Artificial Intelligence and Machine Learning – Globe Awards
2018 Ten Edge Computing Vendors to Watch – ZDNet & 451 Research
2018 The 10 Most Innovative AI Solution Providers – Insights Success
2018 The AI 100 – CB Insights
2017 Cool Vendor in IoT Edge Computing – Gartner
2017 20 Most Promising AI Service Providers – CIO Review

Our Series A round was for $15 million. Our Series B round was for $30 million October 2017. Investors include: Saudi Aramco Energy Ventures, Intel Capital, GE, Dell, Bosch, Honeywell and The Hive.

About the Data Science Solutions team
In 2018, our Data Science Solutions team grew from 4 to 9. We are growing again from 11. We work on revenue generating projects for clients, such as predictive maintenance, time to failure, manufacturing defects. About half of our projects have been related to vision recognition or deep learning. We are not only working on consulting projects but developing vertical solution applications that run on our Lightning platform, with embedded data mining.

Our data scientists like our team because:
We care about “best practices”
Have a direct impact on the company’s revenue
Give or receive mentoring as part of the collaborative process
Questions and challenging the status quo with data is safe
Intellectual curiosity balanced with humility
Present papers or projects in our “Thought Leadership” meeting series, to support continuous learning",4.2,"Foghorn Systems
4.2",Pune,"Palo Alto, CA",1 to 50 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹10 to ₹50 million (INR),-1
Data Scientist,-1,"Job Title
Data Scientist

24-Apr-2020

No. of Positions
1

Job Description
General Position Definition
Finance & Data Operations Data Science Team is tasked with delivering tangible value to business units within Shell through data-driven decision making.
This position is part of Finance & Data Operations Data Science team leading a small team of data scientists delivering advanced analytics projects for different businesses within Shell. The individual will join a growing global data science organization spanning both on/offshore.
Incumbent is responsible for developing analytical models for projects collaborating with different business stakeholders & other partners and working across a range of technologies and tools.
Responsibilities:
Clearly articulate the challenges / opportunities in business / function that can be supported by Process Mining analytics solution
Solicit business requirements and translate them into a Celonis Process Mining analytics solution
Develop actionable insights by providing advanced analytics solutions on a broad range of business issues and data types.
Provide clear guidance to end users on how to effectively use Celonis Process Mining.
Develop and deliver process mining training as required
Implement advanced capabilities in Process mining (e. g. Predictive modelling, Natural Language Processing).
Auto req ID
137322BR

Country of Work Location
India

Employment Type
Full Time

Company Description
The aim of the Shell Business Operations, Chennai is to provide the Group with operational excellence through highlighting and utilizing process improvements and functional efficiencies as well as by leveraging economies of scale. Currently, the Chennai centre provides a wide range of finance, accounting and business services to Shell operating companies across several business sectors globally.

Set up in September 2007, the Chennai centre has grown rapidly and now , in its fourth year of operations , it has crossed the 1600 staff mark. The centre is located in the RMZ Millennia Business Park, where the Shell campus is a LEED Platinum building with world class infrastructure. The business is expected to grow further over the next two years and infrastructural additions to support this have been planned.

The main focus in Chennai is on Finance Operations which supports delivery of the global Finance functional plan. There is also a ‘Downstream India’ - Customer Services Team that handles lubricant depot ordering within the country. The Shell Business Operations (SBO Team) manages the centre facilities and supports business partners’ operations on site. There is a strong focus at SBO on safety & well being of staff and on its three core values: Compliance, Intervention & Respect.

Disclaimer
Please note: We occasionally amend or withdraw Shell jobs and reserve the right to do so at any time, including prior to the advertised closing date.

Before applying, you are advised to read our data protection policy. This policy describes the processing that may be associated with your personal data and informs you that your personal data may be transferred to Royal Dutch/Shell Group companies around the world.

The Shell Group and its approved recruitment consultants will never ask you for a fee to process or consider your application for a career with Shell. Anyone who demands such a fee is not an authorised Shell representative and you are strongly advised to refuse any such demand.

Shell is an Equal Opportunity Employer.

Work Location
Chennai - RMZ Millenia

Requirements
Experience working with process mining tools such as Process X-ray, Process Gold, Signavio, Mint, Celonis (preferred), etc.
Experience working with SAP / SAP HANA (functional modules, underlying data structures, BW)
Minimum of 5+ years of experience working in Analytics, Business Intelligence, and Statistical Modelling
Experience working in any Finance / Business Processes such as Procure to Pay, Order to Cash, Fixed Asset, Trading, Inventory Management, Production Planning, Plant Maintenance, Travel and Entertainment, etc.
Strong understanding and experience with analytical/predictive modelling techniques, theories, principles, and practices.
High Proficient in SQL or ABAP or Python or any other programming language
Prior experience of working with data visualization tools such as SAP Lumira, SAP BO, Tableau, Qlikview or PowerBI
SBO Location
Chennai

City, State (if applicable)
Chennai",4.0,"Shell
4.0",Chennai,"Houston, TX",10000+ employees,1907,Company - Public,Oil & Gas Exploration & Production,"Oil, Gas, Energy & Utilities",₹500+ billion (INR),"ExxonMobil, BP, Chevron"
Data Scientist,-1,"About HP

HP is the world’s leading personal systems and printing company, we create technology that makes life better for everyone, everywhere. Our innovation springs from a team of individuals, each collaborating and contributing their own perspectives, knowledge, and experience to advance the way the world works and lives.

We are looking for visionaries, like you, who are ready to make a purposeful impact on the way the world works.

At HP, the future is yours to create!

Purpose

As a Data Scientist, you will join an industry-leading organization and work on developing tools and analytical models to identify optimal marketing, pricing and sales decisions for our Printing & Personal Systems business in EMEA. Working in the Data Science team, you will develop innovative analytical approaches and tools enabling better insights to implement marketing and pricing guidelines for supplies. You will work closely with Product Management, Sales, and Finance teams to drive profitable growth.

Knowledge, Skill and Abilities

Experience building and interpreting machine learning models (e.g. Naïve Bayes, random forest, regression trees, neural networks)
Ability to merge different data sources, create new variables and conduct regression analyses (probit/logit and other GLM)
Develop and implement frameworks and processes for systematic data analysis, as well as reporting capabilities to track key business performance metrics
Very strong analytical skills, with a high level of attention to detail
Solid problem-solving skills and systems thinking, being able to act independently on building analysis models and business cases
Capable of quickly interpreting analysis results and providing strategy recommendations, including presenting to senior leadership

Additional Qualifications

3+ years of advanced analytics experience
Proficient in R and/or Python programming languages
Good understanding of financial metrics and ability to leverage pricing decision using financials
Strong understanding of data structures, data management and statistical methods
Strong presentation skills
Must be a team player, who is passionate and able to build strong relationships across different functions
University degree in a quantitative discipline (e.g. economics, statistics, econometrics, mathematics, physics), with a postgraduate degree preferred
Analytics experience in Finance, Marketing or Pricing is a plus",4.1,"HP
4.1",Bengaluru,"Houston, TX",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
"Data Scientist (Only from IIT, NIT,IIIT,IIM,VIT,BIT)",-1,"About Zycus :

Headquartered in Princeton, U.S. in 1998, Zycus has grown every day to be established as an organization which now is a leading global provider of complete Source-to-Pay suite of procurement performance solutions.

We develop cloud-based (SaaS) Source-to-Pay solutions for large global enterprises, and have successfully deployed about 200 solutions to over 1000 Global clients. We are proud to have as our clients, some of the best-of- breed companies across verticals like Manufacturing, Automotives, Banking and Finance, Oil and Gas, Food Processing, Electronics, Telecommunications, Chemicals, Health and Pharma, Education and more.

With a team of 1000+employees, we are present in India with 3 development centers at Bengaluru, Mumbai & Pune and offices in the U.S., U.K., Australia, Dubai, Netherlands and Singapore.

Know more about the LEADER of: Gartner’s 2013, 2015 & 2017 Magic Quadrant for Strategic Sourcing Application Suites and The Forrester Wave™: eProcurement, Q2 2017

We are in process of launching Merlin A.I. Studio™.

The artificial intelligence (AI)-based platform will allow procurement teams to to build and deploy bots across the source-to-pay process.

The bots will be used by firms leveraging more than 1,100 APIs from Zycus’ solution suite.

“By deploying the intelligent bots from Merlin A.I. Studio™, procurement can put themselves in cruise control mode as the bots work towards accomplishing tasks with zero human intervention,” The Fortune 500-serving firm explained in its press release

“Be it running an RFI event, discovering contract risks, negotiating with suppliers or transnational procurement; all one needs to do is launch the bot and see the magic unfold.”

“It will empower procurement to transform their routine, repetitive & mundane procurement tasks, so that time, effort & resources can be optimized towards more strategic initiatives.”Exp : 1 to 10 Years

Role : Data Scientist

Location : Bangalore

Drive Timings : 9 AM to 2.00 PM

Education : Any Engineering From IIT ,NIT , IIIT ,VIT , BITS Pilani

Venue Details :

ZYCUS INFOTECH PRIVATE LIMITED

SEZ UNIT,6TH FLOOR,GARNET Building,

Bagmane Developers Pvt Ltd SEZ II,

Bagmane World Technology Centre SEZ,

Mahadevapura,Outer ring Road,

KR Puram Hobli, Bengaluru (Bangalore) Urban,

Karnataka, 560048

Contact Person : Priyanka

Contact Number : 7899408877

Please carry your original ID proof along with Hard Copy of Resume

Requirements

We are especially looking for applicants with a strong background in Analytics and Data mining (Web, Social and Big data), Machine Learning and Pattern Recognition, Natural Language Processing and Computational Linguistics, Statistical Modelling and Inferencing, Information Retrieval, Large Scale Distributed Systems and Cloud Computing, Econometrics and Quantitative Marketing, Applied Game Theory and Mechanism Design, Operations Research and Optimization, Human Computer Interaction and Information Visualization. Applicants with a background in other quantitative areas are also encouraged to apply. If you are passionate about research and developing innovative technologies of interest to Zycus and the research community at large, the BigData Experience Lab may be the right place for you.

All successful candidates are expected to dive deep into problem areas of Zycus’s interest and invent technology solutions to not only advance the current products, but also to generate new product options that can strategically advantage Zycus

Skills
Master’s or Ph.D. in statistics, mathematics, or computer science
Only from Tier 1 Colleges
Experience using statistical computer languages such as R, Python, SQL, etc.
Experience in statistical and data mining techniques, including generalized linear model/regression, random forest, boosting, trees, text mining, social network analysis
Experience working with and creating data architectures
Knowledge of machine learning techniques such as clustering, decision tree learning, and artificial neural networks
Knowledge of advanced statistical techniques and concepts, including regression, properties of distributions, and statistical tests
1- 10 years of experience manipulating data sets and building statistical models
Experience using web services: Redshift, S3, Spark, DigitalOcean, etc.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.
Experience visualizing/presenting data.
Data Scientist will report in to Director Engineering - Data Scentist & the roles & responsibilities are as below:
Work as the data strategist, identifying and integrating new datasets that can be leveraged through our product capabilities and work closely with the engineering team to strategize and execute the development of data products
Execute analytical experiments methodically to help solve various problems and make a true impact across various domains and industries
Identify relevant data sources and sets to mine for client business needs, and collect large structured and unstructured datasets and variables
Devise and utilize algorithms and models to mine big data stores, perform data and error analysis to improve models, and clean and validate data for uniformity and accuracy
Analyze data for trends and patterns, and Interpret data with a clear objective in mind
Implement analytical models into production by collaborating with software developers and machine learning engineers.
Communicate analytic solutions to stakeholders and implement improvements as needed to operational systems
Benefits

Along with a competitive compensation structure, Zycus believes in an open culture learning environment, where everyone gets a chance to share their ideas and deliver par excellence. Here's a sneak peek to our life at Zycus.",3.4,"Zycus
3.4",Bengaluru,"Princeton, NJ",501 to 1000 employees,1998,Company - Private,Computer Hardware & Software,Information Technology,₹500 million to ₹1 billion (INR),"SAP Ariba, GEP, Coupa Software Inc"
Data Scientist,-1,"Looking for:
Strong background in Machine Learning and Statistics.
Fluency in Python and R programming language.
Good understanding of Relational & Non- Relational database and SQL.
Familiar with Tensor Flow, OpenCV and Tesseract OCR.
1-3 years of relevant experience.
Good communication skills.
Portfolio/Demoable project from previous experience.

Responsbilities:
Work on projects related to healthcare.
Build models and analyze medical data collected from healthcare devices and apps.
Build models and tools for analyzing pills and different medicine images.
Expose this data to mobile and web apps to build feature set.

Job Perks:",4.6,"Cumulations Technologies
4.6",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data scientist,-1,"Are you looking at developing future leaders? Come join us at Siemens.

At our Bengaluru Hub nearly 1100 employees provide various types of services – Finance, HR, IT, Supply Chain, Customer Care - to more than 60 Siemens entities across the world, We are global business solutions, that supports Siemens companies worldwide to achieve perfection in their internal process allowing our colleagues to fully focus on their business.

Change the future with us
You will Work with large, complex data sets and applying advanced analytical methods as needed
You will be Developing custom data models and algorithms to apply to data sets.
You will Run PoCs and Pilots projects to investigate and prove the feasibility and benefits of the proposed solutions
You should Interact with multiple partners (from various levels) and optimally present findings by exploiting visual displays of complex quantity information in a simplified way
You will Identify and develop intelligent and innovative data analytics use cases to optimize business processes
You will be the partner of choice regarding technology advisory for advanced analytics
You should Actively and proactively perform market/trend scouting to stay up to date on the state-of-the-art technologies
We don’t need superheroes, just super minds
You should have Knowledge in advanced data analytics/data science
You should Know-how on Extract, Transform and Load (ETL) of Big Data in enterprise environments (e.g., SAP, Oracle), cloud infrastructure (e.g., AWS, Azure), as well as familiarity of data architecture requirements and conceptual approaches for deploying algorithmic solutions in Big Data productive environments
You should be Comfortable working in programming languages like SQL, Python and R, as well as with frameworks like Tensorflow and Keras; experience designing solutions in distributed teams using Version Control tools like GIT
You should have Experience with cloud technologies: Amazon Web Services and/or Microsoft Azure
You should have Very good communication and presentation skills
We’ve got quite a lot to offer. How about you?

This role is based in Bangalore. But you’ll also get to visit other locations in India and globe, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we encourage applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and creativity and help us craft tomorrow.

Find out more about Siemens at: www.siemens.com/careers


Organization: Global Business Services

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Scientist,-1,"Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases to drive optimization and improvement of product development marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences revenue generation ad targeting and other business outcomes.
Develop company A or B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.

Qualifications For Data Scientist

Strong problem solving skills with an emphasis on product development.
Experience using statistical computer languages .R SAS Python SLQ etc.. to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques .clustering decision tree learning artificial neural networks etc.. and their real-world advantages or drawbacks.
Knowledge of advanced statistical techniques and concepts .regression properties of distributions statistical tests and proper usage etc.. and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
We’re looking for someone with 4-7 years of experience manipulating data sets and building statistical models has a Master’s or PHD in Statistics Mathematics Computer Science or another quantitative field and is familiar with the following software or tools:
Coding knowledge and experience with several languages: C C++ Java
JavaScript etc.
Knowledge and experience in statistical and data mining techniques: GLM or Regression Random Forest Boosting Trees text mining social network analysis etc.
Experience querying databases and using statistical computer languages: R SAS Python SLQ etc.
Experience using web services: Redshift S3 Spark DigitalOcean etc.
Experience creating and using advanced machine learning algorithms and statistics: regression simulation scenario analysis modeling clustering decision trees neural networks etc.
Experience analyzing data from 3rd party providers: Google Analytics Site Catalyst Coremetrics Adwords Crimson Hexagon Facebook Insights etc.
Experience with distributed data or computing tools: Map or Reduce Hadoop Hive Spark Gurobi MySQL etc.",3.8,"Mindtree
3.8",Chennai,"Bengaluru, India",10000+ employees,1999,Company - Public,IT Services,Information Technology,₹50 to ₹100 billion (INR),"Infosys, Tata Consultancy Services, Wipro"
Data Scientist,-1,"Function : Clustr

Experience : 3-7 yrs

Why should you join us?

Work in an exciting start-up that builds first-of-its-kind product and services

Access to a unique dataset covering > 85% of SMEs with unmatched diversity and complexity

Opportunity to build truly state-of-the-art algorithms and insight engines that consume and digest complex “Big” data and extract value out of them

Learning and exposure to multiple engineering areas (including Big Data technologies, DevOps) surrounded by a top-quality team

Accelerate your career in a fast-paced, open, non-hierarchical working environment

The Data Science team at Clustr builds algorithms and Machine Learning models that sit at the core of the company’s value proposition. This is a team of intellectuals with high aptitude, hacker attitude, strong curiosity about data, great comfort with Math, good coding discipline and excellent communication skills.

What will you be doing?

Data Scientist will be in-charge of the following stages: translating a business problem to a DS problem, scope definition, data cleaning, explorations, feature engineering, feature selection, modeling, building prototype, documentation of an algorithm and insights, will also help with data collection and algorithm quality monitoring

Involvement in all stages of the development cycle - building scalable machine learning models for various problems in the areas of information extraction, entity resolution and linking, knowledge base curation, machine translation, information retrieval and others

Who are we looking for?

MS/M. Tech or BE with 3+ years of experience in Data Science, Machine Learning or NLP

Experience of working on production-grade machine learning-based solutions would be a plus

Prior publication record at AI/ML conferences would be a plus

Given a DS/ML problem, hypothesize, iterate and evaluate solution options

Good communication skills and ability to work with stakeholders across business, PM, and Engineering

Excitement & curiosity around data in general “Hacker” attitude with “go-getter” mind-set

Comfort with Math and Statistics

Broad understanding of Machine Learning techniques

Very good coding skills in any of these languages: R, Python, Matlab, Java, C and Machine Learning libraries like scipy, numpy, pyspark, tensorflow etc

Basic knowledge of Big Data stack: Spark, Cassandra, Map-Reduce, S3

Prior experience with start-up environment preferred
Ready to join Clustr?
If you fit the bill, email your resume to careers@clustr.co.in with the position name in subject line",4.5,"Clustr
4.5",Bengaluru,"Bengaluru, India",1 to 50 employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"NLP, ML, Python/R, Hadoop, strong mathematical bacground
If you are intrested, please send us your resume at hr@teqnirvana.com",4.2,"TEQNirvana
4.2",Mumbai,"Bengaluru, India",1 to 50 employees,2005,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Scientist,-1,"RequirementsBS/MS degree in Computer science, MathsYou are experienced with data stores such as Mysql, MongoDB, Cassandra, HBase, HiveExperienced with data visualisation tools, such as Tableau, D3.js, GGplot, etcPast experience with Deep Learning/NLP would be an advantage (although not necessary)Good Communication SkillsTeam PlayerWhat We Expect.?You take pride in your knowledge of design patterns, algorithms and data structuresYou are comfortable processing, cleansing, and verifying the integrity of data used for analysisYou understand machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, CART, CHAID etcYou understand feature selection, model performance metrics, building and optimizing machine learning modelsYou are good at doing ad-hoc analysis and presenting results in a clear mannerYou are good at creating automated anomaly detection systems and constant performance trackingYou can code comfortably in R & Python (NumPy, sklearn, xgboost)",5.0,"Pivotchain Solutions
5.0",Maharashtra,"Viman Nagar, India",1 to 50 employees,2017,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"KEY RESPONSIBILITIES :
Using techniques from supervised and unsupervised machine learning, statistical analysis and predictive modelling to deliver business insights to business units based on data
Working directly with internal customers to educate them on “moving beyond BI” and training their internal resources to execute advanced forms of analytics
Creating reusable implementations of statistical tests and models using cutting edge technologies
Working with the academic and business community to develop new techniques and to contribute to research in the area of advanced analytics in media
Assisting in engagement management, requirements definition, project scoping, timeline management, and results documentation to ensure professional relationship management

PERFORMANCE MEASURES :
As per role KPIs

QUALIFICATION :
2-8 Years plus post qualification
Degree in computer science with a machine learning focus (other technical degrees also accepted e.g. applied mathematics, statistics, physics, operations research). PhD will be desirable.

KNOWLEDGE AND SKILLS :
Advanced knowledge of statistical and machine learning methods, particularly in the areas of modelling and business analytics
Strong programming skills
Experience with statistical languages and packages, such as R, SAS, Mat-Lab, and/or Mahout
Experience working with relational databases and/or distributed computing platforms, and their query interfaces, such as SQL, MapReduce and Hive.
Experience with additional programming languages, such as Python, Java, and C/C++.
Excellent written and verbal communications skills, with a proven ability to translate complex methodologies and analytical results to higher-level business insights and key take-away
A proven passion for generating insights from data, with a strong familiarity with the higher-level trends in data growth, open-source platforms, and public data sets.
Experience working hands-on with large-scale data sets
Familiarity with visualization software and techniques (including Tableau), and business intelligence (BI) software, such as Micro-strategy, Cognos, Pentaho, etc.

PERSONAL ATTRIBUTES :
Creative, gritty, driven by curiosity and comfortable with failure
Strong Data intuition: Talent to identify and visualize patterns
Multi Modal Communication skills",4.0,"Star India
4.0",Mumbai,"Mumbai, India",51 to 200 employees,-1,Company - Private,Film Production & Distribution,Media,Unknown / Non-Applicable,-1
Data Scientist,-1,"The thrill of working at a start-up that is starting to scale massively is something else.

Simpl (getsimpl.com) was formed in 2015 by Nitya Sharma, an investment banker from Wall Street and Chaitra Chidanand, a tech executive from the Valley, when they teamed up with a very clear mission - to make money simple, so that people can live well and do amazing things. Simpl is the payment platform for the mobile-first world, and we’re backed by some of the best names in fintech globally (folks who have invested in Visa, Square and Transferwise), and has Joe Saunders, Ex Chairman and CEO of Visa as a board member.

Everyone at Simpl is an internal entrepreneur who is given a lot of bandwidth and resources to create the next breakthrough towards the long term vision of “making money Simpl”. Our first product is a payment platform that lets people buy instantly, anywhere online, and pay later. In the background, Simpl uses big data for credit underwriting, risk and fraud modelling, all without any paperwork, and enables Banks and Non-Bank Financial Companies to access a whole new consumer market.

Job Description :

Responsibilities:
Work with business stakeholders in the organization to identify avenues to take data backed decisions.
Collaborate with product and engineering teams for carrying out experiments and accommodating new changes to the data platform.
Transform the business problem into a mathematical one to leverage cutting edge techniques in machine learning and optimization.
Test hypothesis, generating insights, performing root cause analysis, factor analysis.
Statistical model (predictive & prescriptive) development using various statistical & machine learning techniques/algorithms.
Develop processes & tools to monitor and analyse model performance & accuracy.
Data Extraction from Big Data Platform, Dataset Preparation (creation of base data, aggregation, transformation), performing Exploratory Data Analysis.
Write clean & easy to maintain code and productionise it.
Requirements:
Strong problem solving skills
Deployed at least one industrial project using supervised / unsupervised machine learning.
Good programming skills with clarity in fundamentals - preferably Python
Knowledge of Python Libraries like Scipy, Numpy, Pandas, IPython, Scikit-learn is a plus
Proficient with SQL and relational databases
Proficient with git
Familiarity with infrastructure tools like AWS EC2, AWS EMR, AWS Redshift, Redis, Kafka is a plus
Good communication skills",4.3,"Simpl
4.3",Bengaluru,"Bengaluru, India",51 to 200 employees,2015,Company - Private,Financial Transaction Processing,Finance,Unknown / Non-Applicable,-1
Data Scientist-1,-1,"Required Technical Skills
Good understanding of machine learning (both analytics and engineering).
Hadoop and big data technologies skills, streaming technology.
Robotics Process Automation techniques.
Artificial Intelligence.
Analytical mindset.
Good in Data Structure.
Good in Problem solving.
Preferred Technical Skills
Deep understanding of statistics and ML algorithms work internally with proficiency in at least 2 supervised and unsupervised algorithms in each bucket.
Supervised algorithms : Regression [linear/polynomial], Decision Tree, Random Forest or classification [Logistic Regression, Naïve Bayes, SVM etc]
- Model design and implementation : Experience in deriving feature sets, model training and testing

- Preferred tools and programming languages: TensorFlow/Keras, Python

- Exposure to Deep Learning and NLP is an added advantage.

Required Soft Skills
A team player who values collaboration, innovation, and inclusion.
Interested in keeping update with the latest technological developments.
Comfortable working in an Agile environment.
Strong verbal and written communication skills.
Interest in the payments industry.",3.5,"PayPal
3.5",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Data Scientist,-1,"Data Scientist


Full time

-

Pune

The Company


Talentica Software is a boutique software development company started by ex-IITB grads and industry veterans. It is a privately held company. The company is 16 years old and 400+ employees work exclusively for startups as Tech Partners taking them from a Series-A position to Series-B position and possible acquisition (for example Citrus Pay).
We have built products for over 125 startups, most of them are based in the Bay Area or Europe. These startups come to us primarily because we know the issues that plague startup product development and the solutions for the same, thereby improving their success chances. Owing to the unique space we are in, we deal extensively with cutting edge technology.

The data science team works under the purview of the Technology Excellence Group at Talentica Software. The goal of this team is to solve problems and build algorithms that are typically data driven. Hence, problems involving statistics, optimization, computer vision, machine learning, and natural language processing are of interest to this group.

We are looking to hire a Data Scientist with Computer Vision and Machine Learning experience.

Here is what we are looking for in prospective candidates: Mandatory
Has completed his/her PhD from one of the old IITs or IISc-Bangalore
Should have completed full-time PhD degree
Graduated from IIT or IISc or IIIT-Hyderabad or ISI-Kolkata with a Master’s degree
Should have at least one published full paper in CVPR or ECCV or ICML or NIPS
Excellent programming skills and must be able to implement complex algorithms in Python
Hands-on experience with use of standard image processing and machine learning libraries such as OpenCV, Tensorflow, Keras

Here is what we are looking for in prospective candidates: Good to have
Graduated from IIT-Bombay or IISc-Bangalore or IIT-Delhi
Not required for the current role but it is good to have worked with Mongo/Cassandra/PostgreSQL/Neo4J
Credited courses focused on linear algebra, stochastic models, pattern recognition, design and analysis of algorithms, machine learning
Interest in applications of computer vision algorithms for video, shape recognition, matching & retrieval

Experience:
Should have worked in the industry for at least 2 years.
Should like to work in a startup environment.
Should be capable of converting theory to practice by reading relevant papers.
Should be capable of conceiving original ideas and coding them as working algorithms.",3.8,"Talentica
3.8",Pune,"Pune, India",201 to 500 employees,2003,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Atonarp is looking for self-motivated scientists & engineers to join our supercharged workplace and build a first generation analytical product. If you are a geek about anything - algorithms, math, machine learning, data wrangling/visualizing, high performance computing, scientific computing & tools, or anything else you can convince us about - we want to meet you!

What you'll be doing
Individual technical contributor with self-drive to understand problem statements and make design decisions – ‘own’ what you do, make your calls, and defend them
Build a first generation analytical software product – design, code, test (unit & functional) and maintain the software, while proving that your implementations ‘work’
Implement software engineering processes and discipline for fast and reliable development of high-quality software product – make the software ‘elegant’
Work as a team player in a high performance environment that rewards ownership – make your opinion count withing the team and the organization
What we need to see
Bachelors or Masters in CS / Electronics from a premier institute with 4-7 years of industry experience
Solid design, excellent programming and debugging skills on a Unix-based OS (Ubuntu, Fedora, OSX) and fluency with a DVCS like Git.
Programming Languages: Python, C++
Deal-clinchers

Any of these – more the better!
Skilled with python packages: scikit-learn, pandas, numpy and scipy
Understanding of common algorithms and their application in solving real-world problems
Strong mathematical background in linear algebra, optimization and descriptive & inferential statistics
Understanding of machine learning concepts like generalization, regularization, linear models, neural network and expertise with using data to build systems based on machine learning techniques",3.6,"Atonarp
3.6",Bengaluru,"Tokyo, Japan",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Family Descriptor
Level Descriptor
Data Scientist is responsible for analyzing data and developing forward-looking business solutions for TCL’s SCM function. He / She would need to evaluate and find areas of improvement in SCM’s way of working basis data. He / She is responsible for bringing scientific rigor and statistical methods to the challenges of strategic procurement.

He / She would be responsible for working closely with internal stakeholders such as Sourcing, Operations, and Logistics teams to produce innovative and actionable quantitative models and analyses to achieve the goals of cost leadership and business velocity. He / She would be required to have a customer-centric approach when helping TCL attain its business goals while building long-term capabilities. He / She would need to have a thorough understanding of how SCM functions interact with each other, with Product / Engineering teams and with external stakeholders such as vendors to create actionable solutions.

He / She would need to drive effective written, verbal, and visual presentation to concisely communicate in a way that provides context, offers insights, and minimizes misinterpretation. He / She would need to be a self-starter, quick learner, and be able to work independently. He / She would need to demonstrate attention to detail and resourcefulness. This is a pivotal role that embraces and promotes a change mindset and driving a change to move away from traditional reporting.
Purpose - Broad objective of the role
Operating Network - Key External
Data Scientist is responsible for analyzing data and developing forward-looking business solutions for TCL’s SCM function. He / She would need to evaluate and find areas of improvement in SCM’s way of working basis data. He / She is responsible for bringing scientific rigor and statistical methods to the challenges of strategic procurement.

He / She would be responsible for working closely with internal stakeholders such as Sourcing, Operations, and Logistics teams to produce innovative and actionable quantitative models and analyses to achieve the goals of cost leadership and business velocity. He / She would be required to have a customer-centric approach when helping TCL attain its business goals while building long-term capabilities. He / She would need to have a thorough understanding of how SCM functions interact with each other, with Product / Engineering teams and with external stakeholders such as vendors to create actionable solutions.

He / She would need to drive effective written, verbal, and visual presentation to concisely communicate in a way that provides context, offers insights, and minimizes misinterpretation. He / She would need to be a self-starter, quick learner, and be able to work independently. He / She would need to demonstrate attention to detail and resourcefulness. This is a pivotal role that embraces and promotes a change mindset and driving a change to move away from traditional reporting.
Operating Network - Key Internal
Size and Scope of Role - Financial
Size and Scope of Role - No. of direct reports
Size and Scope of Role - Total team size
Size and Scope of Role - Other size parameters
Minimum qualification & experience
Bachelor’s Degree in quantitative disciplines (e.g., Engineering, Statistics, Computer Science)
3 - 5 years of work experience in vendor data analysis related field in procurement department / supply chain managment
Experience in articulating and translating business questions and using statistical techniques to arrive at an answer using available data
Strong understanding of fundamentals of finance and accounting such as debit/credit and opex/capex expenses etc.,
Demonstrated skills in selecting the right statistical tools given a data analysis problem
Ability to visualize models and results to provide data-driven insights (PowerBI experience is preferred)
Demonstrated resourcefulness, self-direction, attention to detail, meticulous
Change management and automation experience is mush
Ability to handle larget data sets and drive insights to support informed management decisions
Preferred
Master's degree in Engineering, Statistics, Mathematics, Economics or an Applied Science or equivalent practical experience
Experience with statistical software (e.g., R, Python, MATLAB, pandas) and database languages (e.g., SQL)
Experience in delivering bespoke analytics to stakeholders
Experience in using and/or deploying digital analytics and measurement solutions
Other knowledge/skills
Key Responsibilities
Data Management &Analysis:

Work effectively with large, complex datasets to derive actionable insights
Conduct analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables, and presentations
Solve difficult, non-routine analysis problems, applying advanced analytical methods as needed
Leverage data to identify potential supply chain risks

Innovative Solution&Group:

Leverage data analytics and visualization tools to propose innovative solutions for growth, aligned with overall TCL objectives and KPIs
Translate data and model results into tactical and strategic insights that are clear, complete, accurate, relevant, understandable, and applicable to decision-making and needs of varying stakeholders

Stakeholder Management:

Interact cross-functionally, making business recommendations (e.g., cost-benefit, forecasting) with effective presentations of findings at multiple levels of stakeholders through visual displays of quantitative information
Make presentations to internal stakeholders to integrate recommendations into business processes
Lead and/or participate in cross-functional team projects
Technical Competencies
Knowledge / Skills
Communication Skills

Job Segment:
Database, Scientific, Engineer, Computer Science, Supply, Technology, Engineering, Operations",3.8,"Tata Communications
3.8",Mumbai,"Mumbai, India",5001 to 10000 employees,-1,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,₹500+ billion (INR),-1
Data Scientist,-1,"Primary role

Staying abreast with the latest techniques and algorithms used in data analytics and overseeing their adoption by delivery teams. Leading in house efforts in researching newer and novel analytics methodologies. Expected to be actively involved in all stages of solution delivery to the client.

Secondary role

Mentoring junior staff.

Basic skills

An expert in any two or more of the following; Machine learning, Operations research, Agent based modeling, game theory, statistics or similar methodologies.

A strong experience with at least one of the following; R, Matlab, SAS, SPSS or similar packages.

A basic knowledge of one of the following; Python, C/C++, Java.

Preferred skills

Experience with analyzing actual business data.

Domain knowledge of industry verticals (such as healthcare, telecom etc.)

Education

PhD or MS (with peer reviewed publications) in a quantitative field, such as Physics, Machine Learning, Artificial Intelligence, Statistics, Mathematics, Engineering, etc.

If interested, kindly send your cv on hr@gaugeanalytics.com",3.1,"Gauge Data Solutions
3.1",Noida,"Noida, India",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Work with clients to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases, live feeds, third pary sources etc to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Primary Skills: 1. Strong problem solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
We’re looking for someone with experience in manipulating data sets and building statistical models, and is familiar with the following software/tools:
a. Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
b. Experience querying databases and using statistical computer languages: R, Python, SLQ, etc.
c. Experience using web services: Redshift, S3, Spark, DigitalOcean, etc.
d. Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.
e. Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.
f. Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.
g. Experience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.

Secondary Skills: a. Coding knowledge and experience with several languages: C, C++, Java, JavaScript, etc.
b. Experience in multiple industry verticals will be an added advantage.

Soft Skills: a. Must be good at Client interaction skills.
b. Excellent oral and written communication skills.

Educational Background: Must have Master’s or PHD in Statistics, Mathema
Experience Range: 8 Years - 10 Years
Number of Positions: 2
Timeline: Immediate
Location: Bangalore, India
Travel Needs: Occasional Travel to Client Locations.",-1,Germane Analytics Pvt Ltd,Bengaluru,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"We are building our team to offer business and operations analytics solutions to our international and

domestic clients, and are looking for a Data Scientist with comprehensive knowledge of existing and next

gen analytics tools and technology platforms. Passionate, self-starter and innovative our Data Scientist will

bring expert skills and meaningful experience to fore, focusing primarily on Healthcare, Pharmaceuticals,

Banking, Financial Services & Insurance industry verticals.

Responsible for leading client engagements and People, our Data Scientist will be a problem solver, who

relishes the journey of crafting intelligent client solutions – live to find patterns and insights within structured

and unstructured data. Industrious, analytical and result-oriented, our Data Scientist will be a thinker with

natural desire to go beneath the surface of a problem; understand how the products are developed; and

have statistical, mathematical, predictive modelling as well as business strategy skills to build the algorithms

necessary to ask the right questions and find the right answers – You propose analytics strategies and

solutions that challenge and expand the thinking of everyone around you. With hands-on knowledge of

the business, products, technology, regulatory environment, operations our Data Scientist will continuously

seek fresh challenges to engineer solutions that make valuable client business impacts.

A seasoned professional our Data Scientist will operate in collaboration with cross-industry, cross-function,

experts and be a leading example of the Profisor People Culture, independently managing client

engagements, multiple projects and project teams.

Careers

Responsibilities:
Results-based quality delivery of data analytics solutions and services

Manage multiple client projects, problem statements, and multiple project teams

Organize and manage quality review of data analytics operations delivery

Design & develop client solutions and collaboratively respond to client RFP’s & RFI’s

Lead thought leadership articles – point of views – and business development initiatives

Manage client relationships, client experience and client feedback to resolve engagement issues

Co-develop Profisor People and People career models

Manage team performance reviews, expansion and progression planning and People reporting

Lead analytics capability development, learning and training

Counsel, develop People, and manage talent identification and hiring

Minimum Knowledge, Skills & Abilities Required:
8+ years of experience designing and devising data analytics capabilities and solutions for

Healthcare, Pharmaceuticals, BFSI and or Cross-industry clients

Comprehensive knowledge of Natural Language Processing, Machine Learning, Conceptual Modelling,

Statistical Analysis, Predictive Modelling & Hypothesis Testing

Solution-oriented thinker, capable of managing business and technology challenges

Data driven and highly analytical with working knowledge of compliance and ethical standards and

evolving global regulatory environment

Excellent communication (both written and vocal), problem solving and presentation skills

Good human relations and interpersonal skills to collaborate and manage People with diverse

backgrounds

Additional Knowledge, Skills & Abilities:
Data munging, visualization and communication knowledge

Hands-on knowledge of Lean and Agile delivery techniques

Demonstrated ability to maintain strict confidentiality of internal and external customer information

Desirable Knowledge, Skills & Abilities:
Ph.D. or Master’s degree in operations research, applied statistics, mathematics, data mining, machine

learning, physics or a related quantitative discipline

Management experience in Big Data or Data Analytics practice setup",4.5,"Profisor Services
4.5",Gurgaon,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Editorialist YX’s mission is to provide the most personalized online shopping experience in the world. Our highly client-centric approach uses deep data to take the infinite array of luxury goods available for sale online and to recommend the perfect product based on our clients’ lifestyles, preferences, and wardrobes. We define a luxury experience as one that is super-personalized. Editorialist YX fuses personal styling, content, and shopping in one seamless digital experience driven by proprietary technology, e-commerce tools, and luxury fashion content.

Editorialist YX is looking for a Data Scientist. We are a startup with amazing perks. As part of this role, you would be joining a small focused team that solves hard data science problems. You will be responsible for building machine learning models at scale.
Responsibilities
Collect, clean and analyze data from diverse streams of structured & unstructured data
Extract meaningful insights from data and present it to various stakeholders
Work on end-to-end data science lifecycle: from building proof-of concept models to production-ready models & work with engineers to deploy them to production
Build models that improve accuracy of various processes within our pipeline
Build models to improve search ranking and relevance
Work cross-functionally across different teams to understand business requirements, needs of our audience and that of our clients.
Write elegant machine learning and data analysis code in Python
Build other models including personalization & deep learning models
Be a champion of data driven culture in the company
Requirements
Bachelor’s degree in statistics or data science or related.
2+ years experience as a data scientist or machine learning engineer
Experience in python, SQL
Strong knowledge of mathematics, statistics, probability and machine learning
Experience in spark, hadoop, keras, tensorflow is a big plus
Ability to explain complex concepts in simple terms
High Energy/Startup Mindset
Excellent communication (English) and presentation skills
Willingness to learn
Excellent Team Player
Please submit a cover letter along with your resume.",3.4,"Project YX
3.4",Gurgaon,"Santa Cruz, CA",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Kline, a global management consulting and market research firm, is looking for a Data Scientist. This data science professional will help interpret and draw inferences from the information hidden in vast amounts of data, both internal and external, to make more meaningful and insightful decisions that will enable the delivery of better products and services. This technologist should have a minimum of two (2) years of experience working in the data science field or 2 to 4 years of experience working in the predictive analytics, visualization or other ancillary data science sub-field.

The ideal candidate will come from a services firm engaged in Business Intelligence/Market Research or Business/Management Consulting with a focus on Data Management, Knowledge Services, and Business Analytics.

This individual is expected to: use modern technology and state-of-the-art data mining & analysis techniques to conduct statistical and quantitative analyses and build high-quality prediction systems integrated with Kline’s product and service portfolio, build and enhance predictive modelling data products via proprietary models, utilize machine learning to build competitive recommendation engines comparable to those employed by service firms, and guide and grow the data science team.

Candidates must have excellent English verbal and written communication skills.

Responsibilities
Data mining and analysis using state-of-the-art methods
Building and optimizing classifiers using machine learning techniques
Creating/maintaining automated anomaly detection systems and tracking their performance
Enhancing data collection procedures to include relevant information for analytic solutions
Processing, cleansing, and verifying the integrity of data used for analyses
Interacting with and utilizing Azure cloud databases and on-prem Microsoft databases
Conducting ad-hoc analysis and presenting results using modern data visualizers
Skills and Qualifications
Knowledge of developing machine learning models and applying advanced analytics solutions to solve complex business problems
Proficiency with programming languages: Python, Scala, R, SQL, or equivalent
Proficiency with common data science tools: Scikit-learn, TensorFlow, Keras, PyTorch or equivalent
Proficiency with applied statistics, such as statistical forecasting & testing, regression analysis, and multivariate analysis
Experience in constructing and executing queries to extract data in support of Exploratory Data Analysis (EDA) and model development
Experience with supervised Machine Learning techniques like Multiple Regression, Logistic Regression, Decision Trees, k-nearest neighbors (k-NN), SVM, Ensembles, etc.
Experience with unsupervised Machine Learning techniques like PCA, LDA, k-means, DBSCAN, Autoencoder etc.
Experience with forecasting techniques using Time series methods and causal forecasting methods
Experience with predictive modeling, deploying and monitoring ML solutions in an iterative or Agile/DevOps environment using lifecycle management methods and tools
Experience with analyzing and visualizing data from diverse sources, interpreting results in the business context, and reporting results clearly and concisely using tools like Power BI or Tableau
Familiarity with Microsoft Azure services and tools is a plus
Degree in Statistics/Quantitative Analyses, Computer Science, Mathematics, Operations Research, or other related technical fields with equivalent practical experience
Strong communications skills
Kline offers…
A world-class international work environment located in Hyderabad, India
A dynamic, multi-cultural team and collegial work atmosphere
Practical use of English and valuable work experience with a well-established consulting and market research firm
Kline & Company offers a competitive compensation and benefits package in a supportive work environment. Interested and qualified candidates should apply by submitting their resumes and salary history/salary requirements via our website.

Equal Opportunity Employer, M/F/D/V",2.9,"Kline & Company
2.9",Hyderabad,"Parsippany, NJ",51 to 200 employees,1959,Company - Private,Consulting,Business Services,₹1 to ₹5 billion (INR),"McKinsey & Company, Euromonitor, Frost & Sullivan"
Data Scientist,-1,"Machine Learning & AI - Bangalore, IN

Responsibilities

We are looking for a capable data scientist to join the Analytics team, reporting locally in India Bangalore. This person’s responsibilities include research, design and development of Machine Learning and Deep Learning algorithms to tackle a variety of Fraud oriented challenges. The data scientist will work closely with software engineers and program managers to deliver end-to-end products, including: data collection in big scale and analysis, exploring different algorithmic approaches, model development, assessment and validation – all the way through production.

Qualifications
At least 3 years of hands-on development of complex Machine Learning models using modern frameworks and tools, ideally Python based.
Solid understanding of statistics and applied mathematics
Creative thinker with a proven ability to tackle open problems and apply non-trivial solutions.
Experience in software development using Python, Java or a similar language.
Any Graduate or M.Sc. in Computer Science, Mathematics or equivalent, preferably in Machine Learning
Ability to write clean and concise code
Quick learner, independent, methodical, and detail oriented.
Team player, positive attitude, collaborative, good communication skills.
Dedicated, makes things happen.
Flexible, capable of making decisions in an ambiguous and changing environment.
Advantages:
Prior experience as a software developer or data engineer – advantage
Experience with Big data – advantage
Experience with Spark – big advantage
Experience with Deep Learning frameworks (PyTorch, TensorFlow, Keras) – advantage.
Experience in the Telecommunication domain and/or Fraud prevention - advantage",3.3,"Tomia
3.3",Bengaluru,"Vienna, VA",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Location: Bhubaneswar/

Technology:
Job Descriptions:
Any BE/ B.Tech / M. Tech/ MCA minimum 1-5 year expertise. Good in Mathematics & Statistics (Distributions, Statistical testing, Regression), Machine Learning & Algorithm (k-NN, Naive Bayes, SVM, Decision Forests), R/WEKA/NumPy, Data Visualization tools (D3.js, GGPlot), SQL, Hive, Pig, NoSQL databases (MongoDB, Cassandra, HBase), Good scripting and programming skills

Send your Resume at: hr@silicontechlab.com",3.2,"SILICON TECHLAB
3.2",Bhubaneswar,-1,1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Role: Data Scientist

Data Science @ Tookitaki

The data science team is responsible for solving business problems with complex data. Data complexity could be characterized in terms of volume, dimensionality and multiple touchpoints/sources. We understand the data, ask fundamental-first-principle questions, apply our analytical and machine learning skills to solve the problem in the best way possible. We also encourage to participate in competitions like Kaggle.

Our ideal candidate

We are looking for a junior data scientist who has a deep interest in theoretical and applied machine learning and loves working in a fast-paced environment.

He/she should have 3-5 years' work experience in predictive analytics/forecasting space and have solved real-world problems. Candidates with experience in transactional anomaly prediction, operational risk modelling would be given preference.

The role would be a client facing one, hence good communication skills are a must. The candidate should have the ability to communicate complex models and analysis in a clear and precise manner. The candidate would be responsible for:
Comprehending business problems properly - what to predict, how to build DV, what value addition he/she is bringing to the client, etc.
Understanding and analyzing large, complex, multi-dimensional datasets and build features relevant for business
Understanding the math behind algorithms and choosing one over another
Understanding approaches like stacking, ensemble and applying them correctly to increase accuracy
Desired technical requirements
Proficiency with Python and the ability to write production-ready codes. Experience in Scala would be a plus
Big data experience, e.g. familiarity with Spark, Hadoop, is highly preferred
Familiarity with SQL or other databases.
Desired Non-technical Requirements
Very strong communication skills both written and verbal
Strong desire to work with start-ups
Job Perks

Attractive variable compensation package
Opportunity to work with an award-winning organization in the hottest space in tech - artificial intelligence and advanced machine learning",4.8,"Tookitaki Holding PTE LTD
4.8",Bengaluru,"Singapore, Singapore",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"About Flock

Flock is an enterprise messaging and collaboration app. At Flock we believe that synchronous messaging tools, supported with internal and external applications, have the power to smash organisational hierarchies, breakdown silos in the workplace, help companies better capture innovative ideas, support individuals in making faster decisions, and also bring more personable communication style into the workplace.
With 30,000 businesses already using the platform we know that we are onto something big, and are now gearing up for a period of rapid growth.

Flock is founded by Bhavin Turakhia. Serial entrepreneur and billionaire, Bhavin Turakhia is driven by a passion for problem-solving and maximizing efficiency through technology driven innovations. In the last 22 years, he has built 5 successful businesses, all driven by his belief that “it is our moral obligation to make an impact that is proportionate to our potential”. At 17, he co-founded Resellerclub, Logicboxes and BigRock, which he exited in a $160mn transaction in 2014. He is presently heading Flock - a suite of productivity apps, Zeta - a digital payments platform, and Radix - a leading registry for top-level extensions.

Role Overview
We are looking to hire a data scientist who will work with various cross-functional teams such as product, marketing, engineering, sales and customer success to develop and deliver data structures, statistical models, reports and deep-dive analysis that will provide actionable recommendations for Flock business. We are looking for a problem solver with strong analytical and problem-solving skills who has a good understanding of statistics and machine learning, and able to work on projects from conceptualization to execution.
What is the Job like?
Work with a team of high performing data science professionals, and cross-functional business partners to identify business opportunities, optimize marketing campaigns, drive product road map or go to market strategy
Build automated data dashboards and visualizations to deliver business insights to the senior leadership team
Understand business problems and provide data-driven solutions for those problems
Develop statistical models and data-driven solutions to add lift to key performance metrics
Initiate and drive projects to completion with minimal guidance

Who should apply for this role?
Bachelors or Master’s degree in a quantitative discipline - Statistics, Operations Research, Computer Science, Engineering, Economics etc
4+ years of experience working in data science or business analytics role
Experience working with large amounts of data using SQL, SAS, R or other statistical packages
Experience working in a Unix/Linux environment for automating processes with shell scripting
Experience programming in Python, Java or other programming languages
Experience in data dashboarding and visualization tool like Tableau, PowerBI or QuickSight
Experience in machine learning techniques like regression analysis, decision tree etc. a plus

Benefits and Perks
We at Flock love our jobs. And it’s no surprise – we get to work on exciting, new projects with some of the best brains in the industry, and that too in a vibrant atmosphere that is designed to be comfortable and conducive for our personal and professional growth.

And Flock goes the extra mile to make you feel at home. We offer benefits ranging from affordable catered meals and even snacks on the house. Our workspaces are welcoming and fun, complete with bean bag chairs and ping pong tables. You are free to wear what makes you comfortable and choose the hours you keep, as a team. Oh, and we’ve got your family covered too, with great health insurance plans and other benefits. In short, everything you need to be your best self at work!

We are passionate about helping teams move to the next level of communication and collaboration, and believe that happy employees are key to achieving this goal. If you like the idea of working on cutting-edge technologies and solutions that have a truly global impact, get in touch!",4.2,"Flock
4.2",Mumbai,"Mumbai, India",201 to 500 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Slack, Atlassian, Microsoft"
Data Scientist,-1,"Locations: Bangalore, Data Science & Analytics, Mountain View, New Jersey, New York

Alphonso is a TV data company and the market leader in providing brands and agencies with verified TV audiences across all screens. Alphonso’s TV data platform processes billions of data points every day about TV content and ad viewership, in the US and internationally.

Our best-in-class automated content recognition (ACR) uses advanced fingerprinting technology to identify ads and programming on TV in real time. With the industry’s largest TV data footprint, we map ad exposure data from tens of millions of households to a broad range of third-party data sets such as demographic data, location data, transaction data, web visit data and more, all in a privacy-safe fashion, to help brands understand consumer behavior across the digital and offline realms.

We are looking for data scientists / ML engineers who go above and beyond textbook solutions; critical thinkers who apply their expertise to solve unique problems and draw deep insights from this vast pool of data. You will have the opportunity to drive impact across the board, including making strategic decisions about our products and infrastructure.

Responsibilities:
Develop scalable data models, machine learning algorithms to facilitate data-driven decision making
Take advantage of massive amounts of structured data to understand end user behavior and help our advertising customers get better bang for the buck
Design and evaluate experiments
Use AI/deep learning techniques in conjunction with our ACR technology to extract deep insights
Be a thought leader and go-to expert on everything data

Requirements:
MS/PhD in Computer Science, Statistics, Engineering, or another relevant quantitative field
Experience with machine learning algorithms and/or statistical modeling
Proficiency in Python/R/Scala or other programming languages
Familiarity with Big data technologies like Hadoop, Map/Reduce, Spark, Hive etc. is a plus",4.1,"Alphonso
4.1",Bengaluru,"Mountain View, CA",51 to 200 employees,2012,Company - Private,TV Broadcasting & Cable Networks,Media,Unknown / Non-Applicable,-1
Data Scientist,-1,"Experience

1 to 4 years.

Roles and Responsibilities
Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Qualifications
Strong problem solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
Technologies and tools needed
R, Python, SQL.",-1,CogniSure,Bengaluru,"Warrenville, IL",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Requirements
Should have good knowledge of statistics and machine learning techniques
Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value
Should have good problem solving skills
Should have working knowledge or experience with tools such as R, Matlab etc
Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem
Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner

Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques.
Data mining using state-of-the-art methods.
Extending company’s data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis.
Doing ad-hoc analysis and presenting results in a clear manner.
Creating automated anomaly detection systems and constant tracking of its performance

Skills and Qualifications
Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc...
Experience with common data science toolkits, such as R, Matlab, Python related etc.
Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard
Proficiency in using query languages such as R, SQL etc. Experience in Python is plus
Experience with various sdks like mitie, dib, stanford NLP, etc are preferred
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise
We’re looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Master’s or PHD in Statistics, Mathematics, Computer Science or another quantitative field",3.8,"IQLECT
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Data Scientist

Advanced Analytics - Data Scientist will execute advanced computational approaches to accelerate and optimize evidence-based pharmaceutical product development. He/She will leverage high-dimensional population health data to support R&D, Medical, HEVA, commercial product development, access and business strategy. The Advanced Analytics Data Scientist roles will generate analytics required by healthcare decision makers to support patient access and use of Sanofi medicines and he/she will contribute to the insights required by Sanofi internal teams to develop and commercialize the most impactful medicines.

People
Contribute to the Advanced Analytics plans for projects across R&D, Medical Affairs, HEVA and Market Access Strategies and Plans
Performance
Work with the latest tools and technologies that impact drug development.
Leverage analytics involving large datasets to refine and improve data models.
Build and construct prototypes of Advanced Analytic work-flows.
Process
Apply a broad array of capabilities spanning machine learning, statistics, text-mining/NLP, and modelling to extract insights to structured and unstructured healthcare data sources, pre-clinical, clinical trial and complementary real-world information streams.
Work on a variety of team-based projects providing expertise in analytical and computational approaches.
Design and implement data models, perform statistical analysis and create predictive analysis models
Required Skills & Experiences:
Experience with open source technologies, ML libraries, and programming languages (R, python)
Experience with advanced ML techniques - neural networks/deep learning, reinforcement learning, SVM, PCA, etc.
An ability to interact with a variety of large-scale data structures e.g. HDFS, SQL, noSQL
Experience working across multiple compute environments to create workflows and pipelines (e.g. HPC, cloud, Linux systems)
Experience with any of the following: biomedical data types/population health data/real world data/novel data streams.
Strong oral and written communication skills
A demonstrated ability to work and collaborate in a team environment
Desirable Skills & Experiences:
Experience with reproducible and collaborative technology platforms (e.g. GitHub, containers, Jupyter notebooks)
Experience with big data analytics platforms and/or workflow tools
Exposure to NLP technologies and analyses
Knowledge of some datavis technologies (ggplot2, shiny, plotly, d3, Tableau or Spotfire)
Qualifications
Relevant Masters degree, with at least 2-3 years of relevant industry experience (level II), or Masters degree with relevant Essential Skills and Experience (level I)
At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all.",3.7,"Sanofi
3.7",Mumbai,"Paris, France",10000+ employees,1973,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Pfizer, GlaxoSmithKline"
Data Scientist,-1,"• Good Knowledge on the automotive Communication protocols like CAN, Flex ray
• Sound knowledge on the Driver assistance systems (feature functions like lane departure prevention, collision avoidance etc.)
• Practical knowledge of automotive sensors like Camera, RADAR etc.
• Testing, Debugging and validation of application software as per the Requirement (in DOORS)

Additional skills: (Optional)
• Overview on Ethernet communication protocol
• Hands on with visualization tools for sensors
• Good Overview on analyzing time series data, (ASC, MAT, DAT file),
• Good knowledge on latest trends like LIDARs and multi-mode RADARs.
• Knowledge on Atlasian tools like Confluence, JIRA etc.

• Good Knowledge on the automotive Communication protocols like CAN, Flex ray
• Sound knowledge on the Driver assistance systems (feature functions like lane departure prevention, collision avoidance etc.)
• Practical knowledge of automotive sensors like Camera, RADAR etc.
• Testing, Debugging and validation of application software as per the Requirement (in DOORS)

Additional skills: (Optional)
• Overview on Ethernet communication protocol
• Hands on with visualization tools for sensors
• Good Overview on analyzing time series data, (ASC, MAT, DAT file),
• Good knowledge on latest trends like LIDARs and multi-mode RADARs.
• Knowledge on Atlasian tools like Confluence, JIRA etc.",4.2,"Daimler
4.2",Bengaluru,"Stuttgart, Germany",10000+ employees,1886,Company - Public,Transportation Equipment Manufacturing,Manufacturing,₹500+ billion (INR),"Audi, Porsche, BMW"
Data Scientist,-1,"Brief:
This is a highly unique opportunity for a Data Scientist to join a new and rapidly growing team. In this role, you will partner with our close-knit team of quantitative researchers, data engineers, technologists, and data sourcing colleagues to analyze and enrich a broad range of structured and unstructured big data.

Responsibilities:
Enriching a wide range of structured and unstructured data into datasets for quantitative analysis
Enhancing data quality & integrity via a process-orientated approach; developing validation tools to measure the effectiveness of data enrichment; taking full ownership of end-to-end data workflows
Becoming a domain expert on different fundamental datasets, analyzing & understanding the underlying dynamics and behaviors within the data
Communicating data-driven analysis and insights into the team
Developing the utility tools that can further automate the software development, testing, and deployment workflow, that facilitate the team’s research efforts
Using your expertise to provide technical support for global researchers, including diagnosing root causes of technical problems and proposing solutions to developers

Requirements:
At least 3 years of experience as a data engineer or software developer
Strong academic background – a minimum of a bachelor’s degree in a technical or quantitative field
Outstanding software development and data analysis skills
Demonstrated ability to program in C++ and developing real-time applications on Linux/Unix platforms
Familiarity with scripting languages such as Python and Linux shell; and data analysis tools/languages (R, Matlab, Tableau)
Experience in finance or investing related background preferred
Excellent communication skills; both written and oral English
Exceptional analytical & problem-solving abilities, with strong attention to detail
Motivated by a deep curiosity and passion to learn",3.8,"Aquis Search
3.8",Mumbai,"Hong Kong, Hong Kong",51 to 200 employees,2009,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"Company Overview

Fanatics is the global leader in licensed sports merchandise and changing the way fans purchase their favorite team apparel and jerseys. Through an innovative, tech-infused approach to making and selling fan gear in today's on-demand culture, Fanatics operates more than 300 online and offline stores, including the e-commerce business for all major professional sports leagues (NFL, MLB, NBA, NHL, NASCAR, MLS, PGA), major media brands (NBC Sports, CBS Sports, FOX Sports) and more than 200 collegiate and professional team properties, which include several of the biggest global soccer clubs (Manchester United, Real Madrid, Chelsea, Manchester City). Fanatics offers the largest collection of timeless and timely merchandise whether shopping online, on your phone, in stores, in stadiums or on-site at the world's biggest sporting events.

About the Team

Fanatics is first and foremost a technology company. We are powered by cutting-edge tech created by our small agile teams using the latest tools and technologies under our highly analytical, forward thinking, and open-minded leadership. As the global leader in licensed sports merchandise, we challenge ourselves by improving our new fully responsive NodeJS cloud commerce platform, Elasticsearch engine, and deep data science capabilities while building the best-in-class retail manufacturing and supply chain technologies. Our tech teams work together to revolutionize data science and engineering initiatives, provide highly scalable real-time and streaming platforms, and create secure e-commerce and in-stadium fan experience products. Our own e-commerce platform transacts in over 190 countries, 17 languages, and 14 currencies. Our motto is “#GSD”—get stuff done—and we do just that. If you want to be at the nexus of sports, commerce, and technology, come be a part of our industry-leading team here at Fanatics Tech.

About the Team and Role:
Fanatics data science group is a young supply chain research and development team. Our focus is on growing the Fanatics business by providing supply chain knowledge and data-driven solutions using state-of-art AI/ML and deep learning algorithms. The primary engagement is building production scale data-science modules. Our team is looking for strong and enthusiastic data scientist with domain knowledge of supply chain process to join us. The responsibility of the Data Scientist may also be including implementation and deployment of production scale time series models. The individual should be capable of carrying research and development work using active research areas in time series forecasting (Bayesian Forecasting, Deep learning Methods). The person will be responsible for building technical and business reports on daily/weekly basis. Team is backed by strong business leaders in supply chain research & development, thus a foundational mentorship will be provided. Based on past experience the individual may also be engaging in business meetings and coordinate cross-functional technical discussions.
What You’ll Do:
• Create data-science and machine learning products in supply-chain and inventory space,
• Build & deploy production scale models on large-scale datasets using machine learning (or) deep learning technologies for Supply Chain research,
• Work with cross-functional teams to implement and deploy data science products,
• Leverage large scale data processing such as Spark, Hive into the data-science products,
• Provide analysis using mathematical modeling tools to improve business processes and decisions,
• Define creative solutions to business problems using advanced mathematical algorithms,
• Communicate with senior management and cross-functional teams, and
• Facilitate deep technical discussions with end-users and partners.
What You’ll Need:
1. Masters (or) PhD in Computer Science, Statistics, Operations Research, Economics, or other quantitative discipline strongly preferred,
2. Experience in research and development. Conference papers at reputed AI/ML platforms (ICML, NIPS, AAAI) will be a big plus,
3. Experience in Time series modeling (classical methods like ARIMA, STL Forecast). Understanding and implementing active research in Time series forecasting (Bayesian Forecasting, Hierarchical Forecasting),
4. Hands on experience in implementing Deep learning models with textual data/ time series data (CNN, LSTM’s) will be a great plus,
5. Expertise in SCALA (or) functional programming paradigm/ Python / R,
6. Experience in big data technologies like Spark, Hive, Hadoop,
7. Experience in understanding business needs and translating to a data-science problem,
8. Knowledge of the supply chain process – demand forecasting, inventory optimization, sell-through, reorder quantity, recommended buy, and allocation process,
9. Great communication skills, organized, able to multitask and be a team player, and
10. Excellent written and oral communication skills on both technical and non-technical topics.
Tryouts are open at Fanatics! Our team is passionate, talented, unified, and charged with creating the fan experience of tomorrow. The ball is in your court now.",3.3,"Fanatics
3.3",Hyderabad,"Jacksonville, FL",5001 to 10000 employees,1996,Company - Private,Sporting Goods Shops,Retail,₹100 to ₹500 billion (INR),"Lids, Amazon, Under Armour"
Data Scientist,-1,"Description
This position is expected to implement Machine Learning and
Artificial Intelligence Techniques in Data Analytics and Enterprise Digital
Automation projects
Modern Data Scientist will be a part of team comprising of Full
Stack Developers, Data Engineers, BI Developers, DevOps Engineers.
Responsibilities
Create / Implement Statistical Models, Neural Network Based Models
for Supervised, Unsupervised Machine Learning. (Prediction, Classification,
Clustering)
Implement Matrix Profiling on Time Series Data
Implement Anomaly Detection
Implement various Optimization Techniques.
Implement Constraint Satisfaction Techniques.
Implement Genetic Algorithms
Implement Image Processing
Basic Qualifications

Education:
B.E./M.Sc./M.E./M. Tech. – Mathematics and Statistics Specialization
Experience:
5 – 7 years in Core Data Science
Experience
– Working alongside team of Data Engineers, DevOps Engineers
Knowledge & Skills
Very
strong @ R/Python
Strong
statistical skills (frequentist & Bayesian)
Familiarity
with machine learning techniques
Outlier detection
Time series analysis
Natural Language Processing (NLP)
Decision trees
Neural networks
Supervised learning
Recommendation engines
Reinforcement learning
Strong
in Data visualization techniques
Experience
working with Keras on top of TensorFlow, Microsoft Cognitive Toolkit, Theano,
or PlaidML.
Interaction
with SQL as well as No SQL Databases
Interaction
with Event Hub, IoT Hub Databases would be plus
Knowledge
of Files Processing – XML, CSV, Excel, Jason, etc. Formats
Knowledge
of Structured and Non-Structured Data processing
Knowledge
of Distributed Big Data Processing
Knowledge
of Data Warehouse and Data Lake Implementation
Knowledge
of Interaction with REST APIs, Web Services
Required Competencies
Customer
Focus
Good
verbal & written English communication
Ability
to work with globally diverse teams.
Readiness
to work in flexible work timings.
Abstract
& Analytical Thinking.
An
interpersonal savvy. A very good team player
Nimble
learning. Willingness to explore and adapt",3.6,"Emerson
3.6",Pune,"Saint Louis, MO",10000+ employees,1890,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹500+ billion (INR),-1
Data Scientist Intern,-1,"Amazon's looking for Data Scientist to optimize one of the most complex logistics systems in the world. Academic and/or practical background in Computer Science, Engineering, Operations Research, or Process Control are particularly relevant for this position. Experience in the integration of model-based engineering tools and/or multidisciplinary analysis & optimization is also a plus.
Major Responsibilities:
· Use data analyses and statistical techniques to develop solutions to improve customer experience and to guide business decision making
· Identify predictors and causes of business related problems and implement novel approaches related to forecasting and prediction
· Identify, develop, manage, and execute analyses to uncover areas of opportunity and present written business recommendations
· Collaborate with multiple teams as a leader of quantitative analysis and where you develop solutions that utilize the highest standards of analytical rigor and data integrity
· Analyze and solve business problems at their root

Basic Qualifications

· Pursuing Masters or equivalent advanced degree from a top tier Technology school
· Record of delivering large analytical solutions with business impact
· Experience on R/SAS/Matlab and SQL
· Excellent Microsoft Office skills, including a strong working knowledge of Excel
· Problem solving ability and passion for big data
· Excellent communication and data presentation skills
· Fluent written and spoken English

Preferred Qualifications

Masters or equivalent advanced degree in Computer Science, Computer Engineering, Statistics, Mathematics or related technical discipline. Hands-on experience and project based learning in computer science, engineering or mathematics is preferred.
• Academic experience in manipulating/transforming data, model selection, model training, cross-validation and deployment at scale.
• Academic or Project Experience with Machine and Deep Learning toolkits such as MXNet, TensorFlow, Caffe and PyTorch.
• Academic Experience with Big Data platforms like Apache Spark and Hadoop.
• Familiarity with data processing with Python, R & SQL.
• Familiarity with AWS services related to AI/ML highly desirable, particularly Amazon EMR, AWS Lambda, SageMaker, Machine Learning, IoT, Amazon DynamoDB, Amazon S3, Amazon EC2 Container Service, Green Grass etc.",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Scientist,-1,"Experience : 2+ years

What will you do:
Should have working knowledge of relational Database designs (SQL Server, MySQL, Oracle).
Should have knowledge of Queue management systems (Redis, MSMQ, RabitMQ etc).
Should have knowledge of SQL query, Stored Procedures, Functions.
Should have knowledge of No SQL will be an added advantage.
Shall analyze, define and document system requirements for data, workflow, logical processes, interfaces with other systems, auditing, reporting requirements and production configuration.
Shall write and maintain functional and technical specifications.
Shall create scripts and packages for data integration, data maintenance or bug fixes.
Shall analyze code for problem resolution and performance optimizations.
Shall write SQL statement for ad-hoc report generation.

What we can offer
Are a young organization and the workplace is an extension of our families back home
Mondays and Fridays have the same effect on us
Value positive vibes, honesty, sense of judgment, empathy and self-motivation
Believe in experimentation and don't think of new things as daunting enough to take up at any point in time
Are looking for driven and focused individuals
Will be more than happy to hear from you
We want to hear from you
Why don't go ahead and send us a video clip of yourself, giving us a creative brief of who you really are.Once you're done with that, jobs@bookmyshow.com :).",3.9,"Bigtree Entertainment Pvt.Ltd.
3.9",Mumbai,"Mumbai, India",201 to 500 employees,-1,Company - Private,Financial Transaction Processing,Finance,Unknown / Non-Applicable,-1
Data Analyst (Commercial Pharma),-1,"Data Analyst (Commercial Pharma)
Greetings from P360!!
The Analyst will support Sales Force Effectiveness and/or Marketing Science business unit by taking a lead role on projects, as well as mentoring junior staff development with minimal supervision from manager or senior staff.
Location: Remote Location/Work from Home.
Job Title: Data Analyst
Experience: 4-6 years of relevant work experience
Key responsibilities:
Work with clients to understand their analytics and business needs for developing and delivering solutions that will provide critical insights through sophisticated quantitative analyses and data modelling.
Deliver operational analytics, sales operations or business technology oriented projects for sales operations teams within the Life Science industry.
Projects will be primarily related to (but not limited to) incentive compensation, customer targeting, and call planning (response model based), sales force design, promotion evaluation, ad-hoc analysis and reporting.
Apply advanced statistical, econometric and optimization models and algorithms to real-world business problems.
Work hands-on with client business teams with limited or no supervision.
Make presentations and recommendations to clients on optimal customers, sales, and marketing strategies and tactics.
Design project plans and manage client expectations and communication plans for project delivery.
Create documents such as business requirements, functional requirements, business rules, analytics plans, quality checklists, etc. for use by both internal and external customers.
Contribute in business development efforts by creating sales pitches, case studies, solutions for business problems
Mentor junior staff

Qualifications:
Education/Experience
BE/BS Degree or equivalent experience required in Statistics, Computer Science, Information Technology, or any other healthcare related major with quantitative background is preferred. Advanced degree in a relevant area is desirable but not necessary.
3+ years of related experience in Sales/Brand analytics, commercial operations
Sales Operations experience directly in life sciences is significantly valuable.
Skills:
Knowledge of various data source such as Xponent, APLD, DDD, HCOS (from IMS or Symphony), Specialty Data, Calls, Sample, Claims, etc.
Analytical problem solving skills, able to identify and link patterns among data sets, analyze and extrapolate market trends and patterns, and to distill large data sets into meaningful information
In-depth understanding of purpose and process of certain areas in Sales Force Effectiveness and Market Sizing, as well as of the linkage between other business areas. Must be able to assess the impact of other areas and provide business and technical solutions.
Strong presentation skills, good at developing and presenting findings and recommendations from analysis and reporting to key internal and external customers.
Effective oral and written communication skills that enable personal impact with senior-level decision makers
Able to manage multiple projects, priorities, resources and timeline
Strong attention to detail, with a quality-focused mindset
Experience working with US pharma/Bio-Pharma Clients
Promotes and generates innovation and cooperation within and cross teams (onsite-offsite) to achieve a collective outcome.
P360
P360 is a Microsoft Gold Partner and leading provider of technical solutions for the life sciences industry. At P360, our team leverages over 25 years of industry expertise to guide life science companies in defining and executing commercial and clinical strategy. Built on Microsoft’s cloud platform to facilitate a successful digital transition to Pharma 3.0—a patient-centric, high-capability commercial business strategy. When companies partner with P360, organizations access a vast array of cutting-edge, business-enhancing solutions and services that drive your capabilities far beyond your competitors in the marketplace.",4.8,"P360
4.8",Mumbai,"Piscataway, NJ",51 to 200 employees,2015,Company - Private,IT Services,Information Technology,₹500 million to ₹1 billion (INR),-1
Data Scientist,-1,"We are looking for a data scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.

Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance.
Requirements
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc (depending on specific project requirements). Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills (if you expect that the person in this role will integrate the solution within the base application, list any programming languages and core frameworks currently being used)
Data-oriented personality",-1,Hookfish,Mumbai,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Overview:
We at Solugenix are hiring Data Scientist for a full-time job at Hyderabad, the detailed job description is mentioned below. If this job interests you, I urge you to email me your updated resume with your phone number and the best time to call you.

Title: Data Scientist

Location: Hyderabad

Position: Full Time

Solugenix, the longest serving independent IT consulting firm in the nation, delivers comprehensive, managed-services IT solutions known for their innovation, value and dependability. With a strong emphasis on innovation, Solugenix has now created an independent branded Data Science and AI based Incubation center for building next generation solutions which include new and emerging technologies around Machine Learning, Artificial Intelligence, Big Data, Data Science and distributed Cloud computing.

Do you thrive on working on the cutting edge? Working with innovators in the early stages of ideas, products, or platforms? Do you crave new challenges and solving hard customer problems using the latest in technology? Do you want to become part of a high-energy team in Hyderabad where you will play a key role in building a successful company that already has great traction?

In this role, you will work on some of the latest applications of data science to business. You will directly work with key stakeholders to define the business problem and determine solution requirements. You will be responsible for ensuring business value and communicating results, making presentations, etc. If you are passionate to work on unstructured business problems that can be solved using data, we would like to talk to you.

We are looking for candidates with minimum of 5+ years of consulting experience possessing Life Sciences secondary data familiarity – experience working with a variety of Patient, Physician and Payer datasets on solving strategic and tactical sales & marketing business problems across life sciences, biotechnology and healthcare industries.

Responsibilities:
Technical – Able to comprehend complex tasks assigned and execute them with little to no supervision

Hands on in a range of analytics tools (SAS, SQL, R/Python) and big data hosting technologies (at least 1 of AWS, GCP, Azure), with advanced expertise in MS Office (Excel and PowerPoint)
Have in depth knowledge of the various commercially available Physician, Patient and Payer level Life Sciences data sources in the US
Must have experience in development or maintenance of processes to manage and improve sales and marketing operations such as: Sales Force Sizing, Promotion Response Modeling, Promotional Effectiveness, Market Mix Optimization, etc.
Execute analyses and make the results accessible and relevant to a wide variety of business users
Develop and refine analysis templates for problem diagnosis and opportunities assessment
Knowledge of advanced analytics and ability to blend consulting, analytics, and technology to help life sciences and healthcare clients improve the ROI of their sales and marketing functions
Must have experience in using Statistical techniques like: Regression Modeling/ Optimization/ Structuring/ Machine Learning Techniques
Calculation of all sales, activity and managed care KPIs

Logical Thinking – Able to think analytically, use a systematic and logical approach to analyze data, problems, and situations. Spot discrepancies and inconsistencies in information and materials. Collaborate effectively with other analytical team members

Task Management – Basic level of project management knowledge and experience. Should be able to plan tasks, discuss and work on priorities. Support analytical projects by formulating methodology, establish data requirements, identify client deliverables, determine tasks and timing. Demonstrate initiative to improve quality and customer service by striving to exceed customer expectations. Balance team and individual responsibilities and put the success of the team above own interests

Communication – Convey ideas and information clearly and accurately to self or others in writing and verbally. Establish effective mechanisms of communication with team, and the organization’s leadership to foster an environment of openness, trust and teamwork

Qualifications:
You will score brownie points if you:
Can synthesize complex data into user friendly visual presentations for use by Commercial and Strategy leadership folks
Have exceptional communications skills to effectively collaborate with broad customer base
Possess excellent writing and verbal communications skills and the ability to understand and communicate concepts and recommendations
Can understand and deal effectively with problems and opportunities, which arise, in a complex multiprocessing environment

Education:
B-Tech or BE in any engineering discipline from Tier 1 college with a minimum of 5+ years of experience, OR
B-Tech or BE or Bachelors in a quantitative discipline such as Statistics, Mathematics, Operations, Research, Economics or Econometrics from Tier 1 College with a minimum of 5+ years of experience",4.3,"Solugenix Corp
4.3",Hyderabad,"Brea, CA",201 to 500 employees,1969,Company - Private,IT Services,Information Technology,₹5 to ₹10 billion (INR),-1
Data Scientist,-1,"5-15 years of hands on analytics experience in executing projects pertaining to Advanced Analytics involving advanced statistics/machine learning & Optimization algorithms
Must have hands-on experience with data management and quantitative modeling
Hands on experience in Advanced Analytics software like R/Python/Scala
Proficient in SQL or similar database query language.
Proficient in MS Office tools like Word, Excel and PowerPoint
Proficient in analytical techniques
Ability to think strategically and analytically in order to effectively assess each opportunity
Excellent time management skills
Willingness to travel on short assignments on short notice
Education:
Post graduate in Statistics/Mathematics/Computer Science/Economics or Bachelors/Masters in Engineering or Technology with strong knowledge of quantitative modeling.",3.9,"ITC Infotech India Ltd
3.9",Bengaluru,"Bengaluru, India",5001 to 10000 employees,2000,Subsidiary or Business Segment,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Description

About Us

We know that people are our ""greatest asset"". Our staff’s professionalism, innovation, teamwork and dedication to excellence have helped us become one of the world’s leading technology companies. It is these qualities that are vital to our continued success.

As a Ness employee you will be working on products and platforms for some of the most innovative software companies in the world. The opportunity to evolve your expertise by using new cutting edge technologies will expand your horizons and create an exciting work environment. You’ll also gain enormous knowledge working alongside other highly skilled professionals that will help accelerate your career progression.

At Ness we treat our values of rigor, innovation and partnership with the highest priority and they are placed at the very core of our business — to guide us through our daily operations and interactions with our customers. We offer our employees exciting and challenging projects across a diverse range of industries, as well as the opportunity to collaborate with a group of forward thinking, capable partners around the globe.

About Company

Ness

Roles and Responsibility

Excellent skills in Microsoft
.NET web stack programming including C#, ASP.NET, MVC 4+, MSSQL Server and
RESTful APIs.
Expert knowledge of frameworks such as Web API, WCF, MVC, Entity
Framework, etc. and an excellent understanding of data structures, threading,
and performance tuning.
Excellent knowledge of front-end programming using HTML, CSS,
JavaScript, jQuery, etc. with a strong grasp of web technologies and UI/UX
standards.
Sound Knowledge of latest Architecture trends, Design Patterns and
Object Oriented Programming Concepts.
Expert understanding of Common Language Runtime (CLR), its
limitations, weaknesses, workarounds and the fundamental design principles
behind a scalable application.
Excellent knowledge of database programming using MS SQL Server
2008+.
Knowledge of Angular JS, Node JS, Websockets, RabbitMQ and Cloud
Messaging Frameworks (PUSH) will be a plus.
Good understanding of code versioning tools such as Git,
BitBucket, Mercurial, SVN, etc. and familiarity with continuous integration.
Soft Skills: Strong communication and inter-personal skills.
Ability to work in a fast paced, high energy environment.

Desired Skills

Big Data",4.1,"Ness Technologies
4.1",Bengaluru,"Teaneck, NJ",5001 to 10000 employees,1999,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),"Wipro, GlobalLogic, Mindtree"
Data Scientist,-1,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Scientist and as a part of founding team, you will be expected to design and develop applications related to information retrieval, artificial intelligence, natural language processing and predictive modelling. Your rewards will be directly proportional to the value you generate.

Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data
Design and develop out-of-the-box solutions to solve complex data problems
Develop statistical models for various use cases
Develop processes for text mining and extraction of information from unstructured data
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java / R / Python - Intermediate to advanced level`
Regex - Advanced
SQL - Advanced
Apache Weka / Mahout or other similar tools - Intermediate to advanced level
Experience in Search Algorithms, Semantic Analysis, with good knowledge of Machine learning/Distributed System/Data Mining/NLP/Artificial Intelligence
Linux - Intermediate

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion; not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
Data Scientist,-1,"Capable in creating analytics pipelines to pre process, visualize and create machine learning models using at least two of R/SAS/Python
Should have at least working knowledge of SQL and RDBMS
Should have worked on/lead projects using statistical analysis/regression/clustering/other supervised and non-supervised learning algorithms using R/SAS/Python - should have sound basics in Statistics and Machine learning.
Should have experience in working with clients in gathering the requirements and handling client queries
Should have a knack for Problem Solving using technology
Should be capable of working under tight deadlines independently",4.2,"Data Semantics
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2012,Company - Private,IT Services,Information Technology,₹100 to ₹500 billion (INR),-1
Data Scientist,-1,"Key Responsibilities

Understand the key end to end analytics of project requirements and scoping the existing & new requirements.
Assessing the quality & comprehensiveness of data.
Analyzing KPI’s of key business functions like sales & marketing and supply chain.
Work with Data architects to create and evolve dashboard templates.
Set data standards for enhancing data maturity for analytics.
Data pre-processing, modelling & post-processing of data.
Comfortable with basic statistical principles and apply them with the data sets.
Machine Learning: Ability to work with algorithms, understand, interpret and devise your own algorithm for the business problem.
Selection of right algorithms (Regression, Naïve Bayes and Random Forest).

Job Requirements and Skills

Data modelling Skills: SQL, Python and analytics model building using Machine Learning.
Data visualisation skills: Power BI / Tableau / Qlikview / Cognos.
Big Data: Spark, Hive.
ETL.
Domain: Automotive / Non-Automotive (Industrial Manufacturing/Retail/Energy & utilities, Finance)

Years of Experience

Experience: Minimum 5 years of relevant experience.
Projects: Minimum 3 projects in data science delivered to customers (not academic with Kaggle competitions)

Job Location: Chennai

Academic Qualification: B.E or any equivalent degree

No of positions: 3

Proceed to apply job",3.2,"Hindujatech
3.2",Chennai,"Chennai, India",1001 to 5000 employees,2011,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Summary
Job Title: AI and ML or Computer Vision
Location: Bangalore
The purpose of hiring this person is for his Robust experience in the area of Software Development in Computer Vision using a blend of traditional Image Processing based & modern Machine Learning/Deep Learning based techniques.

Responsibilities and Duties
Roles & Responsibilities:
 Experience with object detection, tracking, classification, recognition, scene understanding  Excellent programming & rapid prototyping skills in Python & C/C++ (Optionally)  Exposure to Data structures / Algorithms is a must  Expertise on OpenCV, DLib  Excellent knowledge on any/all of the given concepts in Computer Vision - namely Image Classification, Object Detection and Semantic Segmentation developed using state of the art deep learning algorithms.  Hands on experience in developing efficient and real-time convolution neural network models.  Hands on working experience with anyone of the deep learning frameworks - TensorFlow, Caffe, Pytorch, Keras, MXNet, Theano  Exposure to model compression and pruning in deep learning.  Familiarity with GPU computing (CUDA, OpenCL) and HPC.  Experience/exposure to usage of Open Source technologies  Experience/exposure to Product development methodologies & Software Engineering processes  Experience in owning technical architecture of the products, planning roadmaps & technically managing the team
Qualifications and Skills

Job Requirements:
 BE/B.Tech, MS/M.Tech (Electronics, Computer Science or related) Experience - 4+ Years  Strong Problem Solving & Communication skills  Highly Motivated, Creative and a Team player

Job Type: Full-time

Salary: ₹600,000.00 to ₹1,000,000.00 /year

Experience:
total work: 3 years (Required)
Education:
Master's (Preferred)
Benefits:
Health insurance
Paid leaves / Leave encashment
Flexible work hours
Other
Industry:
Software Development",4.0,"Lincode Labs
4.0",Bengaluru,"Menlo Park, CA",1 to 50 employees,2017,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹10 to ₹50 million (INR),-1
Data Scientist,-1,"Experience : 4-10 Years

Salary : As per the Industry Norms

Job Type : Permanent

Job Location : Noida

Job Description

Understand problem statement, identify and apply appropriate family of predictive models / machine learning algorithms.
Apply proven machine learning methods in open-source and proprietary technologies to explore and extrapolate insights from divergent data types.
Continuously monitor and challenge implemented models in existing projects / solutions and explore opportunities for continuous improvements.
Keep up to date with latest developments in the associated domain and technology areas and utilize them to improve existing projects and solutions.
Assist Healtheoz developing reusable digital assets.
Collaborate with cross-functional teams Works closely with Big Data developers and product owners to prioritize business and information needs.

Job Requirements

4+ years experience in Data Science, Predictive Modeling, and Machine Learning. Demonstrable experience in applying data science tools/techniques to business problem statements.
Graduate / Post Graduate degree in Statistics, Math or Computer Science fields
At least intermediate level skills in either R or Python.
Comfortable with the following at the minimum: Linear Regression and its variations, Logistic regression, kNN, Nave Bayes, Decision Trees and its variations, kMeans, Hierarchical clustering
Good understanding of topics such as Data Pre processing, Visualizations (ggplot2 / matplotlib etc), Cross validation, ensemble modeling.
Basic understanding of the Mathematics (Linear algebra, Calculus) and Statistics (Descriptive, Inferential) behind machine learning algorithms.

Preferred skills

Experience with Big Data technologies, SPARK.
Experience with cloud computing infrastructure like AWS.
Experience with data visualization tools like Tableau.
Good communication and interpersonal skills.",5.0,"Healtheoz India
5.0",Noida,"Noida, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Min. Exp: 3 years
Ahmedabad, India
Job Role
Skills Required
Personality
Job Role
Develop and refine algorithms for machine learning from large datasets.
Write offline as well as efficient runtime programs for meaning extraction and real-time response systems.
Develop and improve Ad-Targeting based on various criteria like demographics, location, user-interests and many more.
Design and develop techniques for handling real-time budget and campaign updates.
Be open to learning new technologies.
Collaborate with team members in building products.
Skills Required
MS/PhD in Computer Science or other highly quantitative field.
Minimum 8 - 10 yrs of hands on experience in different machine-learning techniques.
Strong expertise in Big-data processing.
(Combination of the technologies you should be familiar with Kafka, Storm, Logstash, ElasticSearch, Hadoop, Spark)
Strong coding skills in at-least one object-oriented programming language (e.g. Java, Python).
Strong problem solving and analytical ability.
Prior 4+ year experience in advertising technology is preferred.
Personality
You want to work in a small, agile team.
You mentor other developers when needed.
You work hard and don’t need much oversight.
You like variety in your projects.
You want to be proud of what you do at your job.
Interested applicants should send their resume and cover letter at career@iqm.com",-1,iqm.com,Ahmedabad,"New York, NY",1 to 50 employees,2014,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Miles is looking to expand its data science and data engineering team in INDIA!

Here's a quick checklist:
You live in India
Want to work for a fast-growing Silicon Valley Startup
You are passionate about solving challenging problems
You are looking to put your stamp on the product

What you'll need:

Education
Master's/PhD (preferred) or Bachelor's (required) in CS/ML/AI or relevant computational/engineering discipline

Machine Learning/Data Science:
Solid theoretical understanding of ML fundamentals: linear algebra, probability, statistics (as relevant to ML), optimization
Knowledge of different ML techniques and when/how to use them: classification, regression, clustering, outlier detection, dimensionality reduction, etc.
Comfortable manipulating and analyzing complex, high-volume, high-dimensionality data from varying, heterogeneous sources
Experience with messy real-world data -- handling missing/incomplete/inaccurate data
Proficient in the Python ML ecosystem: NumPy, Pandas, SciPy, Scikit-Learn
Strong understanding of relational databases like PostgreSQL is a plus

Programming experience:
At least 2+ years of experience writing production-quality Python code
Version control: Git, GitHub/Bitbucket
Experience delivering large-scale deployable projects

Great to have
We deal with large volumes of geospatial data, so experience working with geospatial data at scale is a big plus
Knowledge of Python (Shapely, GeoPandas, Fiona, CartoPy, etc) and/or database (PostGIS) geometry/geospatial tools
Domain experience in building models for location-based services, transportation, scheduling, vehicle routing",2.3,"Miles
2.3",Bengaluru,"Redwood City, CA",1 to 50 employees,2016,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"We are looking for a Data Scientist with experience of 3-6 years that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in building data science solutions using machine learning algorithms, doing statistical analysis, and building high quality prediction systems integrated with our products.

Responsibilities:
Identifying the key problem in the system and proposing a solution
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Identify third party data that can be used to enhance the information gained
Processing, cleansing, and verifying the integrity of data used for analysis
Building unsupervised and supervised learning algorithms on existing data such that systems should be proactive in nature

Skills and Qualifications
3-6 years of experience with post graduate/Phd degree in mathematics, statistics, IT or Computer science from IIT/IIIT/NIT/recognized universities
Excellent understanding of machine learning techniques and algorithms, such as Random Forest, Regression, XG Boost, k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Python, Octave, Java. Excellence in at least one of these is a must.
Great communication skills
Proficiency in SQL is must.
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase will be good to have.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Data-oriented personality
To apply on this job, email your resume at alka.dhingra@magicbricks.com",3.9,"Magicbricks
3.9",Bengaluru,"Noida, India",1001 to 5000 employees,2006,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Key Responsibilities:
As a Data Scientist on our team, you will be responsible for solving complex big-data problems for various clients (on-site and off-site) using data mining, statistical analysis, machine learning, deep learning.
One of the primary responsibilities will be to understand the business need and translate it into an actionable analytical plan in consultation with the team.
Ensure that the analytical plan aligns with the customer’s overall strategic need.
Understand and identify appropriate data sources required for solving the business problem at hand.
Explore, diagnose and resolve any data discrepancies – including but not limited to any ETL that may be required, missing value and extreme value/outlier treatment using appropriate methods.
Execute project plan to meet requirements and timelines.
Identify success metrics and monitor them to ensure high-quality output for the client.
Deliver production-ready models that can be deployed in the production system.
Create relevant output documents, as required – power point deck/ excel files, data frames etc.
Overall project management – Creating a project plan and timelines for the project and obtain sign-off.
Monitor project progress in conjunction with the project plan – report risks, scope creep etc. in a timely manner.
Identify and evangelize new and upcoming analytical trends in the market within the organization.
Implementing the applications of these algorithms/methods/techniques in R/Python

Key Skills:
3+ years experience working Data Mining and Statistical Modeling for predictive and prescriptive enterprise analytics.
2+ years of working with Python, Machine learning with exposure to one or more ML/DL frameworks like Tensorflow, Caffe, Scikit-Learn, MXNet, CNTK.
Exposure to ML techniques and algorithms to work with different data formats including Structured Data, Unstructured Data, and Natural Language.
Experience working with data retrieval and manipulation tools for various data sources like: Rest/Soap APIs, Relational (MySQL) and No-SQL Databases (MongoDB), IOT data streams, Cloud-based storage, and HDFS.
Strong foundation in Algorithms and Data Science theory.
Strong verbal and written communication skills with other developers and business client
Knowledge of Telecom and/or FinTech Domain is a plus.

Job Type: Full-time

Salary: ₹450,000.00 to ₹850,000.00 /year

Experience: Machine Learning: 2 years (Required)

Education: Master’s (Preferred)

Language:English (Required)

Interested Candidates please share their resume at careers@datatobiz.com",4.8,"DataToBiz
4.8",Chandigarh,"Chandigarh, India",1 to 50 employees,2018,Self-employed,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
Data Scientist,-1,"Experience required: 2-4 years

We are looking for a passionate Data Scientist to turn data into meaningful information that can help our clients make data informed decisions

Typical responsibilities include end to end execution of advanced data science projects primarily involving applying data mining techniques, doing statistical analysis, and building high quality prediction systems. Youll have access to large B2B and B2C data sets on a robust analytic platform. Customer and account data is enriched with demographics and firmographics, transactional purchase history, Web behavior and cross-channel marketing campaign history. Tools and analytic environment include SAS, Tableau, R/Python and well-managed MPP RDBMS, Hadoop & Hive.

Loyalytics is a startup and our work environment is very conducive to trying and testing out a variety of new things. A high degree of passion, commitment to our customers priorities and willingness to learn new things on the go are some of the qualities that will help individuals succeed at Loyalytics.

Job Description:

· 2-4 years real world experience working as a data scientist

· Hands on experience in statistical modelling software such as R, Python or SAS (optional) along with data visualization tools like Tableau/Power BI

· Good understanding of statistical and predictive modeling concepts.

· Strong expertise in either R or Python

· Excellent analytical thinking, and problem-solving skills.

· Hands on experience in working on data mining and statistical machine learning problems

· In depth understanding of advance ML techniques and algorithms like regression, clustering, decision trees, Neural Networks, Gradient descent, SVM etc

· Experience in project management and handling client communications

· Excellent communication (written/verbal) skills, including logically structuring and delivering presentations.

· Open to learning new methods/techniques in the ever-changing world of analytics. High aptitude to learn quickly, assimilate to new teams and projects, and work well under pressure with appropriate attention to detail.",5.0,"loyalytics consulting
5.0",Bengaluru,"Bengaluru, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"The Company

A leading Healthcare Industry, headquartered in Bengaluru, India, and operates a network of hospitals across the country, with a particularly strong presence in the southern state of Karnataka and eastern India, as well as an emerging presence in northern, western and central India.

The Job

Develop statistical and machine-learning models towards estimation and classification of clinical variables.
Develop computer vision algorithms on medical imaging data with image processing and deep learning/neural networks techniques towards image segmentation, image classification and 3D reconstruction.
Develop NLP algorithms to classify and summarize structured/unstructured text data
The candidate will interact with clinicians and other functional experts to develop a reasonable understanding of the underlying clinical/business concepts for the given problem domain. The candidate will then conceive, develop, deploy, validate and evaluate models to accurately reflect the underlying concept.

Your Profile
In-depth understanding of Statistical Concepts, Image Processing techniques, Machine Learning and Deep Learning Algorithms
Bachelor's in Computer Science/ Engineering, Statistics, Math or related quantitative degree or equivalent work experience.
Expertise in extracting, analyzing and interpreting variety of data - Structured and Unstructured
Excellent critical thinking, verbal and written communications skills
Strong self-drive and passion for data science
Specific Technical Skills
Expertise in Python/R • Competence in ML/Deep Learning Packages (eg. scikit-learn, keras, tensorflow, pytorch)
Reasonable competence in Image Processing Packages (eg. opencv, PIL, SimpleITK)
Reasonable competence in SQL
Reasonable competence in Spreadsheets
Location: Bangalore",4.0,"Edge
4.0",Bengaluru,"Houston, TX",1 to 50 employees,2010,Unknown,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Research Data Scientist,-1,"dunnhumby is looking for a talented Applied Data Scientist!

You will execute projects to distil complex problems into compelling insights that resonate with clients, using the best of dunnhumby science.

What you'll be doing:
Build strong relationships with immediate internal contacts and direct external client to ensure full understanding of client requirements, ensuring clear and effective communication.
Investigate and implement the most appropriate analytical technique for each project, re-using and further developing global solutions or code written by others.
Deploy data science algorithms and market products on chosen tech stack for efficient and cost-effective delivery.
Execute projects that distil complex problems into compelling insights that resonate with clients.
Participate, as required, in client meetings to help explain the proposed methodology and solutions.
Document learnings after deploying solutions for a client to increase the existing knowledge repository.
Ensure smooth running of your projects, working with senior team members for direction.
Follow dunnhumby Quality Assurance processes, ways of working and meet coding standards.
Implement advice from colleagues to resolve challenges.
Who you’ll get to work with:

Within dunnhumby you’ll work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights contacts
What you'll need:
Bachelor’s degree or equivalent in Computer Science, Artificial Intelligence, Machine Learning, Applied Statistics, Physics, Engineering or related field.
Experience with and passion for connecting your work directly to the customer experience, making a real and tangible impact.
Some experience with programming, and the ability to quickly pick up handling large data volumes with modern data processing tools, e.g. by using Hadoop / Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and Testing
Statistical Modelling
Programming (Python, SQL, R, …)
Data Interpretation/ Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence, Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience on any standard data mining and modelling packages such as Python and R.",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Data Scientist,-1,"Analytics

Data Scientist

Pune, Maharashtra, India
APPLY

Job title

Data Scientist
Department

Analytics
Report To

NA
Work Location

Pune

It’s Time For A Change…

Your Future Evolves Here

Evolent Health has a bold mission to change the health of the nation by changing the way health care is delivered. Our pursuit of this mission is the driving force that brings us to work each day. We believe in embracing new ideas, challenging ourselves and failing forward. We respect and celebrate individual talents and team wins. We have fun while working hard and Evolenteers often make a difference in everything from scrubs to jeans.

Are we growing? Absolutelyabout 40% in year-over-year revenue growth in 2018. Are we recognized? Definitely. We have been named one of “Becker’s 150 Great Places to Work in Healthcare” in 2016, 2017, 2018 and 2019, and One of the “50 Great Places to Work” in 2017 by Washingtonian. If you’re looking for a place where your work can be personally and professionally rewarding, don’t just join a company with a mission. Join a mission with a company behind it.

Who You’ll Be Working With:

You’ll join a team of data scientists, analysts, and software engineers working to push the boundaries of data science in health care. We like to experiment, iterate, and innovate with technology, from developing new algorithms specific to health care’s challenges, to bringing the latest machine learning practices and applications developed in other industries into the health care world. We know that algorithms are only valuable when powered by the right data, so we focus on fully understanding the problems we need to solve, and truly understanding the data behind them before launching into solutions – ensuring that the solutions we do land on are impactful and powerful.

What You’ll Be Doing:
Research, conceptualize, and implement analytical approaches and predictive modeling to evaluate scenarios, predict utilization and clinical outcomes, and recommend actions to impact results.
Manage and execute on the entire model development process, including scope definition, hypothesis formation, data cleaning and preparation, feature selection, model implementation, validation and iteration, using multiple data sources.
Provide guidance on necessary data and software infrastructure capabilities to deliver a scalable solution across partners and support the implementation of the team’s algorithms and models into Evolent’s product offerings.
Contribute to the development and publication of white papers showcasing Evolent’s leadership in healthcare data science.
Collaborate with stakeholders from clinical, operations, and product teams to identify advanced analytics opportunities to add value to Evolent’s solution offerings.
Leverage clinical and administrative data to support other business needs related to clinical program improvement, networks optimization, and other strategic initiatives.
The Experience You’ll Need (Required):
Master’s Degree with a quantitative focus (e.g. data science program, software engineering, statistics, mathematics, computer science, health services research).
3-6 years of professional experience in an analytical field related to health service analytics, predictive modeling in health care, or other health care-related experience.
Strong technical abilities with advanced data and analytics tools and programming languages, including Python or R, and at least one database language such as SQL or Mongodb.
Foundational understanding of core concepts in applying machine learning algorithms: data cleaning, feature selection, and parameter tuning.
Strong communication skills, including both communicating with other stakeholders to fully evaluate project requirements and context, as well as communicating project results, findings, and applicability.
Ability to work independently with little technical guidance day-to-day, in a fast-paced environment.
Finishing Touches (Preferred):
Experience in SAS, SAS/CONNECT, and disparate programming language integration techniques
Proficiency in most areas of mathematical analysis methods, statistical analyses, predictive modeling, and/or machine learning (such as neural networks, random forests, gradient boosting, etc), and in-depth specialization in some areas.
Working knowledge of analyzing administrative medical claims, pharmacy claims, and/or EMR data and clinical data.
Proficiency with git or other version-control software, especially in collaboration with others.
Proficiency working at the command line / shell.
Experience in reporting and visualization tools such as R’sggplot, Python’s bokeh, Tableau, MSTR, or geo-mapping tools.
Experience building and/or using APIs.
Work Environment: The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. This position primarily works in a climate controlled based setting.The noise level and the work environment are moderately quiet. This role routinely uses standard office equipment such as computers, phones, photocopiers, filing cabinets and fax machines

Physical demand: Include the physical demands of the job, including bending, sitting, lifting and driving. For example, while performing the duties of this job, the employee is regularly required to talk or hear. The employee frequently is required to stand; walk; use hands to finger, handle or feel; and reach with hands and arms.

Why Join Evolent?Evolent Health developed an integrated value-based care platform for payers and providers. The company created an internal recognition program that encourages departments to acknowledge outstanding achievement as well as focusing on philanthropic values. The company spent four weeks in 2018 giving back to more than 60 local charities and engaged 3,700-plus employees to participate. Evolent provides healthy snacks and drinks in most of its offices as well as an in-office gym at its headquarters and workstations that include treadmill desks. In 2016, the company launched its diversity and inclusion committee that promotes unconscious bias training and established several business resource groups. In 2017, Washingtonian Magazine named Evolent among the 50 Great Places to Work.

APPLY",2.8,"Evolent Health
2.8",Pune,"Arlington, VA",1001 to 5000 employees,2011,Company - Public,Healthcare Services & Hospitals,Healthcare,₹1 to ₹5 billion (INR),-1
Data Scientist,-1,"Position title
Data Scientist
Description
Excellent understanding of machine learning techniques and algorithms
Proficiency with R/ Octave for modeling, Python & Java for production-ready code.
Experience with common data science toolkits, such as R/ Octave for modeling, Python & Java for production-ready code. Excellence in at least one of these is highly desirable.
Experience with data visualization and extracting insights from them.
Proficiency in using query languages such as SQL, Learning in the area of NLP, predictive models & recommendation engines is a big plus
Crunch a large volume of data, observe trends and build scalable & analytical models.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality
Good knowledge of databases like NoSQL, MongoDB, Postgre, etc.
Perform Exploratory Data Analysis and Statistical Analysis; clearly present the results of an analysis to customers and management.
Experience with AWS, Google Cloud is a plus
Exposure with deep learning algorithms is a big plus
Required Skills
Selecting features, building and optimizing models using machine learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Adopting new research methodologies including deep learning (CNNs LSTMs) on projects
Job Responsibilities
Bachelors/ Masters in Computer Science or Electronics from tier 1 & 2 colleges
Contacts

careers@algoscale.com",3.7,"Algoscale
3.7",Noida,"Noida, India",1 to 50 employees,2014,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"About the Company

Meesho is India’s top reselling platform, used by more than 1 million resellers across the country. Resellers are small business owners and home entrepreneurs who sell stuff using Meesho, within their extended social circles. Meesho is reimagining e-commerce for India, and building a platform for the next 20 million entrepreneurs in the country.

Meesho is one of the fastest growing startups in the world, and is backed by top investors globally, including DST Global, YCombinator and Sequoia. You can read more about Meesho’s journey on TechCrunch.

About the role

As a data driven organisation with the core mission of empowering 20 million entrepreneurs throughout the country, Data scientists are an integral part of the Meesho team. You'll develop models and run experiments to infer insights from hard data that meaningfully impacts our 1Million+ resellers. From improving our product usability to identifying new growth opportunities data scientists help all teams within Meesho develop effective solutions.

Here are some of the problems you'll be working on: -

- Understanding reseller preferences to provide them with the most relevant products

- Modelling which resellers will be the most impacted by changes in our incentive structures

- Designing discount programs to help our resellers sell more

- Inferring insights from our existing data to identify new growth opportunities

- Designing experiments to improve usability across our product suite

- How can you help resellers better recognise end customer preferences to improve their revenue?

- Using data to identify bottlenecks that helps our suppliers meet their SLA requirements

- What frontend visualisations will best help category managers understand the current demand for products?

- Modelling seasonal demand to predict key organisational metrics

Mandatory Requirements:-
Bachelor’s Degree from a Tier 1 school (IIT, NIT, IIIT, BITS, DCE)
1-3 years of experience as a Data Scientist
Familiarity with concepts like Neural Networks, Machine Learning etc and tools like SQL, R, Python
Capabilities The ideal candidate for this role has:-
A good understanding of and belief in Meesho’s business model and product
Strong understanding of Statistics and Linear Algebra
Strong understanding of hypothesis/model testing and ability to identify common model testing errors like overfitting, underfitting, type I and type II errors
Experience designing and running A/B tests and drawing insights from them
Familiarity with Python or R, proficiency with SQL
Strong communication skills to explain your analysis
Bonus points We will prefer candidates who have:-
A Computer Science degree
Experience in working on personalization or other ML problems
Familiarity with Big Data tech stack like Apache Spark, Hadoop, Redshift",3.8,"Meesho
3.8",Bengaluru,"Bengaluru, India",501 to 1000 employees,2015,Company - Private,"Department, Clothing, & Shoe Shops",Retail,Unknown / Non-Applicable,"GlowRoad, Shop101, Wooplr"
Data Scientist,-1,"RESPONSIBILITIES
To analyse data and support the development of technology tools relevant for the development sector. Work on creating data insights on developmental and public policy issues with a focus on providing knowledge support to policy makers and informing public discourse.
Support in providing data analytics for all data and technology related projects esp. Jaano India.
Use multivariate statistical analysis to analyse data and produce detailed project reports. Ensure data integrity and consistency across relevant data systems. Making recommendations for solving some of these real world problems.
Collecting, cleaning and maintaining data from Open Government Datasets. Data from all major government schemes and departments must be maintained in a structured data warehouse and updated regularly.
Analysis of cleaned data to identify patterns, correlations and infer meaningful conclusions. Thereafter, presenting them in a visually lucid manner to various stakeholders and policymakers through Swaniti’s Jigyasa portal.
Creating data packages for standardized and customized research output for use of Members of Parliament, Members of Legislative Assembly and Civil Servants.
Conceptualize and create standalone data visualizations and info-graphics on development and governance issues for dissemination to media outlets and general public
Analyzing and interpreting primary level data for Swaniti’s micro planning projects to identify key patterns for national and state level policy making.
If needed provide inputs for knowledge consultations and/or the Jigyasa platform.
QUALIFICATIONS
Graduate degree in any field with courses in Statistics, Econometrics or any data-related subjects. Those with advanced degrees will be given preference.
At least 2 years of active work experience in the public or private sector with a role dealing directly with data cleaning, analysis and visualizations.
SKILLS

Required

The Data Scientist will be expected to have a demonstrated record of being a ‘problem solver’ with ability to analyse big data, and commitment to working on policy and developmental challenges in India.
Familiarity with handling database systems like MySQL and Hive.
Proficiency in Python and Java. Familiarity with packages/libraries used for data manipulation and plotting (eg – numpy, panda, scikit-learn)
Understanding of statistical concepts involving descriptive and inferential stats, hypothesis testing, confidence intervals and sampling, clustering and classification.
Knowledge of common machine learning algorithms, from dimensionality reduction to supervised and unsupervised techniques.
Excellent working knowledge of MS Excel
Strong leadership skills, excellent people and team skills and a constant willingness to learn.

Recommended

Proficiency in R, Python, SAS, SPSS and/or STATA.
Familiarity with MongoDB, Hadoop, Spark.
Understanding of linear algebra concepts such as matrix manipulations, Eigen values and vectors and multivariable calculus.
Knowledge regarding government policies, schemes and their implementation.
Ability to write complex Macros in Excel.",3.9,"Ank Aha
3.9",New Delhi,"New Delhi, India",1 to 50 employees,2016,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Data Sciences team at Priority Vendor uses data and algorithms to build large scale systems to enable better decision making for the invoice discounting as well as render better customer experience to suppliers. Some of the areas of our focus are Rate Determination, Demand Sensing, Recommendation Systems, etc.

Some of the things we are working on:
Daily Rate Determination

Building algorithms to predict supplier expectation on discount amount

Building prediction models to improve on invoice discounting%

Role & Responsibilities

As a data scientist, he/she will have the opportunity to leverage Priority Vendor 3 year old rich data to develop data products that are used by millions of suppliers (end user) and propel the growth of our business. He/she will collaborate with a strong team of engineers, product managers in defining the frontier of data products. Data scientists will work on how to evaluate potential approaches, build features, statistical/machine learning models and determine metrics. He/she will communicate insights/recommendations to a wide spectrum of stakeholders across the company.

Qualification & Skillset

Advanced degree in the quantitative field preferred.

3+ year’s industry experience developing machine learning models at scale from inception to business impact.

Deep understanding of modern machine learning techniques and their mathematical underpinnings such as classification, recommendation systems, and natural language processing.

Proven ability to tailor machine learning solutions to business problems in a cross-functional team.

Experience with distributed machine learning and computing framework (Spark, Hadoop, Mahout or equivalent). Applied experience preferred.

Strong programming skill (Python, R, or Scala preferred).

Experience productionizing machine learning model is a plus.

High proficiency in at least one of the following broad areas:

Machine learning

Statistical modeling/inference

Information retrieval,

Data mining

NLP",4.0,"Priority Vendor
4.0",Noida,"Noida, India",51 to 200 employees,2014,Company - Private,-1,Finance,Unknown / Non-Applicable,-1
Data analyst/ Data scientist,-1,"We are looking for data analyst/ data scientist/Module lead||

Job role:
As a data analyst, you will be responsible for compiling actionable insights from data, sales and marketing managers build data-driven processes. Your role will involve driving initiatives to optimize for operational excellence and revenue and more..
Experience- Min 1yr and above required

Location-Indore, Madhya Pradesh

Salary- negotiable

Note-Applicant should be from Indore only.

For details call

Seven four one five zero three one six eight three

Thank you!

Job Type: Full-time

Experience:
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Bachelor's (Preferred)
Benefits:
Travel allowance",4.0,"emerging business consultant
4.0",Indore,"San Francisco, CA",1 to 50 employees,-1,Company - Private,-1,-1,₹100 to ₹500 million (INR),-1
Data Scientist,-1,"LocationIndia / US / EuropeExperience2 YearsAcademic Qualification:B.S, B.E., B.Tech/MBA from top-tier Engineering /B-School ORMasters in Statistics/Economics from leading UniversityOverviewContinuous, growth opportunities for career progression and personal developmentProfessional, stimulating, continuous learning, work environment based on camaraderie, individual mentorship, on-the-job and corporate trainingCompetitive and performance-oriented compensation and employee benefits packageIndustry benchmarked HR policies and practices, particularly in areas such as Performance Management, Learning and Professional Development, Career Planning and Compensation and Rewards.Roles and responsibilitiesWill involve teamwork as well as work in which individual contribution will be needed.Clear, articulate and confident written and verbal communication skills.Working experience in Advanced Analytics Techniques Predictive modelling Time series forecasting Machine Learning etc.The role will require a sound understanding of business functions, statistical concepts and algorithm design/implementation skills.Core responsibilities include leveraging data science to solve business cases, training other team members, and contributing to pre-sales through quick execution of PoCs. Typical activities will include:Interacting with business stake holders for gathering requirementsAnalysing data to develop key insights on business trends and performanceApplying statistical/mathematical algorithms as needed to address specific business problemsProficiency in using query languages such as SQL(preferable), Hive, Pig, R, SAS, PythonAdditional Skills (preferred)Will involve teamwork as well as work in which individual contribution will be needed.Intermediate querying and scripting skills in SQLExperience in relevant field such as Statistics, Computer Science or Applied Math.SPOCBuddhadeb BhattacharjeeMail toBuddhadeb.bhattacharjee@tcg-digital.com",3.0,"TCG Digital
3.0",India,"Somerset, NJ",201 to 500 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"PipeCandy is a 'one of its kind', 'data science' driven market intelligence platform that tracks the global eCommerce landscape. Our insights are used by well known global brands and startups. We are venture funded by India, the US, and Singapore based investors.

About the Role:
We are building a complex data product that aims to revolutionize industry intelligence by applying sophisticated machine learning & AI algorithms on millions of data points.
We are looking for a Data Scientist to ensure that the quality of this product always stays top-notch and world-class. If you love working with data, have an eye for detail and a strong adherence to quality then we’d love to hear from you.

This is a senior position where the analyst will work under the general direction of the Chief Data Scientist and senior staff in the Data Management team. The primary responsibility is to treat data as an asset and become the expert source for data standards and policy-related questions.

Key Responsibilities:
Manage the creation, deployment, and maturity of data governance processes and technology including master data, metadata, and data quality initiatives
Identify opportunities to ensure transparent, high-quality data across sources and platforms
Review, clean and add business records and formatting rules to every taxonomy/hierarchy in the product database in support of long-term data governance.
Develop processes and tools for data cleansing, de-duplicating, and other data preparation, standardization, and transformation
Collaborate with various teams to standardize data and ensure adherence to data ingestion and governance standards
Conduct root cause analysis and proposed improvement solutions
Leverage subject matter expertise to ensure data products are understood by the business users
This position requires a proficient level of experienced analytical and programming capabilities, defining requirements, developing and/or maintaining computer applications/systems, and ability to meet business needs within deadlines.

Here’s what we’re looking for in you:
Works to develop analytical/ data mining/ machine learning models using Python, R and other tools
Gather, evaluate and document requirements, ability to build an algorithm (statistical/ data mining/ machine learning) based on requirements and specifications provided
Works with data and is able conceptualize and improvise analytical solutions to problems
Ability to deploy analytical algorithms within a larger business application
Ability to visualize data and results of data analysis & analytical models
Create model documentation as per client/ regulatory standards

Qualifications & Competencies Required:
1+ years of total relevant experience
Degree in a quantitative field (Math, Statistics, Economics, Physics, and/ or Engineering, MBA)

Desired:
Ability to work with business and technology teams to build and deploy an analytical solution as per needs
Ability to multi-task, solve problems and think strategically
Strong communication and collaboration skills

Skills Required:
Experience with statistical analysis using R and Python. Experience with Spark and ML as plus
Good experience in data discovery, exploration and algorithm development
Experience with working on large data sets and developing scalable algorithms
Hands-on experience of machine learning and data mining algorithms such as decision trees, classifiers, text mining/ NLP, clustering, and regression
Exp in SAS, SPSS, or scripting languages such as Java a plus
Knowledge of Hadoop and other distributed computing platforms
Broad knowledge of data mining, NLP algorithms, machine learning algorithms and other techniques technologies
Strong analytical and problem solving skills
Excellent presentation and communication skills

Perks:
Flat organization structure with an opportunity to work very closely with the founders
Access to learning, training sessions outside of your immediate line of work
Access to group kindle account with latest titles
Stocked pantry, of course",4.6,"PipeCandy
4.6",Chennai,"Walnut, CA",1 to 50 employees,2016,Company - Private,Internet,Information Technology,₹100 to ₹500 million (INR),-1
Data Scientist,-1,"Implement and support data discovery and predictive analytics models by analyzing business data.

Qualifications:
3+ years of experience with R
3+ years of experience with mahout or machine learning algorithms
1+ years of experience with deep learning libraries like TensorFlow or equivalent
Working experience with java or python
Database experience with MySQL or NoSQL database solutions
Ability to design the models to work on small to very large data sets
If interested, please send the latest CV to data@scalein.com or contact using our contact page.",-1,ScaleIn,Bengaluru,"San Jose, CA",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Experience
– 2 to 4 Years
Education
– B.Sc / M.Sc (Maths / Statistics) B.Tech /B.E. – Computer Science

Job Description:
2 - 4 years of experience in machine learning and data mining
Excellent understanding of different software such as Perl, Python, Hadoop, Java and R programming
Strong technical background and have excellent problem-solving abilities
Good in at least one programming or scripting language
Understanding of databases and ability to write SQL queries
Excellent oral and written communication skills with business acumen
Should be a self-starter with high initiative and enthusiastic to learn and deliver on latest tools and technologies
Experience worked in big data environment is an added advantage",-1,Sybrant Data,Chennai,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"About Company:
Casepoint provides full eDiscovery capabilities through a powerful, secure, cloud-based platform. We are repeatedly chosen by leading law firms and multinational corporations for their largest matters. On an upward trajectory for almost a decade, Casepoint is looking to expand its team globally. Team cooperation, work hard, play hard attitude, open communication, and kindness mark Casepoints culture.
Job Description
We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products
Key job responsibilities:
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending companys data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Required skills & experience
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, Logistic Regression (LR), Linear Discriminant Analysis (LDA), K-Nearest Neighbors (KNN), Classification and Regression Trees (CART), Gaussian Naive Bayes (NB), Support Vector Machines (SVM).
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc. Excellence in at least one of these is highly desirableX
Great communication skills
Experience with data visualization tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality
Compensation & culture:
Excellent culture produces an excellent product. We value our team members, so we provide a nurturing environment of camaraderie. We recognize talent with competitive compensation and career empowerment.
Location: Surat, India",3.4,"Casepoint Pvt. Ltd
3.4",Surat,"Washington, DC",51 to 200 employees,2006,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Description – Data Scientist
Roles & Responsibilities:
Ability to understand a problem statement and implement solutions & techniques for solving natural language processing, text analytics, and information extraction problems, as well as structured data problems.
Work and collaborate with other teams to deliver and create value for clients
Fast learner: ability to learn and pick up a new language/tool/ platform quickly
Conceptualize, design and deliver high-quality solutions and insightful analysis
Conduct research and prototyping innovations; data and requirements gathering; solution scoping and architecture; consulting clients and client facing teams on advanced statistical and machine learning problems.
Come up with actionable ideas to solve problems and implement those ideas.
Communicate context, data, solution and implications to the team, senior leaders and stakeholders.


Skills:
Intermediate to expert level proficiency in at least one of Python and R
Ability to discover effective solutions to complex problems. Strong skills in data-structures and algorithms.
Experience of working on a project end-to-end: problem scoping, data gathering, EDA, modeling, insights, and visualizations
Problem-solving: Ability to break the problem into small problems and think of relevant techniques which can be explored & used to cater to those
Intermediate to advanced knowledge of regular expressions, machine learning, probability theory, information theory, statistics, and algorithms. Discuss and use various algorithms and approaches on a daily basis.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, MySQL, etc.


Qualifications & Experience :
Bachelor's or Master's degree in engineering.
Good knowledge of Basic Statistics (Hypothesis testing, probability, distributions, etc.)
Exposure towards multivariate statistical Analysis (such as PCA, PLS, etc.).
Strong in Machine learning and supervised Learning techniques such as ANN, Decision Trees, SVM, Naïve Bayes etc.
Knowledge on Unsupervised learning techniques such as k-means, hierarchical clustering etc.",3.5,"CoStrategix Technologies
3.5",Bengaluru,"Cincinnati, OH",51 to 200 employees,2006,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Our client is seeking a creative Data Scientist to explore unstructured data from diverse sources in order to extract insights that enable us to create new investment strategies. The candidate should demonstrate a wealth of experience in building models that required advanced machine learning and statistical analysis.

In this position, you will be a cornerstone member collaborating closely with our researchers and engineers to test research hypotheses and build forecasting models. You will play a key role in the global race for financial firms to adopt data-driven investment strategies and your research will have the potential to shape the nascent field of quantitative finance.

The company is looking for a deeply curious candidate who is expert at extracting signal out of flawed data to make valid inferences. You are fascinated and energized by cutting-edge, data-driven techniques increasingly utilized in the financial world. Excited to leverage your data science skills, you can imagine yourself thriving in the fast pace, highly experimental of a start-up.

What you’ll do
Modelling research hypotheses and assumptions of financial experts by pulling all the necessary data from disparate sources and designing and validating models that transform that data into actionable insights
Developing and testing the most predictive and robust statistical, machine learning, and deep learning methods to forecast factors, features, metrics, drivers, etc.
Tackle the challenges of featurizing and modelling large and unstructured data using machine learning and statistical techniques
Manage all aspects of the research and execution process including methodology selection, data collection and quality, modelling and analysis, and performance monitoring
Iterating quickly to test the additive impact of new data and research findings on alpha generation
Deliver research findings to investment teams, portfolio managers, and partners
What’s required:
Advanced degree in computer science, machine learning, applied mathematics, or another technical discipline
Experience in text mining/NLP in a relevant field researching real-world data problems (though not necessarily in finance)
3+ years of experience in data analysis and utilizing statistical modeling techniques (e.g. machine learning, deep learning, or signal processing)
Ability to extract data from varied stores (t-sql, hadoop) and write code for models that can stand up to large datasets (python, spark)
Creative thinker excited by the prospect of ideating and evaluating experiments
Background in time series analysis and interest in time series-related machine learning research
Excited by a high learning curve in the field of financial technology
Excellent written and oral communicator of data-driven findings
Company’s culture:
The company is driven by the mission of shaping the future of investment management. They have an international and multicultural team of creative and open-minded problem solvers.

Combining the best talents from physics, computer science, mathematics, social sciences and finance, the company all together are striving for constant innovation.

For your valuable work, the company offers:
Highly dynamic, innovative, passionate and entrepreneurial team
Open and inclusive company culture
Autonomous and self-managed agile teams
About the company:
The company, backed by leading industry giants, is a developing next generation technology to revolutionize how investment decisions are made. The company offers differentiated, amplified and future-oriented investment intelligence mined from alternative data. Extracting early signals from the vast amount of data, empowering investment professionals with unique investible insight and hence better returns. From hedge fund to asset manager, they help our clients to enhance their investment models and derive information edge from a variety of data sources.

Location: Gurgaon, India

Job Type: Permanent and Full-Tim",5.0,"itForte
5.0",Gurgaon,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Data Scientist

Are you passionate about learning and intellectually curious? Do you thrive in a fast-paced, innovative work environment where team members hold themselves and others accountable? Are you energized by trying new things, have an agile mindset, and enjoy making an impact? Is working for a purpose driven organization important to you? If the answers to these questions are a resounding YES, then read on!

Skillsoft is the global leader in helping businesses solve their biggest challenge – attracting, motivating, and retaining world-class talent. Our team is recognized for cutting-edge digital learning and human capital management solutions. Trusted by the world's leading organizations, including 65% of the Fortune 500, we train more professionals than any other company in the world. Our 100,000+ courses, videos, and books are accessed over 130 million times every month, in 160 countries and 29 languages. At Skillsoft, we believe that knowledge is the fuel for innovation and innovation is the fuel for business growth.

Skillsoft’s SumTotal Strategic Business Unit has nearly 30 years of learning and HR software experience. High-performing organizations recognize that learning and development are core to their business success and overall talent management and workforce initiatives. That’s why more than 3,500 organizations, including many of Fortune’s “Best Places to Work,” rely on SumTotal’s solutions to enable their employees.

We are all about ""Making Work Matter."" With over 2,000 employees around the world, we are always looking for amazing talent!

Overview:

Opportunity Highlights:
Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework and test model quality.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Skills & Qualifications:
Bachelors and 5+ yrs. relevant experience required in Statistics, Math, Finance or other quantitative field or Master’s degree and 3+ years of post-degree experience in Statistics, Math, Finance or other quantitative field (preferred).
Problem Analysis Skills- Understand and be able to apply advanced modeling techniques such as logistic regression, generalized linear models, decision trees, cluster analysis, survival analysis, etc. to answer specific business queries or situations.
Independent - Advanced knowledge of the entire modelling process (design, develop, test, implement, measure) and demonstrated ability to manage time/resources to bring projects to completion.
Results Oriented - Proficient leveraging financial techniques i.e. ROI, NPV and Cashflow to measurement the effectiveness of tools/models.
Technical Expertise - Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets
Success Qualities:

Adaptable and Agile. Responds quickly to the changing needs of the business and is resilient in the face of setbacks or adversity.

Confident & Audacious Achiever. Champions breakthrough initiatives and holds him/herself and others accountable for delivering. Enjoys working hard; is action-oriented and full of energy for the things he/she sees as challenging; not fearful of acting without over-analysis.

Entrepreneurial Spirit with Learner’s Mindset. Is uncomfortable with simply maintaining ""status quo"" and is intellectually curious and demanding of excellence and continuous improvement.

Committed to our Collective Purpose. Leverages cross functional collaboration to solve complex business issues and drive greater results.

Authentic & Customer Centric. Never compromises integrity to achieve results while constantly being mindful of creating a positive customer experience both internally and externally. Adheres to an uncompromising set of core values and beliefs during both good and bad times; practices what he/she preaches. Acts with the highest standards of conduct and is seen as a direct, truthful individual.

Thank you for taking the time to learn more about us.
If this opportunity intrigues you, we'd love for you to apply!

NOTE TO EMPLOYMENT AGENCIES: We value the partnerships we have built with our preferred vendors. Skillsoft does not accept unsolicited resumes from employment agencies. All resumes submitted by employment agencies directly to any Skillsoft employee or hiring manager in any form without a signed Skillsoft Employment Agency Agreement on file and search engagement for that position will be deemed unsolicited in nature. No fee will be paid in the event the candidate is subsequently hired as a result of the referral or through other means.",2.8,"SumTotal
2.8",Hyderabad,"Gainesville, FL",1001 to 5000 employees,1998,Subsidiary or Business Segment,Computer Hardware & Software,Information Technology,₹5 to ₹10 billion (INR),-1
Data Scientist,-1,"Experience: 2-5 Years

Job Summary

Design and execute statistical analysis, modelling, and simulation efforts for clients that lead to actionable decisions affecting operations.

Analyse data sets to summarize, identify trends, predict future states, and characterize uncertainty.

Author complex written products documenting study results. Apply analytical approaches using statistical programming languages, including Python, and R.

Work closely with teammates from non-mathematical disciplines to ensure that operational strategies are considered in the context of applying statistical theory.

Use statistical theory on modelling, simulation, and data analysis to deliver measurable improvements to organizational policies and programs.

Responsibilities
Engage in data mining, algorithm development, statistical analysis, regression, and machine-learning initiatives
As part of ongoing work and interaction with the broader team, identify new opportunities to use modelling and advanced analytics to drive business value
High Proficiency in SQL
Expertise in applied statistics.
Able to translate business objectives into actionable analyses.
Able to communicate findings clearly to both technical and non-technical audiences
Expertise in Python for ML model development.
Experience with machine learning & Deep learning algorithms and predictive analytics
Natural curiosity to enjoy diving deep into the material to find answers to yet unknown questions.
Demonstrated ability to perform comfortably in a fast-paced work environment
Education, Skills and Abilities Required for Consideration:
Sound experience in using statistical and data mining techniques to solve real business problems
Having skills on Python for ML model Development
Passion for problem-solving, developing creative solutions, and continuous learning.
1+ years of Experience in Automotive / Mechanical background.
2+ years of ML/ Data science Experience
Good to have: Having worked on connected device. Having Idea on Clustering etc
Preferred : Deep Learning with Pytorch or TensorFLow Location: Bangalore",4.0,"Careator Technologies
4.0",Bengaluru,"Hyderabad, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Co-relationship models
ARIMA
Exponential Moving Average
Smoothened Exponential Moving Average
Croston
Requirement
Good Oral and Written Communication Skills
Data Digger/Data Analyst
Analytical
Self Starter",5.0,"Techlive
5.0",Noida,"New Delhi, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Description :
Required competencies:
Phd/MTech/MS or equivalent degree in Computer Science or Mathematics or Statistics
Relevant industry or research experience
Strong knowledge of data mining, machine learning techniques and statistics
Experience with analysis on large scale datasets
Strong problem solving, programming skills and computer science fundamentals
Preferred Skills:
Knowledge of Hadoop and other distributed computing platforms
Experience with tools like Weka, R and other machine learning packages
Location : Bangalore",-1,WeRecruit Talent,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"Data Scientist Bangalore As a fully functioning analytics team member, applies best practices to analytics solutions and contributes to the development of improved best practices. Below are the MUST HAVES: • Experience as Data Scientist - Fortune 100 Clients - Prefer Product Base. • Data analysis experience working with large-scale data. • Strong experience using Python & SQL for analysis, modeling, and data visualization.
Advanced statistics, data mining and modeling knowledge. Requirements: • Advanced Python for Data Science (descriptive / predictive models) + Strong Stats background Own the end to end data science process, from initiation to deployment, and through ongoing communication and collaboration. • Drive personalization, real-time decision-making, causal inference, and predictive analytics capabilities through the application of Machine Learning, Deep Learning, NLP, and Simulation in an agile development framework. • Conduct quantitative analysis of experimental, and textual data to generate insights and drive decision making (ANOVA, Regression, Chi-Sq, AB, pre-post etc..) Working knowledge of SQL, Tableau, Hadoop, BigQuery, Presto, Vertica Write well documented code that can be shared and used across teams, and can scale to be used in existing products",3.3,"Calsoft Labs
3.3",Bengaluru,"Bengaluru, India",1001 to 5000 employees,1992,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,"Mindtree, Happiest Minds Technologies, Altran Americas"
Data Scientist,-1,"Description

Key Responsibilities: Team leads for small or module leads for large teams. Responsible for delivery of assigned module/ components /phases of a project.Responsible for people Management, including goal setting and providing performance feedback.Responsible for Status reporting .Responsible for Knowledge transfer and arriving at SLAs for steady state.Technical problem solving skills. Job Requirement and Skills Has a good practical understanding of technology and its application. Good grasp of technology and tools used for development. Good design skills and architectural skills in the technical area.Fair amount of domain expertise gained through working on the application or certification programs (if working in a vertical).Good understanding of the sphere of activities in a horizontal domain. Anticipates and resolves potential problems , handles escalations. Supervisory Level: Works under general supervision with few direct instructions. Carries out routine and semi-routine tasks. Provides input to project-related decisions.People Interactions Within own team or department at operational level.Contact with user/customer at peer / first /middle management level. Qualifications

About ECS

ECS is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., ECS is ranked 205 on the Fortune 500 and is consistently listed among the most admired companies in the world.",3.0,"ECS
3.0",Chennai,"Jersey City, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Required Skills:
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Weka, NumPy, etc
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig, etc.
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality
Good to have:
Master’s degree in stats, applied math, or related discipline
2+ years of project management experience
Professional certifications",4.0,"Aptagrim Consulting
4.0",Hyderabad,"Singapore, Singapore",1 to 50 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist /AI Developer,-1,"Mode of employment: Full time / Contract

As a Data Scientist in the LDA India, you will be involved in designing, implementing and testing a component of the Minerals projects. You will work closely with our product owner, scrum master and other developers in an agile development team throughout the entire product lifecycle.

What are my responsibilities?
• You are proficient in modern technologies and software development for web AI application using Java
o Basic python, tensorflow, regression models, deep learning, neural networks, data science mathematical models and Git
• Design, develop and maintain in on premise and cloud environment (Dev, Test and Release)
• Implement, test and release bug fixes

What do I need to qualify for this job?
General Experience & Skill Set
Qualification: Degree / BE (Computer Science, Information Technology)
Experience: 3+ years of experience on software development projects, out of which at least 2 year of AI Work experience

Required Skills:
• Strong knowledge in software development, build, release.
• Knowledge of AI
1. Python, tensorflow, regression models, deep learning, neural networks, data science mathematical models, Git
• Knowledge of Java
• Strong in OOP concepts

Organization: Portfolio Companies

Company: Siemens Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.0,"Siemens
4.0",Thane,"Munich, Germany",10000+ employees,1843,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹500+ billion (INR),"GE, ABB, Philips"
Data Scientist/ML Engineer,-1,"About Us: https://paytm.com/about-us/

Why Us:
Looking for a company that encourages passion, courage and imagination, where you can be part of the team crafting the future of payments, ecommerce, and financial services? Want to craft how millions of people transact, buy, sell, connect, and share? If you’re passionate about building large scale recommendation engines, fraud detection, discovery, and joining a purpose driven community that is dedicated to creating an ambitious and inclusive workplace, join Paytm – a company you can be proud to be a part of.

About Team:

The ML team within Paytm provides opportunities to innovate in a fast-paced organization that contributes to game-changing projects and technologies that get deployed on devices and the cloud. As an ML engineer, you'll partner with technology and business teams to build new services that surprise and delight our customers. You will be working with massively large data to solve real-world problems. You'll design and run experiments, research new algorithms, and find new ways of recommendations, optimizing risk, profitability, and customer experience.

We’re looking for top data scientists capable of using ML and other techniques to design, evangelize, and implement state-of-the-art solutions for never-before-solved problems.

Experience Required: 4-8 yrs
Job Location: India

Responsibilities

Use deep learning, machine learning and analytical techniques to create scalable solutions for business problems

Have excellent Programming/Debugging skills in Python/Java/Scala.

Have strong hands-on experience with Hadoop, MapReduce, Hive, Spark, Flink.Design, develop, evaluate, and deploy innovative models for predictive learning, content ranking,
Credit scoring and fraud detection.

Interact with customers directly to understand the business problem, help and aid them in implementation of DL/ML algorithms to solve problems.

Analyze and extract relevant information from large amounts of data to help automate and optimize key processesActively identify new areas where data science can be leveraged across the organization.

Hands on experience building models with frameworks like Tensorflow, Caffe, Theano, etc. The motivation to achieve results in a fast-paced environment.

For more Information please connect on monika1.jain@paytm.com",3.5,"Paytm
3.5",India,"Noida, India",1001 to 5000 employees,2010,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Ahmedabad
Be a part of the movement to revolutionize the in-store customer experience through the loyalty program and the other features we have to offer.We believe in creating memories that will last forever. We want to help businesses develop personal connections with their customers and provide the customers with experiences that they will cherish forever and will keep them coming back.
We’re scrappy, hard-working perfectionists looking for people who can add immediate value to our team. As a member of the founding team of # Loyalty, you will have the opportunity to work across different business verticals in an extremely faced paced environment. You'll play a key role in product development, strategy and other business decision.

Job Description
Machine Learning & Artificial Intelligence are embedded deeply into our products evolution. We are looking for talented individuals to help us build these tools and embed them into our product offering. The exposure and impact on the product will be massive! And select individuals would be offered a full-time or part-time position post the internship, depending on the performance during the same.

What we're looking for:
Experience working with Python and libraries like NumPy, SciPy, Pandas, Scikit-learn, Tensorflow etc.
Experience working with large data-sets (provide links to your work on Github/Kaggle)
Solve complex performance problems and architectural challenges
Passionate about Machine Learning and AI
Strong knowledge of PHP web frameworks {{such as Laravel, CI,}}
Worked on real world recommender / ranking systems
Prior experience working at a startup environment would be great
Other Skills
Python, Machine Learning, Numpy/Scipy/Pandas/Scikit-learn
Should be able to handle a team technically.
Experience
PHP: 1+ years (Preferred)

Contact Us to Apply : (+91) 851 187 8094 info@r3coder.com",-1,R3coder,Ahmedabad,"Ahmedabad, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Responsibilities
Identify valuable data sources and automate collection processes
Undertake pre processing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns
Build predictive models and machine-learning algorithms
Combine models through ensemble modeling
Present information using data visualization techniques
Propose solutions and strategies to business challenges
Collaborate with engineering and product development teams
Requirements
Proven experience as a Data Scientist or Data Analyst
Experience in data mining
Understanding of machine-learning and operations research
Knowledge of R, SQL and Python; familiarity with Scala, Java or C++ is an asset
Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop)
Analytical mind and business acumen
Strong math skills (e.g. statistics, algebra)
Problem-solving aptitude
Excellent communication and presentation skills
BSc/BA in Computer Science, Engineering or relevant field; graduate degree in Data Science or other quantitative field is preferred.",-1,Country Veggie,New Delhi,"Jaunpur, India",1 to 50 employees,2019,Private Practice / Firm,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Experienced professional or an active researcher in one or multiple of the following areas: OCR-ICR technologies, Artificial Intelligence, Semantic Technologies, Natural Language Processing, Image Mining, Pattern Recognition on Digital Media ,and Information Retrieval (handling data types, ranging from traditional structured data, semi-structured data such as logs; text, social networks, audio, images, and video)
Experience in Neural network, Deep learning (Feed forward, Recursive, Recurrent LSTM, Auto encoder, CNN), Transfer
Minimum 4-8 years of
Full Stack developer using Tensor flow, Theano, Caffe
Familiarity with details of implementing algorithms on multi-core CPUs, clusters (MPI), GPUs
Strong knowledge in Capability to develop production ready solution using Python.
Worked as a Data Scientist in the product development project
Experience in distributed frameworks (e.g. Graph Lab, Spark, Hadoop)
Experience in Mongo DB, Index server, Graph DB, MQ.",3.2,"Innominds Software
3.2",Hyderabad,"San Jose, CA",501 to 1000 employees,2003,Company - Private,Computer Hardware & Software,Information Technology,₹1 to ₹5 billion (INR),"GlobalLogic, Persistent Systems (India), Mobica"
Senior Data Scientist,-1,"Antuit is a global solutions and services consulting firm and a leader in providing customers with the ability to accurately predict the future of demand, pricing, and marketing. We help Fortune 100, and Fortune 500 enterprises transform their businesses from a data-rich environment to automated decision making through artificial intelligence and machine learning. The net results are increased marketing share, sales, and profit margins.

We are a dynamic and growing company. Our teams are passionate about solving challenging problems, and we give them the independence needed to create innovative solutions for customers. Our people utilize intellectual depth, domain knowledge, and industry expertise to help customers build smarter and more profitable companies. For more information, visit www.antuit.com.

Description
Antuit is interested in hiring a Senior Data Scientist to develop machine learning algorithms in the Supply Chain and Forecasting domain with data science toolkits that include advanced SAS skills. The Senior Data Scientist will also be responsible for participating in the design process, as well as implementation. This is an excellent opportunity to enhance your career while solving world-class data science problems.

Senior Data Scientist Responsibilities and Duties

Develop machine learning algorithms in the Supply Chain and Forecasting domain with data science toolkits that include advanced SAS skills
Further design processes and implement them
Research and develop efficient and robust machine learning algorithms
Collaborate and work closely with cross-functional Antuit teams and domain experts to identify gaps and structure problems
Create succinct presentations with analyses that tell a story that communicates results, insights and recommendations to key decision makers at Antuit and client companies

Information Security Responsibilities

Understand and adhere to information security policies, guidelines and procedures, and apply them to protect organizational data and the information system
Take part in information security training and act accordingly when handling information
Report all suspected security and policy breach to InfoSec team or appropriate authority (CISO)

Senior Data Scientist Qualifications and Skills

Experience / Education. Master’s or PhD in Computer Science, Computer Engineering, Electrical Engineering, Statistics, Applied Math or another related field. 7+ years’ work experience involving quantitative data analyses for problem solving (work experience negotiable for recent PhDs with relevant research experience). Experience working with cloud Big Data Stack to orchestrate data gathering, cleansing, preparation and modelling. Additional experience with forecasting and optimization problems; and implementing data analytics solutions with Python, R or SAS
Exceptionally skilled in machine learning, data analytics, pattern recognition and predictive modelling
Strong communication and presentation skills. Effective communication and story-telling skills
Energy and enthusiasm. Passion for learning and contributing to development
A true team player. Collaborative mindset for effective communication across teams

Information Security responsibilities:
Understand and adhere to Information Security policies, guidelines and procedure, practice them for protection of organizational data and Information System
Take part in Information Security training and act accordingly while handling information.
Report all suspected security and policy breach to Infosec team or appropriate authority (CISO).

EEOC
Antuit is an at-will, equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law.

To apply, please send your resume / CV to careers@antuit.com.",4.0,"Antuit
4.0",Bengaluru,"Chicago, IL",201 to 500 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Location: Chennai, Mumbai, Bengaluru - India
1+ years of Analytics experience
Understand business requirements and technical requirements
Can handle data extraction, preparation and transformation
Create and implement data models
write to careers@ganitinc.com",4.0,"Ganit
4.0",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Position: Data Scientist

About us: WebMD Health Corp., an Internet Brands Company, is the leading provider of health information services, serving patients, physicians, health care professionals, employers, and health plans through our public and private online portals, mobile platforms, and health-focused publications. The WebMD Health Network includes WebMD Health, Medscape, Jobson Healthcare Information, prIME Oncology, MediQuality, Frontline, QxMD, Vitals Consumer Services, MedicineNet, eMedicineHealth, RxList, OnHealth, Medscape Education, and other owned WebMD sites. WebMD®, Medscape®, CME Circle®, Medpulse®, eMedicine®, MedicineNet®, theheart.org®, and RxList® are among the trademarks of WebMD Health Corp. or its subsidiaries.

Aptus Health is a wholly-owned subsidiary of WebMD. As the analytics arm of Aptus Health, we help our clients and our products realize their potential. Helping understand customer behaviour and traits is at the core of what we do. A team of 8 members, we are analogous to a start-up centre with hands-on responsibility for every member.

Role & Responsibilities:


The selected candidate will work on the following:
• Work with real-world case studies in Data Science and a chance to implement various modeling techniques
• Get real-life experience of working with big data in the digital marketing sphere.
• Opportunity to independently execute and lead analytical projects and assignments
• Help solve some challenging Healthcare related digital marketing problems globally. Transform business question into data requirements; collect and merge the data; analyse the data, link it to the business reality and present the results
• Develop predictive models and machine learning algorithms to study the change in physician prescribing behaviour as well as WebMD integrated campaign response behaviour. Build analysis to understand user engagement and behaviours across various WebMD products.
• Build expertise in data preparation, data visualisations and transformations through SAS, R, Tableau and other analytical tools.

Technical Skills needed:
• Experience with data manipulation in SQL environment is a must. Knowledge of Snowflake data warehousing is good to have

• Experience with statistical and data manipulation tools such as SAS or R is a must • Need very good expertise in using Microsoft Excel, and Microsoft PowerPoint. Excellent presentation skills required

• Experience developing statistical models like hypothesis testing, regression models, classifications models, forecasting etc is a must

• Algorithm designing and implementation skills in R or Python is required

Requirements:
• B.Tech/B.E. / MSc Statistics from premier institutes with minimum 80% marks in 10th and 12th grade
• 1.5-2.5 years of relevant work experience in Analytics field",3.4,"Aptus Health
3.4",Mumbai,"Reading, MA",201 to 500 employees,2008,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Scientist,-1,"Location:
Defence Colony, New Delhi

Job Purpose Summary:
Responsible for driving Mahajan Imaging's new focus on medical informatics and data analytics:
Preferably well aquainted with SQL based PACS and Hospital Information Systems.
Putting medical reports and images into an easily searchable structured format for clinical research and scientific purposes.
Responsible for pulling relevant information from company databases.
Would have access to high-end servers and other equipment.
Would have opportunity to work with leading medical imaging companies and universities.",4.0,"Mahajan Imaging
4.0",New Delhi,"New Delhi , India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Machine Learning Scientist,-1,"JOB DESCRIPTION

Job Responsibilities

Machine Learning Scientist, Hyderabad

This is an open invitation for India’s best in class Machine Learning Scientist - Product Engineering to join the disruptive technology and thought leader in the global Talent Relationship Marketing Cloud Platform. If you live & breath engineering by solving not only engineering problems but are passionate about building state of the art products that help a billion+ job seekers, then welcome to Phenom People. At Phenom we build products that connect right fit talented candidates (job seekers) with companies seeking for Phenomenal talent. We help companies establish, nurture and mature relationship with talented candidates through the hiring life-cycle. Based in Greater Philadelphia area, we server global fortune 500 companies. To know more about Phenom People, visit phenompeople.com
Looking for talented engineers with interests in Machine Learning & Data Science
Build amazing products, you will shape the future of our products
What you will do:
Design and implement machine learning, information extraction, probabilistic matching algorithms and models
Research and develop innovative, scalable and dynamic solutions to hard problems
Work closely with Machine Learning Scientists (PhDs), ML engineers, data scientists and data engineers to address challenges head on
Use the latest advances in NLP, data science and machine leaning to enhance our products and create new experiences
Scale machine learning algorithm that powers our platform to support our growing customer base and increasing data volume
Be a valued contributor in shaping the future of our products and services
You will be part of our Data Science & Algorithms team and collaborate product management and other team members
Be part of a fast pace, fun focused, agile team
Job Requirements
1+ years of industry experience (Not Mandatory)
Ph.d in computer science, information systems, or similar technical field
Strong mathematics, statistics, and data analytics
Solid coding and engineering skills preferably in Machine Learning (not mandatory)
Proficient in Java, Python, and Scala
Industry experience building and productionizing end-to-end systems
Knowledge of Information Extraction, NLP algorithms coupled with Deep Learning
Experience with data processing and storage frameworks like Hadoop, Spark, Kafka etc.
Education
Ph.D in computer science, information systems, or similar technical field
About Company

At Phenom People, we believe great people build great companies. We know that there is no difference between marketing and selling products and jobs, so we took CRM best practices and applied them to talent acquisition and built the world’s first Talent Relationship Marketing platform.

Candidates today are not job hunters; they are savvy shoppers. They expect a certain quality of user experience when browsing jobs, researching companies and applying for positions - an experience traditional recruiting tools and tactics cannot deliver. Welcome to the talent relationship business.

TRM is an automated system for managing the talent relationship lifecycle of current and future candidates, driving awareness, interest, engagement and acquisition. Our Phenom TRM platform aligns the objectives, priorities and actions of candidates, recruiters, hiring managers and talent acquisition leaders.

Phenom People strives to be the most innovative HR tech company in the world. By offering unique, engaging experiences for candidates, our platform helps put the right opportunity in front of the right person at the right time so you can continue to build phenomenal teams and achieve business goals for years to come. Stop recruiting. Start relationship marketing.",4.4,"Phenom People
4.4",Hyderabad,"Ambler, PA",501 to 1000 employees,2011,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Educational qualifications
B Tech/ BE, M.Sc.(Maths) or M Tech/ MS or equivalent in Mechanical/Metallurgical/ Electrical/ Electronics/ Computer Science/Instrumentation/Industrial Engineering/Operations Research or in any other relevant discipline.

Relevant experience (Type/ Nature and years of relevant experience required to execute the role)
Min. 2-4 years of experience

Locations: Jamshedpur / Kalinga nagar / Kolkata/ Mumbai

Experience related to advanced analytics
Machine learning, Deep learning, Fuzzy logic, data visualisation, statistics, Derived data analysis etc.
Programming and process trouble-shooting experience will be preferred.
Exposure to mathematical modelling will be preferred.
Understanding of statistics and statistical modelling will be required.
Good process knowledge related to supply chain, iron and steel manufacturing, marketing or mining/mineral processing is preferable.
Programming skills using a high level language (preferably in .net environment) will be necessary.
Knowledge on data acquisition, analytics, statistics and other mathematical modelling tools will be useful.
Sound concepts on Big data analytics will be helpful.

Technical Competencies
Statistics, Data analytics, Artificial intelligence, programming, system engineering and flow design, Logic building, Scenario analysis.
Coding in R/ Python language is Compulsory.

Behavioral Competencies
Learning inclination, Collaboration, Achievement orientation, change orientation",-1,Imurgence,Jamshedpur,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"As a Data Scientist, you will work to resolve ambiguity with data, play a crucial role in the iteration and optimization solutions, and support data-driven decision-making across the organization.

Responsibilities :
Tasked with solving a real-life business problem that requires a processing/analyzing large amounts of data and handling a variety of data sources.
Take ownership of successful completion for the end to end life cycle and implementation.
Proactively investigate, report, and where possible, address data quality issues.
Can envision & implement the optimal analytics technique/approach required for the problem.
Ability to work and execute projects on both structured and unstructured data in a big data environment.
Ability to work across geographies and interact with global stakeholders.
Ability to coordinate and work within multiple business units from a project management perspective.
Prior experience working in Agile methodologies/JIRA would be a plus.
Requirements:
BS/BE in Computer Sciences, Math, Statistics, or related field. Masters preferred.
An expert in at least one of the machine learning frameworks - Keras, Tensorflow, PyTorch, etc, as well as programming, visualization, and statistical tools such as R, JMP, SAS, Tableau, Python, Perl, Java/C++
Minimum of 4+ years of experience in data, advanced analytics, data science, and business intelligence.
Proficient in SQL and experience with efficient processing of large data sets. Ability to write sophisticated and optimized queries against large databases.
Proficient in Python ML libraries, Hadoop/Redshift/BigQuery.
Experience in the Ad-Tech industry is a must.
Job Type: Full-time

Location:
Noida, Uttar Pradesh (Preferred)
Application Question:
How much experience do you have in Data Science?
Do you have experience working in Ad-Tech Industry?",-1,Jubna,Noida,"Dubai, United Arab Emirates",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"About us & Vision

Sequretek is an Indian MNC focused on Information Security and Information Management space. The company is backed by industry veterans who have come together with a vision to build India’s leading Information Security company.
Sequretek’s customers have appreciated its solution offerings, and within a short span the company has acquired marquee clientele in Financial, Pharmaceutical, IT/ITES, and Retail and Logistics sectors.
Sequretek probably is the one of the very few companies that offers a blend of its own core threat intelligence products along with both on-premise and cloud solutions. Our end point detection, protection, and response technology – EDPR is the industry’s only product that replaces up to six different endpoint technologies for our customers.
Our vision is to establish and sustain Sequretek as a Global Leader in terms of the ‘Security’ of Enterprise-level Information-Assets through the consistent delivery of world-class products and solutions that leverage state-of-the-art technologies relevant to the contemporary digital economy.

Why Sequretek?

You will be part of an award winning ""Security Product Company of the Year – 2019” announced by Data Security Council of India (A NASSCOM Initiative).
The team is highly visible, agile, and working on critical problems that directly affect the company’s success.
Our researchers regularly appear at various global conferences and are some of the most sought-after thought leaders in the security industry.
Our ML Engine was certified by ICSA Labs for its detection against unknown / little known malwares.
As part of the research group, you will leverage your problem-solving and analytical skills to further our capabilities, as well as publish and present new and novel research.

Education & Experience

Education:The candidate must have any of the below:
BE/B.Tech/MTech in Computer Science, Statistics, or Data Science.
Experience:
Minimum 1-2 years of experience in applying ML/Deep Learning algorithms and
techniques to real-world data sets.

Key Responsibilities

Skills:
Knowledge of Core Python
Proficiency in Machine learning algorithms (SVM, Decision Trees, PCA, Clustering etc.).
Knowledge and Experience of Deep Learning Algorithms (CNN, RNN, LSTM etc.)
Knowledge of major ML frameworks such as TensorFlow, PyTorch, Keras, and Scikit-Learn.
Strong analytical thinking and problem solving.
Designs scalable processes to collect, manipulate, present, and analyze large datasets in a production-ready environment
Demonstrated participation on platforms like Kaggle is a plus
Prefer great appreciation or expertise in Security products such as End point detection, protection and response, Managed detection and response etc
Must be proactive and flexible and have the ability to work under pressure and possess good follow-through skills.
Must possess excellent written and verbal communication and a quick learner.
Responsibilities:
Wants to build and develop innovative intellectual property through the research and implementation of new approaches in machine learning and simplifying security
Approaches problems from an adversarial mindset in an effort to circumvent prediction systems
Works with internal product and engineering teams to drive development of new products
Has the capability to translate and implement newly published research on specific datasets and problems to validate approaches and potentially improve
Experienced wrangling large volumes of data and applying machine learning techniques towards real product and business problems
Invests time in research including publications, and is committed to keeping up with AI trends
Develop working prototypes of algorithms and evaluate and compare metrics based on large, real-world data sets",4.0,"Sequretek
4.0",Bengaluru,"Mumbai, India",201 to 500 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Scientist (ML/Deep Learning Expert),-1,"Skills:
1. Good understanding of basics of Statistics, Probability, Linear Algebra and Calculus
2. Should be able to explain all ML/DS projects mentioned in resume
3. Good in qualitative and result interpretation
4. Good understanding of business problem
5. Profound understanding of basic DS and ML skills like outlier handling, data imputation, bias, variance, cross validation etc.
6. Good understanding of basic ML algorithm, like linear regression, logistic regression, random forest etc.
7. Take Ownership of on boarding new customers and continuously improve our existing.
8. Experience in building machine learning models or optimization software to solve business problems.
9. Ability to communicate results clearly to both colleagues and less technically versed audiences.
10. Knowledge of multivariate preferably in the Python Data ecosystem.
11. Good communication skills.
12. Passion to learn new tools, languages and frameworks
13. Good either at Python or R from DS perspective
Good in terms of Python
• Understand and uses pandas, numpy, scikit-learn and other scientific libraries
• effectively and efficiently.
• Understand basic data structure of python
• Write pythonic code
Good in terms of R.
• Good understanding on using packages like data. table, ggplot, dplyr etc.
• Good understanding of matrix algebra and memory management.

Desired Skills:
1. Basic understanding of version control systems
2. Experience of working in agile development environment.
Supply Chain Nation
Our Values

If you want to know the heart of a company, take a look at their values. Ours unite us. They are what drive our success – and the success of our customers. Does your heart beat like ours? Find out here: Core Values
Check out Blue Yonder's blog - Supply Chain Nation - the platform for supply chain trends and innovations.",4.3,"Blue Yonder
4.3",Bengaluru,"Scottsdale, AZ",5001 to 10000 employees,1985,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 billion (INR),"SAP, Oracle, Manhattan Associates"
Data Scientist,-1,"Perform data-mining, modeling and hypothesis generation in support of high-level business goals.
Stay current with emerging tools and techniques in machine learning, statistical modeling & analytics.
Strong aptitudes for business, technology, mathematics & statistics.
Need strong oral & written communication skills to present data as a concise story for diverse audiences.
Develop customized algorithms to solve analytical problems with incomplete data sets.

Skills Needed:
R/Python Programming

SQL

Statistical Modeling

Machine Learning Techniques

Knowledge on Software Development is an added advantage",2.5,"BrandIdea Consultancy P Ltd
2.5",Chennai,"Mumbai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist /AI Developer,-1,"Mode of employment: Full time / Contract

As a Data Scientist in the LDA India, you will be involved in designing, implementing and testing a component of the Minerals projects. You will work closely with our product owner, scrum master and other developers in an agile development team throughout the entire product lifecycle.

What are my responsibilities?
• You are proficient in modern technologies and software development for web AI application using Java
o Basic python, tensorflow, regression models, deep learning, neural networks, data science mathematical models and Git
• Design, develop and maintain in on premise and cloud environment (Dev, Test and Release)
• Implement, test and release bug fixes

What do I need to qualify for this job?
General Experience & Skill Set
Qualification: Degree / BE (Computer Science, Information Technology)
Experience: 3+ years of experience on software development projects, out of which at least 2 year of AI Work experience

Required Skills:
• Strong knowledge in software development, build, release.
• Knowledge of AI
1. Python, tensorflow, regression models, deep learning, neural networks, data science mathematical models, Git
• Knowledge of Java
• Strong in OOP concepts

Organization: Portfolio Companies

Company: Siemens Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Thane,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Scientist,-1,"Job ID
R10004765

Location

Mumbai, Maharashtra, India

Business
Star

Date posted
Nov. 21, 2019
Job Summary:


OVERVIEW OF THE COMPANY

StarStar India has defined the Indian media landscape for over two decades and today is one of the country’s leading media conglomerates, reaching approximately 650 million viewers a month across India and more than 100 other countries. Star generates 20,000 hours of content every year and broadcasts 40+ channels in 8 different languages, reaching 9 out of 10 C&S TV homes in India. The network’s entertainment channel portfolio includes Star Gold, Channel V, Star World, Star Movies, Star Utsav, Life OK, Movies OK and Star Plus, India's No. 1 Hindi General Entertainment Channel. It has a leading presence in regional broadcasting as well, through a bouquet of affiliate channels which includes Star Jalsha, Jalsha Movies, Star Pravah, Asianet, Asianet Plus, Suvarna, Suvarna Plus, Vijay and now Maa. It is also present in the Indian movie production and distribution space through Fox Star Studios, an affiliate joint venture company.
JOB DESCRIPTION


KEY RESPONSIBILITIES :
Using techniques from supervised and unsupervised machine learning, statistical analysis and predictive modelling to deliver business insights to business units based on data
Working directly with internal customers to educate them on “moving beyond BI” and training their internal resources to execute advanced forms of analytics
Creating reusable implementations of statistical tests and models using cutting edge technologies
Working with the academic and business community to develop new techniques and to contribute to research in the area of advanced analytics in media
Assisting in engagement management, requirements definition, project scoping, timeline management, and results documentation to ensure professional relationship management
PERFORMANCE MEASURES :
As per role KPIs
QUALIFICATION :
2-8 Years plus post qualification
Degree in computer science with a machine learning focus (other technical degrees also accepted e.g. applied mathematics, statistics, physics, operations research). PhD will be desirable.
KNOWLEDGE AND SKILLS :
Advanced knowledge of statistical and machine learning methods, particularly in the areas of modelling and business analytics
Strong programming skills
Experience with statistical languages and packages, such as R, SAS, Mat-Lab, and/or Mahout
Experience working with relational databases and/or distributed computing platforms, and their query interfaces, such as SQL, MapReduce and Hive.
Experience with additional programming languages, such as Python, Java, and C/C++.
Excellent written and verbal communications skills, with a proven ability to translate complex methodologies and analytical results to higher-level business insights and key take-away
A proven passion for generating insights from data, with a strong familiarity with the higher-level trends in data growth, open-source platforms, and public data sets.
Experience working hands-on with large-scale data sets
Familiarity with visualization software and techniques (including Tableau), and business intelligence (BI) software, such as Micro-strategy, Cognos, Pentaho, etc.
PERSONAL ATTRIBUTES :
Creative, gritty, driven by curiosity and comfortable with failure
Strong Data intuition: Talent to identify and visualize patterns
Multi Modal Communication skills
We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, gender identity, disability, protected veteran status, or any other characteristic protected by law. We will consider for employment qualified applicants with criminal histories consistent with applicable law.

About Star:


Star India has defined the Indian media landscape for over two decades and today is one of the country’s leading media conglomerates, reaching approximately 650 million viewers a month across India and more than 100 other countries. Star generates 20,000 hours of content every year and broadcasts 40+ channels in 8 different languages, reaching 9 out of 10 C&S TV homes in India. The network’s entertainment channel portfolio includes Star Gold, Channel V, Star World, Star Movies, Star Utsav, Life OK, Movies OK and Star Plus, India's No. 1 Hindi General Entertainment Channel. It has a leading presence in regional broadcasting as well, through a bouquet of affiliate channels which includes Star Jalsha, Jalsha Movies, Star Pravah, Asianet, Asianet Plus, Suvarna, Suvarna Plus, Vijay and now Maa. It is also present in the Indian movie production and distribution space through Fox Star Studios, an affiliate joint venture company.

About The Walt Disney Company:


The Walt Disney Company, together with its subsidiaries and affiliates, is a leading diversified international family entertainment and media enterprise with the following business segments: media networks, parks and resorts, studio entertainment, consumer products and interactive media. From humble beginnings as a cartoon studio in the 1920s to its preeminent name in the entertainment industry today, Disney proudly continues its legacy of creating world-class stories and experiences for every member of the family. Disney’s stories, characters and experiences reach consumers and guests from every corner of the globe. With operations in more than 40 countries, our employees and cast members work together to create entertainment experiences that are both universally and locally cherished.
This position is with Star, which is part of a business segment we call Star.",3.6,"Star
3.6",Mumbai,"ALESSANDRIA, Italy",51 to 200 employees,-1,Company - Private,-1,-1,₹1 to ₹5 billion (INR),-1
Data Scientist,-1,"Roles and responsibilities

Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight:
Translate business objectives into analytic approaches, and identify data sources to support analysis.
Analyze and model structured data using advanced statistical methods
Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns.
Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications.
Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods.
Implement algorithms and software needed to perform analyses
Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management.
Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data
Communicate results and educate others through reports and presentations.
Essential skills required
Education / professional qualifications

Masters, or PhD in Computer Science, Statistics, Mathematics

Prior Experience:

Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience

Technical skills
Ability to break down complex problems, and develop strategies to solve them
Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience
Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint.
Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval
Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing
Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred
Experience with command-line scripting, data structures and algorithms
Ability to work in a Linux environment, and process large amounts of data in a cloud environment
Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby)
Behavioral / team skills
Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations
Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills
Excellent written and verbal communication skills Team player; self-driven and ability to work independently
Team player; self-driven and ability to work independently",4.2,"Anlage HRO Services
4.2",Bengaluru,"Mumbai, India",201 to 500 employees,1996,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Currently we are looking for a Senior Computer Vision Engineer who is passionate about the sphere of Big Data, Data Science and AI.

Responsibilities:
Creating solutions and products for leading representatives of different industries;
Analysing business problems, looking for better technical solutions and their implementation;
Expanding company’s expertise in the field of Computer Vision;
Management of the direction of the company in the future.",-1,Exeliq Consulting,Maharashtra,"Schaumburg, IL",1 to 50 employees,2019,Company - Public,-1,-1,₹10 to ₹50 million (INR),-1
Data Scientist,-1,"Location: Bangalore

Skill Sets:
Strong learning acumen
Team Player
High sense of ownership
Ability to work in a fast-paced and deadline driven environment
Passion for technology
Highly skilled at Data Interpretation
Problem solver
Responsibilities:
Hypothesis testing, insights generation, root cause analysis, factor analysis
Statistical model (predictive & prescriptive) development using various statistical methods
Familiar with Machine learning techniques/algorithms
Test/train the model, Improve Model accuracy, Execute & Monitor model performance, prepare reports based on the results of the analysis
Data Extraction from various platforms such as SQL/Big Data Platform/Google CP, Dataset Preparation (creation of base data, aggregation, transformation), performing EDA
Qualifications:
Experience with data analysis/Modelling
Postgraduate with Engineering Background
Hands on exposure of machine learning concepts and algorithms
Must be fluent with any one of these Python, R or Java
Strong in statistical & machine learning concepts
Knowledge of Python Libraries – Scipy, Numpy, Pandas, IPython, Scikit-learn, Tensor-flow, Keras, Theano etc.
Strong Python skills for data wrangling / analysis / visualization / modeling
Experience with distributed big data processing (PySpark, Jupyter, Linux, AWS)
Deployed at least one industrial project using supervised / unsupervised machine learning",2.8,"Bharat Light & Power
2.8",Bengaluru,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Miles is looking to expand its data science and data engineering team in INDIA!

Here's a quick checklist:
You live in India
Want to work for a fast-growing Silicon Valley Startup
You are passionate about solving challenging problems
You are looking to put your stamp on the product
What you'll need:
Education
Master's/PhD (preferred) or Bachelor's (required) in CS/ML/AI or relevant computational/engineering discipline
Machine Learning/Data Science:
Solid theoretical understanding of ML fundamentals: linear algebra, probability, statistics (as relevant to ML), optimization
Knowledge of different ML techniques and when/how to use them: classification, regression, clustering, outlier detection, dimensionality reduction, etc.
Comfortable manipulating and analyzing complex, high-volume, high-dimensionality data from varying, heterogeneous sources
Experience with messy real-world data -- handling missing/incomplete/inaccurate data
Proficient in the Python ML ecosystem: NumPy, Pandas, SciPy, Scikit-Learn
Strong understanding of relational databases like PostgreSQL is a plus
Programming experience:
At least 2+ years of experience writing production-quality Python code
Version control: Git, GitHub/Bitbucket
Experience delivering large-scale deployable projects
Great to have
We deal with large volumes of geospatial data, so experience working with geospatial data at scale is a big plus
Knowledge of Python (Shapely, GeoPandas, Fiona, CartoPy, etc) and/or database (PostGIS) geometry/geospatial tools
Domain experience in building models for location-based services, transportation, scheduling, vehicle routing",3.9,"Miles
3.9",Bengaluru,"Bergen, Norway",51 to 200 employees,2005,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
DATA SCIENTIST,-1,"Should have a Master’s degree in Statistics, Mathematics, Computer Science

Responsibilities Include:
Interacting with the stakeholders, within the company and the customers, to understand the needs
Exploratory analysis from the existing data
Formulating the questions to be answered and hypotheses to be tested
Identifying additional data to be collected and third-party data sources that will help the analysis
Developing data presentations, models and algorithms required
Using data analysis tools and algorithms and to build “prototypes” to obtain stakeholders’ feedback
Providing inputs and support to software / firmware developers to build the required software components, data structures and dashboards
Interact with other project team members to adhere to overall project schedules
Ensure Adherence to internal development policies and participating in continually improving existing processes

Mandatory Technical Abilities:
Strong problem-solving skills with an emphasis on product development
Experience using statistical computer languages (R, Python…) to manipulate data and draw insights from large data sets
Experience of working with and creating data architectures
Experience of analyzing data from 3rd party providers (Google Analytics, SiteCatalyst, Coremetrics, Crimson Hexagon…)
Experience with data analytics and visualization tools (Tibco Spotfire, Business Objects…)
Proficiency in using query languages such as SQL, Hive
Experience with NoSql databases (MongoDB, Cassandra…)
Knowledge of machine learning techniques (classification, clustering, decision tree, artificial neural networks, etc.) and their real-world applications, advantages/drawbacks
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, Bayesian statistics, Inferences...) and experience with applications
Good written and verbal communication skills for coordinating across teams
Ability to learn and master new technologies and techniques",3.8,"Alpha ICT LLP
3.8",Maharashtra,"Pune, India",51 to 200 employees,-1,Other Organisation,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"We are looking for a data scientist that will help us discover the information hidden in vast amounts of data,
and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques,
doing statistical analysis, and building high quality prediction systems integrated with our products.
Responsibilities:
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Skills and Qualifications:
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc .
Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality
skills:
Azure compulsory

Job Type: Full-time

Experience:
work: 3 years (Preferred)
total work: 4 years (Preferred)
Education:
Bachelor's (Preferred)",-1,Techunity Software Systems,Coimbatore,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"Job responsibilities :
Take a leading role and be hands on in all phases of development, including user requirements, functional design, implementation, testing, and design validation.
Capable of developing early stage of product conceptualization and implementing scalable and high-performance systems
Cloud computing knowledge and experience with deploying applications on any of the well-known IAAS/PAAS providers.
Experience in planning projects and meeting delivery deadlines
Experience on continuous development and continuous deployment.
Capable of performing technical root cause analysis and outlining corrective action for problems using debuggers, log files etc
A quick and enthusiastic learner (must) and who is willing to work on new programming languages depending on requirement
Capable of providing reliable solutions to a variety of problems using sound problem-solving techniques
Excellent leadership, aptitude and communication skills
Capable of delivering values to the customer and meeting their expectations
The ability to communicate technical information clearly and succinctly to both technical and non-technical teams
Work closely with all of R&D, Engineering and other teams to jointly deliver high quality products and solutions
The team is also passionate about increasing their productivity and bringing quality features to market at a fast pace.
Required Skills :
2+ years of experience in Face Recognition (Must)
Programming language: Python (Must); C, C++, Matlab (Optional)
Experience with Deep Learning frameworks like Tensorflow, Keras, Pytorch, Theano, Scikit-learn, Caffe.
Experience of working with facial recognition technology is a must (preferably for 2+ years)
Having exposure to Deep learning for Computer vision/Machine learning problems typically involving Object detection, segmentation, classification, regression for both visual and textual data.
Knowledge of computer vision and NLP algorithms like Neural networks, Convolutional Neural networks (CNN), Recurrent neural networks (RNN), and Long short term memory (LSTM).
Projects: At least one project in machine learning or Computer vision.
Job Types: Full-time, Volunteer

Salary: ₹800,000.00 to ₹1,000,000.00 /year

Experience:
work: 2 years (Required)
total work: 5 years (Required)
Education:
Bachelor's (Required)",4.2,"Multi Recruit
4.2",Bengaluru,"Bengaluru, India",1 to 50 employees,2013,Company - Private,Staffing & Outsourcing,Business Services,₹10 to ₹50 billion (INR),-1
Data Scientist,-1,"Job Description

We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.

Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques.
Data mining using state-of-the-art methods.
Extending company’s data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis.
Doing ad-hoc analysis and presenting results in a clear manner.
Creating automated anomaly detection systems and constant tracking of its performance.
Required Skills
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Perl, Python, SparkML, Weka, NumPy, MatLab, etc.
Experience with data visualization tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig.
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase.
Experience with Hadoop or similar distributed computing and storage platforms.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills.
Exceptional analytical abilities,creativity and attention to details.
Good organizational and problem solving skills.
Good team player who is a self-starter and well organized.
Strong oral and written communication skills.
Required Education
Graduate degree in Math, Statistics, Computer Science, or other quantitative discipline.
Please email your resume to careers@gtpltech.com",-1,GridEdge Technologies,Pune,"Rockaway, NJ",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Location
Powai, Mumbai
Experience
5+ years
Education
BE/B.Tech
Type
Regular/Full time
Roles and Responsibilities

Identify valuable data sources and automate collection processes
Undertake reprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns
Build predictive models and machine-learning algorithms
Combine models through ensemble modeling
Present information using data visualization techniques
Propose solutions and strategies to business challenges
Collaborate with engineering and product development teams

Desired skills and experience

Deep experience in machine learning
Excellent skills in Python
Exposure to advanced deep learning techniques such as LSTM, CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow/keras/pytorch/deep AI or equivalent
Experience of working in multiple text mining / NLP solution
Should have experience of deploying and putting into production ML based solution
Should have at-least 1 end-to-end ML project experience
Must possess experience in Python
Experience: 5+ years",3.5,"NSEIT
3.5",Maharashtra,"Mumbai, India",1001 to 5000 employees,1999,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"Who you will work with:


The Data & Analytics (D&A) office is looking for multifaceted Data Engineer to help Cisco to unleash the power of data.

We have a huge amount of information from Cisco's Enterprise datasets, and you'll help provide data engineering and analytics solutions which will enable Cisco to be more data-driven to optimize its day to day operations and strategy. You will help make the data threading, data clean-up and traditional & predictive analytics available and consumable in ingenious new ways, and help build a community of ""Data Engineering & Analytics advocates” across the company to ensure adoption.

What You'll Do
Define and design the overall architecture of data analytic platform;
Drive architecture and data engineering capabilities in the data analytical platform;
Lead data engineers and data scientists, articulate business requirements and optimally translate into technical implementation plans;
Lead the design for application solutions that will solve data analytic needs;
Provide technical expertise to engineering teams.
Who You'll Work With
You will have an opportunity to work cross functionally with Customer Success, IT, Sales, Marketing, Product Teams
Who You Are:

Master's degree in Computer Science (PhD. is a very strong plus)
15+ years of research or R&D leadership experience
Willingness to work across teams and share knowledge and ideas beyond the immediate area of responsibility
Capability to stand up and formulate clear scientific and technical arguments supporting one’s opinion
Ability to quickly grasp the essence of the new technologies and be able to steer the team in the right direction
Can-do attitude with a strong drive to take the initiative and complete tasks
Experience of working in an Agile environment
Willingness to take full ownership for the work you're doing
Scripting, programming languages, and software packages for high-level data analysis such as Python or R
Bigdata frameworks such as Apache Kafka, Hadoop, Spark, etc.
Advanced modelling techniques
Programming tools such as version control, build tools, and documentation tools
Experience building production AI solutions
Advanced skills/experience in database systems or data warehousing, data analysis, ETL, solutions design;
Great problem solver; ability and ability to learn on your own and work in an ambiguous environment
Ability to manage multiple projects at the same time, working across time zones and cross-culturally; Ability to work as part of a team
Hands on experience in Data Science/Machine Learning
Excellent written and verbal communication skills.
Additional requirements that will be a plus
R&D experience in several of the following areas: Machine Learning and Data Science, Computer Science, Statistics, Artificial Intelligence, Data Mining, Pattern Recognition, Cloud Computing, Game Theory, Graph Theory
Scientific publication track in the area of machine learning and AI
Why Cisco


People, processes, data, and things. taking ambitious risks to shape the technologies that give us smart cities, connected cars, and handheld hospitals. And we do it in style with standout personalities who aren’t afraid to change the way the world works, lives, plays and learns. We are leaders with a point of view, tech geeks, pop culture aficionados, and we even have a few purple haired rock stars. We celebrate the creativity and diversity that fuels our innovation. We are dreamers and we are doers.

At Cisco, each person brings their groundbreaking talents to work as a team and make a difference.

Yes, our technology changes the way the world works, lives, plays and learns, but our edge comes from our people.
We connect everything – people, process, data and things – and we use those connections to change our world for the better.
We innovate everywhere - From launching a new era of networking that adapts, learns and protects, to building Cisco Services that accelerate businesses and business results. Our technology powers entertainment, retail, healthcare, education and more – from Smart Cities to your everyday devices.
We benefit everyone - We do all of this while striving for a culture that empowers every person to be the difference, at work and in our communities.
Colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool. Pop culture geek? Many of us are. Be you, with us! #WeAreCisco

Gem20",4.2,"Cisco Systems
4.2",Bengaluru,"San Jose, CA",10000+ employees,1984,Company - Private,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Alcatel-Lucent, Juniper Networks"
Data Scientist,-1,"Candidate should be able to analyse data and discover information, with high level inputs from the functional team. Understanding of data mining techniques and statistical analysis is important.",3.5,"Pattern Effects Labs
3.5",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Experience : 2+ years

What will you do:
Should have working knowledge of relational Database designs (SQL Server, MySQL, Oracle).
Should have knowledge of Queue management systems (Redis, MSMQ, RabitMQ etc).
Should have knowledge of SQL query, Stored Procedures, Functions.
Should have knowledge of No SQL will be an added advantage.
Shall analyze, define and document system requirements for data, workflow, logical processes, interfaces with other systems, auditing, reporting requirements and production configuration.
Shall write and maintain functional and technical specifications.
Shall create scripts and packages for data integration, data maintenance or bug fixes.
Shall analyze code for problem resolution and performance optimizations.
Shall write SQL statement for ad-hoc report generation.

What we can offer

Are a young organization and the workplace is an extension of our families back home
Mondays and Fridays have the same effect on us
Value positive vibes, honesty, sense of judgment, empathy and self-motivation
Believe in experimentation and don't think of new things as daunting enough to take up at any point in time
Are looking for driven and focused individuals
Will be more than happy to hear from you

We want to hear from you
Why don't go ahead and send us a video clip of yourself, giving us a creative brief of who you really are.Once you're done with that, [email protected] :).",-1,big tree,Mumbai,"Großostheim, Germany",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Description
BizViz provides a 360 degree view of a business's data, serving any vertical and meeting the demanding needs of all business executives. With a 50+ strong team building the BizViz platform over several years, it is targeted at creating technological solutions that will give our customers the edge they need to succeed.

We strongly believe that our success lies in the success of our customers. We aim to build applications the way they envisioned, keeping each business' unique ideas and requirements in mind. We offer businesses a better alternative to using standard cookie-cutter ERP templates.

Job Summary
Design and execute statistical analysis, modeling, and simulation efforts for clients that lead to actionable decisions affecting operations. Analyze data sets to summarize, identify trends, predict future states, and characterize uncertainty. Author complex written products documenting study results. Apply analytical approaches using statistical programming languages, including Python, SAS, and R. Work closely with teammates from non-mathematical disciplines to ensure that operational strategies are considered in the context of applying statistical theory. Use statistical theory on modeling, simulation, and data analysis to deliver measurable improvements to organizational policies and programs.

Responsibilities
Engage in data mining, algorithm development, statistical analysis, regression, and machine-learning initiatives
As part of ongoing work and interaction with the broader team, identify new opportunities to use modeling and advanced analytics to drive business value
High Proficiency in SQL
Expertise in applied statistics.
Able to translate business objectives into actionable analyses.
Able to communicate findings clearly to both technical and non-technical audiences
Expertise in at least one statistical software package such as SAS or Python and R
Experience with machine learning algorithms and predictive analytics
Natural curiosity to enjoy diving deep into the material to find answers to yet unknown questions.
Demonstrated ability to perform comfortably in a fast-paced work environment
Education, Experience, Skills and Abilities Required for Consideration as a Candidate:
PhD or MSC in a quantitative discipline: Statistics, Applied Mathematics, Operations Research, etc.
3+ years of experience in using statistical and data mining techniques to solve real business problems

Minimum of 3 years of experience in any one of the following:
Machine Learning
Data Mining
Predictive analysis
R & Python or SAS.
Passion for problem-solving, developing creative solutions, and continuous learning.
Experience in at least one of the following domain - Retail, Healthcare & Education.
Location
Bangalore & Hyderabad.",3.0,"BDB
3.0",Bengaluru,"London, United Kingdom",51 to 200 employees,1993,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Help us improve access to life-changing therapies that can transform human health
We are Cytiva, a global provider of technologies and services that advance and accelerate the development and manufacture of therapeutics. Formerly part of GE Healthcare, we have a rich heritage tracing back hundreds of years, and a fresh beginning since 2020.

Our customers undertake life-saving activities. These range from fundamental biological research to developing innovative vaccines, biologic drugs, and novel cell and gene therapies. Our job is to supply the tools and services - the pots, pans, soups and sauces - they need to work better, faster and safer, leading to better patient outcomes.

What you’ll do
The candidate will be working with multiple teams & functions for data collation, data deep dives and analytical story building. The individual will be responsible for communicating insights from available data sources to Marketing & Commercial teams. The individual must have strong experience of using a variety of data mining/data analysis methods & tools, building and implementing models, using/developing algorithms and creating/running simulations. We are looking for solid communication and presentation skills in this role.
Mine and analyze data from databases to drive the optimization and improvement of marketing techniques and business strategies.
Program management of critical Advanced Analytics programs (incl Forecasting, Targeting and Propensity models, etc.)
Use predictive & prescriptive modeling to increase and optimize customer experiences, revenue generation, marketing initiatives and other business outcomes.
Processing, cleansing, and verifying the integrity of data used for analysis.
Being a key contributor / influencer to strategic marketing plans
Clear communication with stakeholders: help our business understand in a very simple manner what we are doing, how we are going to do it (per project and more conceptually) – raising awareness of the fundamentals and details of data science.

Who you are
Masters Degree in Marketing, Business Administration or Statistics/Economics or equivalent
4 - 5 years’ experience in Analytics
Well versed with Statistical tools (eg R / SAS / Python, etc) and techniques feeding into advanced predictive & prescriptive analytics.
Knowledge of a variety of machine learning techniques (statistical tests, regressions, clustering, decision trees, artificial neural network, etc) and experience in their application and output interpretation.
Knowledge on classification, prediction, optimization, clustering and market basket analysis models.
Working experience with visualization tools incl Spotfire / Tableau / Qlikview / Power BI
Well versed with Digital Analytics and understanding digital & web data.
Co-ordinate with different functional teams to implement models and monitor outcomes.
Excellent English oral and written communications skills.
Desirable Experience
Background in biopharma, pharma, life sciences or healthcare industry.
Experience of working in Marketing & Commercial teams.
Experience / knowledge of working with databases & data architecture.
Ability to influence and make recommendations at all levels of the company
Excellent project management skills – able to lead and manage complex matrix teams
Experience working in a dynamic and horizontal team environment.
High energy, works proactively and demonstrates flexibility in approach to changing priorities.
Team oriented – ability work well with diverse, cross-functional teams

What to expect as a career path in this role
This individual will grow as an Advanced Analytics professional along with a) core exposure in the
analytics industry & b) business and domain knowledge of the BioPharma industry.
Who we are
Whatever your role, we bring purpose and challenge into our everyday work. If you are driven to make the world a better place thanks to science and medicine, you’ll feel right at home here. If you’re flexible, curious and relentless, you’ll belong. If you are excited about a global culture, this can be the place to further your career.

Want to know more? Experience life at Cytiva on our Careers website , Instagram channel and LinkedIn page !

Cytiva is a 3.3 billion USD global life sciences leader with nearly 7000 associates across 40 countries who are dedicated to our mission to advance and accelerate therapeutics. As a trusted partner to customers that range in scale and scope, Cytiva brings efficiencies to research and manufacturing workflows, ensuring the development, manufacture and delivery of transformative medicines to patients.

Cytiva is part of the Danaher family of companies, a global science and technology innovator committed to helping customers solve complex challenges and improving quality of life around the world.",-1,Cytiva,Bengaluru,"Vancouver, Canada",1 to 50 employees,-1,Subsidiary or Business Segment,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
Data Scientist,-1,"We are looking for a Data Scientist to help us create machine learning products. Data Scientist responsibilities include understanding the business problem and experimenting with different modelling architectures to create the best possible setup from model performance as well as computational performance. To do this job successfully, you need exceptional skills in Machine Learning and Programming. Your ultimate goal will be to find the best data-based solution for the problem at hand

Job Description:
Understanding business objectives and developing models that help to achieve them, along with metrics to track their progress
Develop and maintain robust data processing pipelines and reproducible modelling pipelines
Build mathematical models to solve various problems ranging from Time Series forecasting to Neural Networks and ensure seamless deployment in production pipelines.
Explore data and communicate insights clearly to non-technical as well as technical audience
Analyze experimental results, iterate and refine models to create significant business impact
Follow strict coding standards and other software engineering best practices and be the proponent of the culture in the organization.
Preferably from FMCG Industry

Requirements

Bachelor’s Degree in a Quantitative discipline
4-6 years’ experience in data science/Analytics roles
Expert Proficiency in Time Series Forecasting – Classical & Machine Learning
Proven experience as a Data Scientist or similar role
Expert ability to write robust code in Python
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn , StatsModels )
Should be proficient in evaluation metrics (MAPE, F1, RMSE, Confusion Matrix)
Should possess strong problem-solving skills
Excellent verbal and written communication skills
You take complete ownership of your work and are self-driven.

Good to Have

Deep Learning Frameworks like Tensorflow, PyTorch etc.
Familiarity in working with Azure, AWS, GCP etc.
Experience with NoSQL databases, such as MongoDB, Cassandra
Experience with containerizing applications using Docker

Mandatory Skills

R, Python ,Machine leaning

Desirable Skills

R, Python ,Machine leaning",4.7,"Thoucentric
4.7",Mumbai,"Bengaluru, India",51 to 200 employees,2015,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
"Data Scientist , Apple Care Online Support",-1,"Summary
Posted: Feb 24, 2020
Role Number:200131127
The people here at Apple don’t just build products — they build the kind of wonder that’s revolutionized entire industries. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple, and help us leave the world better than we found it.

Imagine what you could do here.

The AppleCare Digital team is looking for an outstanding data scientist who is interested in designing, developing and identifying data mining solutions that have direct and measurable impact to AppleCare’s support operations.

AppleCare has a tremendous amount of data, and we have just begun the exploration of data in the areas of NLP, pattern detection, predictive modelling and optimization. The person in this position will work with various Online business managers to help identify viable analytical opportunities and then implement an end to end analytical solution. The role requires both a broad knowledge of existing data mining algorithms and creativity to invent and customize when necessary.

The job is located in Bangalore, India
Key Qualifications
Hands-on experience in algorithms like Linear/Logistic, SVM, Random Forest, K-means, K-Nearest neighbour (KNN), PCA, Naive Bayes, apriori etc.
Exposure to deep learning algorithms like Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Long Short-Term Memory Networks (LSTMs), Stacked Auto-Encoders etc.
Expertise in NLP concepts like Text wrangling & pre-processing, parts of speech tagging, NER and supervised & unsupervised models for Text data
Knowledge of SQL and strong programming skills in Python or R is a must
Excellent interpersonal, written, and verbal communication skills
Ability and comfort working independently and making key decisions on projects
Description
Analyze large datasets to glean actionable insights
Focusing on solving concrete customer and business problems at scale
Design classifiers and ranking algorithms
Perform ad-hoc statistical analysis
Present results of analysis to team and leadership across Apple
Create metrics to measure the success of the service
Education & Experience
Ph.D. in Data Science, Machine Learning, Statistics, Operations Research or related field or B.Tech/M.Tech/M.S. in related field with 5+ years experience applying data science techniques to real business problems.",4.7,"Apple
4.7",Bengaluru,"Cupertino, CA",10000+ employees,1976,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Google, Microsoft, Samsung Electronics"
Data Science Professional,-1,"Job title: Data Scientist | IT Global Operations

We are part of SOP IT APD DA which deals with Data Analytics and
Business Intelligence for Asia. As a Data Scientist in the Analytics Lab India,
you will be involved in designing, implementing and testing a component different
projects with diverse background. You will work closely with our product owner,
scrum master and other developers in an agile development team throughout the
entire product lifecycle.

This is your role. What part will you play?
Perform strategic data analysis and
research within SAP data structures to support business processes and
strategy and discuss results with team leads and customers.
Process large amounts of data from
multiple sources and extract relevant insights.
Build predictive models and ensure the
models are robust enough to be used in production


We dont need superheroes, just super minds.

Qualification:
Degree / BE (Computer Science, Information Technology)
A masters degree in mathematics, Physics,
Statistics, Computer Science, Engineering, a similar quantitative field or
equivalent practical experience.
3+ years of
experience on software development projects as business/data analyst,
ML/AI developer, Data visualization expert, Cloud developer
Experience with statistical software and
scripting languages (e.g. R, Python, SAS).
Proficiency in SQL.
Experience analyzing and modeling data
sets.
Experience with statistical and machine
learning methods (preferred).
Ability to communicate technical concepts
into simple terms to present to non-technical audiences (preferred).
Effective written and verbal communication
skills (preferred).


We are looking forward
to receiving your online application. Please ensure you complete all areas of
the application form to the best of your ability as we will use the data to
review your suitability for the role.

Make your mark in our exciting world at Siemens.

This role is based in Pune, where youll get the chance to
work with teams impacting entire cities, countries and the shape of things to
come.

Were Siemens. A collection of over 379,000 minds building the
future, one day at a time in over 200 countries. We're dedicated to equality
and we welcome applications that reflect the diversity of the communities we
work in. All employment decisions at Siemens are based on qualifications, merit
and business need. Bring your curiosity and creativity, and help us craft
tomorrow.

Organization: Siemens Operations

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.0,"Siemens
4.0",Pune,"Munich, Germany",10000+ employees,1843,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹500+ billion (INR),"GE, ABB, Philips"
Data Scientist,-1,"FiFyles is changing lives!

As Data Scientist eager to jump into brand new learning experiences, you’ll have fun analyzing complex, massive data sets. If this sounds like you, please read on!

Who You Are

You cut your baby teeth on Bayesian modeling and Markov chains
You love the idea of working at a startup-within-a-startup
You are curious enough to always want to dig deeper
You dream of applying machine learning to everyday tasks
You never wait for someone else to ask “why?”
You drive others crazy with how open-minded you are
Your imagination knows no bounds when it comes to slicing and dicing complex problems and data sets
You are strongly opinionated on what makes for great software skills, and love playing devil’s advocate
You believe every experience, good or bad, is an opportunity to grow
You are convinced that the best use of experience is to leverage it to learn more
You are a natural-born leader
You know how to prioritize
You are analytically curious
You still like to play “Where’s Waldo?” on occasion to test your awesome pattern-recognition skills
There’s always methodology to your madness
You know that numbers tell a good story
Spock is your favorite Star Trek character

What You Want From Your Next Career Move

To change the world using your skills in solving analytical problems. To learn. To perform data analyses on massive data sets, at scale. To manage the data demands of a company with a heart.

Why We Need You

FitFyles is a company that saves lives. A company that is going to change the face of health care for good. We need someone to administer the flow of ideas regarding data and make recommendations to influence the direction of our business by communicating results to numerous stakeholder groups. You’ll work with the massive datasets, information, and knowledge that we’re collecting and organizing, and help to drive innovation in our product and enhance user experiences. We need your unique skills to:

Help manage our intense growth by developing and executing data analyses to manage the growth demands of FitFyles
Develop, implement and maintain robust reporting methodologies and tool to support mission-critical business objectives
Pioneer new uses of data to help save lives by enhancing user growth and engagement

How You’ll Change Global Healthcare

You’ll help millions live longer, healthier, happier lives through your ability to exercise creativity in addition to your analytic skills.

What you’ve achieved

BS / MS / PhD in a quantitative discipline (applied mathematics, statistics, CS, OR, or related field)
5+ years of experience using quantitative approaches to solve challenging and meaningful analytical problems (or equivalent)
Proficiency in programming and the use of analytic tools to perform rapid design, prototyping, analysis, simulation of, and experimentation with, advanced algorithms and applications (such as Matlab / Mathematica, Java, Ruby, Python, and experience in various relational and non-relational databases)
Solid grounding in applied mathematics and statistics including expertise in Bayesian modeling, multivariate regression, logistic regression, machine learning, cluster analysis, decision analysis, time series analysis and forecasting, factor analysis, structural equation modeling, item response theory, Markov chains, and data visualization (preferred)
Startup or equivalent experience (preferred) and the drive to live the dream (required)",-1,Fitfyles,New Delhi,"New Delhi, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"We are looking for people with the right blend of technology skills, business knowledge and a passion for revolutionizing machine vision.

Explore and prototype solutions or products at intersection of computer vision, image processing, applied machine learning by leverage existing or new vision or machine learning algorithms.
Solid understanding on linear algebra, image processing, computer vision and machine learning knowledge.
Develop and prototype computer vision algorithms in Python or C++
Familiar with one or two deep learning frameworks: Tensorflow, Pytorch/Caffe2, Keras etc.
Hands on experience in one or more of the following areas: real-time object detection/segmentation/recognition/tracking, visual scene understanding, 3d vision, augmented reality
Minimum Qualifications

Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field OR Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field

Additional Preferred Qualifications

Experience with C++/CUDA/TensorRT and model compression is a plus
Send in your resume to Careers@JidokaTechnologies.com",-1,Jidoka Technologies,Chennai,"Chennai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Applied Scientist,-1,"Amazons Selection Monitoring team is responsible for making the biggest catalog on the planet even bigger. We build software to find products not already sold on Amazon and algorithmically add them to the Amazon catalog. Our work involves building Information Retrieval (IR) infrastructure, Machine Learning systems, and distributed compute and storage systems to process data at cloud-scale to extend and enrich the Amazon catalog. We apply the state- of- the-art Web-mining, Cloud Computing and Deep Learning to process millions of products from the web every day and make the data actionable. We constantly stretch the boundaries of Machine Learning to tackle business challenges. If you are customer obsessed, self-driven, tenacious and analytical, you will have fun solving our business problems of unprecedented scale. As an experienced machine learning scientist, you will help research and develop new computer algorithms leveraging both classical and deep learning techniques.

We are looking for ML Scientist to tackle challenging problems in the areas of information retrieval at internet scale using data science. You should have depth and breadth of knowledge in text mining, information retrieval and deep learning. You should also have programming and design skills to manipulate unstructured data and systems that work at internet scale.


You will encounter many challenges, including
· Scale (build models to handle billions of pages),
· Accuracy (extreme requirements for precision and recall),
· Speed (generate predictions for millions of new or changed pages with low latency),
· Diversity (models need to work across different languages, market places and data sources)

Come join us in our journey to make everything and yes, we do mean *everything* that anyone wants to buy, available on Amazon!

Basic Qualifications


· Bachelors/Master Degree in Computer Science with advanced degrees preferred.
· 5+ years of hands on experience in building machine learning systems for large data sets.
· Strong skills in problem solving, programming and computer science fundamentals.
· Expertise in using Python, Java / C++, or other programming languages, as well as ML toolkits such as scikit-learn, Theano, Tensorflow, Keras or similar machine learning tools.



Preferred Qualifications


· PhDs, specialized in Information Retrieval and Machine Learning.
· Experience in designing and implementing information retrieval, web mining systems using Deep Learning and Neural Networks.
· Big thinker that can take broad visions and concepts and develop structured plans, actions and measurable metrics and then execute those plans.",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Scientist,-1,"We provide Virtual Business Process Services to various types of overseas clients and this position is to be part of the team which provides support to USA client from Mortgage Finance industry. Hence we are looking to hire Data Scientist with experience in analyzing large amounts of data and information. Data Scientist will provide data manipulation, scrubbing and synthesizing of information into easy to read weekly, monthly and quarterly reports.

RESPONSIBILITIES

Work with large data sets and produce real-time and streamlined analysis
Work will include analyzing lender performance, asset type, leverage, etc.
Analyze third party vendor data and helping to apply that data retroactively to back-test default history
Ability to perform data mining
Pro-actively apply data frameworks to better optimize pool performance
Participate in client conversations, phone calls, company presentations, etc.
Develop forms and enhanced data tools to streamline processes and create efficiencies.
Will include data tracking and pipeline management.

QUALIFICATIONS and EXPERIENCE

Strong intellect with solid communication, quantitative, financial and analytical skills
College degree in Finance, Math, Engineering, Computer Science, Statistics, Economics or related field
Strong modeling skills to include Excel VBA and Macros, SQL (Python and Tableau a plus), Access, etc.
3+ Years of experience in similar roles
Excellent written and English verbal communication skills who works well with others in a team environment.
Strong analytical skills and attention to detail
Ability to interpret and error-check work to ensure analysis is logical
Experience with real estate mortgages is a plus
Self-starter and motivated individual with a good attitude
Ability to multi-task while working independently in a fast-pace environment

SKILLS

Advanced MS Excel skills, Excel VBA and Macros and MS PowerPoint skills
Data Science, Data Analytics and Reporting
Working Knowledge in Data Visualization Applications
Creative problem solver, Exceptional interpersonal skills, Impeccable integrity and trustworthiness
Strong Knowledge in using internet and web based applications

QUALITIES

Strong commitment to support overseas client with utmost care.
Good team player with greater level of integrity
Maintains Strict confidentiality of Client’s Data and information
Self-Motivated and Tough task master.
Quick learner and continuous learner of new technologies.

Location: Hi-Tech City, Hyderabad

Timings: USA Shift IST 5-30pm to 2-30am

salary range: As Per Industry Standards

Send Application TO: hr@finacplus.com",4.4,"FinAcPlus
4.4",Hyderabad,"Hyderabad, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"Imagine if you had a magic wand to go back in time, when amazon.in launched in 2013, and you were tasked to single handedly design the inventory management system that Amazon's top sellers would use?
We are looking for a Sr Data Scientist, who can design a scale-able Inventory Management System from scratch. This Inventory Management System will be a complex data model and optimisation engine, which will need to take real-time data from tens of data sources, create an algorithm or ML logic to suggest the right inventory management decisions for millions of ASINs. This is a confidential and a very high-visibility project. The role requires a hands-on Data Scientist, who has experience creating complex data models using Python or similar languages. The person will need to design a data model system, which is hosted on cloud and has high fidelity for outputs and has enough redundancy built in to be fail-safe. At the same time, the person will need to Invent and Simplify to be able to launch the MVP very soon.The person needs to have good communication skills to be able to present the model in front of leadership, understand stakeholder feedback and refine the model further.


Amazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation




Basic Qualifications

· Experience working in very large data warehouse environments
· 5+ years of experience in a data engineer or Sr Data Scientist role with a technology company
· 2+ years of experience with Supply Chain Management concepts i.e. forecasting, planning, optimization and logistic

Preferred Qualifications

· Experience working in very large data warehouse environments
· 5+ years of experience in a data engineer or Sr Data Scientist with a technology company
· 2+ years of experience with Supply Chain Management concepts i.e. forecasting, planning, optimization and logistics
· Experience conducting large scale data analysis to support business decision making
· Strong verbal/written communication and data presentation skills, including an ability to effectively communicate with both business and technical teams",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Scientist,-1,"Responsibilities
¢¢ Work closely with business partners and engagement managers to translate complex business
problems into analytics problems and solutions. Ask questions to understand business intent,
problem statement, analytics opportunity and value creation.
¢¢ Work closely with data engineering team to identify and consume relevant structured and
unstructured data sources (including IoT sources such as manufacturing sensors systems).
¢¢ Identify key hypotheses and data science approaches to answering analytics problems and getting
to business outcomes.
¢¢ Develop statistical and machine learning models/algorithms through iterative process and rapid
prototyping.

Qualifications
¢¢ A master¢¢s degree in data science, predictive analytics, computer science, applied mathematics,
statistics, software engineering, physics, or related quantitative discipline.

¢¢ 5+ years of hands-on experience in machine learning and statistical modelling, including a
demonstrated high-level of proficiency in applying data science techniques to solving customer
problems.
¢¢ High proficiency in conducting analyses using tools like Python, R and data visualization tools (e.g.
Tableau, Power BI, Qlik, Ploty) .
¢¢ Rigorous understanding of the fundamentals of statistics, machine learning and artificial
intelligence using both structured and unstructured data sets.
¢¢ Experience in presenting complex analytics methodologies, analyses and insights in simple and
concise manner to the business partners and senior leaders.

We Value
¢¢ A PhD degree and/or additional relevant industry certifications (in analytics, software platforms,
cloud environments, etc.).
¢¢ Experience in analytics solutions in industrial and/or manufacturing domains.
¢¢ Experience moving prototypes to production environment and optimizing models in production
environment.
¢¢ Experience mentoring business analysts and other data scientists.
¢¢ Exposure to distributed computing frameworks as well as cloud technologies.
Keyskills
predictive modelling
r
python
data science
data modelling
predictive analytics
machine learning
ML
Desired Candidate Profile
Please refer to the Job description above
Company Profile

Cerentral Consultants Pvt Ltd

Technology company that designs and manufactures connectivity and sensor products for harsh environments in a variety of industries, such as automotive, industrial equipment, data communication systems, aerospace, defense, medical, oil and gas, consumer electronics and energy.

It has a global workforce of 80,000 employees, including more than 8,000 engineers. The company serves customers in approximately 140 countries.
Experience 5 - 10 Years",-1,Cerentral Consultants,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"Responsibilities
Ability to translate business problems into analytical structures and can be solved using statistical/ML techniques.
3+ years of applied work experience with analytics & machine learning on large datasets.
Experience with statistical software (e.g., R, Python, MATLAB, pandas) and database languages (e.g., SQL).
Good exposure to exploratory analysis and knack of deriving business insights & value. Comfortable with exploring large data sets.
Develops recommendation from complex data and business analyses and formulates them into business plan.
Has strong consultative skills in addition to quantitative (and statistical) ability to harness customer data in order to address business problems that materially impact business.
Work under minimal supervision and display strong independent behaviour while leading the team in developing structured analysis.
Must Have Skills
Build statistical models/ ML models, train and test them to and drive towards the optimal level of model performance.
Quickly prototype solutions and build models to test feasibility of solution approach.
Work across the spectrum of reporting and data visualization, statistical modelling and supervised learning tools and techniques and apply the right level of solution to the right problem.
Exposure to Big Data platforms like Hadoop and its eco-system (Hive, Pig, Sqoop, Mahout) is a plus.
Passion to learn new tools, languages and framework.",-1,Tenzai,Karnataka,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"Exp: 2 - 7 years

Must Haves: SAS, Python, Machine Learning, Big data, Web Analytics, Digital Data

Talents from: eComm/Internet/Adtech/Media/Analytics Only

Job Description
Perform advanced analytics tasks, including but not limited to predictive statistical models, customer profiling, segmentation analysis, data analysis and mining, and external data enhancement using SQL, SAS, R, Python or PySpark
Extract and process large quantities of data from data warehouses and other data marts in support of assignments
Assist in determining quantitative methods for solving client issues
Analyze marketing metrics to identify cause-effect relationships between marketing levers and outcomes
Turn complex data into practical and actionable marketing insights
Consolidate and package up insights, analytic outputs, and action items into a well-organized, consumable package with actionable recommendations and strategies for marketers (MS Excel, PowerPoint, Word, etc.)
Support development of efficient and accurate project management plans for project delivery
Qualifications
2 - 7 years of industry experience required
Bachelors or Masters degree in Mathematics, Statistics, Economics, Finance, or Engineering required
Strong experience in SQL programming required
Statistical software: SAS, R, strongly preferred, Python, PySpark a plus
Must have strong experience with statistical concepts and applying statistical techniques such as regression, naïve Bayes, decision trees, clustering, factor analysis, time series, random forest, gradient boosting algorithms, etc. to solve business problems
Understanding of digital data including the systems and processes used to generate and manipulate it by media type (web, ad, email, mobile, etc.) a plus
Web Analytics (Omniture, WebTrends, Google Analytics) experience a plus
Experience in data visualization tools like Tableau a plus",-1,Staffio HR,Pune,"Bengaluru, India",1 to 50 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Scientist,-1,"Role Summary/Purpose:
The Data Scientist will work in teams addressing statistical, machine learning and data understanding problems in a commercial technology and consultancy development environment. In this role, they will contribute to the development and deployment of modern machine learning, operational research, semantic analysis, and statistical methods for finding structure in large data sets.

Essential Responsibilities:
The Data Scientist will be part of a data science or cross-disciplinary team, typically including statisticians, computer scientists, software developers, engineers, product managers, and end users, working in concert with partners in BH. Potential application areas include remote monitoring and diagnostics across infrastructure and industrial sectors, and business operations optimization. The data scientist will lead engagements with internal/external customers, and develop analytics within defined business objectives to address customer needs and opportunities. The work will involve a range of activities, including but not limited to:

Working with business stakeholders to understand the business problem/requirements and helping define analytic objectives
Forming hypotheses, exploratory data analysis, generating insights and validating the hypothesis,
Working with engineering teams to incorporate analyses and solutions, including working with data engineers on data quality assessment, data cleansing and data analytics efforts, and visualization team on representing results
Developing re-usable components that can be applied to similar problem classes across contexts

Qualifications/Requirements:
Bachelor's Degree in a STEM major (Science, Technology, Engineering, Mathematics)
Minimum 8 years analytics development in a commercial setting
Demonstrated skill in the use of one or more analytic software tools or languages (e.g., R, Python)
Demonstrated skill at data cleansing, data quality assessment, and using analytics for data assessment
Demonstrated skill in the use of applied analytics, descriptive statistics, and predictive analytics on industrial datasets
Demonstrated skill in modeling techniques, including but not limited to Predictive modeling, Supervised learning, Unsupervised learning, Machine Learning, Statistical Modeling
Demonstrated skill in analytic prototyping, analytic scaling, and solutions integration
Strong communication & visualization skills to help stakeholders define requirements, and explaining data science outcomes to non-expert audiences
Generating insights for a business context

Desired:
Experience with cloud technologies for building, deploying and delivering data science applications.
Experience in building digital twin and analysing stream data is a plus.
Must have strong product intuition, data analysis skills and business presentation skills.
Must be a self-starter and a great team player with excellent interpersonal skills.

Location:
Bangalore, India

Baker Hughes Company is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.",3.6,"Baker Hughes
3.6",Bengaluru,"Houston, TX",10000+ employees,-1,Company - Public,Oil & Gas Services,"Oil, Gas, Energy & Utilities",₹500+ billion (INR),-1
Data Scientist,-1,"Roles and Responsibilities
Understand clients business objectives and strategy to ensure that analysis work is focused on the areas where most value can be added.
Collaborate with stakeholders/ team leaders in order to understand problem statements and design and execute potential solutions.
Mentor team members and ensure fault-free execution of projects / solutions.
Integration of multiple sources of data working on BigData platforms.
Perform Exploratory Data Analysis on large and complex data sets comprising of structured, semi-structured and unstructured data.
Work on multiple unstructured problems to deliver insights/ end-to- end solutions and improve our clients- understanding of their customers using analysis / statistics / machine learning algorithms.
Keep abreast of the latest developments in the data science space across industries for potential uses.

Please mail your CV to career@torcai.com",-1,torcai digital media,Pune,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"Data Scientist Large Banking MNC 5 - 10 years Bangalore QUALIFICATION Bachelor’s or Masters Technology Degree in Computer science or Equivalent Job Description The senior data scientist will get the opportunity to work in an agile software development enviornment addressing machine learning and optimization analytics problems. The senior data scientist will be part of cross diciplinary data science team working on software development projects, typically involving large, complex data sets. They will work with technical team in development and deployment and application of predictive analytics. Key Skills Required Demonstrated skill of data cleansing, data qualityy assesment.

Use the descriptive statistics, feature extraction and predictive analytics on real datasets. Skills at data visualization and storytelling for an audience of stakeholders. Experience in working with Hadoop and spark will be added advantages.",-1,TALCHEMIST,Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
Data & Applied Scientist,-1,"At Microsoft, our mission is to empower every person and every organization on the planet to achieve more. We plan to achieve this mission by building best-in-class platforms and productivity services for a mobile-first, cloud-first world. Our core ambitions are to reinvent productivity & business processes, build the intelligent cloud platform and create more personal computing. The Experiences + Devices organization is critical to delivering on this mission and vision, maintaining responsibility for the end-to-end physical and digital supply chains for Microsoft’s vast array of existing and next-generation hardware and software products.

The Microsoft Devices Supply Chain (MDSC) organization within Microsoft is responsible for the design, manufacturing, distribution, sales, and customer support of Microsoft's hardware products. The product portfolio includes HoloLens, Xbox, Surface, Surface Hub and others spanning operations in hundreds of countries across online, retail, enterprise and operator channels. This role will be a critical part of the Supply Chain Analytics team, which reports into the COO of Microsoft’s Devices Organization.

We are looking for a skilled Data & Applied Scientist who is passionate about data analytics, is comfortable dealing with ambiguity, and has a track record of storytelling and making data-driven recommendations to drive business value.

Responsibilities

Successful candidates will have experience in solving complex business problems through data analysis, building proof-of-concepts to prove out business value, and partner with the data engineering team on building out BI solutions in a deadline-driven environment, with a quality-first mindset. You have strong analysis and investigative skills with the ability to quickly identify the root cause of problems, formulate mitigation strategies, and report findings to stakeholders clearly and concisely. You have strong SQL, R, Python and coding skills that can enable you to interrogate data and tease out business insights in a big data environment. You have good communication skills, both in interviewing stakeholders and reporting your findings. You must have a demonstrated ability to build relationships with stakeholders, manage expectations, and establish credibility. When researching issues, you can identify and recommend process and tooling changes to address systemic issues. You work well in an agile, fast-paced environment, deal well with ambiguity, have a bias for action, and are solution-oriented.

Our work is highly varied and offers a chance to focus on many different data science techniques and aspects of the Devices Operations businesses and beyond. As a Data Scientist, you will need a mix of deep data science and broad consultative skills.

You will work with stakeholders to formulate approaches to solve problems using algorithms and data sources in context of customer, engineering, and business needs.
You will use data exploration techniques to discover new opportunities within your problem area.
You will interpret the results of analyses, validate approaches, and learn to monitor, analyze, and iterate to continuously improve.
You will engage with stakeholders to produce clear, compelling, and actionable insights that influence product and service improvements that will impact millions of customers.
You will also engage in the peer review process and act on feedback while learning innovative methods, algorithms, and tools to increase the impact and applicability of your results.

Qualifications
Bachelor’s degree required
4-8 years’ experience as a data engineer, BI developer, or data analyst, in an engineering or technology operations environment
4-8 years' experience in building BI solutions, Excel, PowerBI, and SQL required
Experience with complex data stores and big data platforms required
Excellent project management skills, including issue tracking, research, cross-group collaboration, and communication
Strong problem resolution, judgment and decision-making skills required
Prior experience and knowledge of MS systems tools such as MS Sales, SAP, Azure Insights preferred
Prior experience programming in SQL, R, Python preferred

This description has been designed to indicate the general nature and level of work performed by employees within this position. The actual duties, responsibilities, and qualifications may vary based on assignment or group.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.",4.3,"Microsoft
4.3",Hyderabad,"Redmond, WA",10000+ employees,1975,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Google, Amazon, Apple"
Applied Scientist I,-1,"Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the worlds largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·

· Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
· Perform analysis of data and metrics relevant to ad content generation and policing
· Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
· Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs

Basic Qualifications

Basic Qualifications:
· Very good English skills (including the ability to read and write technical papers in English)
· Bachelors (BS/BE) in Computer Science or related field
· Publications in top-tier NLP and or ML/DL conferences or journals
· Skills with programming language like R, Python and/or Scala or similar scripting language
· At least 5+ years of hands-on-experience in predictive modeling and analysis
· At least 5+years of algorithmic development experience
· At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent

Preferred Qualifications


· Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
· 5+ years of extensive experience applying theoretical models in an applied environment.
· Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
· Strong fundamentals in problem solving, algorithm design and complexity analysis
· Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
· Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
· Experience with defining organizational research and development practices in an industry setting.
· Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
· Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Scientist,-1,"We are looking for a experienced Data scientist to join our growing team.

Roles and Responsibilities
Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Working with several large and complex SQL databases.
Designing and building reports and analytical dashboards.
Skills Required
Highly proficient in SQL with ability to write efficient queries and taking data from multiple data-sets as and when required.
Should have a strong working knowledge in Excel and proficiency in either R or Python for automation purposes.
Tools -Any Big data knowledge (e.g. Hadoop) will be an added advantage.
At least 1 year of experience in Data Science and Programming skills in Python, R, SQL programming with the ability to quickly create prototype and debug solutions.
Qualifications
Educational qualification – Degree (Bachelors/ Masters) in Computer Science/ IT,Engineering, Information Systems, Math’s/Statistics or Equivalent.
Positive, people-oriented, and energetic attitude.
Self-starter and curious person who sees information as a tool to find answers to business questions
Analytical, creative, and innovative approach to solving problems.
Strong written and verbal communication.
Experience - (1-2 yrs)

Job Type: Full-time

Salary: ₹15,000.00 to ₹30,000.00 /month

Experience:
total work: 1 year (Preferred)
Education:
Bachelor's (Preferred)",-1,ACUWIN INNOVATIONS Pvt Ltd.,Thiruvananthapuram,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"Apply Now

Understanding and experience with leading supervised and unsupervised machine learning methods such as GLM/Regression, Logistic Regression, Neural Networks, Deep Learning, KNN, Naive Bayes, SVM, Decision Trees, Random Forest, Gradient Boosting, Ensemble Methods, Text Mining, Social Network Analysis, Unobserved Components Modeling (UCM) and Use Scenario based Optimization Techniques.
Should be a Data Scientist with extensive predictive Modeling and Machine Learning Experience. The Candidate will be responsible for conducting data analysis and developing predictive models leveraging data science and machine learning to solve various business use cases, including marketing intelligence, customer segmentation, and predictive models for sales and marketing organization.
Candidate should have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.

For more details, Contact :
+91 - 7022998695",-1,Shiras HR Advisory & Services,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"About Mate Labs (https://www.matelabs.ai/):

Mate Labs is looking for a kick-ass and enthusiastic Data Scientist who has a really good understanding of machine learning and deep learning. We love GitHub and open source projects. We look for guys who are passionate for open source projects and contributions.

Mate Labs has built Mateverse for Data Analysts so that they can build customized machine learning and data science models for quick prediction like sales forecasting without writing even a single line of code.

At Mate Labs, we are solving a unique problem of algorithm & Hyperparameter selection in the field of Artificial Intelligence.

Job Responsibilities:

Be working on client projects, majorly on the solutions.

Be working with Regression Algorithms (Linear Regression, Logistic Regression, Polynomial Regression, Ridge Regression, Lasso Regression etc.)

Be working with ARIMA and LSTMs for time-series forecasting

Be working with custom Mateverse algorithms

Be working with technologies like Scikit-learn, Pandas, Numpy, Scipy, Matplotlib, Seaborn and Statsmodels

Be building mathematical models and implementing it in Python (preferably).

Skills Required:

Machine Learning Algorithms(Regression(MUST)& Time-series forecasting (MUST), Classification, Clustering)

Frameworks - Scikit-learn, Keras, Tensorflow, Pandas, Numpy, Scipy, Matplotlib, Seaborn and Statsmodels

Has worked on multiple business use-cases.

SAS or equivalent, Tableau or any other data preparation tools.

Requirements:

2 - 3 years of experience

B.Tech graduate.

Benefits:

Startup culture (immense scope to learn and grow).

Amazing team to work with.

Health Insurance for the employees.

A lot of freedom to experiment with new things.",-1,Matelabs Innovations Pvt. Ltd.,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Junior Data Scientist,-1,"Job Summary
We are looking for Data Science Fresher’s candidate with ME or M. Tech in Computer Stream whose focus area is on AI/ ML
Shift timing:
9.30 AM - 6.30 PM.
Interview Process:
Aptitude Test / Quick Logical Round (30 Mins)
System Round -- Programming Problem to be solved in System (4 Hours)
Research Paper Presentations
Technical Discussion
HR Round
Required Experience and Qualifications
Candidate must be 2019 Passout.
Candidates with ME/ M. Tech in Computer Science and Engineering (CSE) only
Training / Courses in AI/ML is an added advantage
Job Type: Full-time
Salary: ₹200,000.00 to ₹400,000.00 /year
Experience:
total work: 1 year (Preferred)
Education:
Master's (Required)
Location:
Bengaluru, Karnataka (Required)
Work Remotely:
Temporarily due to COVID-19",2.7,"Ninestars Information Technologies
2.7",Bengaluru,"Bangalore , India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Consulting with internal customers (e.g., Marketing team, Game Producers) to develop analysis and frame actionable insights that helps the management in decision making
Wrangling data from multiple sources (including but not limited to): sales, product, player events, and customer/player databases, to create integrated views that can be used to drive decision making
Working with several large and complex SQL databases
Designing and building reports and analytical dashboards
Perform statistical analysis and A/B tests in events of new feature or content releases
Routinely keep an eye on anomalies in the game data and provide reasoning for the same
Qualifications:
Educational qualification – Degree (Bachelors/ Masters) in Computer Science/ IT; Engineering; Information Systems; Math’s/Statistics
Highly analytical data junkie who enjoys business analysis by using data interpretation skills
Positive, people-oriented, and energetic attitude
Self-starter and curious person who sees information as a tool to find answers to business questions
Analytical, creative, and innovative approach to solving problems
Strong written and verbal communication
Tech Skills:
Highly proficient in SQL with ability to write efficient queries and taking data from multiple data-sets as and when required
Should have a strong working knowledge in Excel and proficiency in either R or Python for automation purposes
Exposure to any visualization tool/ library (Tableau, ggplot, matplotlib, etc)
Machine learning algorithms – Individual who has exposure to ML modelling techniques will be an added advantage
Tools -Any Big data knowledge (e.g. Hadoop, Spark) will be an added advantage
Job Type: Full-time

Experience:
Data Analytics: 3 years (Required)
Education:
Bachelor's (Required)
Work Remotely:
Temporarily due to COVID-19",-1,"Ruby Seven Studios,Infopark,Kochi",Kochi,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"Job Description :
5 to 7 years of total software/IT engineering/code development experience. Out of this at least 4+ Data science and Data intelligence experience
Five + years performing virtualization in cloud, hybrid and hosted environments
Five + years designing and implementing solutions
Writing policy and systems descriptions for how multiple environments work together
Strong oral and written communication skills and ability to transform technical knowledge into business language
Desirable Requirements:
Should have experience on any of the data virtualization tools from Denodo/Tibco (Composite) or any other equivalent tooletc.
Knowledge of relevant development trends and technologies (Docker, Kubernetes, CI, etc.)
Proven application development experience
Experience writing unit tests
00-8.00 Years
Bachelors/ Degree",-1,Collasys Global Services LLP,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are building a world-class language-related product that has the potential to positively transform lives worldwide. We have a passionate team of data scientists, coders, and linguists who have been working on it. We are looking for a Senior Data Scientist who will lead the team from the technology standpoint. You will identify and implement the best data-driven methodologies considering the product requirements and guide the team in delivering meaningful results. As a Senior Data Scientist, you will serve as the technology leader driving the vision of the product.

Work location: Mumbai

If this opportunity sounds exciting, APPLY NOW!!",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Jr. Data scientist,-1,"Responsibilities :
Responsibilities include Identify, develop and implement the appropriate statistical
techniques, algorithms and Deep learning / ML Models to create new, scalable solutions that
address business challenges across industry domains.
Define and develop, maintain and evolve data models, tools and capabilities.
Communicate your findings to the appropriate teams through visualisations.
Collaborate and communicate findings to diverse stakeholders.
Provide solutions but not limited to: Object detection/Image recognition, natural language
processing, Sentiment Analysis, Topic Modeling, Concept Extraction, Recommender
Systems, Text Classification, Clustering , Customer Segmentation & Targeting, Propensity
Modeling, Churn Modeling, Lifetime Value Estimation, Forecasting, Modeling Response to
Incentives, Marketing Mix Optimization, Price Optimization.

Qualifications and Experience :
Bachelors Computer Science, Information Systems, Machine Learning, Statistics,
Econometrics, Applied Mathematics, Operations Research or related technical degree with
ability to break complex business problems.
Minimum of 1 to 3 years of experience in a related position, as a data scientist or business
analyst building predictive analytics solutions for various types of business problems.
Knowledge of statistical techniques, machine learning algorithms and deep learning
frameworks like Tensorflow, Theano, Keras, Pytorch.
Minimum 1 years of Programming background and expertise in building models using at
least one of the following languages: Python, R ,Java, C,C++.",4.6,"Blackstraw
4.6",Chennai,"Tampa, FL",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist III,-1,"General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation, Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions\
Experienced in proposing ROI based solutions to business",3.8,"Blackstraw
4.6",Chennai,"Minneapolis, MN",10000+ employees,1866,Company - Public,Food & Drink Manufacturing,Manufacturing,₹500+ billion (INR),-1
Data Scientist,-1,"Be part of a strong team of data scientists working on next generation of analytics platform in the domain of network monitoring and customer experience management.

The team will be a diverse team consisting of multi-disciplined experts from background like telecom, computer science, applied mathematics, statistics and machine learning.

Job requirements:
1 – 2 years of experience with Big Data technologies - Spark, Storm, Hive
1 years of hands-on experience with any statistical languages and packages (R, Matlab etc.)
Strong programming skills in any languages
Strong mathematical background, hands-on experience in statistical analysis, development of models
Knowledge of Machine Learning domain
Good written and oral communication
Ability to work independently as well as collaboratively within a team
Ph.D / Masters in computer science, applied mathematics, statistics or machine learning
Experience
3 – 6 yrs

Education
Ph.D / Masters

Location
Delhi NCR

Work-Type
Full Time

To apply send mail to hr@pinnacledigital.in with Job title as subject line",2.5,"Pinnacle Digital Analytics
2.5",New Delhi,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Responsibilities and Duties
Use machine learning tools and statistical techniques to produce solutions to problems
Test data mining models to select the most appropriate ones for use on a project
Maintain clear and coherent communication, both verbal and written, to understand data needs and report results
Create clear reports that tell compelling stories about how customers or clients work with the business
Assess the effectiveness of data sources and data-gathering techniques and improve data collection methods
Horizon scan to stay up to date with the latest technology, techniques and methods
*

Required Experience and Qualifications
3+ Years of Experience

Job Type: Full-time

Experience:
Machine Learning: 3 years (Preferred)
total work: 3 years (Preferred)
Education:
Bachelor's (Preferred)
Industry:
Software Development",-1,QBYTEZ INFOLABS PVT LTD,Kozhikode,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"We are looking for the following kind of professionals to join our team. In case you are interested, please mail us your resume at team@numbertheory.in

What you'll be doing in your new job:
Create examples, prototypes, demonstrations to help others to better understand the work.
Deeper understanding of design and architecture principles. We like people who have a holistic approach of the problem.
Ability to work autonomously. Smart people like independence and we encourage it.
Ability to think through different approaches and decide on the optimal one while solving problems.

What are we looking for (Must have):
At least 2+ years of experience in Big Data and Machine Learning. Should have worked on large data sets to solve any Big Data Problem.
Worked on at least one of the Open Source framework of machine learning with deep knowledge; including in/out each part of that framework.
Knowledge of different Machine Learnig Algorithms and their Applications.
Worked on Hadoop(HDFS, MapReduce). Not Necessary to have knowledge of complete Hadoop Stack.
Comfortable with coding in Java and Scala/Python.
Basic Algorithmic knowledge(Can assess the complexity of logic and also can decide depending on the situation which algorithm can use and how) .
Worked on Apache Spark.
Basic Linux Knowledge.

What are we looking for (Nice to Have):
Worked in Personalization Engine, Credit Scoring, Cross Sell etc domain is more desirable.
Worked on NoSql database HBase is more desirable.
Worked on full-text search engine Solr/ElasticSearch is more desirable.",-1,Number Theory,Gurgaon,"Gurgaon, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Deep learning (RNN/CNN/LSTM),transfer learning , training dense layers.

Deep learning architectures(SSD, YOLO)

Experience in keras , pytorch, caffe,MxNet,python,pyspark,sql

Mandatory business skills

Experience in videos and image analytics

Optional skills:

Graphical Network modeling knowledge

overall 7 years experience in analytics with 2+ years in above mandatory tehsils

Job Type: Full-time

Experience:
work: 7 years (Preferred)
total work: 10 years (Preferred)
Education:
Secondary(10th Pass) (Preferred)",3.2,"Joulestowatts business solutions
3.2",Mumbai,"Bengaluru, India",1001 to 5000 employees,2015,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Staff Data Scientist,-1,"Staff Data Scientist & Technical Architect



Eligibility Criteria:
Years of Experience: Minimum 12 - 15 years
Job Experience: Experience in developing Data Science, BI infrastructure and Analytics.
Educational: Bachelor’s or Master’s Degree: Math/Statistics/Operations Research/Industrial Engineering/Computer Science
Primary Responsibilities:
Provide technical leadership for developing end to end solutions for business applications, analytical tools, and KPI Dashboards
Design complex system/data integration models. Building Datawarehouse
Deliver solutions combining SQL Server, SAP HANA models, Complex T code conversions, complex SQLL/CVs, programs, ETL tool
Establish self as a Go to person for all technical queries in DW BI area
Effectively communicate specifications, diagrams, and flowcharts to have end user alignment and thorough instructions for programmers to follow.
Overseeing implementation, coordinating tests, and proper sign off for production go-live.
Proactively prioritize projects, manage customer expectations, and organizing the team’s effort and effectiveness.
Become a change agent ensuring lean principles and best practices are followed.
Effectively manage end users, application developers, analyst, system changes, and collaborating with GIS on IT roadmap
Understanding and Knowledge of SAP systems
Good skill on managing Stakeholders Expectation
Complex Data Analysis and applying deep learning and machine learning algorithms
Technical Governance and Reviews.
Mandatory Skills required to perform the job:
Hands on SQL Server Platforms (SSAS, SSIS) and architecting technical solutions
Hands on architecting enterprise level DW BI platforms
Hands on Advance and complex SQL, Stored procedures development capabilities (Oracle/SQL server/Hana/Teradata)
Experience in implementing ETL data extracts (preferably BODS), SSIS, Designing ETL work flows.
Ability to coach, mentor the team on technology
Experience on Cloud Computing
Experience Data Science – Deep Learning & Machine Learning
Desirable Skill:
SQL Server Data Base Engine, SSAS & SSIS, ETLs,
SAP HANA, BODS, Hanafication
Experience on Cloud Computing – Azure
Hands on working knowledge on Analytics and Data Science.
Prefer experience in Supply Chain, Inventory, Logistics, and Finance
Familiar with Web Development Platforms, HTML, CSS, JavaScript, ASP.net
SAP Tcode conversion into sql models
Hands on working knowledge on any Big data platform
Good understanding on statistics",4.3,"Lam Research
4.3",Neem-Ka-Thana,"Fremont, CA",10000+ employees,1980,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹500+ billion (INR),"Applied Materials, Tokyo Electron, ASML"
Sr Data Scientist,-1,"Description

SHIFT: Day Job

SCHEDULE:

Design, develop, troubleshoot and debug software programs for databases, applications, tools, networks etc.

As a member of the software engineering division, you will assist in defining and developing software for tasks associated with the developing, debugging or designing of software applications or operating systems. Provide technical leadership to other software developers. Specify, design and implement modest changes to existing software architecture to meet changing needs.

Duties and tasks are varied and complex needing independent judgment. Fully competent in own area of expertise. May have project lead role and or supervise lower level personnel. BS or MS degree or equivalent experience relevant to functional area. 4 years of software engineering or related experience.

Qualifications

Oracle Cloud Infrastructure (OCI) is a strategic growth area for Oracle. It is a comprehensive cloud service offering in the enterprise software industry, spanning Infrastructure as a Service (IaaS), Platform as a Service (PaaS) and Software as a Service (SaaS). OCI is currently building a future-ready Gen2 cloud Data Science service platform. At the core of this platform, lies Cloud Cognitive Service.

What OCI Cognitive Services are: A set of services on public cloud, that are powered by ML and AI to meet the Enterprise modernization needs, and that work out of the box. These services and models can be easily specialized for specific customer/domain by leveraging existing OCI services.

Key Points: Enables customers to add AI capabilities to their Apps and Workflows easily via APIs or Containers, Useable without needing to build AI expertise in-house and Covers key gaps – NLP, Computer Vision, for Public Clouds and Enterprise in NLU, NLP, Vision and Conversational AI.

You’re Opportunity: As we blaze the trail to provide a single collaborative ML environment for data-science professionals, we will be extremely happy to have you join us and share the very future of our Machine Learning platform - by building a Cognitive Cloud service.

We are addressing exciting challenges at the intersection of artificial intelligence and cutting-edge cloud infrastructure. We are building cloud services in natural language processing (NLP) and, computer vision that works out of the box for enterprises. Our product vision includes the ability for enterprises to be able to customize the services for their business and train them to specialize in their data by creating micro models that enhance the global AI models.

What You’ll Do
Provide machine learning methodology leadership.
Build a core model of cognitive service using various open source and machine learning principles and techniques (CNN, learning rates, fast.ai, DL based NLP, NLU).
Brainstorm and Design various POCs using ML/DL/NLP solutions for new or existing enterprise problems.
Work with fellow data scientists/SW engineers to build out other parts of the infrastructure, effectively communicating your needs and understanding theirs and address external and internal shareholder's product challenges.
Building core of Artificial Intelligence and Cognitive Service as Vision, Text, NLP, NLU, and others.
Leverage Cloud technology – Oracle Cloud (OCI), AWS, GCP, Azure, Heroku or similar technology.
Build models with Python and machine learning libraries (Numpy, Tensorflow), Big Data, Hadoop, HBase, Spark, etc
Capable of quickly becoming familiar with new approaches to Machine Learning.
You have been exploring or working on some of the latest advancements in the deep learning space like TensorFlow.
Qualifications
MA/MS or Ph.D. degree in computer science, artificial intelligence, machine learning, speech recognition, natural language processing, operations research, or related technical field.
4+ years of Experience designing and implementing machine learning pipelines in production environments.
Working knowledge of current techniques and approaches in machine learning and natural language processing: text categorization, text summarization, information retrieval, question answering, sentiment analysis, semantic parsing, etc.
Experience using ML and DL languages using Python and Java, to manipulate data and draw insights.
Practical experience and deep knowledge in algorithms for NLP, NLU, sentiment analysis, Text to Speech, Vision, recommender systems, reinforcement learning, and another cognitive service.
Practical experience in feature engineering and evaluation, automation of such tasks, model interpretation &visualization.
Experience or willingness to learn and work in Agile and iterative development and DevOps processes.
Strong drive to learn and master new technologies and techniques.
Deep understanding of data structures, algorithms, and excellent problem-solving skills.
You enjoy a fast-paced work environment.
Additional Details
Experience with Cloud Native Frameworks tools and products is a plus
Have an Impressive portfolio on Kaggle Profile is a plus.
Hands-on experience with horizontally scalable data stores such as Hadoop and other NoSQL technologies
Our vision is to provide an immersive AI experience on Oracle Cloud. Aggressive as it might sound, our growth journey is fueled by highly energetic, technology savvy engineers like YOU who are looking to grow with us to meet the demands of building a powerful next-generation platform. Are you ready to do something big?

]]>",3.6,"Oracle
3.6",Bengaluru,"Redwood City, CA",10000+ employees,1977,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹500+ billion (INR),"SAP, Salesforce, Microsoft"
Senior Data Analyst - Ad Tech,-1,"JOB TITLE: SENIOR DATA ANALYST - AD TECH

LOCATION: GURGAON, INDIA

OUR STORY:

JioSaavn is South Asias leading music streaming service. We are over 200 entrepreneurs, across New York, California, Mumbai, Gurgaon, and Bangalore, who help music lovers access, discover, and listen to their favorite songs across languages and genres. In early 2018, a merger between JioMusic and Saavn was announced; creating a combined entity valued at over $1 billion.

We blend digital technology, data analysis (which we have affectionately coined Music Science), and a strong, fearless business acumen to reach all corners of the globe. Through partnerships with Apple, Google, Amazon, Facebook, Twitter and Shazam - to name a few - JioSaavn reaches more music fans across the world. Our award-winning mobile products, partnerships, innovations and thought leadership have been featured in some of the worlds leading publications, from The New York Times, to The Wall Street Journal, The Economic Times to Forbes, and many more. We are well-funded by some of the worlds most successful institutional investors and global media companies as well as a number of strategic individuals. Beyond investing, they are advisors and supporters of our vision, our passion, and our collective ability to deliver a revolutionary music experience as the leader in India.

OUR CULTURE:

At JioSaavn, we ignite passion and performance to work towards a collective goal: creating the perfect mobile entertainment ecosystem that delivers the best possible music experience to millions of listeners around the world. Our default mode is that of perpetual innovation. Together, we form a concerted rhythm that goes beyond borders. We don't just go with the flow, we create it.

JioSaavn offers a dynamic and unconventional work environment, full of fun wholesome experiences from in-office performances by some of the worlds most beloved musicians to opportunities for international travel. We believe creativity and technology blend together like sweet melodies. When you choose JioSaavn, you join a diverse world of high-calibre techies, artists, and inventors hailing from companies like Yahoo!, Twitter, LinkedIn, Google, Qualcomm, HBO, Microsoft, Flipkart, Amazon, Paytm, Quikr, MSN, and NDTV. We are one of the few digital companies to provide employment opportunities that meet the Silicon Valley benchmark right here in Mumbai! Figures, since weve got Silicon Valley covered, too.

Our value-based, people-first work culture is about empowering every individual in our global team to be catalysts for change in this dynamic digital world. Every day is an opportunity to bring your vision to life, and to expand, learn and grow. No idea is left unconsidered. No voice is left unheard.

With listeners speaking multiple languages in almost every country in the world, we like to think we have the most diverse user base on the planet. This has only been made possible because of the value we place on radical inclusivity in our offices across the globe. We believe different is wonderful, and what sets us apart is also what brings us closer. JioSaavn prides itself on being an equal opportunity employer. We have committed ourselves to creating a safe environment with fair and equal access and opportunities, sans discrimination. We encourage everyone to be open to experiences and perspectives beyond their normal; divergent thinkers create differentiated products, and even better music.

If our vibe matches with yours, we'd love to hear from you.

ROLE:

JioSaavn is seeking a Senior Data Analyst who will use their expertise in data-mining, quantitative analysis & data visualization to tell the story behind numbers and derive actionable insights for JioSaavn advertisers and help in achieving business goals.

RESPONSIBILITIES:
Provide relevant data to the Sales team to help them in their conversation with the clients
Conceptualize and build dashboards that are simple, visually appealing, yet showcase a powerful story
Solve ambiguous problems using data and providing practical business insights
Provide actionable insights to multiple stakeholders in the organization
Improve understanding of user engagement; setting KPIs, monitoring key trends and partnering with product and strategy teams to optimize customer experience based on insights delivered
Perform hands-on analysis of large volumes of data and across multiple datasets primarily using SQL and Python/R.
Design models to solve business problems and, where appropriate, manage integration of the insights into regular reporting
Understand business challenges and transform them into advanced analytics / machine learning / data mining problems; use your analytics toolbox to effectively solve them
Consult/support ad-hoc requests for data and analysis
REQUIREMENTS:
Bachelors in quantitative field such as Engineering/Mathematics/Statistics/Physics/Economics
2+ years of experience in advanced statistical analysis and modelling
Efficient programmer in Python/R
Experience in manipulating large data sets from multiple sources (SQL, S3)
Passionate about solving real world problems using machine learning
High level of intellectual curiosity and willingness to take action by generating business insights
Expertise in visualizing complex data using Tableau/R/Python
Strong written and oral communication skills
BENEFITS AND PERKS:

At JioSaavn, we blur work and play, and you get all the perks of a global company. You will get to work with a dynamic group of entrepreneurs, who are delivering results and working zealously across time zones to make a difference in the way the world experiences music. We love what we do, and we think you will too.
Group Mediclaim
Fun Fridays
Flexible vacation policies
Free healthy (and unhealthy) lunches & snacks
JioSaavn-sponsored team outings
Powered by JazzHR",4.2,"Saavn
4.2",Gurgaon,"New York, NY",201 to 500 employees,2007,Company - Private,Music Production & Distribution,Media,Unknown / Non-Applicable,-1
DATA SCIENTIST,-1,"DATA SCIENTIST (Analytics & Technology)

Experience : 7+ yrs.

Location : Gurgaon & Bangalore

Qualification :Masters (preferred) or Bachelors Honors in Statistics, Economics, Computer Science, Engineering, Mathematics preferred

Technical expertise: Provide expertise in Statistics, Mathematical modeling and simulation, Numerical Analysis and Differential Equation.
Curiosity: a desire to go beneath the stated client needs and discover and distill a problem down into a very clear set of hypotheses that can be tested.
Problem solver: Ability to work with adhoc/ unstructured data and arrive at a potential business proposition and hence, be able to define and design customized business solution.
Storytelling: the ability to use data to tell a business-outcome impacting story and to be able to communicate it effectively.
Cleverness: the ability to look at a problem in different, creative ways.
Experienced in mathematical modeling and programming, statistical analysis, forecasting/predictive modeling, simulations, optimization, visualizations, machine learning, data mining, etc.
Proficiency in one or more statistical programming language, like R, SAS, WEKA or Python, and a database querying language like SQL.
Demonstrated ability of thought leadership and to work with ambiguous problem definitions, recognize dependencies and deliver impactful solutions through logical problem solving and technical ideations.
Ability to learn new analytical methods, technologies and apply in practical business problems.
Strong communication and interpersonal skills: Ability to communicate clearly and confidently with clients/stakeholders. Ability to tell a clear, concise, actionable story with data. Ability to work with multiple teams with different backgrounds.
Attitude to work in a fast paced and continuously changing environment.
Understanding of Big Data Technologies like Map Reduce and Hadoop.
Proficiency with any general purpose programming language Java/Python/C/C++.",2.8,"Melstar Information Technologies Limited
2.8",Bengaluru,"Mumbai, India",201 to 500 employees,-1,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),-1
Data Scientist,-1,"Responsibilities
Translate high-level problems and key objectives into granular model requirements.
Define acceptance criteria that are well structured, detailed, and comprehensive.
Developing and testing electricity and carbon allowance price forecasting algorithms using large datasets such as load, weather, historical, grid, forward markets etc.
Developing and testing algorithms using our price forecasts, and customers' energy portfolio.
Leading software engineering team in deploying the developed models tailored to specific customer needs.
Participating in the software development process, testing, and debugging required to support the deployed models.
Ensure tracking of appropriate events/metrics, so that monitoring is timely and rigorous.
Drive the response to the discovery of regressions or failures, by undertaking various exercises (e.g. debugging, RCA, etc.) as needed
Stay up-to-date on evolutions in best practice, tooling, and strategies in the ML space.
Requirements
Advanced knowledge of Python.
Experience in working with libraries like Numpy, Pandas, sk-learn, tensorflow 2.0, pytorch, keras, xgboost, autograd, plotly, Jupyter etc.
Knowledge of ML algorithms like clustering, SVMs, NNs, XGBoost etc.
Experience working with large databases to access, manipulate and process data. Knowledge of MySQL, MongoDB, ElasticSearch or other nosql database implementations.
Comfortable with the concept of APIs and JSON-REST. Able to access and work with various data APIs.
Comfortable with a wide set of machine learning approaches and designing the features and data processing to actually make them work.
Demonstrate ability to transform theoretical knowledge to practical, real-world situations.
Be results-oriented, able to meet tight deadlines and produce clear and concise feedback/reports to senior management.
Proven ability to work on multiple complex and competing business objectives in a highly fluid and dynamic environment.
Excellent English communication skills; the ability to convey your message to team members and other stakeholders
Flair for using the right metrics to measure model performance, quality, and reliability.
Ability to think critically and conceptually about the role of each feature/development unit in the achievement of the product’s goals
Aptitude for and interest in taking ownership of the roadmap (and achievements) of a product
Willingness to embrace the start-up mindset: Ambition, adaptability, and a get-it-done approach
Experience with consumer marketing, or utilities markets is a plus.
Experience with semi-remote or fully distributed teams is a plus.
Good to have knowledge of backend technologies Message Queues, IPC.
Good to have knowledge of working with cloud providers like AWS and DigitalOcean.
Job Type: Full-time

Salary: ₹600,000.00 to ₹800,000.00 /year

Experience:
total work: 3 years (Required)
Education:
Bachelor's (Required)
Work Remotely:
Temporarily due to COVID-19",-1,Regent Climate Connect Knowledge Solutions Private Limited,Pune,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"About us:
Established in May 2015, Indus OS is a homebred system apps company, building India’s only content and commerce platform for users to discover and consume digital content & services in the language of their choice. With a vision of digitally connecting 1 Billion Indians, Indus OS is constantly striving to adapt its existing portfolio (App Store, Minus One Screen, Keyboard, Messenger, etc) by introducing new features to enrich the user experience in their native language.
Currently, Indus OS has a user base of over 12+ Million on the back of 10+ smartphone brand partnerships with leading OEMs such as Samsung, Gionee, iTel, Micromax, Intex, Karbonn, and others. The Indus platform is available in English & 23 Indian regional languages and is intended to digitally connect the next 1 billion people in the emerging markets.
Indus App Bazaar: Indus also has its very own app market place called Indus App Bazaar with over 400,000 applications. Indus App Bazaar is India’s largest indigenous app store available in 12 languages, designed to suit specific requirements of the Indian consumers. The recent partnership with Samsung will see Indus App Bazaar power Samsung’s new Galaxy Apps Store in all Samsung Devices. With this partnership, we will be able to reach a user base of over 50 Million by 2019.

Indus OS in News:
Bloomberg: http://bloom.bg/2adsFRB
Financial Express: http://bit.ly/29FDQg5
Economic Times: http://bit.ly/2ayTvD4
https://bit.ly/2JgL3JU
https://yourstory.com/2019/07/startup-funding-indus-os-samsung-venture

What we do:
To create the mobile ecosystem for the next billion smartphone users from emerging markets in their native language.

What you’ll be doing

Actively monitor all data stack at Indus OS.
Leverage all the data to build best in class products to enhance Indus' product offerings.
You’ll be responsible for designing, implementation & maintenance of various data and machine learning-based
components and applications for mobile platforms.
Communicate often & effectively about the status of new & ongoing development efforts within the company. This will
help in understanding as well as evangelizing how data can be used more & more effectively.
Represent the Data Science engineering team at high-level meetings.
Motivate, mentor and lead other team members by rolling up your sleeves and offering technical insights into data
science and AI
Work closely with various teams to create exciting mobile user experiences while leveraging data
You’ll be continuously keeping an eye on the latest cutting-edge Data Science, ML & AI technologies and leveraging
these in one’s own and the team’s work as necessary

Your Profile

2+ Experience of working on large data stacks
Complete end to end exposure of first-time training and system set up to deliver a product which leverages trained
models to feedback collection and retraining
Strong knowledge of Spark
Deep learning using Tensorflow/CNTK
Command over programming in Python/Scala/R but we generally like people who are programming language agnostic
Working over the large quantum of data using HBase/MapR/Cassandra etc
Must have set up data pipelines to move data across systems
Exposure over working with Audio (speech), Image, Video or any other non-textual data would be a huge plus
Knowledge of working in the cloud
Experience of working with version control, bug tracking, continuous integration, and other productivity enhancement
software like SVN, Bugzilla, Jira, etc.
Prior experience in implementing Agile software methodologies
The ability to effectively manage technical people (internal & external development resources) and projects
Taking responsibility and ownership in the team’s work

Additional Requirements:
B-Tech/BS/BE/BS/MS/M.Tech/MS in Electronics or Computer Science from a premier institute in India (IITs, BITS, NITs, etc) or abroad.

Our Offering:
True start-up experience – no bureaucracy and a ton of tough decisions that have a real impact on the business from day one.
The camaraderie of an amazingly talented team that is working tirelessly to build a great OS for India and surrounding markets.

Perks:
Awesome benefits, social gatherings, etc.
Work with intelligent, fun and interesting people in a dynamic start-up environment.

Catch up with us on Social Media:
Visit www.indusos.com for detailed information.
Facebook – https://www.facebook.com/indusos/
Twitter – https://twitter.com/indusos
LinkedIn – https://www.linkedin.com/company/indusos",4.3,"Indus OS
4.3",Mumbai,"Mumbai, India",51 to 200 employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Science Professional,-1,"Job title: Data Scientist | IT Global Operations

We are part of SOP IT APD DA which deals with Data Analytics and
Business Intelligence for Asia. As a Data Scientist in the Analytics Lab India,
you will be involved in designing, implementing and testing a component different
projects with diverse background. You will work closely with our product owner,
scrum master and other developers in an agile development team throughout the
entire product lifecycle.

This is your role. What part will you play?
Perform strategic data analysis and
research within SAP data structures to support business processes and
strategy and discuss results with team leads and customers.
Process large amounts of data from
multiple sources and extract relevant insights.
Build predictive models and ensure the
models are robust enough to be used in production


We don’t need superheroes, just super minds.

Qualification:
Degree / BE (Computer Science, Information Technology)
A master’s degree in mathematics, Physics,
Statistics, Computer Science, Engineering, a similar quantitative field or
equivalent practical experience.
3+ years of
experience on software development projects as business/data analyst,
ML/AI developer, Data visualization expert, Cloud developer
Experience with statistical software and
scripting languages (e.g. R, Python, SAS).
Proficiency in SQL.
Experience analyzing and modeling data
sets.
Experience with statistical and machine
learning methods (preferred).
Ability to communicate technical concepts
into simple terms to present to non-technical audiences (preferred).
Effective written and verbal communication
skills (preferred).


We are looking forward
to receiving your online application. Please ensure you complete all areas of
the application form to the best of your ability as we will use the data to
review your suitability for the role.

Make your mark in our exciting world at Siemens.

This role is based in Pune, where you’ll get the chance to
work with teams impacting entire cities, countries – and the shape of things to
come.

We’re Siemens. A collection of over 379,000 minds building the
future, one day at a time in over 200 countries. We're dedicated to equality
and we welcome applications that reflect the diversity of the communities we
work in. All employment decisions at Siemens are based on qualifications, merit
and business need. Bring your curiosity and creativity, and help us craft
tomorrow.

Organization: Siemens Operations

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Pune,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Analytics Scientist,-1,"Designation: Analytics Scientist
Experience: 1- 3 Years
Location: Bangalore
Commitment: Full-Time
Functional Team: Analytics
Number of opening: 1

Job Description:
Coming up with data driven solutions to control risk and collections
Finding opportunities to acquire more customers by modifying/optimizing existing rules
Doing periodic upgrades of the underwriting strategy based on business requirements
Evaluating 3rd party solutions for predicting/controlling risk of the portfolio
Running periodic controlled tests to optimize underwriting
Monitoring key portfolio metrics and take data driven actions based on the performance
Building models to predict risk and other key metrics
Do You Know? (Technical Skills and Experience)
1 – 2 years of experience in Financial Services/Analytics Industry
Strong Analytical aptitude and logical reasoning ability
Knowledge of analytical tools such as R/Python
Dexterity with SQL/MySQL, MS Excel
Strong presentation and communication skills.
Understanding of the financial services business
Established competency in statistics
Experience in handling complex data sources and working on advanced machine learning techniques

If you’re interested in applying for this position, please mail your resume to Careers@oyefin.com",4.8,"OYE Loans
4.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Science Consultant,-1,"Hewlett Packard Enterprise advances the way people live and work. We bring together the brightest minds to create breakthrough technology solutions, helping our customers make their mark on the world.

You will join the HPE Global Operations Advanced Analytics team housed in Bangalore. You will work closely with HPE Global Operations Advanced Analytics organization in working on and managing different aspects of Business planning, reporting and analytics.

Your Role:

Designs, develops and applies programs, methodologies and systems based on advanced analytic models (e.g. advanced statistics, operations research, computer science, process) to transform structured and unstructured data into meaningful and actionable information insights that drive decision making.
Uses visualization techniques to translate analytic insights into understandable business stories (eg. descriptive, inferential and predictive insights).
Embeds analytics into clients business processes and applications. Combines business acumen and scientific methods to solve business problems.

Responsibilities:

• Formulates and defines analytics solution objectives and technical requirements based on user needs, an understanding of business processes, industry requirements, and advanced analytic models (statistical, operations research, computing, process).

• Conceptualizes, builds, develops and enhances a client's analytic model. Selects the relevant analytic modeling methodology for the use case, available structured and unstructured data, cost and timing constraints to solve the business issue and deliver clear business focused insights.

• Embeds analytic models in an enhanced business process of operational system by collaborating with Application Developers. Responsible for measuring business performance based on the model.

• As a fully functioning analytics team member, applies best practices to analytics solutions and contributes to the development of improved best practices. Leads the model enhancements.

• Summarizes complex ideas by developing visual models to display insights to simplify user experience.

• Communicate the analytics solution to the appropriate stakeholders.

Education and Experience Required:

PhD degree in Statistics, Operations Research, Computer Science or equivalent preferred. Or Master´s Degree in these areas and at least 4-12 years of relevant experience.

Knowledge and Skills:

• Advanced knowledge of advanced data science methodologies including but not limited to classical regression, neural nets, CHAID, CART, association rules, sequence analysis, cluster analysis, and text mining.

• Ability to translate business requirements into mathematical models and data science objectives to achieve measurable business outcomes.

• Advanced understanding of analytics software (eg. R, SAS, SPSS, Python). Advanced understanding of analytics deployment architectures.

• Advanced machine learning, data integration, and mathematical modeling skills and ETL tools (eg. Informatica, Ab Initio, Talend).

• Advanced communication and presentation skills.

• Strong interpersonal skills and effectiveness in working across geographical boundaries.

• Working knowledge of programming languages such as Python, SQL, R, SAS, Java, Unix Shell scripting. Working knowledge of Hadoop framework desired.

• Advanced knowledge of data visualization techniques and software tools (eg. Spotfire, SAS, R, Qlikview, Tableau, HTML5, D3).

Join us and make your mark!

We offer:

• A competitive salary and extensive social benefits

• Diverse and dynamic work environment

• Work-life balance and support for career development

• An amazing life inside the element! Want to know more about it?

Then lets stay connected!

https://www.facebook.com/HPECareers

https://twitter.com/HPE_Careers

1061305",4.2,"Hewlett Packard Enterprise
4.2",Bengaluru,"Palo Alto, CA",10000+ employees,2015,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Oracle, Accenture"
User & Business Monetization - Associate Data Scientist,-1,"About us :
Remember the days when the phone rang and you didn't know who it was? If it was the company you always dreamt of working for? A call from a hospital trying to tell you someone close to you got sick? Or just that stubborn sales guy.

Our mission is to make it possible for you to know who's trying to contact you, and also tell you when not to pick up. We want to remove all uncertainty, making your communication safe and efficient by separating the important stuff from the noise and create trust, no matter if it's in the beginning of a call, in the middle of a transaction or at the end of a signature. We are building a platform which empowers our users to take control of their own digital identity and making their communication more safe and efficient.

Truecaller is one of the fastest growing tech companies in the world. We have 100 million daily active users around the world with the strongest presence in South Asia, Middle East and Africa.

We are backed by some of the most prominent investors in the world such as Sequoia Capital, Atomico, and Kleiner Perkins Caufield & Byers.

Your Mission :
At Truecaller, we have an ocean of data to mine, we believe in working hard & smart, learning every day in this constantly evolving
space while adding value to our users and business.
We focus on measurable and impactful work and don't forget have a lot of fun along the way. If this sounds like you, we want to talk to you!

Job Description:
We are looking for a data scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter
decisions to deliver even better products. translating a business problem to a DS problem, scope definition, data cleaning, explorations, feature engineering, feature selection, modelling, building prototype, documentation of an algorithm and insights, will
also help with data collection and algorithm quality monitoring.

Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems
integrated with our products.

Classifying based on a variety of data and meta data, anomaly detection systems, recommendation systems, internal A/B testing
procedures, improve and extend the features used by our existing classifiers.

Responsibilities :
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company's data with other sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems,Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner,Creating automated anomaly detection systems and constant
tracking of its performance

Communication between teams and ability to transfer knowledge in a readable/understandable manner for everyone.

Skills and Qualifications :
Good understanding of machine learning techniques and algorithms, such as Neural Networks, K-Means, k-NN, Naive
Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as Spark, sklearn, GGplot, Advanced Excel, NumPy, MatLab, etc.
Great communication skills
Experience with data visualisation tools, such as tableau, Google Data Studio etc.
Proficiency in using query languages such as SQL, Hive, Spark, Cassandra
Experience with NoSQL databases, such as MongoDB, Cassandra, Hive, Hadoop
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personalityMaster's/PGDDS in Computer Science, Statistics, Mathematics,
Engineering, Operations Research or related fields
1-3Y Exp in an Analytics/Data Science or similar roles, self- curated projects

Personality
Well-structured
Proactive
Team player
Polite and respectful
Honest and trustworthy
Never give up
Taking ownership
We offer

At Truecaller we have built a dynamic and diverse culture where we are keen to take ownership of what we are doing, learn and develop ourselves and are willing to share their knowledge with others. We love to experiment with new tools and technologies to push the envelope and be able to deliver the best product to our users and we believe that failure is halfway to success. At Truecaller you will find challenges and a team with passion for what we do.

Applying

This position is located in Bengaluru, India.

We only accept applications in English.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, or marital status.",3.5,"Truecaller
3.5",Bengaluru,"Stockholm, Sweden",201 to 500 employees,2009,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Editorialist YX’s mission is to provide the most personalized online shopping experience in the world. Our highly client-centric approach uses deep data to take the infinite array of luxury goods available for sale online and to recommend the perfect product based on our clients’ lifestyles, preferences, and wardrobes. We define a luxury experience as one that is super-personalized. Editorialist YX fuses personal styling, content, and shopping in one seamless digital experience driven by proprietary technology, e-commerce tools, and luxury fashion content.

Editorialist YX is looking for a Data Scientist. We are a startup with amazing perks. As part of this role, you would be joining a small focused team that solves hard data science problems. You will be responsible for building machine learning models at scale.
Responsibilities
Collect, clean and analyze data from diverse streams of structured & unstructured data
Extract meaningful insights from data and present it to various stakeholders
Work on end-to-end data science lifecycle: from building proof-of concept models to production-ready models & work with engineers to deploy them to production
Build models that improve accuracy of various processes within our pipeline
Build models to improve search ranking and relevance
Work cross-functionally across different teams to understand business requirements, needs of our audience and that of our clients.
Write elegant machine learning and data analysis code in Python
Build other models including personalization & deep learning models
Be a champion of data driven culture in the company
Requirements
Bachelor’s degree in statistics or data science or related.
2+ years experience as a data scientist or machine learning engineer
Experience in python, SQL
Strong knowledge of mathematics, statistics, probability and machine learning
Experience in spark, hadoop, keras, tensorflow is a big plus
Ability to explain complex concepts in simple terms
High Energy/Startup Mindset
Excellent communication (English) and presentation skills
Willingness to learn
Excellent Team Player
Please submit a cover letter along with your resume.",-1,Editorialist YX,Gurgaon,-1,-1,-1,-1,-1,-1,-1,-1
DA&I DATA ENGINEER,-1,"Position Title
DA&I DATA ENGINEER

05-May-2020

Business Group
Control Products and Solutions

No. of Positions
1

Requisition Number
92123BR

Job Category
Software and Engineering

Position Type
Full Time

Relocation Eligible
Not Applicable

Position Summary
Role Purpose: The Full Stack Data Engineer will design, develop, and deliver reliable, scalable data management (acquisition, integration, transformation) using DevOps methodologies and DA&I Microsoft PaaS platforms. Design and enable DA&I solutions and services throughout the company. This role is DA&I’s competitive advantage to delivering business outcomes via actionable analytics, decision intelligence and help our businesses recognize value and here to shape how we deliver analytics solutions going forward.

The Data Engineer is multi-skilled engineer who helps to estimate work, accept stories into delivery increments and complete tasks to deliver the work. Is proficient in Source Data Analysis, profiling, integration, modelling. Has expertise in data management technologies such as SAP data services, Azure ADF, ADLS, Databricks, SQL DB, Open source data management tools or equivalent.
Company Background
Rockwell Automation, a $7B industrial with 23,000 employees in 100 countries is at the forefront of the IoT revolution and is transforming its IT organization to digitize our customer experiences. We need full stack engineering professionals with a passion for technology to drive innovative solutions.

Key Responsibilities:
Designs, codes and tests new data management solutions, including supporting applications and interfaces.
Architects data structures to provision and enable “Data as a Service” .
Supports cross-functional development activity in various DA&I and Connected Enterprise related projects, for internal and external customers
Develops and tests infrastructure components in Cloud and Edge-level environments
Proactively monitors industry trends and identifies opportunities to implement new technologies
Manages the DevOps pipeline deployment model
Implements software in all environments
Leverages containerization models and works with other engineers and architects to keep the architecture current
Assists in the support and enhancement of applications
Writes high-quality code compliant with regulations
Collaborates with business systems analysts and product owners to define requirements

Qualifications
Skills, Knowledge, Experience and Education
Bachelor’s Degree in computer science, software engineering, management information systems, or related field
Experience in systems development lifecycle
Experience in Data management concepts and implementations
Experience with Agile development methodologies and system/process documentation
Experience with server-side architectures and containerization
Experience with SAP Data Services, Azure ADF, ADLS, SQL, Tabular models, or other domain-specific programming languages
Familiarity with business concepts and impact of data on business processes
Experience managing multiple projects simultaneously
Excellent interpersonal, verbal and written communication skills
Ability to adapt quickly to new technologies and changing business requirements
Solid problem-solving skills, attention to detail, and critical thinking abilities

Temperament
Ability to adapt to and assist colleagues to work through change and support change management processes
Strong team orientation and ability to collaborate with the business and IT organizations
Ability to retain and convey a positive attitude in challenging circumstances
Act courageously by sharing viewpoints openly and directly with others, providing relevant and timely information and feedback, as required
Ability to influence and obtains results through others within Rockwell in a respectful way
Adapt appropriately to competing demands and shifting priorities

IPC - Information Processing Capability (Factors of Complexity)
Ability to work on issues of moderate scope where analysis of situations or data requires a review of relevant factors.
Exercise judgment within defined procedures and practices to determine appropriate action.
Seek out and embrace relevant perspectives when assessing a situation or making a decision; demonstrate clear understanding of multiple viewpoints
Leverage business insights in proposing solutions and facilitating change
Ability to manage competing demands, accept criticism and constructive feedback, while being extremely adaptable and flexible
Strong analytical skills; ability to distill information from disparate data sources and the capability to tell the “story” behind it, as well as recommendations for next steps

Accepts Role Requirements
Unwavering commitment to, and the ability to model, the standards of behavior set in our Code of Conduct.
Enthusiasm for relationship building and partnership across the organization at all levels
Values working in a team-oriented culture and building consensus with stakeholders before making key decisions
Actively pursues personal continuous learning and development of skills

Country(s)
India

Company Overview
Over centuries, the world has evolved and advanced. New innovations change how we work. How we live. How things get made.

The next industrial evolution is here — a new test of intelligence for humans and machines. Where breakthroughs are hard–won and success requires sifting through overwhelming data for insights, clarity and confidence.

Rather than fearing change, we embrace its possibilities. We know how to connect the imaginations of people with the potential of machines to make the world work better. More intelligent. More connected. More productive.

We stand with the problem solvers, the builders, the makers, the innovators because we belong to that community. And we stand ready to lead the way. At Rockwell Automation, we are expanding human possibility.

Work State/City
Noida, Pune",3.8,"Rockwell Automation
3.8",Noida,"Milwaukee, WI",10000+ employees,1903,Company - Public,Industrial Manufacturing,Manufacturing,₹500+ billion (INR),"Emerson, ABB, Siemens"
Data Scientist/ Senior Data Scientist,-1,"Strong problem-solving skills preferably with an emphasis on service, platform, product enabled solutions.
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, k-NN, Naive Bayes, SVM, Decision Forests etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.",3.8,"Mindtree
3.8",Bengaluru,"Bengaluru, India",10000+ employees,1999,Company - Public,IT Services,Information Technology,₹50 to ₹100 billion (INR),"Infosys, Tata Consultancy Services, Wipro"
Data Scientist,-1,"Responsibilities:
Undertake preprocessing of structured and unstructured data.
Build data products to extract valuable business insights
Build models to address business problems.
Propose solutions and strategies to business challenges.
Presenting information using data visualization techniques.

Requirements:
MSc / PhD in Computer Science, Statistics, Engineering or related field
Experience in probability, statistics, and statistical modeling or machine learning
Fluency in at least one scripting language
Excellent analytical and problem-solving skills
Excellent communication skills and business acumen
Good command in written and spoken English",-1,RedLotus,Mumbai,"Kowloon City, Hong Kong",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"We are looking for a data scientist with an experience of 3+ years in deriving insights using analytical models handling vast amounts of data available across multiple platforms. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products. Experience in social media analytics is a must.

RESPONSIBILITIES
Data mining using state-of-the-art methods
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Selecting features, building and optimizing models using machine learning techniques
Doing ad-hoc analysis and presenting results in a clear manner
Creating proposals and presentations
SKILLS
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests etc.
Experience in Predictive modelling, ensemble modelling, sentiment analysis, NLP, Time-Series Analysis, Deep Learning, Reinforcement learning, Recommender Systems
Experience with common data science toolkits, such as R, Python etc.
Experience with data visualisation tools, such as Tableau, Power BI, Qlikview etc.
Proficiency in using query languages such as SQL and HQL
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Great communication skills
Benefits and Perks
Working with smart, young, mission-driven people
Approachable management team
Mobile allowance
Travel allowance
Regular team outings
Flexible Schedules",1.0,"Emerging India Group
1.0",India,"Noida, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"Job Responsibilities :
To help designing, innovating and building our next generation ML architecture
6-8 years of full time programming experience within an operations or technical department.
Identify valuable data sources and automate collection processes
Undertake preprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns
Build predictive models and machine-learning algorithms
Combine models through ensemble modelling
Present information using data visualization techniques
Propose solutions and strategies to business challenges
Collaborate with engineering and product development teams
Teach and mentor others in the use of AI/Machine Learning
Keyskills :

Programming, Machine Learning, Artificial Intelligence, Data Science, Business Analytics, Product engineering, Requirement gathering, Problem formulation, quick POCs

Must Have :
Experience in data mining

- Strong math skills (e.g. statistics, algebra)

- Strong programming skills in: R, Python and familiarity with Java, Scala, C++
DB/NoSql - MongoDB, Neo4J, MySql. Cassandra, DynamoDB, Redshift

- Experience on Hadoop Map reduce, Pig, Hive, Mahout and Apache Spark, H20

- Strong experience in Data warehousing, ETL, BI (e.g. Tableau, Power BI) and Data Visualization tools (matplotlib, D3.js, Plotly.js, Shiny etc)

- Experience in neural networks, regression, classification and clustering

- Think big & scale
Good to have :
Experience with Deep Learning tools - Tensorflow, Theano, Caffe etc.

- Elastic Search, NLP background and Machine Learning Platforms

- Experienced in deployment of High performance, Scalable Big Data Hadoop clusters and Web applications on cloud infrastructure (Azure, AWS, Bluemix etc)",4.2,"Netcore Solutions
4.2",Mumbai,"Mumbai, India",501 to 1000 employees,1998,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"What would a VISA/Mastercard payments network look like if designed ground up? Simpl is focused on re-imagining the payments stack that have not changed for decades . We believe that payments data, if harnessed the right way, can accelerate formal credit distribution in a market like India, while unlocking precision marketing opportunities.

Its first product is a micro credit based payment mode that provides greater than 99% success rate, instant refunds within seconds, tokenized security flow combined with the convenience of all the transactions getting added into a single bill, payable on the 1st and 16th of every month. To power our micro credit line, Simpl uses alternate data ( Multiple millions of data pings everyday) provided by merchants to underwrite users at internet scale.

Simpl was founded in 2015 by Nityanand Sharma and Chaitra Chidanand, and went live in 2016

Major responsibilities include:
· Helping to build production systems that take inputs from multiple models and make decisions in real time.
· Deliver ML / DL projects from beginning to end, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models to deliver business impact to the organization.
· Utilizing effectively data to work with terabytes of data.

Basic Qualifications

· Bachelors in quantitative field (Computer Science, Mathematics, Machine Learning, AI, Statistics, or equivalent)
· 4+ years of industry experience in predictive modeling, data science and analysis
· Previous experience in a ML or data scientist role and a track record of building ML or DL models
· Experience using Python and/or R
· Knowledge of SparkML
· Able to write production level code, which is well-written and explainable
· Experience using ML libraries, such as scikit-learn
· Experience working with GPUs to develop models
· Experience handling terabyte size datasets
· Track record of diving into data to discover hidden patterns
· Familiarity with using data visualization tools
· Knowledge and experience of writing and tuning SQL
· Past and current experience writing and speaking about complex technical concepts to broad audiences in a simplified format
· Experience giving data presentations
· Strong written and verbal communication skills",4.3,"Simpl
4.3",Bengaluru,"Bengaluru, India",51 to 200 employees,2015,Company - Private,Financial Transaction Processing,Finance,Unknown / Non-Applicable,-1
Data Scientist II,-1,"Position Title
Data Scientist II

08-May-2020

Job ID
287040BR

Job Description
20 petabytes of data across 30 data domain across the whole bio-pharma value chain waiting for you to unlock the next breakthrough in medicine.

Your responsibilities include, but are not limited to:
● Think creatively, conceptualize and lead projects resulting in substantial long-term impact on the company’s vision in many key strategic areas such as drug discovery/manufacturing, product launches, determining optimal treatment plans/courses, expanding patient access, predictive/precision medicine, risk mitigation, business growth, brand management, product life cycle, data strategy etc
● Design, develop and deliver various data science based insights, outcomes and innovation (using mathematics, computer science, statistics, engineering, management science, technology, economics, etc) and create “proof of concepts & blueprints” to drive faster, timely, highly precise, workable and proactive decision making based on data based insights and science and shape strategic glidepath of the company
● Lead successful cross-functional collaborations with significant execution rigor, customer focus and “Data to Decision” thinking
● Demonstrate a comprehensive view of science and technology and deliver a compelling enterprise vision of how Data, Digital & Artificial Intelligence can contribute to providing quantum in leap in building foundational/groundbreaking capabilities.
● Own adoption, execution and integration of data science based solution end to end all the way from discovery to launch/post-launch and also into business, design, product, delivery, operations, marketing, brand management, research and technology roadmaps.

Minimum requirements
• M.S/Ph.d in Computer Science, Mathematics, Statistics, Operations Research, Cognitive Sciences, Engineering, Finance, Economics, Medicine, Technology, Management Science, other Quant disciplines
• Business Fluent in English 6-10 years of overall experience with demonstrated track record in data science solutioning

Why consider Novartis?
750 million. That’s how many lives our products touch. And while we’re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people’s lives?
We believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you’re given opportunities to explore the power of digital and data. Where you’re empowered to risk failure by taking smart risks, and where you’re surrounded by people who share your determination to tackle the world’s toughest medical challenges.

Job Type
Full Time

Country
India

Work Location
Hyderabad, AP

Functional Area
BD&L & Strategic Planning

Division
CORPORATE

Business Unit
DIGITAL OFFICE

Employment Type
Regular

Company/Legal Entity
Nov Hltcr Shared Services Ind

Shift Work
No",3.9,"Novartis
3.9",Hyderabad,"Basel, Switzerland",10000+ employees,1996,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
Science Data Analyst ( Curriculum),-1,"Who are Kïdo Education?

Kïdo are a network of innovative international nurseries.

We take elements from Montessori, Reggio Emilia and Waldorf Steiner, and combine them

with beautiful learning spaces and 21st century technology. Our customised experiences are

the most effective way for children to develop their cognitive, social, physical and creative

abilities.

Our vision is to create a truly modern Early Years environment that meets the needs of both

children and their parents.

We now have 24 schools across 4 countries (Hong Kong, Dubai, India and the UK) and

almost 400 employees which is a growing number! We are launching in the USA in 2020,

starting in Texas.

Roles and Responsibilities

Collect data regarding the learning process of children in different countries and analyse

the data.

● Prepare graphs and spreadsheets to portray results of the Curriculum Implementation

across different countries and levels (Learning results of the children, progression,

activities evaluation)

● Collect quantity and quality data for Curriculum result analysis from the Junior

Curriculum Developer.

● Create presentation slides and posters to help CAO present findings.

● Working closely with CAO to identify and drive through improvements to our

Curriculum.

● Unpack the Curriculum into its component parts (e.g. learning,

● teaching, knowledge, society, resources); evaluates how the parts fit together, say in

terms of focus and coherence; checks underlying beliefs and assumptions; And seeks

justification for curriculum choices and assumptions based on data.

● Analyse the activities across different countries to make an assessment of the curriculum

in order to improve it.

● Identify potential and actual problems as early as possible based on the analisis.

● Analyse and collect data to determine whether the goals have been met.

● identify strengths and successes in order to build on them; to examine whether

assumptions underlying the curriculum are valid and defensible.

● Create an assessments framework alongside with CAO based on the data collected.

● Collect Feedback from different Countries related to Curriculum quality.

● Develop research protocols for Kido based on the data collected.

Requirements

Great communication skills, excellent written and spoken English

● Well organised and able to work independently

● Ability to think outside of the box and be flexible regarding the design and development.

● High level of mathematical ability

● Programming languages, such as SQL, Oracle and Python.

● The ability to analyse, model and interpret data.

● Problem-solving skills.

● A methodical and logical approach.

● The ability to plan work and meet deadlines.

● Accuracy and attention to detail.

● Interpersonal skills.

● Team Working skills.

Qualifications

● Quantitative ability to draw data-driven insights using various tools including excel.

● Proven analysis experience.

● Science - Data Analyst Background.

Benefits
Competitive Salary
Working for a growing organisation",5.0,"Kïdo
5.0",Khar,"London, United Kingdom",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Novique is a revolutionary online clinic startup that reverses type 2 diabetes safely and sustainably, without the risks, costs, or side effects of medications or surgery. Our innovations in nutritional biochemistry, data science and digital tools combined with our clinical expertise are shifting the diabetes treatment paradigm from management to reversal. Our mission – to reverse type 2 diabetes in 10 million people by 2030.

As a full stack health care company of physicians, engineers, scientists, marketers and more under one roof – Novique collects comprehensive data on our patients’ experience. The Data Science & Engineering team leverages this data and our growing compute resources to build the next generation of health care for chronic diseases. Data scientists at Novique drive science and algorithmic solutions into the fabric of Novique’s products, operations, and decision making. You will be an evidence-based partner to our department leaders and executive team as we scale our operation to reverse type 2 diabetes in millions of people.

Responsibilities:
2+ years experience applying statistical or machine learning models to real business problems
A strong ability to break down vague business problems into component parts that can be solved algorithmically
Experience with Python’s open source data ecosystem (e.g. numpy, pandas, sklearn, tensorflow, statsmodels, spacy etc.)
Familiarity with SQL

Bonus Points for:
Complex data domains, especially: natural language, health data e.g. insurance claims
Recommender systems
Sequential decision-making: reinforcement learning, bandit algorithms, adaptive clinical trials
Probabilistic programming: e.g. mc-stan, pymc3, or edward

Responsibilities:
Translate nebulous, mission-critical business problems into the language of science and algorithms. Then, build high-performance systems to solve those problems
Partner closely with our product, sales, and clinical leaders to set company priorities, define data-driven cross-functional initiatives, and drive execution.
Work autonomously on your projects, supported by a growing and ambitious team of data scientists and engineers

Apply to careers@noviquehealth.com with subject line: Data Scientist",-1,NOVIQUE HEALTH,Mumbai,"New Delhi, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Ads -Data Scientist,-1,"About us :

Remember the days when the phone rang and you didn't know who it was? If it was the company you always dreamt of working for? A call from a hospital trying to tell you someone close to you got sick? Or just that stubborn sales guy.
Our mission is to make it possible for you to know who's trying to contact you, and also tell you when not to pick up. We want to remove all uncertainty, making your communication safe and efficient by separating the important stuff from the noise and create trust, no matter if it's in the beginning of a call, in the middle of a transaction or at the end of a signature. We are building a platform which empowers our users to take control of their own digital identity and making their communication more safe and efficient.
Truecaller is one of the fastest growing tech companies in the world. We have 100 million daily active users around the world with the strongest presence in South Asia, Middle East and Africa.
We are backed by some of the most prominent investors in the world such as Sequoia Capital, Atomico, and Kleiner Perkins Caufield & Byers.

Your Mission :

The Data Scientist is responsible for collecting, organizing, analyzing and interpreting Truecaller data and drawing insightful conclusions with the aim of enhancing BU's road map, business plan and customer experience. The individual will work in close collaboration with the Product, Engineering and platform team in order to identify and follow up on metrics, evaluate A/B tests and user behavior and identify product insights. The role requires working both independently and proactively with identifying improvement opportunities as well as being involved in separate projects. The Data Scientist will act as an advisor to the BU's Product improvement, strategy building and Management Team by identifying and communicating data insight.

Key responsibilities:
Collecting, organizing, analyzing and interpreting all data and drawing insightful conclusions from it that enables us to work in a smarter way
Create visual interpretations from data and explain graphs and charts with insightful notes and summaries
Analyzing users data and assist product development in finding new innovative ways of presenting and making use of data
Support our management team in identifying, measuring and following up on key metrics
Providing regular, accurate and comprehensive statistical reports
Providing objective insight and analysis to influence decision making
Constantly asking the right but difficult questions on why, what and how and also help us answering those questions
Ensuring quality of data and actively working on cleaning data to make sure of top notch relevance and accuracy
Actively keep up to date on external market and data research and work towards adding data points from external sources to our own data in order to create a value added analysis
Required minimum competencies:

3 to 5 Years Experience in an Analytics/Data Science or similar roles, self- curated projects
Familiarity with database modeling and data warehousing principles with a working knowledge of SQL
Familiarity with data modeling on Hadoop clusters, the tools in Big Query, Hive, Spark Kafka ecosystem, stream processing to support the day-to-day work
Extensive experience with analytical and quantitative problem solving
Experience with analysis tools, open source or commercially available libraries and toolsets
Excellent communication skills
Great attention to detail and analytical skills
A passion for numbers, data and finding patterns
Ability to excel with challenging tasks with a calm and positive attitude
Working knowledge of data mining algorithms including decision trees, probability networks, association rules, clustering, regression, neural networks and reinforcement learning
Experience from working with mobile applications and big data is a great advantage
Programming knowledge in at least one language in addition to SQL
Global / multinational experience
Applying:

This position is located in Bengaluru, India.
We only accept applications in English.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, or marital status.",3.5,"Truecaller
3.5",Bengaluru,"Stockholm, Sweden",201 to 500 employees,2009,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Associate - Data Science,-1,"? Publishing of Regular Portfolio Performance Deck and regular dashboards
? Automation of existing dashboards using SAS / Python / SQL / Tableau
? Adhoc – analysis for top management.
? Data maintenance, Data Quality, Enrichment and Validation
? Cross functional analytical projects
? Customer/Stakeholder Management for dashboard automation and regular dashboards

Job Description ? Publishing of Regular Portfolio Performance Deck and regular dashboards
? Automation of existing dashboards using SAS / Python / SQL / Tableau
? Adhoc – analysis for top management.
? Data maintenance, Data Quality, Enrichment and Validation
? Cross functional analytical projects
? Customer/Stakeholder Management for dashboard automation and regular dashboards
? SAS
? Tableau
? Python
? Dashboard Automation",3.2,"TATA Capital
3.2",Mumbai,"Mumbai, India",1001 to 5000 employees,-1,Subsidiary or Business Segment,Investment Banking & Asset Management,Finance,₹100 to ₹500 billion (INR),-1
Data Scientist,-1,"Advising the business on the potential of data, to provide new insights into the business's mission, and through the use of advanced statistical analysis.
Job Types: Full-time, Part-time",-1,Globelancer,New Delhi,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"Bachelor's or Master’s degree in Statistics, Applied Math, Operations Research, Economics, Engineering or a related quantitative field with 5 years of working experience as a Data Scientist.
In-depth knowledge on supervised and unsupervised machine learning algorithms including classification, clustering, and regression.
Experience building productions systems with statistical analysis, data modeling, regression modeling and forecasting, time series analysis, and deep learning neural networks.
Expertise in coding using one or more programming languages such as R, Python, MATLAB, and Spark to build machine learning models. Skilled in manipulating and processing data using libraries such as Scikit-learn, Pandas, and NumPy. Demonstrated experience in SQL and/or NoSQL data modeling.
Experience processing, filtering, and presenting large quantities of data. Ability to design for performance, scalability, and availability.
Excellent communication, analytical and problem-solving skills. Ability to distill informal customer requirements into problem definitions, dealing with ambiguity and competing objectives.
Obsession with quality, operational excellence, and customer experience. Ability to convey rigorous mathematical concepts and considerations to non-experts.
At Amazon, we strive to be most customer-centric company on the earth. To get there, we need exceptionally talented, bright, dynamic and driven people to develop the next-generation technologies.
Are you champion of innovating on behalf of the customer by turning data insights into action? Do you want to be part of Amazon’s strategic and highly impactful finance and payroll technology projects? Amazon’s Finance Automation Payroll Tech team has an opportunity for a seasoned Data Scientist whose experience illustrates a clear ability to create world class machine learning systems to meet long-term Payroll needs.

At Finance Automation, we are passionate about building systems and services that deliver a seamless and transparent finance experience for Amazon partners. We build, operate, and scale systems that are responsible for billions of dollars in transactions, and are central to the success of worldwide finance. We ""think globally, act locally"" to revolutionize a worldwide employee and customer experience and fulfill our promise to pay accurately, on-time, with lowest cost to Amazon.

As a Data Scientist at Finance Automation, you are self-driven leader with extensive experience in applying statistics and data science concepts to bring tangible benefits for global finance operations. Finance and Payroll domain knowledge is a plus but not required.
Work with finance and payroll stakeholders to understand the organization goals, objectives, and pain points. Identify key areas to drive Machine Learning initiatives, define needle-moving business questions and success criteria.
Collect and analyze finance, HR, and payroll data across multiple isolated systems. Derive actionable insights from large volumes of heterogeneous data.
Create reliable and maintainable code to build regression, classification, clustering, and anomaly detection systems. Work closely with software engineers to develop data ingestion and visualization, and productionize your models.
Partner with finance analysts, and payroll managers to deploy and test machine learning systems with your statistical models at the core. Automate feedback loops, tune, and improve the models in production.
Train non-tech stakeholders and partners to effectively use your machine learning systems. Set the right expectations on model limitations and prove business value.
Create and maintain business and technical artifacts such as requirements documentation, use cases, performance evaluation, and model metrics.
Learn and utilize AWS technologies and Amazon machine learning systems to effectively work with terabytes of data.
Being part of Amazon Finance Automation gives you the opportunity to work in a rapidly growing organization with many high performing global technology teams. Come join us in making history!
Passion to dive deep to resolve problems at their root, looking for failure patterns amenable to long-term solutions via simplification and automation.
Experience in AWS is a huge plus. Functional knowledge of AWS platforms such as Sagemaker, S3, Glue, Dynamodb, and RedShift.
Exposure to finance and payments domain is a plus.
Deep understanding of data, application, server, and network security.
Experience with agile or scrum methodology.",-1,ADCI HYD 13 SEZ,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist II,-1,"As a Data Scientist of the Alexa AI - Alexa Data Services Team, you will research and create models, improve models for natural language processing and speech recognition problems.

You will gain hands-on experience with Amazons heterogeneous structured data sources; as well as large-scale computing resources to accelerate advances in training deep neural networks for natural language understanding and automatic speech recognition on thousands of hours of speech. You will be leading on solving highly visible and impactful business problems in areas of new product development, automation, self-service solution and quality improvement, to continue delight Alexa customers and help driving Amazon business performance.


The ideal candidate is clearly passionate about delivering experiences that delight customers and creating solutions that are robust. Creating reliable, scalable and high performance products requires exceptional technical expertise, and a sound understanding of the fundamentals of Machine Learning.


We value academic collaborations and encourage our scientists and engineers to publish in top conferences such as NIPS, ICML, ICLR, KDD etc. and do open source contribution.


(S)He should thrive and have demonstrated success in an environment which offers ambiguously defined problems, big challenges, and quick changes. (S)He will be expected to balance detailed execution with speed and possess solid collaborative skills. (S)He will be working in a fast-paced environment where every day brings new challenges and new opportunities. (S)He should have excellent business and communication skills and be able to work with business owners to develop and define solutions. This position involves regular communication with senior management on project status and risks. Cross-team coordination, project management, and executive presentation skills are essential.





Basic Qualifications

· MS or PhD in Data Science, Mathematics, Statistics, Computer Science, Engineering, or related field, or related industry experience
· 3+ years experience in Data Science
· 1+ years of scripting experience
· Experience in qualitative and quantitative analysis, machine learning and statistical modeling techniques

Preferred Qualifications

· PhD degree in Data Science, Mathematics, Statistics, Engineering, machine learning, computer science or related discipline
· 5+ years of industry or postdoctoral experience in machine learning or data science
· 3+ years of experience in natural language understanding/processing or speech recognition
· Publications on peer-review journals
· Experience in building large-scale machine learning systems
· Hands on Python or other OO language
· Proficiency in MxNet, pyTorch or TensorFlow",4.2,"Amazon
4.2",Hyderabad,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Scientist / Data Analyst,-1,"This position will be responsible for Finance Analytics product offerings thereby generate Business Performance Improvement opportunities for the Stake Holders. Our Client is looking for an experienced Senior Data Scientist to join our talented engineering team. As our data guru, you’ll be responsible for analyzing the large data set and making recommendations that will impact major business decisions. They are looking for a proven technical leader that can excel in a fun, fast-moving startup environment and help them elevate their customer experience.

Job Responsibilities

Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases to drive optimization and improvement of sales projections, processes, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modelling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Develop algorithms and predictive models, create prototype systems and visualizations
Implement and keep models in optimal production state
Strong data & visual presentation skills and ability to explain insights using tools like tableau, D3 charts or other tools.
Experience working with big data tools such as MapReduce, Pig, Spark and NoSQL data will be an add-on
Must have end-end hands-on experience in delivering & implementing data analytics models in production. Must have skills, such as Synthesizing data, defining the problem, feature engineering, building the model, deploying the same in production.
Ability to work closely with others to execute projects rapidly in a multi-disciplinary environment
Demonstrated data science experience in the Sales & Marketing domain with at least 3 to 4 projects delivered end-to-end, Ability to collaborate business and data science.
Strong project management skills, a passion to drive task based processes to successful completion – organized, strong communicator, high-energy and takes initiative
Consultative and collaboration skills; able to influence complex stakeholder communities
Education : Bachelor’s degree in computer science, statistics, engineering and relevant fields,

Experience : with 6+ years of hands-on experience in the following:

Statistical analysis tools such as R, Python, SAS, etc.
Machine learning techniques for classification, regression, clustering, decision trees, text analytics, deep learning & time-series data etc.
Scripting languages such as Python, Perl, Ruby, etc.

Strong communicator written and oral; able to work effectively with remote, global project teams

What You Need for this Position

You should have knowledge of:
Data Science
Data Analyst
SQL
R
Python
SAS
Python
Perl
Ruby
MapReduce
Pig
Spark and NoSQL
Aditional
No. of Positions
3
Education level
Bachelor’s Degree in Computer Science
Career level
Experienced",4.8,"Bloom Consulting Services
4.8",Bengaluru,"Nagpur, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
Customer Data Scientist,-1,"Company Overview

H2O.ai is the open source leader in AI with a mission to democratize AI for everyone. H2O.ai is transforming the use of AI with software with its category-creating visionary open-source machine learning platform, H2O. More than 18,000 companies use open-source H2O in mission-critical use cases for Finance, Insurance, Healthcare, Retail, Telco, Sales and Marketing. H2O Driverless AI uses ""AI to do AI"" in order to provide an easier, faster and cost-effective means of implementing data science. H2O.ai partners with leading technology companies such as NVIDIA, IBM, AWS, Intel, Microsoft Azure, and Google Cloud Platform and is proud of its growing customer base which includes Capital One, Progressive Insurance, Comcast, Walgreens, and MarketAxess. For more information and to learn more about how H2O.ai is driving an AI Transformation, visit www.h2o.ai.

Job Summary:
Can you code proficiently in at least one language used by data scientists and/or data engineers, and does it excite you to learn more?
Are you skilled at predictive modeling?
Do you view communication skills just as important as technical ones?
Can you listen to the needs of your peers and customers and adapt where need be?
Do you have a competitive drive to be the best you can be?
Can you finish what you start?
Can you own assignments given to you?
If the answer is ""yes"" to these questions, you potentially could be an excellent fit to join the team of customer engineering makers at H2O.ai. We deliver world-class solution experiences for our customers and drive revenue for our organization. Some of the technical projects you will work on include: training advanced machine learning models at scale in distributed environments, influencing next-generation data science tools and data products, and pioneering ideas and products in new areas, such as machine learning interpretability, automatic machine learning, model management, deployment pipelines, and GPU computing.

Responsibilities and Duties:

As a Customer Data Scientist, you will be part of Customer Success team working closely with sales directors to:
Problem solve and assess technical problems, determine solutions, and work with internal engineering and customer teams to resolve them.
Demonstrate ML solutions with engaging storytelling and technical accuracy.
Architect, Design, and Deliver end to end machine learning workflows and systems from data ingestion to model deployment.
Provide best practices and guidance to customers on machine learning workflows and systems from data ingestion to model deployment.
Own account-related technical activities and relationships.
Translate business use cases and requirements into technical ones.
Communicate effectively to a diverse audience, including engineers, business people, and executives. Audiences will be large and small, and interactions will be in-person and online.
Drive field feedback back into product development and be very hands-on for all technical activities.
Qualifications and Skills
Bachelor's degree in engineering, computer science, mathematics or a related field. A graduate degree is a plus.
2+ years experience with performing hands-on Data Science and Machine Learning
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Visualization skills using R, Python or other languages and frameworks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.
2+ years experience using statistical computer languages (R, Python, etc.) to manipulate data and draw insights from large data sets.
2+ year working with data in Hadoop and /or Spark ecosystem
Desirable: Maker mindset, coachable, and have an urge to learn/master new technologies
Work Location - Chennai

H2O.ai Perks!
Flexible work hours and time off.
H2O.ai is an equal opportunity employer. We welcome and encourage diversity in the workplace regardless of race, gender, sexual orientation, gender identity, disability or veteran status.

Powered by JazzHR",4.2,"h2o.ai
4.2",Chennai,"Mountain View, CA",201 to 500 employees,2011,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"5+ years of experience in software development of large-scale data infrastructure and distributed systems
5+ years of experience in data extraction, transformation, statistical analysis and data modeling
5+ years of experience developing enterprise software using Java or Python
3+ years of experience in applying Data Mining and Machine Learning techniques to solve business problems
3+ years of experience using major RDBMS, Hadoop, Spark, Elasticsearch, or similar technologies
3+ years of experience with statistical modeling tools such as R, SAS, SciKit-learn, or TensorFlow
Bachelor’s degree in Computer Science, Computer Engineering, Machine Learning, or related field or equivalent experience.
Amazon strives to be Earth's most customer-centric company where people can find and discover anything they want to buy online. We hire the world's brightest minds, offering them a fast paced, technologically sophisticated, and friendly work environment.

The FinAuto Data Engineering and Analytics team, part of Finance Automation Org focuses on the application of machine learning methods designed to enable Amazon to increase free cash flow by optimizing spend, expense, payroll defects. All of this work is performed in close coordination with senior business leaders. These are exciting fast-paced businesses in which we get to work on extremely interesting analytical problems, in an environment where you get to learn from other data engineers and apply econometric, statistics, and machine learning at massive scale.
As a member of the FinAuto Data Engineering and Analytics team, you will partner closely with a team of stake holders, payment teams, data engineers and software engineers.

In this role you will:
Work with data engineers to design and implement machine learning applications and solutions.
Implement and maintain a high-volume, highly available, hybrid (SQL + No SQL) data processing solutions that consists of structured and semi-structured data.
Design and implement a very large distributed data warehousing and reporting solution and integrate it with business intelligence tools
Master’s degree in Computer Science, Computer Engineering, Machine Learning, or related field; PhD a plus
Deep expertise in Statistics, Machine Learning or related disciplines
Advanced knowledge in performance, scalability, numerical accuracy, enterprise system architecture, best practices.
Experience building solutions using AWS big data and machine learning services
Ability to communicate complex technical concepts and solutions to all levels of the organization",-1,Amazon Dev Center India - Hyd,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"“Make every logistics journey your best one yet” - Quincus
The Company.
At Quincus, our technology is designed to ease shipping issues—wherever in the world they may be. We commit ourselves in designing the most effective total end to end supply chain solutions through a dedicated technology ecosystem. This offers our users a personalized experience that bypasses traditional and expensive logistics options.
By combining advanced technology, data analytics, and hands-on experience, we eliminate traditional and expensive logistics options.

The Opportunity.
As our business continues to grow, we are looking for a Data Scientist to join our team who will discover the information hidden in vast amount of data and help make smarter decisions for better products. The primary focus will be applying data mining techniques, doing statistical analysis and building high quality prediction systems integrated with our product.

Your day to day.
- Interpret and manage data and solve complex problems
- Selecting features, building and optimizing classifiers using techniques.
- Enhancing data collecting procedures to include information that is relevant for building analytic systems.
- Processing, cleaning and verifying the integrity of data used for analysis.
- Doing ad-hoc analysis and presenting results in a clear manner.

Who you are.
- Minimum 2 years of relevant experience working within a high growth environment.
- Understanding of NLP techniques for text representation, semantic extraction techniques, data
structures and modeling.
- Strong problem solving skills along with excellent verbal and written communication skills.
- Experience in technologies such as Python, Java, R.
- Understanding of techniques and algorithms.
- Good statistical skills.
- Proficiency in using query languages.

What’s in it for you.
- People : Work with passionate, smart, and entrepreneurial go-getters.
- Fun environment : cool office space, stocked pantry, and team bonding.
- Compensation: competitive salaries and benefits.",5.0,"Quincus
5.0",New Delhi,"Singapore, Singapore",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Analytic Consultant 2,-1,"Department Overview Conduct Management Analytics, Insights, & Reporting (CMAIR), About the Role As part of the Conduct Management Analytics, Insights, & Reporting (CMAIR), you will be responsible for the development of highly complex activities providing insights, developing analytical strategies, performing analytical support and/or modeling for Conduct Management. You will be responsible to design and lead some of the most complex projects/analyses, generally spanning multiple products/business lines/functional areas/data sources and may involve extremely complex analytical application of industry-leading experimental techniques or exploratory data analytics. Responsibilities Partnering with CMAIR teams on internal fraud/ethics/sales practice analysis to identify team member behaviors that warrant Internal Investigations or HR review Conducting research and analysis on detection strategies during various stages of development prior to deployment into production Providing specific and detailed recommendations to the developer to enhance the effectiveness and quality of the output Utilize CMAIR analysis to identify root cause of risky behaviors identified Partner with CMAIR teams to assist in conducting manual review and research necessary to support more complex analytic exercises focused on team member misconduct Essential Qualifications 4+ years of fraud prevention or claims experience ( RQO0001681) Experience in case reviews and research to drive data driven insights and detect data mis-classification Experience in fraud, BSA/AML, investigations of financial crimes transactions or policy violations, risk management, compliance, or allegations Ability to provide independent summaries and recommendations on operational data (DQO0004800) Experience working with fraud scenario/strategy development Strong analytical skills with high attention to detail and accuracy Excellent verbal, written, and interpersonal communication skills Diversity champion enabling team collaboration. Leads and influences diverse views to foster problem solving, and delivery of extraordinary work that promotes team success Experience building positive partnerships, influencing and effective collaborating with the risk community, legal, audit, regulators, technology, and peers to identify, formulate, and implement risk mitigation strategies Demonstrated ability to collaborate effectively with internal and external partners Desired Qualifications Recent experience working with internal fraud, in the banking industry Experience working with Wells Fargos compliance policies and procedures Extensive knowledge of Wells Fargo systems and ability to utilize various applications in research 49792",3.6,"Wells Fargo
3.6",Hyderabad,"San Francisco, CA",10000+ employees,1852,Company - Public,Banks & Building Societies,Finance,₹500+ billion (INR),-1
Applied Scientist - Intern,-1,"Excited by Big Data, Machine Learning and Predictive Software? Interested in creating new state-of-the-art solutions using Machine Learning and Data Mining techniques on Terabytes of Data?

At Amazon Bangalore, we are developing state-of-the-art large-scale Machine Learning Services and Applications on the Cloud involving Terabytes of data. We work on applying predictive technology to a wide spectrum of problems in areas such as Amazon Retail, Seller Services, Customer Service, Alexa, Chatbots and so on. We are looking for talented and experienced Machine Learning Scientists (Ph.D. in a related area preferred) who can apply innovative Machine Learning techniques to real-world e-Commerce problems. You will get to work in a team dedicated to advancing Machine Learning technology at Amazon and converting it to business-impacting solutions.

Major responsibilities
· Use machine learning, data mining and statistical techniques to create new, scalable solutions for business problems
· Analyze and extract relevant information from large amounts of Amazons historical business data to help automate and optimize key processes
· Design, develop and evaluate highly innovative models for predictive learning
· Establish scalable, efficient, automated processes for large scale data analyses model development, model validation and model implementation
· Research and implement novel machine learning and statistical approaches

Basic Qualifications

Basic Qualifications
· A Masters and/or PhD in CS, Machine Learning, Operational research, Statistics or in a highly quantitative field.
· Experience in predictive modelling and analysis, predictive software development.
· Strong problem-solving ability
· Good skills with Java/Scala or C++, Perl/Python (or similar scripting language)
· Experience in using R, Matlab, or any other statistical software
· Strong communication and data presentation skills

Preferred Qualifications

Preferred Qualifications
· Experience handling gigabyte and terabyte size datasets
· Experience working with distributed systems and grid computing
· Knowledge of the latest and state of the art ML technology.
· Publications or presentation in recognized Machine Learning and Data Mining journals/conferences",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Scientist,-1,"Location: Guntur or Mumbai.
Salary Rs. 60,000 to Rs 1,00,000 per month.
As a Data Scientist you will work with huge datasets, troubleshooting challenging issues with machine learning, programming and analytical techniques.

Requirements:
Strong C/C++ or Java skillsExperience building and deploying real world machine learning applications in a production environment
Previous experience of large datasets
Excellent mathematical skills
Degree educated in Computer Science or related subject

Desirable: MSc Maths, Deep Learning, HPC/GPU experience in the context of machine learning, KDB, Python, Unix, Machine Learning Frameworks
Visualization Tools: SAS VA, TABLEAU, SAP FIORI

Send your resume with cover letter to hr@coveventure.com",-1,Cove Venture,Guntur,"Scottsdale, AZ",51 to 200 employees,-1,Company - Private,Real Estate,Real Estate,₹100 to ₹500 million (INR),-1
Data Scientist,-1,"Required Experience, Skills and Qualifications :
Basic understanding of statistics, linear algebra and calculus.

Good understanding of data structures.

Proficient in Python and should have worked on statistical packages

Good understanding of AI and ML technology

Working with big data sets; data extraction, data mining, visualization, storytelling

Comfortable working on both supervised and unsupervised machine learning problems.

Worked on (at-least one of) the specialized packages pertaining to textual data like nltk and image data like pil, opencv, etc.

Worked on deep learning frameworks like tensorflow, etc

Hands-on experience in dealing with text and/or image data

Knowledge of distributed and parallel processing frameworks like Spark.

Understanding of search platforms like Solr/Elastic Search.

Qualification : Bachelor of Computer Application Bachelor of Engineering/ Bachelor of Technology Master of Computer Application Masters of Engineering/ Masters of Technology
Working Days : 5 Days a Week ( to )
Job Nature : Full Time

Salary 15 Lac To 25 Lac P.A.
Industry IT Software - Application Programming / Maintenance
Work Experience 5 - 12 Years
Qualification Professional Degree

Key Skills

Data Science Data Analysis AI Python IT linear algebra calculus big data

Company Profile

Email ID getintouch@saffroncareers.in",-1,Saffron Consultancy Services,New Delhi,"Gurgaon, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Description :

Designation - Data Scientist

Exp - 1 year

Skills - Data Science & Machine Learning with Python or R

Previous experience in start-ups preferred Master’s or equivalent degree in Computer Science or Mathematics or Statistics, Applied Mathematics, or a related field with 1-5 yrs. experience or Bachelors's with 1-5 yrs. experience in data sciences

Location - Coimbatore

For more details contact: HR Uma Maheshwari - 8838702802

Job Types: Full-time, Walk-In

Experience:
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Secondary(10th Pass) (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Spectrum Digital Infocom,Coimbatore,-1,-1,-1,-1,-1,-1,-1,-1
Global Data Scientist,-1,"About Swiss Re

Swiss Re is one of the world’s leading providers of reinsurance, insurance and other forms of insurance-based risk transfer, working to make the world more resilient. We anticipate and manage a wide variety of risks, from natural catastrophes and climate change to cybercrime.

At Swiss Re we combine experience with creative thinking and cutting-edge expertise to create new opportunities and solutions for our clients. This is possible thanks to the collaboration of our 15,000 employees across the world.

We offer a flexible working environment where curious and adaptable people thrive. Are you interested in joining us?

About the Role

As Product Data Analyst, by using Data as the Foundation, you will work with clients to build balanced, healthy portfolios. You will be analyzing client data to determine the general health of a portfolio and potential loss drivers. This will also include incorporating exposure, claims, financial, community-level and other data to:
Understand patterns in cost, utilization and quality/dis-quality
Identify trends and changes over time.
Identify the cost drivers of the In Force portfolio (product, benefit, UW rules, diagnoses, procedures, physicians, hospitals and insured individuals that drive the majority of costs).
Identify opportunities to manage cost, utilization and/or quality and work in association with the regional data centers and Medical Operations Department to define potential interventions.
Define methodologies to measure the effectiveness of defined interventions.
Overview of Medical Re data repository platform.
Key Accountabilities:
Defining the business question to be answered with appropriate analytics models
Providing incident & problem management for analytics solutions
Generating insights from structured and unstructured data for Swiss Re's Clients and strategic initiatives (e.g., Big Data & Smart Analytics, create trending models for loss drivers, predictive models, implementing analytics solutions to solve business issues re products and claims and scale their usage.
Establish and maintain positive relationships with clients. Assist with communication of the analytical results to clients, Medical Pricing Team, Medical Operations and internal stakeholders. The communication will include preparation and presentation of results in graphic and tabular formats accompanied by data insights. Will need to liaise with the entire Medical team to identify potential solutions to the issues identified.
Work with Client Markets and Underwriting to ensure best in class service to our clients and to collaborate with the Medical Pricing team for Claims Data Analysis and interpretation. This will include feedback for future product development and pricing.
Suggest appropriate interventions to improve the client's overall portfolio experience.
Support the Global Medical Team in tendering for new business, in developing innovating products and in the promotion of SwissRe expertise globally.
Work closely together with the regional data centers to ensure the onboarding of new treaty data to the Medical Re data platform.
Provide regular feedback and suggestions for improving the efficiency of processes of the Med Re data platform and improve reporting functionalities.
Participate in Global Projects, sharing analytical insights and solutions Work closely together with Data regional data science and costing teams on global data analytics projects.
Educates the internal & community of the value of data analytics
About the Team

As the world's leading reinsurance company, we specialize in providing solutions to capital and risk management problems. We are an equal opportunity employer who combines financial strength with experience, knowledge and creative thought to exploit new opportunities in the interests of our clients, staff and shareholders. Our team contributes to these goals, as part of the Global Medical Products team, by collaborating with Client Markets to define and execute Swiss Re's strategy for this Line of Business. The team is also responsible for closely monitoring the portfolio performance and taking actions to improve the profitability of new and existing business.

About You
Formal qualification in data science, math, statistics, actuarial science or epidemiology.
Strong experience in the management of large, complex data sets.
Knowledge of medical insurance basics and terminology.
Ability to present to clients and sell this differentiated service.
Working knowledge of contemporary care management interventions/technologies including pharmaceutical management, provider networks, case management etc is highly desirable.
Strong experience to statistical tools such (SAS and/or R)
Comfortable with large data sets.
Experience in direct and/or reinsurance industry is highly desirable
Good management skills (line management and project management)
Good communication and negotiation skills
An aptitude for languages would be an advantage
Swiss Re",3.8,"Swiss Re
3.8",Bengaluru,"Zurich, Switzerland",10000+ employees,1863,Company - Public,Insurance Agencies & Brokerages,Insurance,₹500+ billion (INR),"Munich Re, Hannover RE, SCOR"
Senior Data Analyst - Business Insights,-1,"JOB TITLE: Senior Analyst - Business Insights

LOCATION: MUMBAI, INDIA

OUR STORY:

JioSaavn is South Asias leading music streaming service. We are over 200 entrepreneurs, across New York, California, Mumbai, Gurgaon, and Bangalore, who help music lovers access, discover, and listen to their favourite songs across languages and genres. In early 2018, a merger between JioMusic and Saavn was announced; creating a combined entity valued at over $1 billion.

We blend digital technology, data analysis (which we have affectionately coined Music Science), and a strong, fearless business acumen to reach all corners of the globe. Through partnerships with Apple, Google, Amazon, Facebook, Twitter and Shazam - to name a few - JioSaavn reaches more music fans across the world. Our award-winning mobile products, partnerships, innovations and thought leadership have been featured in some of the worlds leading publications, from The New York Times, to The Wall Street Journal, The Economic Times to Forbes, and many more. We are well-funded by some of the worlds most successful institutional investors and global media companies as well as a number of strategic individuals. Beyond investing, they are advisors and supporters of our vision, our passion, and our collective ability to deliver a revolutionary music experience as the leader in India.

OUR CULTURE:

At JioSaavn, we ignite passion and performance to work towards a collective goal: creating the perfect mobile entertainment ecosystem that delivers the best possible music experience to millions of listeners around the world. Our default mode is that of perpetual innovation. Together, we form a concerted rhythm that goes beyond borders. We don't just go with the flow, we create it.

JioSaavn offers a dynamic and unconventional work environment, full of fun wholesome experiences from in-office performances by some of the worlds most beloved musicians to opportunities for international travel. We believe creativity and technology blend together like sweet melodies. When you choose JioSaavn, you join a diverse world of high-calibre techies, artists, and inventors hailing from companies like Yahoo!, Twitter, LinkedIn, Google, Qualcomm, HBO, Microsoft, Flipkart, Amazon, Paytm, Quikr, MSN, and NDTV. We are one of the few digital companies to provide employment opportunities that meet the Silicon Valley benchmark right here in Mumbai! Figures, since weve got Silicon Valley covered, too.

Our value-based, people-first work culture is about empowering every individual in our global team to be catalysts for change in this dynamic digital world. Every day is an opportunity to bring your vision to life, and to expand, learn and grow. No idea is left unconsidered. No voice is left unheard.

With listeners speaking multiple languages in almost every country in the world, we like to think we have the most diverse user base on the planet. This has only been made possible because of the value we place on radical inclusivity in our offices across the globe. We believe different is wonderful, and what sets us apart is also what brings us closer. JioSaavn prides itself on being an equal opportunity employer. We have committed ourselves to creating a safe environment with fair and equal access and opportunities, sans discrimination. We encourage everyone to be open to experiences and perspectives beyond their normal; divergent thinkers create differentiated products, and even better music.

If our vibe matches with yours, we'd love to hear from you.

Role:

JioSaavn is seeking an analytically driven and open-minded individual to join our rapidly growing global team of entrepreneurs. The Business Insights team acts as a trusted business adviser to teams across the company, as well as to senior leadership. This team is responsible for analyzing high priority business challenges and for proposing solutions based on thorough quantitative analysis.

The Business Insights group is a part of the COOs team and the Senior Analyst will report directly to the Senior Manager of Business Insights.

Responsibilities:
The role will be an integral member of the Business Insights team and will be responsible for providing support and analysis across the breadth of work provided by the team
Examples of such responsibilities include:
Using a combination of Python and SQL to support data analysis on a variety of cross-functional projects
Creating and regularly updating data dashboards to help define and measure progress towards KPIs across key business focus areas
Identifying opportunities for continuous improvement and automation of tasks using Python and SQL where relevant
Identifying ways in which complex and ambiguous business problems can be solved in a systematic and objective manner with the help of data and market research
Analyzing internal and external data to uncover trends on user behavior and the industry as a whole, influencing product, content, and marketing roadmaps
Creating presentations for the executive team summarizing key insights and action items derived through robust research and analyses
Working closely with a number of departments across the company including Data Engineering, Product, Marketing, Strategy & Operations, and Content, to support data driven decision making
Preferred Qualifications:
3-4 years of experience working in a highly analytical environment providing data insights (Technology, Consulting, Banking or other relevant industry)
Exceptional data querying skills
3+ years experience working with SQL
3+ years experience working with Python for data analysis, visualization, and automation
1-2 years of experience with data visualization tools such as Tableau
Ability to effectively articulate complex ideas in simple and effective presentations to a diverse group of stakeholders
Extremely comfortable with Excel, PowerPoint / Keynote
Passion and deep understanding of the technology, media, and entertainment space
Ability to work collaboratively and build effective relationships across teams to solve and operationalize complex business problems.
An entrepreneurial, roll up your sleeves attitude and willingness to perform tasks with a range of difficulty from routine tasks to preparing analysis for senior management.
Effective in working autonomously to get things done and taking the initiative to anticipate needs of teams and senior management
Bachelors or higher degree in Statistics, Math, Computer Science, Engineering or other related quantitative field
BENEFITS AND PERKS:

At JioSaavn, we blur work and play, and you get all the perks of a global company. You will get to work with a dynamic group of entrepreneurs, who are delivering results and working zealously across time zones to make a difference in the way the world experiences music. We love what we do, and we think you will too.
Group Mediclaim
Fun Fridays
Flexible vacation policies
Free healthy (and unhealthy) lunches & snacks
JioSaavn-sponsored team outings
Powered by JazzHR",4.2,"Saavn
4.2",India,"New York, NY",201 to 500 employees,2007,Company - Private,Music Production & Distribution,Media,Unknown / Non-Applicable,-1
Senior Data Scientist - AWS Professional Services,-1,"Excited by using massive amounts of data to develop Machine Learning (ML) and Deep Learning (DL) models? Want to help the largest global enterprises derive business value through the adoption of Artificial Intelligence (AI)? Eager to learn from many different enterprises use cases of AWS ML and DL? Thrilled to be key part of Amazon, who has been investing in Machine Learning for decades, pioneering and shaping the worlds AI technology?
At Amazon Web Services (AWS), we are helping large enterprises build ML and DL models on the AWS Cloud. We are applying predictive technology to large volumes of data and against a wide spectrum of problems. Our Professional Services organization works together with our AWS customers to address their business needs using AI.

AWS Professional Services is a unique consulting team. We pride ourselves on being customer obsessed and highly focused on the AI enablement of our customers. If you have experience with AI, including building ML or DL models, wed like to have you join our team. You will get to work with an innovative company, with great teammates, and have a lot of fun helping our customers.

If you do not live in a market where we have an open Data Scientist position, please feel free to apply. Our Data Scientists can live in any location where we have a Professional Service office.

A successful candidate will be a person who enjoys diving deep into data, doing analysis, discovering root causes, and designing long-term solutions. It will be a person who likes to have fun, loves to learn, and wants to innovate in the world of AI. Major responsibilities include:
· Understand the customers business need and guide them to a solution using our AWS AI Services, AWS AI Platforms, AWS AI Frameworks, and AWS AI EC2 Instances .
· Assist customers by being able to deliver a ML / DL project from beginning to end, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models to deliver business impact to the organization.
· Use Deep Learning frameworks like MXNet, Caffe 2, Tensorflow, Theano, CNTK, and Keras to help our customers build DL models.
· Use SparkML and Amazon Machine Learning (AML) to help our customers build ML models.
· Work with our Professional Services Big Data consultants to analyze, extract, normalize, and label relevant data.
· Work with our Professional Services DevOps consultants to help our customers operationalize models after they are built.
· Assist customers with identifying model drift and retraining models.
· Research and implement novel ML and DL approaches, including using FPGA.

This role is open for Mumbai/Pune/Bangalore/Chennai/Hyderabad/Delhi/Pune.


Basic Qualifications

· A Bachelor or Masters Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.) or equivalent experience
· 10+ years of industry experience in predictive modeling, data science and analysis
· Previous experience in a ML or data scientist role and a track record of building ML or DL models
· Experience using Python and/or R
· Knowledge of SparkML
· Able to write production level code, which is well-written and explainable
· Experience using ML libraries, such as scikit-learn, caret, mlr, mllib
· Experience working with GPUs to develop models
· Experience handling terabyte size datasets
· Track record of diving into data to discover hidden patterns
· Familiarity with using data visualization tools
· Knowledge and experience of writing and tuning SQL
· Past and current experience writing and speaking about complex technical concepts to broad audiences in a simplified format
· Experience giving data presentations
· Extended travel to customer locations may be required to deliver professional services, as needed
· Strong written and verbal communication skills

Preferred Qualifications

·
· PhD in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.)
· 12+ years of industry experience in predictive modeling and analysis
· Good skills with programming languages, such as Java or C/C++
· Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
· Consulting experience and track record of helping customers with their AI needs
· Publications or presentation in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
· Experience with AWS technologies like Redshift, S3, EC2, Data Pipeline, & EMR
· Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customers organization
· Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment",4.2,"Amazon
4.2",India,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
DATA SCIENTIST,-1,"Employment: Full time.

Role: Data Scientist

Job Summary

We are looking for experienced data scientists with strong advanced analysis and machine learning model development experience. Data scientists will be working with a team of technical experts on the development of a scalable, real-time, big data analytics solutions with data visualizations leveraging the latest technologies. The ideal candidate will have a proven track record of solving large, complex big data challenges and developing machine learning models to address emerging cybersecurity requirements. Responsibilities will include the analysis of the data to uncover useful and valuable information and finally supporting the engineering team to build the results into the end product. You will be working with an experienced team of data scientists and technical experts, and be part of the Security, Risk, and Governance (SR&G) solutions Centers of Excellence (COE). This position is responsible for the design, architecture, development, and implementation of emerging Security and Operations use cases, and partner with R&D engineers to productize the same to support go-to-market initiatives.

Responsibilities and Duties
Collaborate with a multi-disciplinary team of engineers and analysts on a wide range of cybersecurity problems.
Bring analytical rigour and statistical methods to the challenges of measuring quality, improving security products, and understanding the behaviour of end-users, computer systems, and network devices.
Build innovative predictive analytics and data science solutions for a myriad of cybersecurity problems.
Multi-task and work independently
‘Think like an adversary’
Identify and articulate risks and remediation in a relevant and approachable manner with both technical and non-technical audiences.
Identifies data sources, collects, transforms and prepares large amounts of data for analysis. May also develop tools to help the data collection process as needed.
Uses appropriate methods, tools, and algorithms to analyze the data and create an implementation plan from the business problem.
Validates the results of the data analysis to avoid errors.
Interprets results and identifies value form the analysis to help solve the business problems. Works with the business or customer and provides guidance on risks and limitations.
Monitors and continuously improves the data sources, usability and data
mining results.

Required Experience, Skills and Qualifications Education and Experience
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field
3-5 years of working experience in machine learning and data science projects;
2-3 years of experience in working with large scale production data sets
Good understanding of the foundations of machine learning methods
Exceptional coding skills in SQL, and Python or R
Excellent communication skills
Knowledge and Skills

Basic Qualification:
Experience with deep learning methods, models and frameworks
Familiarity with multiple programming and scripting languages (such as Java, Javascript, C/C++, Perl, etc.)
Familiarity with data visualization tools
Experience with passive and active measurement techniques
Experience with applying statistical modelling, machine learning and data mining algorithms to business problems.
A profound understanding of big data systems
Must have:
Background in statistics
Linux System knowledge as user and administrator
Experience with Vertica or other column store databases is a plus
Experience in cybersecurity, network data
Knowledge of networking concepts and devices (Firewalls, Routers, Switches,
and Load Balancers)
Knowledge of network and web related protocols (such as TCP/IP, UDP, IPSEC,
HTTP, HTTPS, DNS, SSH, routing protocols)",-1,Inference Labs,Bengaluru,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientists,-1,"CAREERS

Data Scientists

Bengaluru, India
JOB DESCRIPTION

As a Data Scientist with Tredence, you will play a key role in translating data into insights for our clients. You will design, develop and implement processes and framework that will help our clients make sense of the data they generate, and consume the insights to make informed decisions.
THE IDEAL CANDIDATE WILL

Have the ability to handle structured /unstructured data and have prior experience in loading, validating and cleaning various types of data.
Have very good understanding of data structures and algorithms.
Have excellent coding skills in one or more of the following languages: Python, Java, C++ or R
Have thorough understanding of one or more of the following: Machine Learning algorithms, Natural Language Processing techniques, and Information Retrieval techniques
Have the ability to apply these algorithms in a professional setting.
Be accountable for measuring and optimizing the quality of algorithms.
Have good background in Math and Statistics.
Have ability to identify opportunities where data science techniques can be applied to solve business problems.
Take ownership of the end to end system from Problem statement to Solution Delivery
Preferred Skills
Experience working with Hadoop/AzureML/Hive/H2O would be an added advantage.
Experience with deep learning techniques like Theano, Torch and TensorFlow is preferred.
ELIGIBILITY CRITERIA

BE/B. Tech/MS degree in Computer Science or related quantitative field with 2-8 years or relevant experience in a team building world class applications in the areas of Predictive Analytics and Data Science.
Send your CV to careers@tredence.com",3.7,"Tredence
3.7",Bengaluru,"San Jose, CA",501 to 1000 employees,2013,Company - Private,Consulting,Business Services,₹1 to ₹5 billion (INR),-1
Data Scientist,-1,"3- 6 Years – Hyderabad, Gurgaon
Job Description

Big Data Eco System like Hadoop and Spark and Scala ML

Machine learning models. Predictive Analytics .

Exp Range: 3 Years to 6 Years

Salary: Open

Industry: IT-Software / Software Services

Functional Area: Analytics & Business Intelligence

Role Category: Analytics & BI

Role: Data Analyst

Keyskills:
Hadoop, Spark, SCALA, BigData, Machine Learning, Predictive Analytics.",-1,AGUILASS,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Driving Infinite Possibilities Within A Diversified, Global Organization


When you join Honeywell, you become a member of our global team of thinkers, innovators, dreamers and doers who make the things that make the future. That means changing the way we fly, fueling jets in an eco-friendly way, keeping buildings smart and safe and even making it possible to breathe on Mars.
Working at Honeywell isnt just about developing cool things. Thats why all our employees enjoy access to dynamic career opportunities across different fields and industries.

Are you ready to help us make the future?

Join a company that is transforming from a traditional industrial company to a contemporary digital industrial business, harnessing the power of cloud, big data, analytics, Internet of Things, and design thinking.

You will lead change that brings value to our customers, partners, and shareholders through the creation of innovative software and data-driven products and services. You will work with customers to identify their high value business questions and work through their data to search for answers. You will be responsible for working within Honeywell to identify opportunities for new growth and efficiency based on data analysis.

JOB ACTIVITIES

As a Data Engineer, you will be part of a team that delivers contemporary analytics solutions for the Data Management & Analytics function at Honeywell. You will build strong relationships with leadership to effectively deliver contemporary data analytics solutions and contribute directly to business success. You will develop solutions on various Database systems viz. Hive, Hadoop, SnowFlake, etc.

You will identify and implement process improvements and if you dont like to do the same thing twice, you will automate where possible. You are always keeping an eye on scalability, optimization, and process. You have worked with Big Data before, IoT data, SQL, Azure, AWS, SnowFlake

You will work on a team including scrum masters, product owners, data architects, data engineers, data scientists and DevOps. You and your team collaborate to build products from the idea phase through launch and beyond. The software you write makes it to production in sprints. Your team will be working on creating a new platform using your experience of APIs, microservices, and platform development.

CORPIT2020

YOU MUST HAVE


· Bachelor's degree in Computer Science, Engineering, Applied Mathematics

· 4 years of data engineering experience

· 2 years in supply chain, materials planning, logistics/distribution, procurement, finance and/or order management.

WE VALUE


· Should have developed and deployed complex big data ingestion jobs in Talend/Informatica BDM bringing prototypes to production on Hadoop/NoSQL/MPP platforms.

· Should have minimum 4 years of hands on experience with MapReduce, Pig/Hive, Spark, etc. and automation of data flow using NiFi and Airflow/Oozie.

· Minimum 3 years of experience in developing and building applications to process very large amounts of data (structured and unstructured), including streaming real-time data (Spark, R/Python, Scala, Kafka, Spark streaming or other such tools).

· Minimum 2 years of experience in working with at least one NoSQL system (HBase, Cassandra, MongoDB etc.). In-depth knowledge of schema design to effectively tackle the requirement.

· Experience in writing complex SQL statements

· Experience in working with cloud based deployments. Understanding of containers & container orchestration (Swarm or Kubernetes).

· Hands on experience in Cloudera, Hortonworks and/or Cloud (AWS EMR, Azure Data Lake Storage) based Hadoop distributions.

· Good understanding of branching, build, deployment, CI/CD methodologies such as Octopus and Bamboo

· Experience working with in Agile Methodologies and Scrum Knowledge of software best practices, like Test-Driven Development (TDD)

· Effective communication skills and succinct articulation

· Experience in building advanced analytics solutions with data from enterprise systems like ERPs, CRMs, Marketing tools etc.

· Experience with dimensional modeling, data warehousing and data mining

· Experience with machine learning solutions and data science methods promotion

· Database performance management and API development

· Technology upgrade oversight

· Experience with visualization software, Tableau preferred.

· Understanding of best-in-class model and data configuration and development processes

· Experience working with remote and global teams and cross team collaboration

· Consistently makes timely decisions even in the face of complexity, balancing systematic analysis with decisiveness

Additional Information
JOB ID: HRD94048
Category: Information Technology
Location: Devarabisanahalli Village, KR Varturhobli,,East Taluk - Phase I,Bangalore,KARNATAKA,560103,India
Exempt
Business Services",3.8,"Honeywell
3.8",Bengaluru,"Charlotte, NC",10000+ employees,1885,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"GE, Johnson Controls, United Technologies"
Data Engineering - Senior Associate,-1,"Data Engineering – Job Description Location: Bangalore

Responsibilities

• You will be responsible for maintaining large-scale data processing systems, data warehouses and data lakes to help manage the ever-growing information needs of our clients. • Your technical challenge will be to test and optimize systems that ingest, aggregate and visualize terabytes of data that solve business relevant problems of our customers.

• Work with business users to refine analytical requirements for quantitative data (view-through, clickstream, acquisition, product usage, transactions), qualitative data (survey, market research) and unstructured data (blog, social network). • Designing and developing schema definitions and support data warehouse/mart to enable integration of disparate data sources from within Client environment and outside, aggregate it and make it available for analysis. • As a key member of the team drive adoption of new technologies, tools, and process improvements to build world class analytical capabilities for web analytics, optimization, experimentation and personalization. • Develop high performance, scalable implementations of the statistical/machine learning models developed by our Data Scientists.

Qualifications

• BS/MS in computer science or equivalent work experience. • 6 to 8 years’ experience in developing Data Models, DB schemas, creating ETLs, and familiar with Hadoop Ecosystem • 2+ years experience with data ingestion through batch and streaming methodologies using open source or public tools like Kafka, Airflow, Azure Data Factory etc..

• Experience with databases both RDBMS and NoSQL (Vertica, Netezza or Oracle and AWS data services tech). Through understanding of SQL (any variant) • Good understanding of Data Ware House methodologies. • Hands on experience in any of the programming languages (Shell scripting, Python, Scala, Java, etc)

Good to have

• Knowledge of Big Data ecosystem like Hadoop M/R, Pig and Hive is a strong plus. • Understanding of IN memory distributed computing frameworks like Spark (and/or DataBricks) and its parameter tuning, writing optimized queries in Spark • Scheduling and Monitoring of Hadoop and Spark jobs • Good understanding of any reporting tools such as Tableau, Pentaho or Jasper is a big plus. • Experience in design, development and deployment of one or more tools - ETL (Informatica, OWB, ODI), reporting (Business Objects, QlikView, Tableau)",4.7,"TheMathCompany
4.7",Bengaluru,"Bengaluru, India",201 to 500 employees,2016,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Data Analyst - Business Insights,-1,"JOB TITLE: DATA ANALYST - BUSINESS INSIGHTS
LOCATION: MUMBAI, INDIA

OUR STORY:

JioSaavn is South Asias leading music streaming service. We are over 200 entrepreneurs, across New York, California, Mumbai, Gurgaon, and Bangalore, who help music lovers access, discover, and listen to their favourite songs across languages and genres. In early 2018, a merger between JioMusic and Saavn was announced; creating a combined entity valued at over $1 billion.

We blend digital technology, data analysis (which we have affectionately coined Music Science), and a strong, fearless business acumen to reach all corners of the globe. Through partnerships with Apple, Google, Amazon, Facebook, Twitter and Shazam - to name a few - JioSaavn reaches more music fans across the world. Our award-winning mobile products, partnerships, innovations and thought leadership have been featured in some of the worlds leading publications, from The New York Times, to The Wall Street Journal, The Economic Times to Forbes, and many more. We are well-funded by some of the worlds most successful institutional investors and global media companies as well as a number of strategic individuals. Beyond investing, they are advisors and supporters of our vision, our passion, and our collective ability to deliver a revolutionary music experience as the leader in India.

OUR CULTURE:

At JioSaavn, we ignite passion and performance to work towards a collective goal: creating the perfect mobile entertainment ecosystem that delivers the best possible music experience to millions of listeners around the world. Our default mode is that of perpetual innovation. Together, we form a concerted rhythm that goes beyond borders. We don't just go with the flow, we create it.

JioSaavn offers a dynamic and unconventional work environment, full of fun wholesome experiences from in-office performances by some of the worlds most beloved musicians to opportunities for international travel. We believe creativity and technology blend together like sweet melodies. When you choose JioSaavn, you join a diverse world of high-calibre techies, artists, and inventors hailing from companies like Yahoo!, Twitter, LinkedIn, Google, Qualcomm, HBO, Microsoft, Flipkart, Amazon, Paytm, Quikr, MSN, and NDTV. We are one of the few digital companies to provide employment opportunities that meet the Silicon Valley benchmark right here in Mumbai! Figures, since weve got Silicon Valley covered, too.

Our value-based, people-first work culture is about empowering every individual in our global team to be catalysts for change in this dynamic digital world. Every day is an opportunity to bring your vision to life, and to expand, learn and grow. No idea is left unconsidered. No voice is left unheard.

With listeners speaking multiple languages in almost every country in the world, we like to think we have the most diverse user base on the planet. This has only been made possible because of the value we place on radical inclusivity in our offices across the globe. We believe different is wonderful, and what sets us apart is also what brings us closer. JioSaavn prides itself on being an equal opportunity employer. We have committed ourselves to creating a safe environment with fair and equal access and opportunities, sans discrimination. We encourage everyone to be open to experiences and perspectives beyond their normal; divergent thinkers create differentiated products, and even better music.

If our vibe matches with yours, we'd love to hear from you.

Responsibilities:
The role will be an integral member of the Business Insights team and will be responsible for providing support and analysis across the breadth of work provided by the team
Examples of such responsibilities include:
Using a combination of Python and SQL to support data analysis on a variety of cross-functional projects
Creating and regularly updating data dashboards to help define and measure progress towards KPIs across key business focus areas
Identifying opportunities for continuous improvement and automation of tasks using Python and SQL where relevant
Identifying ways in which complex and ambiguous business problems can be solved in a systematic and objective manner with the help of data and market research
Analyzing internal and external data to uncover trends on user behaviour and the industry as a whole, influencing product, content, and marketing roadmaps
Creating presentations for the executive team summarizing key insights and action items derived through robust research and analyses
Working closely with a number of departments across the company including Data Engineering, Product, Marketing, Strategy & Operations, and Content, to support data driven decision making
Preferred Qualifications:
1-2 years of experience working in a highly analytical environment providing data insights (Technology, Consulting, Banking or other relevant industry)
Exceptional data querying skills
2+ years experience working with SQL
2+ years experience working with Python for data analysis, visualization, and automation
1-2 years of experience with data visualization tools such as Tableau
Ability to effectively articulate complex ideas in simple and effective presentations to a diverse group of stakeholders
Extremely comfortable with Excel, PowerPoint / Keynote
Passion and deep understanding of the technology, media, and entertainment space
Ability to work collaboratively and build effective relationships across teams to solve and operationalize complex business problems.
An entrepreneurial, roll up your sleeves attitude and willingness to perform tasks with a range of difficulty from routine tasks to preparing analysis for senior management.
Effective in working autonomously to get things done and taking the initiative to anticipate needs of teams and senior management
Bachelors or higher degree in Statistics, Math, Computer Science, Engineering or other related quantitative field
BENEFITS AND PERKS:

At JioSaavn, we blur work and play, and you get all the perks of a global company. You will get to work with a dynamic group of entrepreneurs, who are delivering results and working zealously across time zones to make a difference in the way the world experiences music. We love what we do, and we think you will too.
Group Mediclaim
Fun Fridays
Flexible vacation policies
Free healthy (and unhealthy) lunches & snacks
JioSaavn-sponsored team outings
Powered by JazzHR",4.2,"Saavn
4.2",Mumbai,"New York, NY",201 to 500 employees,2007,Company - Private,Music Production & Distribution,Media,Unknown / Non-Applicable,-1
Data Scientist (4+ Years) for an Online Ecommerce Company,-1,"We are looking for a “Data Scientist” for one of our esteemed Clients for Bangalore ,India Location.

Job Requirement:
Understand problem statement/product requirement.
Work with Data Engineers to get required data.
Analyse the data and identify statistical/machine learning models.
Build POCs to demonstrate success/failure of the hypotheses.
Post that, work with ML and Data Engineers to implement your models on existing production systems and big data platform.

Must Have:
Qualification – Masters or Ph.D. in Statistics, Math, CompSci, Econ, Physics, Engineering or related scientific disciplines; preferably from a premier scientific institute like ISI or IISC.
Work experience – At least 4 years in Tech, with 2 years as a Data Scientist or equivalent position.
Statistical knowledge – Proven experience in statistical methods like Markov Models, Stochastic models, Bayesian Models, Classification Models, Cluster Analysis, Multivariate Stats, Regression Models.
Machine Learning – Prior work experience in one or more of these knowledge areas (domain agnostic): Price Modelling, Demand Forecasting, Recommender Systems, User Profiling, Fraud Detectors.
Technologies – Proficiency in Python (must have) and any other prog. language; Specific libraries may include – TensorFlow, Keras, Torch, Caffe, Theano, etc;
Experience with Kaggle is a bonus.",3.7,"zyoin
3.7",Bengaluru,"BENGALURU, India",51 to 200 employees,2005,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Junior Data Scientist,-1,"Junior Data Scientist
Job Description


The ITS Data Scientist is responsible for integrating business, information, and technology into analytical models that help drive business performance and competitive advantage and providing the business with answers to questions. The role collaborates with Business, IT Functional Engineers and Platform architects to create value from varied data sources. Creating value from data requires a range of talents: from data integration and preparation, to architecting specialized computing/database environments, to data mining and intelligent algorithm development.

Hiring Requirements

Job Details

Development of analytics to help drive competitive advantage from data with accountabilities across multiple functional and technical areas with wide range of complexity. The Data Scientist must understand medium/complex data types (integrate, manipulate, prepare), know advanced analytics (appropriate techniques, interpret data and diagnose models, meet business requirements), and focus on the business outcomes (goals, constraints, decisions while communicating outcomes via presentations). Develop models and algorithms that drive innovation throughout the organization. This may include marketing, supply chain, inventory planning and deployment, network planning, order routing, and order fulfillment and delivery Conduct advanced statistical analysis to provide actionable insights, identify trends, and measure performance Build learning systems that monitor data flows and react to changes in customer preferences, network constraints, and business objectives Collaborate with engineers to implement and deploy scalable solutions Provide thought leadership by researching best practices, conducting experiments, and collaborating with industry leaders Partners as a bridge between the business and the information management teams to make sure that the solution fits within the data management principals Coordinates data science implementations while leading design variances based upon business needs while ensuring artifacts and repositories are documented Manages engagements with vendors as they relate to evaluation, design and delivery of business capabilities Contributes to the evaluation and selection of software product standards Leader in industry representation, policy formation, User Groups, and strategic direction

Mentors others to complete Continuous Improvement (CI) initiatives; consults and shares knowledge across org; awareness of industry trends.

Education required/ preferred:
MS/PhD in computer science, statistics, or operations research or related technical discipline.
Experience:
2-3+ years of continuous experience in software engineering, software development, solution architecture
Knowledge of machine learning, statistics, optimization or related field
Experience with R, Python, Matlab is required
Experience building machine learning application in areas like time series forecasting, classification models, clustering models, multivariate regression models etc
Experience in Microsoft Azure Stack in the Cloud with focus on Data Factory, Data Bricks, BLOBs, Data Lake Storage, ML Studio, Azure Analysis Services, Azure Data Warehouse, Power BI etc
Experience working with large data sets and distributed computing tools a plus (Map/Reduce, Hadoop, Hive, Spark, Python, R, Gurobi, MySQL, etc.)
Excellent written and verbal communication skills along with strong desire to work in cross functional teams
Consumer products experience in an online and/or retail/manufacturing environment is preferred
Possess strong leadership skills and exhibit creative thinking to be able to come up with inventive solutions to solve business challenges
Provide thought leadership while keeping up with industry trends and disseminating information across the organization
Experience working with blended teams consisting of employees, vendors, and consultants with both onshore and offshore resources
Strong Technical leadership of advanced analytics teams and vendors
Extensive experience collaborating with Enterprise Architects and infrastructure engineers to identify, design, and implement highly complex, end-to-end solutions
Cultivates networking opportunities within the organization
Broad range of business and IT experiences; Has achieved technical and/or business certification(s).
Skills/Competencies:

Communication: Data scientists must communicate effectively up and down the data supply chain: first, to obtain access to the data they require; second, to work with those who understand the business meaning behind the data; and third, to articulate findings and implications to business leaders in language they understand. A data scientist must be able to use data to tell stories. Key components of these communication skills are those of persuasion and expectation management. The ability to insert themselves into core business functions and assert their ideas is therefore critical.

Collaboration: Working directly for business leaders and side-by-side with business unit personnel, they need to shed the introverted statistician stereotype. Increasingly, business professionals require access to analytic techniques beyond basic math and must be able to rely on the data scientist to work closely with them. The data scientist enables the broad consumerization of derivative result sets and analytics (if not the raw data). The data scientist must have the ability to juggle competing priorities and pressures.

Leadership. The role of the data scientist can incorporate data oversight responsibilities including directing the efforts of teams of consultant statisticians, data administration and integration professionals, and data visualization, reporting, and application integration developers.

Creativity. The work of the data scientist is very much an innovation-oriented exercise in solving open-ended conundrums. Data scientists are tasked with finding opportunities to optimize, expand or transform the business through the lens of information. Moreover, data scientists must be creative in sourcing data, modeling problems and employing a range of analytic techniques.

Discipline. Although creativity is critical, data scientists must remember that ""science"" is part of their directive. This means following established scientific methods, employing legitimate techniques, using valid data and embracing causality. Scientific methods demand that questions are well-defined, true data (observations) is collected, and hypotheses are formed, investigative methods are selected, data is analyzed and interpreted with yielding conclusions, and results are formally communicated and tested. Although rigid methodology is recommended, results perfection is not. Business opportunity costs in a fast-paced marketplace are too high to spend excessive time achieving incrementally better analyses. However, a data scientist just as any good statistician or other analytics professional must understand the differences between correlation and causality and between incidental and insightful patterns.

Passion: An obsession for information, solving insurmountable problems and finding unique ways to accelerate the business.

Consultancy: Manages provision of specialist knowledge over a range of topics in data science including the role of IT in the business; in own areas of expertise provides advice and guidance influencing the effectiveness of the organizations business processes.

Data Design: Controls analytics data design practice within the enterprise. Influences industry-based models for the development of new technology applications. Develops effective implementation and procurement strategies, consistent with business needs.

Data Analysis: Sets standards for advanced analytics tool usage and techniques, advises on their application, and ensures compliance. Manages the investigation of corporate data requirements, and co-ordinates the application of data analysis and analytics techniques, based upon a detailed understanding of the corporate information requirements, in order to establish, modify or maintain analytical models and their associated components.

Autonomy: Has authority and responsibility for all aspects of data science, including policy formation and application. Is fully accountable for actions taken and decisions made, both by self and subordinates.

Influence: Makes decisions critical to organizational success. Influences developments within the IT industry at the highest levels. Advances the knowledge and/or exploitation of IT within one or more organizations. Develops long-term strategic relationships with customers, partners, industry leaders and government.

Complexity: Performs highly complex work activities covering technical, financial and quality aspects. Contributes to the formulation and implementation of IT strategy. Creatively applies a wide range of technical and/or management principles.

Business Skills Absorbs complex technical information and communicates effectively at all levels to both technical and non-technical audiences. Assesses and evaluates risk. Understands the implications of new technologies. Demonstrates clear leadership and the ability to influence and persuade. Has a broad understanding of all aspects of IT and deep understanding of own specialism(s). Understands and communicates the role and impact of IT in the employing organization and promotes compliance with relevant legislation. Takes the initiative to keep both own and subordinates' skills up to date and to maintain an awareness of developments in the IT industry.

Global VISA and Relocation Specifications:
K-C requires that an employee have authorization to work in the country in which the role is based. In the event an applicant does not have current work authorization, K-C will determine, in its sole discretion, whether to sponsor an individual for work authorization. However, based on immigration requirements, not all roles are suitable for sponsorship.
This role is available for local candidates already authorized to work in the roles country only. K-C will not provide relocation support for this role.
Primary Location
IT Centre Bengaluru GDTC
Additional Locations
Worker Type
Employee
Worker Sub-Type
Regular
Time Type
Full time",3.9,"Kimberly-Clark Corporation
3.9",Bengaluru,"Irving, TX",10000+ employees,1872,Company - Public,Consumer Products Manufacturing,Manufacturing,₹500+ billion (INR),"Procter & Gamble, Georgia-Pacific, Unilever"
"Sr Data Scientist (Data Analysis, Machine Learning)",-1,"What's the role?


At HERE Technologies in Automotive Product Engineering organization, we are looking for highly skilled, self-motivated, Sr/Lead Data Scientist who is passionate about innovating and developing machine learning and data analytics solutions to build our industry-leading map. We provide the opportunity to collaborate with an energetic and dedicated team that works on cutting-edge technology to create tools and services. The candidate will work with researchers, developers, architects, IT to develop, deploy, and maintain applications in multiple environments.

What You’ll Get:
Challenging problems to solve
Opportunities to learn cool new things
Work that makes a difference in the world
Freedom to decide how to perform your work
Variety in the types of projects
Feedback so you will know how well you are doing
Collaborative, Supportive Colleagues
Responsibilities:
Help design and build the next iteration of process automation in HERE Content Engineering employing a highly scalable Big Data infrastructure and machine learning as applied to global-scale digital map-making.
Build and test analytic and statistical models to improve a wide variety of both internal data-driven processes for map-making data decisions and system control needs.
Act as an expert and evangelist in areas of data analysis, machine learning, statistics, and predictive analysis and modeling.
Function as a predictive modeling or application team lead.
Who are you?
MS or PhD in a discipline such as Statistics, Applied Mathematics, Computer Science, Data Science, or others with an emphasis or thesis work on one or more of the following areas: statistics/science/engineering, data analysis, machine learning, computational geometry, and image processing.• 5+ years related, professional experience.• Knowledge of data mining and analytic methods such as regression, classification, clustering, association rules, decision trees, Bayesian network analysis, etc. expert-level knowledge in one or more of these areas.• Proficiency with a statistical analysis package and associated scripting language such as Python, C++, R, Matlab, SAS, etc. • Programming experience with SQL, shell script, Python, etc. • Knowledge of and ideally some experience with Cloud platform such as AWS, and the tools such as Pig, Hive, etc., for working with big data in Hadoop and/or Spark for data extraction and data prep for analysis.• Experience with and demonstrated capability to effectively interact with both internal and external customer executives, technical and non-technical to explain uses and value of predictive systems and techniques. • Demonstrated proficiency with understanding, specifying and explaining predictive modeling solutions and organizing teams of other data scientists and engineers to execute projects delivering those solutions.Preferred Qualifications: • Development experience with C++/Python/Shell Script• Development experience with Docker• Development experience with GIS data• Development experience with Relational Database/ NoSQL Database""

What we Offer

We will support you in delivering your day to day tasks and achieving your personal goals and develop your skills. Personal development is highly encouraged at HERE. You can take different courses and trainings at our online University and join cross-functional team projects within our Talent Platform. Our office is located with easy access by public transportation options. So, what are you waiting for? Apply now and make HERE your destination. We are just getting started...!

HERE is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, age, gender identity, sexual orientation, marital status, parental status, religion, sex, national origin, disability, veteran status, and other legally protected characteristics.

Make HERE your destination, we are just getting started! Apply now!
Who are we?


Ever checked in somewhere on social media? Ever tracked your online orders? You might be using HERE Technologies every single day without even realizing it. You can find us everywhere: in vehicles, smartphones, drones or third-party apps. We believe that with the right people, we will continue to be a game-changer in the technology industry and improve the daily lives of people around the world. Find out more by clicking the video below or going HERE.",3.7,"HERE Technologies
3.7",Mumbai,"Amsterdam, Netherlands",5001 to 10000 employees,1984,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Google, TomTom, Apple"
Data Scientists,-1,"Our Data Scientists are quantitative analysts who can extract meaningful insights from customer data, and leverage predictive models to optimize business performance. They support Risk management, Marketing, Capital Markets, Operations and Finance teams. This is a strategic role that sits at the heart of value creation by turning data into a long term competitive advantage.

As a Senior Data Scientist you will...

Drive the evolution of best in class Channel Analytics by:
Working with Tech & Data teams to define requirements and review solution builds
Applying insights from customer response data to build response and targeting models
Building Attribution Models and optimising offline and online Marketing Mix to drive growth
Developing and applying real time links between spend across channels and response patterns
Working with Tech and Operational teams to ensure identified wins are delivered
Managing and mentoring direct and indirect reports to deliver significant increases in productivity
Deliver cutting edge models using the latest techniques and upskill the team: Use advanced statistical analysis to design testing and predictive models whilst creating and improving on best practices to be used across the Funding Circle analytics community
Drive thought leadership across the business: Recommend optimal business strategies based on historical performance, predictive analytics and scenario analysis
Build global frameworks that are scalable across markets and help to drive business outcomes & portfolio performance
Work closely with partner teams across business and risk to ensure analytical outputs meet stakeholder expectations
Communicate effectively analytical outcomes to wide variety of internal and external constituents including senior stakeholders Up to 20% travel
Demonstrable strong Machine learning/AI experience along with proficiency in analytical tools like R and Python, Excel VBA, Tableau, SQL
Demonstrates strong knowledge of data architecture, modelling techniques, consumer behaviour patterns and the key drivers of marketing or credit performance optimization
Has exceptional analytical skills with an advanced degree in a quantitative field like mathematics, physics, computer science, statistics, economics, econometrics etc
Have strong experience in a channel or product analytics role in a major digital or financial services organization with demonstrated track record of data science delivery in channel analytics, marketing analytics and/or risk analytics
Possesses strong interpersonal skills and the ability to communicate effectively to technical and non-technical audiences
Identifies with our mission, “to build a better financial world”
What You Need for this Position

You should have knowledge of:
Python
Excel VBA
Tableau
SQL
Risk management
Marketing
Capital Markets
Operations
Finance teams.
Aditional
No. of Positions
Education level
Career level
Experienced",4.8,"Bloom Consulting Services
4.8",Bengaluru,"Nagpur, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
Tech Lead - Data Scientist (NLP),-1,"AI team at Ultria is working on state of the art Natural Language Processing technologies including document structure detection, domain specific neural embeddings, deep neural network architectures for extraction and classification tasks etc. We are looking for a passionate data scientist to develop new statistical models for delivering high-quality NLP products.

RESPONSIBILITIES:
Identify new opportunities to apply Machine Learning to different parts of the product
Develop advanced algorithms to solve problems of high dimensionality in a computationally efficient and statistically effective manner
Have responsibility for the creation and development of our Text Analytics strategy and software
Take end to end ownership of Machine Learning products
Partner with other teams such as Data, Design and Product to collaborate on projects across the company
Work with the engineering management team to develop new initiatives and improve existing processes across the entire engineering team
Implement small and large scale projects in Advanced Analytics to help derive business insights for measurable success
Evaluate emerging datasets and technologies that may contribute to our products
Requirements

3 -7 years of strong Python development experience
3+ years of experience in Machine Learning/Deep Learning, specifically in NLP and text analytics domain including:
Extracting, cleaning and embedding text data
Text classification
Entity extraction/NER
Text summarization
Similarity and sentiment analysis
Topic modelling
Research experience in machine learning or natural language processing
Experience in deploying ML projects in production environment
Strong statistical analysis skills and demonstrated experience in deriving insights from unstructured data
Ability to run experiments scientifically and analyze results
Good understanding of ML tools/libraries like: Tensorflow, Keras, Pandas, Spacy, Pytorch, NLTK, SkLearn etc
Knowledge of big data technologies like Hadoop, Hive, Scala or Spark is preferred
Strong collaborative mindset
Excellent critical thinking and problem solving skills
Benefits

About Ultria

Ultria offers end-to-end, SaaS-deployed, Contract Lifecycle Management solution for the Enterprise—Ultria CLM. It is a market-proven solution with a legacy of successful deployments over more than seven years. With a workflow based authoring and approval tool, and a comprehensive repository of contracts and clauses, Ultria CLM helps companies across the spectrum derive greater value from their contracts. By connecting with eSignature and CRM solutions, Ultria CLM seamlessly streamlines the quote to contract conversion process. Its post-signoff contract management capabilities empower the enterprise to extract the maximum value out of contracts, mitigate risks, and ensure regulatory compliance.

Our Products are built around an intuitive user experience, leveraging a comprehensive knowledge base, robust Artificial Intelligence technology, encapsulates industry's best-of-breed processes and methodologies.

Several of Fortune 500 companies have chosen Ultria solutions for the following reasons:

In-depth industry and domain expertise with a robust implementation methodology
Ability to ensure semantic and structural data integrity and quality
End-to-end solution for Data Governance renowned by leading market Analysts

To know more, you can visit our website: www.ultria.com",4.2,"Ultria
4.2",Bengaluru,"Princeton, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"Position Title
Senior Data Scientist

08-May-2020

Job ID
295408BR

Job Description
20 petabytes of data across 30 data domain across the whole bio-pharma value chain waiting for you to unlock the next breakthrough in medicine.

Your responsibilities include, but are not limited to:
•Contribute to the overall Novartis Data science implementation strategy & independently lead data science and AI work in collaboration with globally dispersed internal stakeholders and cross-functional teams to solve critical business problems, drive operational efficiencies, and deliver successfully on high visibility strategic initiatives.
•Evangelize the use of analytical decision-making across Novartis in research, development, commercial, manufacturing and support functions including but not limited to: Customer Segmentation & Targeting, Event Prediction, Propensity Modelling, Churn Modelling, Customer Lifetime Value Estimation, Forecasting, Recommender Systems, Modelling Response to Incentives, Marketing Mix Optimization, and Price Optimization.
•Understands life sciences data sources including sales, contracting, promotions, social media, patient claims, clinical trials, and Real World Evidence & Defines right choices from a breadth of tools, data sources and analytical techniques to Develops and executes roadmap for delivery efficiency, enabling creation of automated product suites for repeatedly refreshing analysis and generating holistic insights.
•Acts as an Chief evangelist & catalyst for innovation in BI & Analytics & Presents analytical content concisely and effectively to non-technical audiences and influences non-analytical business leaders to drive major strategic decisions basis analytical inputs & Solutions / recommendations to business users.
•Project manages critical initiatives: plans proactively, anticipates and actively manages change, sets stakeholder expectations as required, identifies operational risks and independently drives issues to resolution, balances multiple priorities and minimizes surprise escalations
•Identifies learning needs & defines tracks for reading and explorations in order to enable continuous learning and keep abreast of latest developments in the field, which will grooms Data Scientists, Analyst, Subject Matter Experts, & mentors associates for higher responsibilities.
•Presents and publishes articles in conferences and academic institutions of repute and serves as an ambassador for promoting Novartis Data Sciences brand & Supports external branding of Novartis as a leader in the field of AI/ML and advanced analytics.
https://www.youtube-nocookie.com/embed/Mo1vwtVPVA0

Minimum requirements
•Masters in a quantitative discipline, Ph.D. highly preferred (e.g. Applied Mathematics, Computer Science, bioinformatics, epidemiology and Statistics.
•10+ years of relevant experience in Data Science, with at least 2 years in Pharma/Healthcare.
•Cross-industry experience highly preferred.
•2 plus years of international experience working with Global teams
Why consider Novartis?
799 million. That’s how many lives our products touched in 2019. And while we’re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people’s lives?

We believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you’re given opportunities to explore the power of digital and data. Where you’re empowered to risk failure by taking smart risks, and where you’re surrounded by people who share your determination to tackle the world’s toughest medical challenges.

Imagine what you could do at Novartis!
Commitment to Diversity & Inclusion:
Novartis embraces diversity, equal opportunity and inclusion. We are committed to building diverse teams, representative of the patients and communities we serve, and we strive to create an inclusive workplace that cultivates bold innovation through collaboration, and empowers our people to unleash their full potential.

Join our Novartis Network: If this role is not suitable to your experience or career goals but you wish to stay connected to learn more about Novartis and our career opportunities, join the Novartis Network here: https://talentnetwork.novartis.com/network

Job Type
Full Time

Country
India

Work Location
Hyderabad, AP

Functional Area
BD&L & Strategic Planning

Division
CORPORATE

Business Unit
DIGITAL OFFICE

Employment Type
Regular

Company/Legal Entity
Nov Hltcr Shared Services Ind

Shift Work
No",3.9,"Novartis
3.9",Hyderabad,"Basel, Switzerland",10000+ employees,1996,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
Data Analyst,-1,"Job Title: Data Analyst
Location: Chennai

This role will be responsible for the data analysis, requirement capture, stakeholder management and IMCC mailing.
What will you be doing?
Support / manage the design and development of process solutions to meet the agreed business requirements including management information requirements and mitigation of risks (via appropriate controls / reconciliations) within the technology / process solutions
Proficiency and Experience in Teradata/SQL is mandatory
HADOOP Experience preferably in Hive, Impala and Spark is required.
Support Customer Targeting manager to deliver data discovery and participate in data walkthroughs
Contribute to create Risk Assessments on activity to support in the mitigation of known risks.
Create / Develop Data Dictionaries working with campaign delivery managers to support testing and build of letter though OTX (include testing scenarios & validation)
Help define improvements for the bank in terms of Products & Customer / Colleague experience
Ability to work across different lines of business in Barclays and interact with a spectrum of people
Ability to map business requirements to tools / technology stacks
Provision of business analysis skills
Production and review of functional and non-functional specifications
Providing data analysis to support the delivery of the strategy, propositions & plans in order to maximise the functions knowledge & intelligence.

What were looking for:
Strong Knowledge in Data warehousing.
Strong Knowledge and Hands on Experience in Teradata.
Unix expertise
Meticulous attention to detail

Skills that will help you in the role:
Knowledge and Hands on Experience in HADOOP - HDFS File System
Knowledge and Hands on experience in tools like Ab Initio, SAS

Where will you be working?
Chennai

Be More at Barclays
At Barclays, each day is about being more as a professional, and as a person. Be More @ Barclays represents our core promise to all current and future employees. Its the characteristic that we want to be associated with as an employer, and at the heart of every employee experience. We empower our colleagues to Be More Globally Connected, working on international projects that improve the way millions of customers handle their finances. Be More Inspired by working alongside the most talented people in the industry, and delivering imaginative new solutions that are redefining the future of finance. Be More Impactful by having the opportunity to work on cutting-edge projects, and Be More Valued for who you are.
Interested and want to know more about Barclays? Visit home.barclays/who-we-are/ for more details.

Our Values
Everything we do is shaped by the five values of Respect, Integrity, Service, Excellence and Stewardship. Our values inform the foundations of our relationships with customers and clients, but they also shape how we measure and reward the performance of our colleagues. Simply put, success is not just about what you achieve, but about how you achieve it.
Our Diversity
We aim to foster a culture where individuals of all backgrounds feel confident in bringing their whole selves to work, feel included and their talents are nurtured, empowering them to contribute fully to our vision and goals.
Our Benefits
Our customers are unique. The same goes for our colleagues. That's why at Barclays we offer a range of benefits, allowing every colleague to choose the best options for their personal circumstances. These include a competitive salary and pension, health care and all the tools, technology and support to help you become the very best you can be. We are proud of our dynamic working options for colleagues. If you have a need for flexibility, then please discuss this with us.",3.9,"Barclays
3.9",Chennai,"London, United Kingdom",10000+ employees,1690,Company - Public,Banks & Building Societies,Finance,₹500+ billion (INR),"Deutsche Bank, HSBC Holdings, Royal Bank of Scotland"
Sr. Data Scientist,-1,"Job Description:
Work with business partners and stake holders to understand the business, formulate the problems, come up with the solutions and communicate them back effectively to non-technical audience
Analyze data to identify trends, perform root cause analysis and test hypotheses
Design A/B testing experiment set ups and measure their performance across product platform & marketing
Work with large volumes of data; extract, manipulate & visualize large datasets using standard tools such as SQL, Python, R & Tableau
Lead complex, multifunctional data science projects
Communicate complex concepts and the results of the models and analyses to technical and non-technical audience
Design, develop and implement real-time, highly automated solutions to solve credit business problems and improve existing monitoring capabilitie
Qualification:
Advance degree (MS or PhD) in science or engineering field with 6+ years of relevant experience
Strong problem-solving and communication skills
Ability to deal with large amount of data and fluency with SQL or SQL-like tools
Proven track record of building and implementing automated advanced analytical solutions
Experience in leading cross-functional, highly complex Data Science projects
Data Mining experience in Python, R.
Familiar with various Machine Learning algorithms and Statistical methods
Have a passion for working on big data and professional experience in data mining, statistical analysis, predictive modeling and data manipulation
Financial services or eCommerce experience a big plus",3.5,"PayPal
3.5",Chennai,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Senior Data Scientist,-1,"TechVantage is a product engineering company that builds first-of-its-kind AI-centric products is looking for Senior Data Scientist to be a part of product development of AI powered software.
The work location is in Technopark, Trivandrum and the ideal candidate should be willing to travel to client sites outside India

What we are looking from an ideal candidate?

You need to be a thinker. We are looking for a very curious Lead data scientist who enjoys a deep dive into the raw data to help figure out the right set of questions and find the answers to those questions.
You need to be a doer. You will be responsible for data cleansing, transformation and creating predictive models and classifiers.
You need to be ambitious. You must be passionate about applying mathematical modeling to solve real world problems.
You need to be smart and build smart products. A big part of this job is about creating actionable insights for our customers and the business using machine learning and statistical techniques. Translate analytic insights into concrete, actionable recommendations for business or product improvement.
Design and build Machine Learning, Deep Learning, and NLP, infrastructure, models and applications to generate scalable and high-performance Prediction, Evaluation, Recommendation, anomaly detection, bots, sentiment insights and ontologies from structured/unstructured Big Data and domain rules
Determine the best AI technique for a particular customer problem in any industry domain and apply, learn, and adapt.

Limited front row seats are available. If you fit the description, do not hesitate to apply- jobs@techvantagesystems.com. This is the job for you! - See you soon at TechVantage! For more information about us, please visit www.techvantagesystems.com

Preferred Skills:
What skills do you need?

A big part of this job is about creating actionable insights for our customers and the business using machine learning and statistical techniques.

Should be strong in Probability, Statistics, Optimization, Calculus, General Math
Experience with some or all of the following: data mining, predictive modeling, statistics, experimental design, computational analytics, econometric modeling, data visualization
Hands-on experience in feature engineering and building scalable machine learning algorithms
Prior experience of handling large volumes of unstructured data with high diversity
Excellent client management skills
Tech/MS/M.Tech or PhD in Computer Science, Machine Learning, AI, or related field
Prior experience with start-up environment preferred is a plus",4.1,"Techvantage Systems
4.1",Thiruvananthapuram,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Science Engineer,-1,"We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.

Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company's data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance

Skills and Qualifications
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc. (excellence in at least one of these is highly desirable)
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills in Ruby and Python
Data-oriented personality",3.9,"Involvio
3.9",Bengaluru,"New York, NY",1 to 50 employees,-1,Company - Private,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Data Scientist (Upto 5years),-1,"Desired Candidate Profile

Experience in relevant field such as Statistics, Computer Science or Applied Math or Operational Research.
Must have Masters in (Maths/Statistics or Applied Mathematics/Machine Learning etc.)
History of successfully performing customer implementations
Strong customer facing skills, and previous consulting experience.
Experience of handling high frequency streaming data for real time analysis and reporting.
Familiarity with - Natural Language Processing, Statistical Analysis (distribution analysis, correlation, variance
Experience with open source technologies is a must.
Energy/Hunger for Growth
Excellent communication and executive presence to connect at CXO levels
Ability to lead & build strong teams
Ability to work in an ambiguous environment.
Desired Skills and Experience

Languages/Tools:Python/R,Scala,SQL,
Experience in applying Data Science methods to Business Problems. Machine Learning,
Concepts: Strong presentation and communication skills with a knack for explaining complex analytical concepts to people from other fields.
Team leadership, Mentoring and project management skills.
Education :PG - Any Postgraduate - Any Specialization, MS/M.Sc(Science) - Any Specialization, Maths, Statistics",5.0,"XLNC Technologies
5.0",Mumbai,"Mumbai, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"Graduate in the analytical fields with strong academic credentials
Excellent written and verbal communication skills
Should have worked on excel and advance excel, MS Office
Please send your CV to:careers@q-dat.com",5.0,"Q-Dat IT Solutions
5.0",Bengaluru,"RajajiNagar, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"The candidate should be passionate about machine learning and deep learning.

Should understand the importance and know-how of taking the machine-learning-based solution to the consumer.

Hands-on experience with statistical, machine-learning tools and techniques

Good exposure to Deep learning libraries like Tensorflow, PyTorch.

Experience in implementing Deep Learning techniques, Computer Vision and NLP. The candidate should be able to develop the solution from scratch with Github codes exposed.

Should be able to read research papers and pick ideas to quickly reproduce research in the most comfortable Deep Learning library.

Should be strong in data structures and algorithms. Should be able to do code complexity analysis/optimization for smooth delivery to production.

Expert level coding experience in Python.

Technologies: Backend - Python (Programming Language)

Should have the ability to think long term solutions, modularity, and reusability of the components.

Should be able to work in a collaborative way. Should be open to learning from peers as well as constantly bring new ideas to the table.

Self-driven missile. Open to peer criticism, feedback and should be able to take it positively. Ready to be held accountable for the responsibilities undertaken.",3.6,"Quantiphi
3.6",Mumbai,"Marlborough, MA",501 to 1000 employees,2013,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
"Research Scientist, Google Research",-1,"Due to the current health crisis related to COVID-19 and the escalating visa/travel restrictions in place, we're currently unable to extend offers to anyone who cannot work from India due to lockdown visa/travel restrictions, or other restrictive measures until further notice. Consequently, we will be prioritizing candidates who can start in this location by set date as expected. We're keeping the situation under review and would adjust our position should the restrictive measures be removed later on.

Minimum qualifications:
PhD in Computer Science, related technical field, or equivalent practical experience
Experience in Machine Learning, NLP/NLU, Computer Vision, Optimization, Game Theory, Computer Systems, Market Algorithms
Experience with general purpose programming languages e.g., C/C++ or Python
Contributions to research communities including publishing in top forums (e.g: NeurIPS, ICML, ACL, CVPR, KDD, AAMAS)
Preferred qualifications:
Relevant work experience, including full time industry experience or as a researcher in a lab.
Strong publication record
Ability to design and execute on research agenda.
About the job


As an organization, Google maintains a portfolio of research projects driven by fundamental research, new product innovation, product contribution and infrastructure goals, while providing individuals and teams the freedom to emphasize specific types of work. As a Research Scientist, you'll set up large-scale experiments and deploy promising ideas quickly and broadly, managing deadlines and deliverables while applying the latest theories to develop new and improved products, processes, or technologies. From creating experiments and prototyping implementations to designing new architectures, our research scientists work on real-world problems that span the breadth of computer science, such as machine (and deep) learning, data mining, natural language processing, hardware and software performance analysis, improving compilers for mobile platforms, as well as core search and much more.

As a Research Scientist, you'll also actively contribute to the wider research community by sharing and publishing your findings, with ideas inspired by internal projects as well as from collaborations with research programs at partner universities and technical institutes all over the world.

Our mission at Google Research India is to contribute to fundamental advances in AI and apply our research to solve big problems and deliver impact for Google, India and communities around the world.

The lab in Bangalore is a part of Google’s global network of researchers: participating in conferences, publishing research in scientific papers, and collaborating closely with one another. We are also establishing partnerships with the scientific research community and academic institutions both in India and around the world to support collaborative research programs.
Responsibilities
Undertake cutting edge research in the above mentioned areas.
Develop solutions for real-world, large-scale problems.

At Google, we don’t just accept difference—we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form.",4.4,"Google
4.4",Bengaluru,"Mountain View, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Microsoft, Apple, Facebook"
Data Analyst,-1,"About Swiss Re

Swiss Re is one of the world’s leading providers of reinsurance, insurance and other forms of insurance-based risk transfer, working to make the world more resilient. We anticipate and manage a wide variety of risks, from natural catastrophes and climate change to cybercrime.

At Swiss Re we combine experience with creative thinking and cutting-edge expertise to create new opportunities and solutions for our clients. This is possible thanks to the collaboration of our 15,000 employees across the world.

We offer a flexible working environment where curious and adaptable people thrive. Are you interested in joining us?

About the role:
Provide data analysis, transformation and technical support needed by L&H Products Americas Actuarial team to support L&H pricing initiatives, analysis of reinsured lives business, new product development initiatives.
Support and develop processes to deliver quantitative studies of internal mortality and lapse data.
Provide high quality and timely technical support to the L&H Products Americas staff.
Coordinate workflow between data analysts and actuarial teams.
Follow established guidelines and best practices for internal and external data management processes, which includes appropriate documentation in support of business controls.
Create, maintain, and enhance guidelines and best practices when necessary.
Streamline current processes for efficiency when appropriate.

About the team:

US Experience Studies team is responsible for assisting in the development of client specific pricing assumptions & maintaining data set and study quality for all other purposes. The team is located in two main offices: Fort Wayne (US) and Bangalore (India).

About you:
2-3 years of experience related to technical processes necessary to support L&H Product's needs.
Experience with Microsoft Access, Microsoft Excel, SQL and client database tools, or others such as R, Python, SAS and Oracle.
1-2 yrs. of experience in insurance related fields, knowledge of insurance products & their administration is desired.
Cross cultural experience working with colleagues globally; experienced in managing data works handover processes between teams in different geographical locations.
Demonstrates strong oral and written English communication skills, along with strong interpersonal skills.
Shows initiative in identifying data related issues and supporting other team members, peers and senior stakeholders.
Strong creative problem solving and analytical skills.
Strong documentation skills.
Ability to work independently, accurately and deliver to deadlines.
Swiss Re",3.8,"Swiss Re
3.8",Bengaluru,"Zurich, Switzerland",10000+ employees,1863,Company - Public,Insurance Agencies & Brokerages,Insurance,₹500+ billion (INR),"Munich Re, Hannover RE, SCOR"
Senior Data Scientist - GAIA,-1,"Date: Mar 26, 2020

Ericsson is one of the leading providers of Information and Communication Technology (ICT) to service providers. We enable the full value of connectivity by creating game-changing technology and services that are easy to use, adopt, and scale, making our customers successful in a fully connected world. Headquartered in Stockholm, Sweden, Ericsson is proud of its global presence across 100+ countries and market areas. With a strong focus on innovation, we possess 49 thousand registered patents and a global strength of over 95 thousand competent professionals. We also take pride in supporting networks that cater to a capacity of 40 percent of the world’s mobile traffic, thereby connecting more than 2.5 billion subscribers and counting. We are a world leader in the rapidly changing environment of communications technology – by providing hardware, software, and services to enable the full value of connectivity.

Senior Data Scientist – Product Development (Global AI Accelerator India)

Job Description

Ericsson Overview:

Ericsson is world’s leading provider of communications technology and services. Our offerings include services, consulting, software and infrastructure within Information and Communications Technology.

Using innovation to empower people, business and society, Ericsson is working towards the Networked Society: a world connected in real time that will open up opportunities to create freedom, transform society and drive solutions to some of our planet’s greatest challenges.

We are truly a global company, operating across borders in over 180 countries, offering a diverse, performance-driven culture and an innovative and engaging environment. As an Ericsson employee, you will have freedom to think big and the support to turn ideas into achievements. Continuous learning and growth opportunities allow you to acquire the knowledge and skills necessary to progress and reach your career goals. We invite you to join our team.

Exciting Opportunity:

It will be practically impossible for human brains to understand how to run and optimize next generation of wireless networks, i.e., 5G network with distributed edge compute, that will drive economic and social transformation for all aspects of society. Machine Learning (ML) and other Artificial Intelligence (AI) technologies will be vital for us to handle this opportunity. We are setting up a Global AI Accelerator (GAIA) in the US, Sweden and India, with 300 experts, to fast-track our strategy execution.

Machine Intelligence, the combination of Machine Learning and other Artificial Intelligence technologies is what Ericsson uses to drive thought leadership to automate and transform Ericsson offerings and operations. MI is also a key competence for to enable new and emerging business. This includes development of models, frameworks and infrastructure where we in our advancements push the technology frontiers. We engage in both academic and industry collaborations and drive the digitalization of Ericsson and the Industry by developing state of the art solutions that simplify and automate processes in our products and services and build new value through data insights.

Ericsson is now looking for Senior Data Scientists to significantly expand its global team for AI acceleration for our group in Bangalore and Chennai.

Do you have in depth understanding of Machine Learning and AI technologies?

Do you want to apply and extend those skills to solve real complex problems with high societal impact; going beyond ML/AI for consumption and advertising?

Then, you do want to join Ericsson’s global team of Engineers/Scientists pushing the technology frontiers to automate, simplify and add new value through large and complex data.

Role Summary:

As a Senior Data Scientist, you will need to have strong programming skills and deep understanding of data science and Machine Learning tools. Your knowledge and experience in Data Science methodologies will be applied to solve challenging real-world problems as part of a highly dynamic and global team. You will work in a highly collaborative environment where you communicate and plan tasks and ideas. You will be working on high impact initiatives with other DS in Machine Intelligence to drive growth and economic profitability for Ericsson and its customers by accelerating current Ericsson offerings. Your contribution will also help to create new offerings in the areas of MI driven 4G and 5G network, distributed cloud, IoT and other emerging businesses.

Key Responsibilities:
Lead functional and technical analysis within Ericsson businesses and for strategic customers to understand MI-driven business needs and opportunities
Define the model validation strategy and business success criteria in data science terms
Identify the right architecture and flow for the data and DS model
Design the implementation and deployment strategy for the model into production
Contribute to rapid and iterative development of validated minimum viable solutions addressing these needs. This includes working with petabytes of 4G/5G-networks, IoT and exogenous data, and proposing/selecting/testing predictive models, recommendation engines, anomaly detection systems, statistical models, deep learning, reinforcement learning and other machine learning systems
Lead studies and creative usage of new and/or existing data sources. Work with Data Architects to leverage existing data models and build new ones as needed.
Collaborate with product development teams and partners in Ericsson Businesses to industrialize machine learning models and solutions as part of Ericsson offerings including providing source code, workflows and documents
Work with unstructured data including text and images in AI/ML models
Work with new technologies and be the ambassador for them in MI Communities within Ericsson, nurturing the communities and mentoring junior data scientists.
Provide MI Competence build-up in Ericsson Businesses and Customer Serving Units
Develop new and apply/extend existing, concepts, methodologies, techniques for cross functional initiatives
Engage with external ecosystem (academia, technology leaders, open source etc.) to develop the skills and technology portfolio for MI’s needs
Present and be prominent in MI related forums and conferences, e.g., publishing patents, presenting papers, organizing sessions etc.
Key Qualifications:
Bachelors/Masters/Ph.D. in Computer Science, Data Science, Artificial Intelligence, Machine Learning, Electrical Engineering or related disciplines from any of the reputed institutes. First Class, preferably with Distinction.
Applied experience: 5+ years of ML and/or AI production level experience; and an overall industry experience of around 10+ years.
Proven skills of implementing a variety of Machine Learning techniques
Experience in Security, Internet of Things is a plus
Strong skills in the use of current machine learning frameworks such as H2O, Keras, TensorFlow, Spark ML etc.
Demonstrated ability to implement new algorithms and methodologies from leading open source initiatives and research papers addressing their functionalities, scalability and overall industrialization viability
Experience with Big Data technologies such as Hadoop, Cassandra etc.
Good with effective big data storage and retrieval strategies including indexing, partitioning, etc.
Hands on working with data pipeline and flow
Hands on with API design/development for AI/ML models
Strong grounding in math and statistics.
Proven ability of leading projects end-to-end.
Proven experience writing production-grade software
Extensive experience in model development and AI model life-cycle-management in one or more industry/application domain
Strong Programming skills in various languages (C++, Scala, Java, R) with proficiency in Python and/or C++
Good communication skills in written and spoken English
Creativity and ability to formulate problems and solve them independently
Ability to build and nurture internal and external communities
Experience in writing and presenting white papers, journal articles and technical blogs on the results
Additional Requirements:
Certifying MI MOOCS, a plus
Applications/Domain-knowledge in Telecommunication and/or IoT, a plus.
Experience with data visualization and dashboard creation is a plus
Ability to work independently with high energy, enthusiasm and persistence
Experience in partnering and collaborative co-creation, i.e., working with complex multiple stakeholder business units, global customers, technology and other ecosystem partners in a multi-culture, global matrix organization with sensitivity and persistence
Ericsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetics. Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development. Ericsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetic information.",3.9,"Ericsson-Worldwide
3.9",Bengaluru,"Stockholm, Sweden",10000+ employees,1876,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Huawei Technologies, IBM, Cisco Systems"
AI Scientist,-1,"An AI scientist at Wadhwani AI will build research-driven solutions to bring AI to the benefit of the underserved billions across the developing world.

ABOUT US

The Wadhwani Institute for Artificial Intelligence (Wadhwani AI) is the world’s first independent nonprofit research institute developing AI solutions for social good. Our mission is to develop AI solutions to overcome challenges of societal importance in domains such as health, agriculture, financial inclusion, and infrastructure.

Our team consists of world-renowned scientists, innovators, and entrepreneurs from Stanford, Yale, Cornell, and the IITs, with experience at companies like Microsoft, Google, Amazon, and DE Shaw. We have research collaborations with Stanford University, Carnegie Mellon University, New York University, University of Southern California, and the University of Washington.

ROLES AND RESPONSIBILITIES

As an AI scientist, you will be responsible for building machine learning solutions to problems of societal importance, and mentoring other team members in this effort. You will participate in problem definitions and the development and execution of algorithms and solutions to the problems.

In order to apply machine learning and related technologies for social good, you will need to understand user challenges and their context, curate and transform data, train and validate models, run simulations and broadly derive insights from data. In doing so, you will work in cross-functional teams spanning research, engineering, product and program management, and designers. You will also work closely with social sector organizations, and are encouraged to collaborate with researchers across the world.

You will be encouraged to drive fundamental advances to the technology domains themselves as part of the efforts towards their application, present your work in technical and other forums of interest, and publish in leading conferences and journals.

At Wadhwani AI, excellence as an individual contributor goes hand-in-hand with good teamwork and collaboration. You will mentor junior researchers, post-docs and interns, and participate in recruiting and hiring activities. You will also be expected to interact with external partners of Wadhwani AI when required, and to make periodic visits to the communities from where challenges are derived and where the solutions will be deployed.

REQUIREMENTS

We are looking for AI scientists with experience applying AI, machine learning and data science to real world problems. Ideal candidates should have a strong research background and be adept at a variety of data mining/analysis methods and tools, building and implementing models, visualizing data, creating/using algorithms and running simulations.

Candidates should be comfortable working with cross-functional teams, must have excellent communication skills and a track record of driving projects to completion.

Candidates should care about using their technical skills to solve large societally important problems.",4.0,"Wadhwani AI
4.0",Mumbai,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist - PhD,-1,"Company Description

About Affine

Affine is a Data Sciences & AI services provider, offering capabilities across the analytical value chain from data engineering to analytical modelling and business intelligence to solve strategic & day to day business challenges of organizations worldwide. They empower their clients to make informed decisions & to take proactive actions through impeccable technology-based development & business acumen.

They develop solutions for multiple verticals such as Retail, CPG, E-commerce, High-Technology, BFSI, Media & Entertainment, Manufacturing among others and are respected as one of the Marquee names in the “Consultancies for Transformation” space.

Affine is headquartered in Bengaluru, India with other offices in New York & Seattle, United States and Singapore.

Job Description

Experience: 0 – 4 years
Education requirement: PhD in Machine Learning/Deep Learning/Artificial Intelligence/Image
processing/Statistics/Computer Science/ Mathematics

Responsibilities
• Utilizing artificial intelligence and machine learning concepts to solve challenging business problems
• Work on problems from various domains like NLP, Recommendation engine, computer vision
• Should participate in complete project cycle i.e. understanding a problem statement, data gathering,
analyzing data, implementing ML/AI solutions
• Should be able to learn new tools/languages quickly and continue expanding knowledge on latest
advances in ML/AI
• Managing project timing, client expectations and meeting deadlines
• Publishing research articles, papers and blogs

Desired skills and experience:
•Strong experience in machine learning/artificial intelligence in academics or academics plus
industry
• Expert level in at least one programming language. Preferably R or Python
• Knowledge of statistics and machine learning (Probability theory, parametric and non-parametric
models, supervised and unsupervised ML techniques, etc.)
• Knowledge of deep learning algorithms (CNN, RNN, autoencoders, etc.)
• Knowledge in databases preferable",3.8,"Affine Analytics
3.8",Bengaluru,"Bengaluru, India",201 to 500 employees,2011,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
REQUIRED DATA SCIENTIST,-1,Urgently Looking for an experienced Data Scientist in Calicut Kerala Job Details * Identify the important input variables data needed for model building *Design the Validation metric to evaluate machine learning models *Do the feature engineering and build the model *Move the model into production as a micro service *Ability to work on multiple projects in parallel *Prepare dashboards to track performance and responsiveness of the model in production Job Requirements * Minimum 3 years experience is required * IT Skills * Good Communication Skills * Bachelors Degree in computer science,-1,Qbytez Infolabs Pvt Ltd,Kozhikode,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"Experience: 5+ years

Location: Madurai, Tamil Nadu, India

Technology: Python, ML libraries scikit-learn and pandas, DL Framework TensorFlow/Keras, datasets visualisation, OpenCV, Linux.

Desired Skills and Experience:
Analyzing the ML algorithms that could be used to solve a given problem and ranking them by their success probability.

Exploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real world.

Verifying data quality, and/or ensuring it via data cleaning.

Supervising the data acquisition process if more data is needed.

Finding available datasets online that could be used for training.

Defining validation strategies.

Defining the preprocessing or feature engineering to be done on a given dataset.

Defining data augmentation pipelines.

Training models and tuning their hyperparameters.

Analyzing the errors of the model and designing strategies to overcome them.

Deploying models to production.

Email to: careers@techmango.net",3.7,"Techmango Technology Services
3.7",Madurai,"Westchester, IL",51 to 200 employees,2014,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist DA4AD,-1,"Responsibilities
Selecting features, building and optimizing classifiers using machine learning and Deep Learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance

Skills
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, CNNs, etc.
Very good experience with common data science toolkits of Python like numpy, pandas, pyTorch. Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools like matplotlib, Tableau
Proficiency in using query languages such as SQL
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality

Responsibilities
Selecting features, building and optimizing classifiers using machine learning and Deep Learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance

Skills
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, CNNs, etc.
Very good experience with common data science toolkits of Python like numpy, pandas, pyTorch. Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools like matplotlib, Tableau
Proficiency in using query languages such as SQL
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality",3.5,"Mercedes-Benz Research and Development India Private Limited
3.5",Bengaluru,"Chakan, India",1001 to 5000 employees,1996,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),"Volkswagen, Tata Motors"
Data Scientist-ONWARD,-1,"Data Scientist-ONWARD
Job Description


At Kimberly Clark, we believe in a truly diverse and inclusive culture and towards this end a brand new initiative – ONWARD, Career Restart Program has been recently launched .

The vision of the program is to broaden and diversify candidate talent pools by empowering experienced professionals to restart their careers, following a hiatus, with Kimberly Clark. Seasoned professionals (often women) with a career break are highly skilled and are an untapped pool of experienced talent. Through this program we will provide a road to re entry, strengthening our workforce diversity and maximizing women’s workforce participation.

If you think you qualify for this program and have the skills, check out the following open job with us-

IT Data Scientist- ONWARD

Job Description Summary

The ITS Data Scientist is responsible for integrating business, information, and technology into analytical models that help drive business performance and competitive advantage and providing the business with answers to questions. The role collaborates with Business, IT Functional Engineers and Platform architects to create value from varied data sources. Creating value from data requires a range of talents: from data integration and preparation, to architecting specialized computing/database environments, to data mining and intelligent algorithm development.

This role is viewed as an expert in making sense of complex data environments, encompassing both business data and process understanding and technical expertise. Leads in developing innovative, technical solutions to important, highly complex strategic and operating problems. Has strong knowledge in business and technical functions that are touch points with their area of expertise. Provides technical consulting on complex projects. Acts as a source of direction, training and guidance for other team members. Is knowledgeable in industry best practices in their area of expertise and uses resources outside of KC to deliver solutions.

Duties and Responsibilities:Job Details
Development of advanced analytics to help drive competitive advantage from data with accountabilities across multiple functional and technical areas with wide range of complexity.
The Data Scientist must understand complex data types (integrate, manipulate, prepare), know advanced analytics (appropriate techniques, interpret data and diagnose models, meet business requirements), and focus on the business outcomes (goals, constraints, decisions while communicating outcomes via presentations).
Develop models and algorithms that drive innovation throughout the organization. This may include marketing, supply chain, inventory planning and deployment, network planning, order routing, and order fulfillment and delivery.
Conduct advanced statistical analysis to provide actionable insights, identify trends, and measure performance.
Build learning systems that monitor data flows and react to changes in customer preferences, network constraints, and business objectives Collaborate with engineers to implement and deploy scalable solutions.
Provide thought leadership by researching best practices, conducting experiments, and collaborating with industry leaders.
Partners as a bridge between the business and the information management teams to make sure that the solution fits within the data management principals.
Coordinates data science implementations while leading design variances based upon business needs while ensuring artifacts and repositories are documented.
Manages engagements with vendors as they relate to evaluation, design and delivery of business capabilities.
Contributes to the evaluation and selection of software product standards Leader in industry representation, policy formation, User Groups, and strategic direction
Mentors others to complete Continuous Improvement (CI) initiatives; consults and shares knowledge across org; awareness of industry trends.
Education required/ preferred:
B.A. or B.S. in Information Technology, Data Science, or related field.
At least 8 years of IT experience and at least 4 years or more of work experience in data scientist discipline.
Deep knowledge of machine learning, statistics, optimization or related field.
Experience with R, Python, Matlab is required.
Experience building machine learning application in areas like time series forecasting, classification models, clustering models, multivariate regression models etc.
Experience in Microsoft Azure Stack in the Cloud with focus on Data Factory, Data Bricks, BLOBs, Data Lake Storage, ML Studio, Azure Analysis Services, Azure Data Warehouse, Power BI etc.
Experience working with large data sets and distributed computing tools a plus (Map/Reduce, Hadoop, Hive, Spark, Python, R, Gurobi, MySQL, etc.).
Excellent written and verbal communication skills along with strong desire to work in cross functional teams.
Consumer products experience in an online and/or retail/manufacturing environment is preferred.
Possess strong leadership skills and exhibit creative thinking to be able to come up with inventive solutions to solve business challenges.
Provide thought leadership while keeping up with industry trends and disseminating information across the organization.
Experience working with blended teams consisting of employees, vendors, and consultants with both onshore and offshore resources.
Strong Technical leadership of advanced analytics teams and vendors.
Extensive experience collaborating with Enterprise Architects and infrastructure engineers to identify, design, and implement highly complex, end-to-end solutions
Cultivates networking opportunities within the organization
Broad range of business and IT experiences; Has achieved technical and/or business certification(s).
Travel may include less than 10% of work time. Travel may also include travel via aircrafts and motor vehicles to various locations, if applicable. Varying working conditions may include prolonged sitting, typing and viewing computer/laptop screens, along with occasional bending, reaching, lifting, carrying, climbing, twisting, stooping, walking and standing.

Global VISA and Relocation Specifications:
K-C requires that an employee have authorization to work in the country in which the role is based. In the event an applicant does not have current work authorization, K-C will determine, in its sole discretion, whether to sponsor an individual for work authorization. However, based on immigration requirements, not all roles are suitable for sponsorship.
This role is available for local candidates already authorized to work in the role’s country only. K-C will not provide relocation support for this role.
Primary Location
IT Centre Bangalore GDTC
Additional Locations
Worker Type
Employee
Worker Sub-Type
Regular
Time Type
Full time",3.9,"Kimberly-Clark
3.9",Bengaluru,"Irving, TX",10000+ employees,1872,Company - Public,Consumer Products Manufacturing,Manufacturing,₹500+ billion (INR),"Procter & Gamble, Georgia-Pacific, Unilever"
Senior Data Scientist,-1,"Position
We are hiring senior data scientist with 4-6 years’ experience for Bangalore location. If you are interested, please share your CV to this posting or to careers@3d-ipsemi.com
Responsibilities
Development of Artificial Platform (AI) products useful across industries
Algorithm and technology development in AI, ML,CNN and NLP.
Leading the team
Responsible for complete product development and mentoring junior engineers
Use ML techniques such as Regression, Unsupervised Learning, Data Visualization, Natural Language Progressing and Neural and Convolution Network.
Desired Skills
4-6 years of relevant experience in solving problems using machine learning or computer vision.
Programming experience in C++, Java, Android, Python, PHP, R or Matlab.
Familiarity with Machine learning, RESTful Services, AWS/EC2/ELB/S3/DynamoDB, Data Science, Hadoop/Hive/Spark/Scala.",4.0,"3D-IP Semiconductors
4.0",Bengaluru,"Bangalore, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"Do you want to define the future of Internet commerce?
Are you a top-notch software engineer with a creative flare, strong problem-solving skills, the drive to build and ship products often, a solid computer science foundation, and the desire to build Amazon's next generation Internet-facing technology? Come talk with us about joining our team to help our tax teams serve customers better.
Is your next project defining a world class Internet service?
With us, you will be building cutting-edge applications and services in an environment of highly distributed systems used by Amazon Tax teams. Your innovation will provide new functionality for millions of vendors/payees globally with a goal of making it easy to comply with tax regulations.
Are you ready to create systems to expand one of the worlds largest e-commerce engines?
If so, come be a member of Amazons Taskless Technology team. Taskless Tech builds software systems that ensure compliance for Amazon businesses and its subsidiaries and makes it easy for for millions of Amazon vendors including publishers, app developers, game developers, marketplace sellers, associates and others to comply for tens of billions of dollars in transactions. We're constantly looking for opportunities to expand capabilities in new geographies and new lines of business.
Can you work at the scale of the biggest Internet companies?
The solutions that you will deploy must scale to accommodate rapid processing and integration with large enterprise customers. However, to add to the challenge, the solutions must also support intuitive world class UI for Amazon Tax teams to pay millions of vendors.
Amazon is a premier place to build, deploy and operate Internet-scale services.
Join our development team to work hard, have fun and make history. You will join a highly technical and entrepreneurial culture defining and building a selling experience to complement Amazons world-class websites.



Basic Qualifications

· Strong problem solving skills
· Strong coding skills
· Passion for building scalable, global, complex systems to solve problems with proven ability to deliver high quality software.
· Solid understanding of Object-Oriented design and concepts.
· Innovative and creative with Web technologies to build high performing websites and web services.
· Demonstrated proficiency with AJAX, Javascript, CSS is a plus.

Preferred Qualifications

· BS or MS in Computer Science or in a relevant Engineering discipline.
· 5+ years of industry experience
· Strong analytical thinker who knows how to pick the right tool for the job
· Knowledge of professional software engineering practices & best practices for the full software development life cycle, including
· Agile methodologies, coding standards, code reviews, source control management, build processes, testing, and operations
· Ability to communicate clearly and concisely with technical and non-technical customers in order to understand ambiguous problems and articulate technical designs and solutions to complex problem",4.2,"Amazon
4.2",Gurgaon,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Scientist – Text Analytics/NLP Engineer,-1,"About Crediwatch

Crediwatch is an insights-as-a-service platform that deploys scalable deep learning tools across disparate digital footprints left by private entities (big and small). Crediwatch provides actionable credit intelligence and dynamic credit management as a service to Financial Institutions. Crediwatch does this with no human intervention by deploying AI /ML and NLP tools, on structured as well as unstructured data, that provide the most reliable and comprehensive real-time insights. Crediwatch has created over 18 million risk profiles of companies and unregistered small businesses. Some of the leading financial and non-financial institutions trust Crediwatch’s insights to grow and protect their ventures.

Data Scientist – Text Analytics/NLP Engineer

We are looking for Savvy Text Analytics Engineer to join our growing team of data scientists and experts. You will be responsible for expanding and optimizing our data models, prediction algorithms, text analytics and allied opportunities. You will support our software developers, data engineers on building and enhancing models. You must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Objectives and responsibilities

Drive Operational Excellence – Ensure execution of critical Text Mining projects, including driving innovative implementation and insights derived from unstructured data. Perform big data operations using Apache Hadoop stack and develop high end tools to solve complex problems in business.

Consultant – Providing thought leadership and best practices related to Text Mining and Big data to Crediwatch’s customers. Identify specific capability, practices, tools, and people that the organization would need to develop. Social network modelling expertise using unstructured and structured data preferred

Solutioning – Conceptualize and develop Text Mining solutions for the customer in focus. Envisioning opportunistic areas with our client by demonstrating relevant and credible Text Mining solutions and paradigms. High level assessment of customer’s Text Mining readiness and create the analytics benchmark to converge into a client specific Text mining roadmap. Understanding client’s current Text Mining projects / infrastructure and developing solutions that complement existing/ongoing efforts would be key.

Key Roles and Responsibilities

The Text Mining Scientist (TMS) is expected to play a pivotal bridging role between enterprise database teams, and business /functional resources. At a broad level, the TMS will leverage his/her solutioning expertise to translate the customer’s business need into a techno-analytic problem and appropriately work with database teams to bring large scale text analytic solutions to fruition. The right candidate should have prior experience in developing text mining and NLP solutions using open source tools.

The key responsibilities of the Text Mining Scientist are

Develop transformative AI/ML solutions to address our clients’ business requirements and challenges

Understand and research cutting edge industrial and academic developments in AI/ML with NLP/NLU applications in diverse industries such as Finance, Risk, Compliance, Credit.

Conceptualize, Design, build and develop solution algorithms which demonstrate the minimum required functionality within tight timelines

Interact with clients to collect, synthesize, and propose requirements and create effective analytics/text mining roadmap.

Work with digital development teams to integrate and transform these algorithms into production quality applications

Do applied research on a wide array of text analytics and machine learning projects, file patents and publish the papers

Qualifications

MS in Computer Science, Information systems, or Computer engineering, Systems Engineering with 2+ years of relevant experience in Text Mining / Natural Language Processing (NLP) tools, Data sciences, Big Data and algorithms. Must come with a solid understanding of machine learning

Additional weightage to candidates with a PhD in Computer Science, Computational Science or Engineering with 3+ years of industry experience in Text Mining / Natural Language Processing (NLP) tools, and algorithms. Hands on to Big Data Concepts. Full cycle experience desirable in atleast 1 Large Scale Text Mining/NLP project from creating a Business use case, Text Analytics assessment/roadmap, Technology & Analytic Solutioning, Implementation and Change Management, considerable experience in Hadoop including development in map-reduce framework.

A suitable candidate will also have had experience working with and influencing and possess vast experience and expertise with probability and statistics, inclusive of machine learning, experimental design, and optimization.

Top notch Communication skills will also be a necessity

Exposure to statistical and modeling packages such as SAS, Statistica, Matlab, R, visualization and other advanced analysis tools. He will also be an expert in data management programming such as SQL, PL-SQL, and Python as well as being familiar win the workings of motion-tracking data and time-series analyses.

Must have experience in deploying machine learning models on production systems. Candidates having experience in AWS SageMaker will have an advantage.",-1,Crediwatch,Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist (m/f/d),-1,"Are you looking to join a world-class manufacturing organization? At Husky Injection Molding Systems, we strive to be the best with a strong foundation built on innovation, collaboration and a unique culture with great people. If you are attracted to bold goals, believe in uncompromising honesty, support mutual respect, care about environmental responsibility, have a passion for excellence and a desire to make a positive contribu-tion – we want you to join the Husky team!

What we offer
Excellent benefits package and retirement savings plans as well as life insurance program
Competitive vacation policy promoting work-life balance
Challenging career opportunities and growth
Opportunity to work, innovate and collaborate with passionate people who drive change
Amazing team – we are the best in the world at what we do!
Husky Campus
Large, beautiful campus with clean, state-of-the-art air-conditioned offices and man-ufacturing facilities with high air quality, climate control and outstanding safety rec-ords
Onsite fitness and wellness center
Organized out- and indoor sports activities such as soccer, beach volley ball, run-ning teams, and bycicle teams
Access to onsite medical practitioners
Onsite cafeterias with fresh and healthy meal options
Free parking
Job Description

This role can be either located in Dudelange / Luxembourg, or Bolton / Canada.

Responsibilities
Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Qualifications
Strong problem solving skills with an emphasis on product development.
Experience using statistical computer languages to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
Fluent English, additional language skills considered an asset
We’re looking for someone with 5-7 years of experience manipulating data sets and building statistical models, has a Master’s or PHD in Statistics, Mathematics, Computer Science or another quantitative field, and is familiar with the following software/tools:
Coding knowledge and experience with several languages: C, C++, Java, JavaScript, etc.
Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
Experience querying databases and using statistical computer languages: R, Python, SLQ, etc.
Experience using web services: Redshift, S3, Spark, DigitalOcean, etc.
Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.
Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.
Experience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.
Husky Injection Molding Systems offers a competitive compensation and benefits package and excellent opportunities for growth and advancement. We are committed to equal employment opportunity and respect, value and welcome diversity in our workplace. Husky also values being a great place to work and strives to maintain a safe workplace. No agency or telephone inquires please.",4.0,"Husky Injection Molding Systems
4.0",Global Village Park,"Bolton, Canada",1001 to 5000 employees,1947,Company - Private,Industrial Manufacturing,Manufacturing,₹50 to ₹100 billion (INR),-1
"Data Analyst, Strategy & Operations",-1,"JOB TITLE: Data Analyst, Strategy & Operations

LOCATION: MUMBAI , INDIA

OUR STORY:

JioSaavn is South Asias leading music streaming service. We are over 200 entrepreneurs, across New York, California, Mumbai, Gurgaon, and Bangalore, who help music lovers access, discover, and listen to their favorite songs across languages and genres. In early 2018, a merger between JioMusic and Saavn was announced; creating a combined entity valued at over $1 billion.

We blend digital technology, data analysis (which we have affectionately coined Music Science), and a strong, fearless business acumen to reach all corners of the globe. Through partnerships with Apple, Google, Amazon, Facebook, Twitter and Shazam - to name a few - JioSaavn reaches more music fans across the world. Our award-winning mobile products, partnerships, innovations and thought leadership have been featured in some of the worlds leading publications, from The New York Times, to The Wall Street Journal, The Economic Times to Forbes, and many more. We are well-funded by some of the worlds most successful institutional investors and global media companies as well as a number of strategic individuals. Beyond investing, they are advisors and supporters of our vision, our passion, and our collective ability to deliver a revolutionary music experience as the leader in India.

OUR CULTURE:

At JioSaavn, we ignite passion and performance to work towards a collective goal: creating the perfect mobile entertainment ecosystem that delivers the best possible music experience to millions of listeners around the world. Our default mode is that of perpetual innovation. Together, we form a concerted rhythm that goes beyond borders. We don't just go with the flow, we create it.

JioSaavn offers a dynamic and unconventional work environment, full of fun wholesome experiences from in-office performances by some of the worlds most beloved musicians to opportunities for international travel. We believe creativity and technology blend together like sweet melodies. When you choose JioSaavn, you join a diverse world of high-calibre techies, artists, and inventors hailing from companies like Yahoo!, Twitter, LinkedIn, Google, Qualcomm, HBO, Microsoft, Flipkart, Amazon, Paytm, Quikr, MSN, and NDTV. We are one of the few digital companies to provide employment opportunities that meet the Silicon Valley benchmark right here in Mumbai! Figures, since weve got Silicon Valley covered, too.

Our value-based, people-first work culture is about empowering every individual in our global team to be catalysts for change in this dynamic digital world. Every day is an opportunity to bring your vision to life, and to expand, learn and grow. No idea is left unconsidered. No voice is left unheard.

With listeners speaking multiple languages in almost every country in the world, we like to think we have the most diverse user base on the planet. This has only been made possible because of the value we place on radical inclusivity in our offices across the globe. We believe different is wonderful, and what sets us apart is also what brings us closer. JioSaavn prides itself on being an equal opportunity employer. We have committed ourselves to creating a safe environment with fair and equal access and opportunities, sans discrimination. We encourage everyone to be open to experiences and perspectives beyond their normal; divergent thinkers create differentiated products, and even better music.

If our vibe matches with yours, we'd love to hear from you.

ROLE:

JioSaavn is seeking a driven and open-minded Data Analyst to join our growing global team. The role will be an integral member of the Strategy & Operations team and will be responsible for providing support and analysis across the breadth of strategic projects.

The Strategy & Operations team acts as a trusted business partner to Founders, senior leadership and key teams across the company. The team is responsible for analyzing high priority business challenges and for proposing solutions based on thorough quantitative analysis.

RESPONSIBILITIES:
Performing data analyses on a variety of cross-functional projects using a combination of Python and SQL
Creating and regularly updating data dashboards to help define and measure progress towards KPIs across key business focus areas
Identifying opportunities for continuous improvement and automation of tasks using Python and SQL where relevant
Identifying ways in which complex and ambiguous business problems can be solved in a systematic and objective manner with the help of data and market research
Analyzing internal and external data to uncover trends on user behavior and the industry as a whole, influencing product, content, and marketing roadmaps
Creating presentations for the executive team summarizing key insights and action items derived through robust research and analyses
Working closely with a number of departments across the company including Business Insights, Data Engineering, Product, Marketing, and Content, to support data driven decision making
Regularly interface with members of Business Insights team, to stay current on analytical techniques, best practices, and JioSaavn data systems
REQUIREMENTS:
Bachelors or higher degree in Statistics, Math, Computer Science, Engineering or other related quantitative field
1-2 years of experience working in a highly analytical environment providing data insights (Technology, Consulting, Banking or other relevant industry)
Exceptional data querying skills
+2 years experience working with SQL
+2 years experience working with Python (or R) for data analysis, visualization, and automation
1-2 years of experience with data visualization tools such as Tableau
Ability to effectively articulate complex ideas in simple and effective presentations to a diverse group of stakeholders
Extremely comfortable with Excel, PowerPoint, Keynote
Passion and deep understanding of the technology, media, and entertainment space
Ability to work collaboratively and build effective relationships across teams to solve and operationalize complex business problems.
An entrepreneurial, roll up your sleeves attitude and willingness to perform tasks with a range of difficulty from routine tasks to preparing analysis for senior management.
Effective in working autonomously to get things done and taking the initiative to anticipate needs of teams and senior management
BENEFITS AND PERKS:

At JioSaavn, we blur work and play, and you get all the perks of a global company. You will get to work with a dynamic group of entrepreneurs, who are delivering results and working zealously across time zones to make a difference in the way the world experiences music. We love what we do, and we think you will too.

Group Mediclaim

Flexible vacation policies

Free healthy (and unhealthy) lunches & snacks

JioSaavn sponsored team outings

Powered by JazzHR",4.2,"Saavn
4.2",Mumbai,"New York, NY",201 to 500 employees,2007,Company - Private,Music Production & Distribution,Media,Unknown / Non-Applicable,-1
Data Scientist (Risk Analytics & Modeling),-1,"Data Scientist (Risk Analytics & Modeling)


Nov. 2, 2017

Experience:
Minimum 2 years of experience in implementing statistical/machine learning algorithms (regression, decision trees, SVM) and statistical programming tools (R/Matlab/Octave/Weka)
Proficiency in programming: R/Python/VBA
Strong background in statistics and probability
Experience in handling large structured and unstructured dataset
Knowledge and experience in structured finance products (securitization structures) would be a plus
Excellent writing, oral communication and presentation skills
Qualification: PGDM/Masters degree in Maths/Statistics/Econometrics/Economics/Finance/Engineering /other quantitative disciplines. Also Actuaries/FRM/CFA/CQF/PRM certification would be a plus.

Job Description: Lead the Business Analytics for Credit portfolio Analysis of Loan Pools of NBFC & Micro Finance Companies

Primary Responsibilities:
Develop and implement new (maintain and use existing) statistical/machine learning models to identify performance and risk drivers in the credit portfolio
Develop and implement new (maintain and use existing) risk and performance assessment models to measure risk and performance in the portfolio
Manage large loan level and borrower level data used for risk and learning models
Measure the risk and performance indicators for debt and structured finance products using existing and new models
Perform qualitative and quantitative analysis of various performance metrics for structured transactions
Document the analysis methodology and findings in report and present the analysis to the internal and external stakeholders/platforms (model notes, white papers, working papers, etc.)
Contribute towards other risk management work done by the risk management function
Travel not more than 20% of the time to meet partners and understand the lending models",-1,LoanXpress,Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"Summary


Do you get excited by intellectually stimulating problems? The Senior Data Scientist has to have a mix of advanced technology, customer and strategic business acumen. You will work in and lead teams as technical domain expert addressing statistical, machine learning and data understanding problems. You will be part of a data science or cross-disciplinary team on commercially-facing development projects, typically involving large, complex data sets. These teams typically include statisticians, computer scientists, software developers, engineers, product managers, and analysts

What you get to do

Develop analytics solutions to address customer needs and opportunities
Work alongside software developers and data engineers to translate algorithms into commercially viable products and services
Work in technical teams in development, deployment, and application of analytics solutions, leveraging technical components
Take responsibility for insights, reports, annotated code, and other projects artifacts to document, archive, and communicate outcomes to client and prospects based on these
Be responsible for entire solutioning and implementation cycle: From definition of business questions and hypotheses, to data sourcing and preparation, model development, and insight generation. Output of these analyses will be the basis for strategic resource allocation by BU and Leadership
Collaborate closely with other functions to advise, and support Business leadership in various types of advanced quantitative analyses, including but not limited to: Marketing Mix Analysis, Advanced Segmentation & Targeting, Personalization, Chatbot & Personal Assistant, CLTV etc
Lead and mentor a highly motivated team with exceptional talent
Work with the Business Development team in the pre sales & pilot engagements for analytics engagements
Evangelize TEG’s vision through case studies, participation at conferences, and creating thought leadership articles

What you will need to make an Impact
Should maintain high standards of quality and thoroughness. Should be able to monitor accuracy and quality of others work
Ability to lead new initiatives, prepare project plans and other supporting information
Experience across verticals will be a plus
Strategic business acumen, focus on results, passion for keeping up with media and technology trends
Ability to influence cross-functional and upper management to impact decision-making
Ten years of progressive advanced analytics work experience
Experience in marketing mix modeling, promotional response and price modeling, forecasting, optimization, simulation, and/or decision analysis
Post-graduate degree (Master’s/Ph.D) in a quantitative field (Statistics, Management Science, Operations Research, Engineering, Finance, Applied Mathematics, Mathematics, Business Administration etc, from Tier-1 institute",3.1,"TEG Analytics
3.1",India,"Bengaluru, India",51 to 200 employees,2008,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
MASTER DATA SCIENTIST,-1,"The Data Scientist will be part of the Core Data Scientist Team. This team identifies and develops advanced analytics statistical model, machine learning methods and solutions for our clients to improve various business outcomes.

The objective of the team is to:
Successfully develop, conceptualize and test various statistical models.Integrate the outcomes as real time analytics to create value for clients in areas and through means not immediately apparent to clients.

Job location:
Bangalore. Candidate should be flexible to travel & open for onsite positions within India & outside India for short-durations of 4 to 6 months.

Industry Focus:
Manufacturing, Financial Services, Investment Banking

Experience:
4 to 7 years of research experience in Statistical and Machine Learning Models. PhD freshers can also apply (Thesis submitted).

Qualifications:
Masters in a quantitative discipline such as Mathematics, Statistics & Machine Learning
Hands-on experience in running various methods in Supervised & Unsupervised ML like Regression, Classification, Clustering Random forest, k-NN, k-means, boosted trees, SVM, Neural Network, dimension reduction, model optimization, text mining, statistical modeling, data mining, exploratory data analysis, hypothesis testing & descriptive statistics.
Compelling communication and influencing skills. Should be able to communicate results and key findings to the stakeholders in a clear, concise and business friendly manner.
Ability to think creatively in solving problems real time.
Experience in diagnosis and prognosis of machines for early detection of signs of failure using ML techniques, using sensor data to analyze trend & patterns for industrial problems will be an added advantage.",-1,Inference Labs,Bengaluru,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Research Data Scientist,-1,"KEY RESPONSIBILITIES

Contribute to the strategic development of AQ analytics and create blueprints.
Design and deliver innovative, state-of-the-art machine learning products and platforms in-line with AQ’s go-to-market strategy.
Research new or adapt existing machine learning approaches to provide decision support to some of the leading marketers in the world.
Be involved across all the different stages: from data discovery/generation and feature engineering to model building and prototype design.
Partner with various stakeholders (within AQ as well as the larger Kantar organization) to innovatively answer key business questions.
Empower the growing AQ community to generate value from existing data assets.
Frame optimal analytical solutions to business problems by leveraging the latest developments in Machine Learning.
Be a thought-leader, keeping up with the academic and industry trends.

ESSENTIAL SKILLS & QUALITIES

Excellent theoretical understanding of machine learning concepts and practice.
Experience in various statistical and machine learning models.
Strong expertise in one of the following - Bayesian Modelling, Classification Models, Cluster Analysis, Neural Networks, Non-parametric Methods, Timeseries Models, Stochastic/ Markov Models, NLP etc.
Proficiency in statistical and other tools/languages – preferably R/ Python.
Knowledge of numerical optimisation methods.
Knowledge of NLP and related solutions.

QUALIFICATIONS

Graduate degree in Applied Statistics, Mathematics, or Computer Science from a premier institute.
4 years of experience building cutting edge analytic solutions from scratch.

SALARY & OTHER DETAILS

Salary including benefits will be based on prior experience & qualifications and will match industry standards.
To apply, please write to careers@aqinsights.com, stating the job ID you are applying for along with your resume.",3.7,"Analytics Quotient
3.7",Bengaluru,"Bengaluru, India",201 to 500 employees,2008,Company - Private,Consulting,Business Services,₹1 to ₹5 billion (INR),-1
Senior Data Scientist - Mathematical Finance,-1,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.

What is the Senior Data Scientist – Mathematical Finance – Client Analytics group responsible for?
Works individually in support of a Fintech (Wealth Management) initiative.
Designs, develops and programs methods, processes, and systems to consolidate and analyze structured or unstructured, diverse “big data” sources to generate actionable insights and solutions for on-going research and product enhancement.
Develops and codes software programs, algorithms and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources.

What are the ongoing responsibilities of an Senior Data Scientist – Mathematical Finance?
Mathematical Modelling:
Demonstrates Expertise in advanced mathematics, especially mathematical finance
Demonstrates a good grasp of probability distributions and stochastic calculus
Designs and validates mathematical models to find interlinkages and applications of academic models within a business context
Works on mathematical optimization modules similar to Traveling salesman problems under multivariate constraints. Familiarity with Lagrangian multivariate optimization problems a plus
Analyzes and interprets the results of research experiments through statistical models Solves analytical problems utilizing large structured, semi-structured and un-structured data in a distributed processing environment

Data Analysis:
Collects data from disparate systems, analyzes and delivers the data as intelligence that is actionable
Uses distributed and parallel processing frameworks like Spark for the analysis
Statistical Analysis (Data Mining and Advanced Analytical Techniques)
Develops predictive, statistical, behavioral, or other models using supervised and un-supervised machine learning / statistical modeling techniques
Performs ad hoc statistical and data mining analyses
Training, Research and Development

What ideal qualifications, skills & experience would help someone to be Successful?
Master’s degree in Mathematical Finance / Quantitative Finance / Financial Engineering from Tier-1 or Tier -2 Institutes highly preferred
Ph.D in Mathematics, Statistics, Econometrics, Engineering or related disciplines, from Tier-1 or Tier -2 Institutes. (Mandatory)
4-6 years of experience in data science.
Certifications in Financial Mathematics or related subjects from institutes such as IIQF, IFMR, TIFR etc would be highly valued.

Experience:

4-6 years of experience in data science
Understanding and prior experience with financial markets (Mandatory)
Knowledge of and Experience with Stochastic calculus, Simulations, Linear Algebra, statistical modeling, Time series analysis (especially state space models) (Mandatory)
Knowledge and experience of key machine learning and deep learning framework, e.g. Keras, TensorFlow
Hands on Experience in Python (Mandatory)
Proven Experience in Statistical and Mathematical modelling
Experience in SQL

Other Skills:


Proven ability to take initiative and work under pressure in a changing/growing environment
Should be self-driven and be able to work in an unstructured environment
Proven ability to work with ambiguous (not well defined) challenges
Excellent written and verbal communication skills
Displays curiosity to learn and learns independently
Ability to translate business challenges into analytical problems
Able to cultivate interpersonal customer and co-worker relationships
Ability to articulate and explain statistical / machine learning techniques to business partners
Ability to work individually or as a team as task requires

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
Data Analyst,-1,"Parity Computing, a unit of RELX/Elsevier, is inviting applications for data analyst positions for its OrgDB product to curate organization metadata and name variants to help produce excellent organization publication profiles. The work involves investigating research organizations and their structure to extract and normalize data, interpreting the metadata policies, deciding the best approach to curate the data, and analyzing the impact of curation on organization publication profiles. We are looking for individuals who can conduct excellent research, work independently, and pay attention to detail. Premium is placed on those individuals who can produce a high-quality content.

Parity’s OrgDB product is the leading authoritative database of the world’s research producing organizations. OrgDB powers STM industry applications for characterizing organizations and accurately attributing their research works.

Required skills

Able to think analytically, use a systematic and logical approach to analyze data, problems and situations.,

Familiarity with scientific research, publications, universities and research organizations,

Ability to perform independent research on topics related to the structure of and relationships among universities and research organizations,

Ability to think abstractly and collect and classify entities such as person and organization names, organizational structure, scientific expertise, and related entities,

Ability to interpret policies, follow them consistently, develop positive and negative examples for each policy, and assist in fine tuning policies

Ability to assess the quality, completeness, and other characteristics of the content

Preferred qualifications

Post Graduation

· Outstanding oral and written communication skills

· Skills in working with databases, software tools, and modeling languages such as XML.

· Demonstrated ability to meet deadlines

· Excellent planning, organizational, and time management skills.

· Ability to work under pressure and meet deadlines

Elsevier is an equal opportunity employer: qualified applicants are considered for and treated during employment without regard to race, color, creed, religion, sex, national origin, citizenship status, disability status, protected veteran status, age, marital status, sexual orientation, gender identity, genetic information, or any other characteristic protected by law. If a qualified individual with a disability or disabled veteran needs a reasonable accommodation to use or access our online system, that individual should please contact 1.877.734.1938 or accommodations@relx.com.

Elsevier is a global information analytics business that helps institutions and professionals progress science, advance healthcare and improve performance for the benefit of humanity. We help researchers make new discoveries, collaborate with their colleagues, and give them the knowledge they need to find funding. We help governments and universities evaluate and improve their research strategies. We help doctors save lives, providing insight for physicians to find the right clinical answers, and we support nurses and other healthcare professionals throughout their careers.Elsevier provides digital solutions and tools in the areas of strategic research management, R&D performance, clinical decision support, and professional education; including ScienceDirect, Scopus, SciVal, ClinicalKey and Sherpath. Elsevier publishes over 2,500 digitized journals, including The Lancetand Cell, more than 35,000 e-book titles and many iconic reference works, including Gray?s Anatomy. Elsevier is part of RELX Group, a global provider of information and analytics for professionals and business customers across industries. Elsevier employs over 7,000 people in more than 70 offices worldwide. We are an employer of choice, attracting and developing talented and creative people who thrive in a challenging and fast-paced environment. We offer an excellent compensation and benefits package as well as a real opportunity for career growth in a growing organization.",4.4,"Elsevier
4.4",Bengaluru,"Amsterdam, Netherlands",5001 to 10000 employees,1880,Subsidiary or Business Segment,Publishing,Media,₹100 to ₹500 billion (INR),"Clarivate Analytics, Springer Nature, Thomson Reuters"
Sr. Data Modeler,-1,"The role sits within our Decision Analytics business, one
of our four Global Business Lines.

Experian Decision Analytics helps client achieve and
sustain significant growth. We do this by enabling clients to make
analytics-based customer decisions that support their strategic goals. As
experts in uniting business understanding with consumer and business
information, analytics and strategy execution, we empower clients to optimise
customer value and actively manage it over time. This role therefore has clear
accountability for creating measurable value within our client organisations.

Purpose of Role

As a member of custom analytics delivery team in India to
provide analytical solution to clients. Individual will be responsible to
deliver on the agreed approach for analytical projects. Develop new methodology
for identifying credit risk/operations risk & marketing effectiveness.

CANDIDATE PROFILE

Successful candidates will have knowledge of statistical
modelling/data analysis tools (SAS, Python, R), techniques. They will be
actively contributing in developing right solution for the client and would be
working closely with Team Lead / Manager to deliver as per agreed scope.

We are looking for someone who :-
· Proven track record in risk
analytics preferably in Indian BFSI industry
· Identify & deliver appropriate
analytics solutions
· Use analysis and customer insights
to develop value propositions for customers
· Maintain and enhance the suite of
suitable analytics products for India.
· Actively seek to share knowledge
within the team
· Share findings with peers from other
teams and management where required

· Experienced in
Analytics team management

· Become a
trusted advisor for analytics within the organization.

Essential Duties and
Responsibilities

· Responsible
for developing high quality analytical and value added services for the clients

· Responsible
for adhering to timelines as promised to the client

· Handling
around 2-3 client engagements delivery at any given point in time

· Work closely
with team members to deliver the apt solution and contribute to brainstorming sessions

· Engage
Business/Technical Consultants and delivery teams appropriately so that there
is a shared understanding and agreement as to deliver proposed solution

Actively contribute to a culture where the fair treatment
of customers is at the heart of the Experian business. Take personal
responsibility to ensure that you adhere to all regulatory requirements and
apply appropriate controls in the interests of our customers.



Knowledge :

· Good
understanding of analytics preferably in Retail lending industry.

· Knowledge of
statistical modelling/data analysis tools (SAS, Python, R), techniques and
market trends

· Knowledge of
different modelling frameworks like Linear Regression, Logistic Regression,
Multiple Regression, LOGIT, PROBIT, time- series modelling, CHAID, CART etc.

· Knowledge of
Machine learning & AI algorithms such as Gradient Boost, KNN, et will be
advantageous

Experience :

· 2-5 years of
relevant work experience in BIU unit of a large bank/financial institution
and/or in an consulting firm dealing
with developing analytics, preferably for banks or telecom.

· Experience on
handling large data volumes using data analysis tools and generating good data
insights

· Hands on
experience in Excel and Excel Macros for basic data analysis.

Qualifications :

· Masters’ degree
in Statistics, Mathematics, Economics, Business Management or Engineering from
a reputed college",4.1,"Experian
4.1",Mumbai,"Dublin, Ireland",10000+ employees,1980,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),"Equifax, Acxiom, TransUnion"
Machine Learning-AI - Data Science,-1,"Job Skill:AI - Data Science
Designation: Career Level - 10-Analyst
Job Location: Bengaluru
Qualifications: Any Graduation
Years of Experience: 5-7 years
About Accenture


Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Combining unmatched experience and specialized skills across more than 40 industries and all business functions underpinned by the worlds largest delivery network Accenture works at the intersection of business and technology to help clients improve their performance and create sustainable value for their stakeholders. With 500,000 people serving clients in more than 120 countries, Accenture drives innovation to improve the way the world works and lives. Visit us at www.accenture.com



Job Summary


You will be aligned with our Artificial Intelligence vertical and help us apply your expertise in building world class solutions, conquering the business problems, addressing technical challenges using AI Platforms and technologies. Utilize the existing frameworks, standards, patterns to create architectural foundation and services necessary for AI applications that scale from multi-user to enterprise class. Demonstrate self as an expert by actively blogging, publishing research papers and creating awareness in this emerging area.

You will be working as a part of Machine Learning team which provides computers with the ability to learn without being explicitly programmed. It focuses on the development of computer programs that can change when exposed to new data.

You will be responsible for AI - Data Science wherein you will be working in operations that follow multiple approaches for project execution from adapting existing assets to use cases, exploring third-party and open source solutions for speed to execution. You will leverage the vast global network of Accenture to collaborate with internal teams to create unique solutions.
Solid knowledge in at least one of the following Supervised and Unsupervised Learning, Classification, Regression, Clustering, Neural Networks, Ensemble Modelling, Multivariate Statistics, Non-parametric Methods, Reliability Models, Markov Models, Stochastic models, Bayesian Models are required for this role.

Good to have skills: AI - Data Science,Good communication skills

Roles and Responsibilities


In this role you are required to do analysis and solving of increasingly complex problems. Interaction is with peers within Accenture before updating supervisors. Likely has some interaction with clients and/or Accenture management. Minimal instruction on daily work tasks and a moderate level of instruction on new assignments will be provided. Decisions made by you impact your own work and may impact the work of others. In this role the person would be an Individual contributor and/or oversees a small work effort and/or team",3.9,"Accenture
3.9",Bengaluru,"Dublin, Ireland",10000+ employees,1989,Company - Public,Consulting,Business Services,₹500+ billion (INR),"Cognizant Technology Solutions, EY, McKinsey & Company"
Data Analyst,-1,"Responsibilities:
Create data-driven analysis and insight to share management decisions.
Access data through internal and external reporting and business intelligence tools.
Summarize and circulate key findings in the form of presentations, email, slack and project management software.
Primary responsibilities for this position include but are not limited to:
Work efficiently with clients and analytics partners to define, extract, and synthesize available data and share results and insights with team members.
Analyze scenarios to assess the before/after impacts of target market selection, changes to the software product. Skills Required:
Comfortable manipulating, transforming, and analyzing complex, high-volume, high-dimensional data from varying sources.
Excellent presentation and communication skills; comfortable explaining technical topics to non-technical users.
Good client management skills with a strong grasp of both technical and business perspectives.
Hands-on experience in performing quantitative/statistical analysis, preferably for product based company (mobile & web apps).
Experience in using tools like Tableau for creating dashboards, reports and data exploration (strongly preferred).
Strong hands-on experience with SQL, dashboarding and reporting, involving very large datasets and multiple data sources, with the ability to interpret data and produce meaningful insights.
Experience with clickstream analytics(Google Analytics, Adobe Analytics, Appsee, Glassbox, etc) preferred.
Proven ability to work in a fast-paced environment, and to meet changing deadlines and priorities on multiple simultaneous projects.
Enjoy working in both individual and team settings. APPLY NOW",3.7,"Galaxy Weblinks
3.7",Indore,"Indore, India",51 to 200 employees,1998,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Scientist (1-3 yrs),-1,"Role & Expectations
Data scientists who are good with knowledge of statistics & programming in R/Python, transforming the business problem to analytics framework and weaving final results into actionable items for customers. Share your resume at [email protected]

Requirements and General Skills
Leading and managing analytics engagements
Coordinate daily interaction with the client and in-house analytics team
Propose and finalize modeling techniques relevant to a business problem
Drawing managerial insights through Statistical Techniques and Predictive Modelling
Managing client satisfaction, feedback process, managing/tracking workflow
Drawing actionable recommendations from data for senior management
Build sales and marketing collateral for prospects
Qualifications & Technical Skills
2 – 4 years of experience in Advanced Analytics within consulting environment
Hands-on with R & Python with application of varied machine learning algorithms i.e. Random Forests, Decision Trees, SVM, Neural Networks, Linear/Logistic Regression, Clustering, NLP
Demonstrated experience in translating business problems into analytics frameworks and translating analytics results back to final results for client consumption. Able to decide modeling techniques that can be applied to solve business problems effectively.
Consulting Skills: Ability to impact business decisions through analytics and research
We are an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",4.0,"Valiance Solutions
4.0",Noida,"Noida, India",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"We are looking for a Machine Learning (ML) Engineer to help us create artificial intelligence products. Machine Learning Engineer responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming. If you also have knowledge of data science and software engineering, we'd like to meet you. Your ultimate goal will be to shape and build efficient self-learning applications.

Responsibilities:
Designing and developing machine learning and deep learning systems.
Running machine learning tests and experiments.
Implementing appropriate ML algorithms.
Study and transform data science prototypes.
Design machine learning systems.
Research and implement appropriate ML algorithms and tools.
Develop machine learning applications according to requirements.
Select appropriate datasets and data representation methods.
Run machine learning tests and experiments.
Perform statistical analysis and fine-tuning using test results.
Train and retrain systems when necessary.
Extend existing ML libraries and frameworks.
Keep abreast of developments in the field.

Requirements:
Proven experience as a Machine Learning Engineer or similar role.
Understanding of data structures, data modeling and software architecture.
Deep knowledge of math, probability, statistics and algorithms.
Ability to write robust code in Python, Java and R.
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn).
Excellent communication skills.
Ability to work in a team.
Outstanding analytical and problem-solving skills.
BSc in Computer Science, Mathematics or similar field; Master's degree is a plus.",3.9,"Involvio
3.9",Bengaluru,"New York, NY",1 to 50 employees,-1,Company - Private,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Robotic Process Automation Data Scientist,-1,"Location: Bangalore- India
Job ID: 19WD35532

Position Overview
The Robotic Process Automation Data Scientist is responsible for developing automation solutions based on a solution design provided by the Technical Solution Architect leveraging existing software or developing their own solutions using a variety of technologies. This role will support the RPA team in developing and maintaining statistical models to allow us to automate more judgement related processes.

Responsibilities
Research and develop statistical learning models for data analysis
Collaborate with product management and engineering departments to understand company needs and devise possible solutions
Communicate results and ideas to key decision makers
Implement new statistical or other mathematical methodologies as needed for specific models or analysis
Ability to turn high-level requirements into a working system through iterative development
Strong design and development foundation of applications and solid understanding of methodologies, technology and platforms that support design
Flexible to adapt to changing requirements
Communicate to colleagues or customers during the product development to make sure it fits design
Responsible for the different facets of the tool/application development process including: research, design, programming and testing
Perform due diligence and assessment of business processes to determine target processes ideal for automation
Program new tools and automations using programming languages and available platforms to deliver operations efficiencies
Identify opportunities to expand the deployment of existing productivity tools, proactively research for new tools and automations in operations within area of responsibility
Provide training to end users
Prepare release notes
Responsible for successful deployment of project
Support all tools and automations after delivery in accordance to established Automation Support processes
Understand business requirements and help translate the same into design
Optimize solution performance
Minimum Qualifications
Master’s Degree in Computer Science, Statistics, Applied Math or related field
7 years’ practical experience with R, SAS, ETL, data processing, database programming or data analytics
Extensive background in data mining and statistical analysis
Able to understand various data structures and common methods in data transformation
Excellent pattern recognition and predictive modeling skills
Experience with programming languages such as Java/Python an asset
Excellent understanding of current Data Science and Automation products and technology & upcoming trends in technology landscape
Experience in product development environments and SDLC
Proficiency with some of the following technologies: C# , Java, HTML CSS, SQL
Proficiency and experience with Microsoft Technology (VB .NET, Windows, Internet Explorer, SQL Server, Web Services)
Proficiency and experience with scripting languages (e.g, perl, powershell, bash, vbs, etc.)
Proficient in requirements management
Skilled in process analysis and data modelling
Self-Managing
Analytical and problem-solving skills
Dealing with ambiguity in a fast-paced environment
Preferred Qualifications
Some experience as an RPA developer using UiPath, Automation Anywhere, or Blue Prism
Knowledge of SAP systems
Experience in an Agile software development team",4.0,"Autodesk
4.0",Bengaluru,"San Rafael, CA",5001 to 10000 employees,1982,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),-1
Data Scientist/Senior Data Scientist - Deep Learning,-1,"Danaher Corporation

Danaher is a global science and technology innovator with more than 59,000 associates committed to helping our customers solve complex challenges and improve quality of life around the world. Our world class brands have unparalleled leadership positions in some of the most demanding and attractive industries and our technologies address a broad range of societal needs:
Protecting the global water supply and ensuring environmental stewardship
Protecting the world's food supply and verifying pharmaceutical dosages and authenticity
Leading scientific research and advancing patient health with the highest diagnostic confidence
Improving dental outcomes and promoting access to comfortable patient care around the world
Danaher generates over $20 billion USD of annual revenue from business segments: Life Sciences, Diagnostics, Water Quality, and Product Identification.

For additional company details, see www.danaher.com.

Danaher Digital

Danaher Digital is our digital innovation and acceleration center where were bringing together the leading strategic product and business leaders, technologists and data scientists for the common purpose of accelerating development and commercialization of disruptive and transformative digital solutions into the marketplace.

We accelerate Danahers digital innovation journey by partnering with Danaher operating companies (OPCOs) to monetize and commercialize the potential of emerging digital trends.

Located in Silicon Valley, the heart of global innovation, Danaher Digital is ideally situated to capitalize on the digital mega trends transforming our world, including IoT, Data, AI, cloud, mobile, Augmented Reality (AR), Blockchain and other Digital frontiers.

Position Description


This position reports to Director of Data & Analytics and is responsible for leading the vision, design and development of scalable Machine Learning (ML) solutions for Danahers IoT and Analytics (ML) initiatives. You will work with other Data Scientists, Software engineers and business groups and lead the development of innovative ML models for Danahers big data from health sciences, medical diagnostics, industrial and other markets. You will use your Agile experience to work collaboratively with other Product Managers/Owners in geographically distributed teams.

Responsibilities
Understand business challenges and propose new modeling and algorithmic solutions that leverages the latest in statistical and machine learning techniques.
Study new data sources and find insights/correlation to investigate how data can be used to solve new business challenges. Create prototypes with data sets and provide guidance on leveraging and combining new data sources for new business insights.
Apply statistical analysis and modeling techniques on small and large datasets to solve specific business problems in diverse industrial domains.
Provide strategic leadership in selection of platform, tools, techniques and processes in the practice of Data Science discipline.
Work collaboratively with other Product Owners/Product Managers from other business units and/or customers to translate business requirements in to technical requirements that can be answered with statistical and machine learning techniques. Guide and work with engineers and domain owners to produce the required data if not available.
Provide mentorship to other Data Scientists in the team.
Own and drive contemporary best practices in applying and deploying data science at scale.
Requirements
Advanced degree (Ph.D. preferred) in Engineering, Science, Mathematics, or related
Expert knowledge of statistical programming languages such as R, Python, and SQL.
Expert knowledge of probability, statistics and machine learning theory including experience in: Deep Learning, Clustering, Decision Trees, Logistic Regression, Dimensionality Reduction, and Random Forests for prediction and recommendations.
Must have delivered data science components as part of a commercial solution at scale.
Readiness to work with engineering teams to develop a prototypes of software products leveraging exploratory data analytics.
Desirable: Consultative experience providing technology and solution consultation to customers/clients.
Expert knowledge of data visualization, using tools such as Tableau or PowerBI.
Experience working with the cloud computing, including AWS and/or Azure
Experience working with distributed data storage and computing, including Hadoop, Spark, Cassandra, and so forth
Experience working with traditional databases, such as MS SQL, Teradata, MySQL, and Postgres.
Expert knowledge of Experimental Design and Statistical Decision Theory
Agile mindset to jump in to a diverse set of projects.
Ability to summarize results from analysis to a diverse set of audiences with varying background and technical skills.
Willingness to travel up to 25% required.
Experience


Required:
7+ years working with business stakeholders as a trusted adviser in Data Science and Monetization
7+ years communicating effectively with project and business stakeholders about Data Science and data science projects
5+ years building production-ready image or video analysis models using Deep Learning techniques such as CNN and RNN.
3+ years leveraging tools such as TensorFlow or Theano.
5+ years providing mentorship, education, and thought leadership to organizational stakeholders regarding best practices in data science
5+ years translating business requirements into data science problem statements and execution tasks
5+ years leading the organization towards adoption of a data-driven culture
3+ years mentoring and supporting junior team members
Desired:
7+ years building operations analytics models, including demand forecasting, inventory optimization in manufacturing or related industries.
7+ years building IoT analytics models, including failure diagnosis and failure prediction
7+ years executing customer advanced analytics, including marketing mix analysis, segmentation, retention modeling, targeted marketing, basket analysis, next product recommendation, and so forth.
5+ years executing data science in the fields of life sciences, medical diagnosis, biostatistics, and so forth.
Danaher Corporation and all Danaher Companies are equal opportunity employers that evaluate qualified applicants without regard to race, color, national origin, religion, sex, age, marital status, disability, veteran status, sexual orientation, gender identity, or other characteristics protected by law. The EEO is the Law poster is available here.",-1,Danaher Digital,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Principal Data Scientist - BLR,-1,"As a Data Scientist at Noodle.ai, you will collaborate with our Enterprise Services team,Software Engineers, Designers, and industry-specific experts from our customers. You willvbuild a deep understanding of the business problems our customers are tackling and then develop, test, and deploy advanced machine learning algorithms. As we grow, you will also develop reusable IP to help us move faster, dive deeper, and work more efficiently by generalizing the algorithms, methodologies, and supporting infrastructure that you build. As one of the early hires to join the Noodle.ai team, you will have a significant impact on the future of Enterprise Artificial Intelligence.

Job responsibilities:
Implement a breadth of different modeling approaches/ techniques in machine learning
Manipulate and prepare large, heterogeneous data sets to support advanced analytics
Iteratively conceptualize, design and build data-driven analytical models
Develop processes and tools to monitor and analyze model performance and data accuracy
Translate deep mathematical concepts and practices into language that non-experts can understand and build upon. And conversely, translate business needs and user needs into language and concepts that other data scientists can understand and work with.
Productionalizing machine learning code and interfacing with industry standardmsoftware systems
Understand and manipulate unstructured data from different platforms.
Demonstrate proficiency at real-world modeling problems/DS problems - getting to a result that demonstrably generate business value
Qualifications:
Required:

Graduate degree in a relevant field (Computer Science, Operations Research, Statistics, Applied Math...) or Bachelors degree and 2-4 years applying advanced AI techniques to real-world problems

Good to have:
7+years of experience applying advanced AI techniques to real-world problems
Experience tackling data science problems characterized as high-dimension, low sample size (i.e., lots of potentially predictive features and highly diverse but low quality or highly sparse data.)
Knowledge & understanding of a functional area of focus (i.e. Experience applying advanced analytics to supply chain optimization, demand forecasting, and/or revenue management)
Knowledge & understanding of an industry area of focus (i.e. retail, manufacturing,CPG, 3PL, travel...)
Skills and Competencies:
Experience with common analysis tools (SQL, R, and Python).
Demonstrable familiarity with code and programming concepts.
Knowledge of Spark and/or Hadoop
Knowledge of machine learning areas and techniques - Supervised machine learning,Unsupervised machine learning, Time series, Natural language processing, Outlier detection, Computer vision, Recommendation engines, Survival analysis,
Reinforcement learning, and Adversarial learning
Knowledge of data visualization tools - ggplot, d3.js and Matplottlib, and Tableau
Strong problem solving skills with an emphasis on product development
Focus on delivering value and building lasting relationships through collaboration in an open and respectful working style
Passion for learning and a desire to grow",4.5,"Noodle.ai
4.5",Bengaluru,"San Francisco, CA",201 to 500 employees,2016,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),-1
Data Scientist (Open),-1,"Qualification: Masters in statistics, mathematics or any other masters with very good analytical skills

Skills required:
– Experience in using any of the deep learning frameworks ( Tensorflow, Keras, and Pytorch etc) in a professional environment.
– Expertise in Python programming language with exposure to computational libraries like Pandas, Numpy etc.
– Expertise in traditional machine learning frameworks such as Scikit-learn, Stanford NLP or NLTK.
– Comfortable in solving both computer vision ( Classification, Segmentation, and Object detection ) and NLP problems ( Text classification, Named entity recognition etc).
– Experience in using CV libraries like OpenCV etc.
Experience: 1-4 yrs
Job location: Ahmedabad
Employment type: Full time",-1,Protocolzone,Ahmedabad,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"Role Summary:
We are looking for a highly motivated individual, passionate about technology to join Baker Hughes Digital team. As the Senior Data Scientist, in Baker Hughes Digital, you will focus on developing impactful and innovative analytics products for the O&G industry. The candidate will be responsible for designing analytics for products and solutions, leverage strong machine learning expertise to develop new analytics for driving growth in asset, application & industry coverage and lead engagements with external/internal customers. The candidate is also expected to mentor other engineers in analytics methods.

Essential Responsibilities:
Work in cross-functional teams to translate algorithms into commercially viable products and services.
Contribute to technical teams in development, deployment and application of applied analytics, predictive analytics and prescriptive analytics capabilities.
Develop self-learning systems that can predict failures and autocorrect based on multiple data sources
Work with the engineering team to incorporate your analyses and solutions, including working with the visualization team to create intuitive UI and rich UX stories. Partner with data engineers on data quality assessment, data cleansing and data analytics efforts
Gather and analyze data, devise innovative data science solutions and build prototypes to enable development of high-performance algorithms in scalable, product-ready code.
Initiate and propose unique and promising modeling features, develop new and innovative algorithms and technologies, pursuing patents where appropriate
Stay current on published state-of-the-art algorithms and competing technologies.
Contribute to the development of software and data delivery platforms that are service-oriented with reusable components across teams (multiple teams) that can be orchestrated together into different methods for different businesses.
Research and evaluate emerging technology, industry and market trends to assist in project development and/or operational support activities to for multiple teams or complex scenarios.

Qualifications/Requirements:
MS Degree in Computer Science or in “STEM” Majors (Science, Technology, Engineering and Math)
A minimum of 2 years as data scientist
A minimum of 3 years of technical hands-on coding experience

Eligibility Requirements:
Legal authorization to work in India. We will not sponsor individuals for employment visas, now or in the future, for this job
Any offer of employment is conditioned upon the successful completion of a background investigation and drug screen
Must be willing to travel

Desired Characteristics:
PhD in Computer Science or in “STEM” Majors (Science, Technology, Engineering and Math)
Strong distributed systems and architecture knowledge, and experience with multitier architecture
Mission critical systems experience is preferred
Ability to manage complex technical projects.
Demonstrates expertise in problem solving and technical innovation.
Demonstrated experience of delivering on commitments to clients.
Demonstrates capability of 'rolling up sleeves and getting hands dirty'.
Works well in fast paced growing environment.
Provides excellent influential communication skills and business acumen to both an arbitrator and advocate for technical issues.
Experience developing applications in an agile/DevOps environment would be a distinct advantage
Solid understanding of software development tools & infrastructure

Effective teaming and problem-solving abilities

Strong interpersonal and leadership skills
Able to interface effectively with all levels of the organization and external customers

Technical Expertise:
Proven experience coding in Machine Learning/AI techniques including Deep learning techniques (RNN, CNN, GAN, etc), Support Vector Machines; Regularization Techniques; Boosting, Random Forests, Ensemble Methods, image/video/audio processing, Bayesian modeling, time series modeling
Demonstrated experience in Parallel programming frameworks for GPUs, TPUs
Demonstrated ability to develop containerized solutions (Docker/Mesos etc)
Strong implementation experience with high-level languages and frameworks such as R, Python, Perl, Ruby, Scala, Apache Spark, Storm, SAS
Demonstrated ability to work with a variety of Deep learning frameworks including TensorFlow, Keras, Caffe, CNTK, etc…
Strong hands-on skills in sourcing, cleaning, manipulating and analyzing large volumes of data including SQL and NoSQL databases
Experience with end-to-end modeling projects, from research to solutions to analytic products
Proven experience in using well-established supervised and unsupervised machine learning methods for large industry-strength data analysis problems.
Participates in enterprise strategy development, including environmental analysis, opportunity identification, value cases and business innovation portfolio development. Reviews and/or analyzes and develops architectural requirements at domain level, aligning architectural requirements with software development strategy.
Leads and facilitates the domain’s architecture governance process based on EA’s governance structure.
Leads teams in developing plans and assessing improvement options.

Business Acumen:
Create, analyze and manage projects that provide direct business benefit; demonstrate detailed knowledge of business operations and strategic direction, including merger & acquisition opportunities
Understand industry trends and competitive landscape and the implications for your business
Partner with business leaders to align projects with business goals and needs.

Leadership:
Recommends allocation of budget to meet architectural initiatives critical to business/mission success.
Develops the business case for approval.
Provides leadership, technology guidance and mentors others throughout their domain.
Define the skills, competencies in the skills and talents for architecture team members.
Facilitates dialogues that produce new perspectives and trigger recommendations for substantial innovative / enhancements, and analysis of consequences.
Influences through others.
Uses experts or other third parties to influence.
Builds direct and ""behind the scenes"" support for ideas, uses chains of indirect influence.

Personal Attributes:
Challenges conventional thinking and traditional ways of operating and invites stakeholders to identify issues and opportunities.
Takes a holistic systems perspective.
Envisions, compares and contrasts multiple potential long-range enterprise-wide futures.
Empathizes with multiple points of view

Locations:
Bangalore, India",3.6,"Baker Hughes
3.6",Bengaluru,"Houston, TX",10000+ employees,-1,Company - Public,Oil & Gas Services,"Oil, Gas, Energy & Utilities",₹500+ billion (INR),-1
Risk Analytics - Machine Learning Engineer,-1,"About this Opportunity

The incumbent will be responsible for studying data, discovering the information hidden and help making smarter and better decisions for the Business. The primary focus of the role will be on applying text and data mining techniques, doing statistical analysis and building high quality and high-performance prediction systems integrated with the Risk applications. They will also have proven experience in data analysis, modeling and implementing solutions along with sound understanding of capital markets and financial risk domain to be able to recommend the best-fit model and solution approach.

Business Unit: Global Chief Risk OfficeOur Risk Management teams work to protect the safety and soundness of our systems and are responsible for identifying, managing, measuring and mitigating a spectrum of key risk types including credit, market, liquidity, systemic, operational and technology in all existing and new products, activities, processes and systems.


What You'll Do
Collaborate with cross functional teams to collate data
Enhancing data collection procedures to include information that is relevant for building analytical solutions
Analyze, extract and understand meaningful patterns from the large volumes / dimensions of historical data by utilizing analytics techniques and SMEs’ inputs
Design, develop, evaluate and implement high quality innovative predictive/prescriptive models using open source tools such as R, Python, or similar scripting within Apache Spark/AWS cloud based big data environment
Support the team in creating/executing novel approaches to solve challenging problems by leveraging AI/ ML/NLP and Big Data/Cloud technologies
Collaborate closely with Business Partners/Analysts, Data Analysts, Application Development and other Data Scientists to integrate innovations and algorithms into useable data products
Doing ad-hoc analysis and presenting results in a clear manner
Aligns risk and control processes into day to day responsibilities to monitor and mitigate risk; escalates appropriately

Sound Like You?
Minimum of 6 years of related experience
Bachelor's degree preferred with Masters or equivalent experience
Additional Qualifications
Minimum of 3-5 years of related experience in Data analysis, Data Science, Modeling
Experience with SQL, Python, Big Data and Machine Learning Algorithms
Strong analytical and problem-solving skills
Great communication skills
Experience in Financial industry with focus on Risk Management is preferred
Experience in Data Visualization tools and AWS is a plus
Leadership Competencies
Accountability - Demonstrates reliability by taking necessary actions to continuously meet required deadlines and goals.
Global Collaboration - Applies global perspective when working within a team by being aware of own style and ensuring all relevant parties are involved in key team tasks and decisions.
Communication - Articulates information clearly and presents information effectively and confidently when working with others.
Innovation and Creativity - Thinks boldly and out of the box, generates new ideas and processes, and confidently pursues challenges as new avenues of opportunity.
Who We Are

With over 45 years of experience, DTCC is the premier post-trade market infrastructure for the global financial services industry. From operating facilities, data centers and offices in 16 countries, DTCC, through its subsidiaries, automates, centralizes and standardizes the processing of financial transactions, mitigating risk, increasing transparency and driving efficiency for thousands of broker/dealers, custodian banks and asset managers. Industry owned and governed, the firm simplifies the complexities of clearing, settlement, asset servicing, data management, data reporting and information services across asset classes, bringing increased security and soundness to financial markets. In 2018, DTCC’s subsidiaries processed securities transactions valued at more than U.S. $1.85 quadrillion. Its depository provides custody and asset servicing for securities issues from 170 countries and territories valued at U.S. $52.2 trillion. DTCC’s Global Trade Repository service, through locally registered, licensed, or approved trade repositories, processes over 14 billion messages annually. To learn more, please visit us at www.dtcc.com or connect with us on LinkedIn, Twitter, YouTube and Facebook.",3.3,"DTCC
3.3",Chennai,"New York, NY",1001 to 5000 employees,1973,Company - Private,Brokerage Services,Finance,₹50 to ₹100 billion (INR),-1
Sr Data Scientist - DNA,-1,"Neustar, Inc. is a leading global information services provider driving the connected world forward with trusted, holistic identity resolution. More information is available at https://www.home.neustar.

Job Requisition:

R-1661 Sr Data Scientist - DNA (Open)

Primary Location:

BANGALORE

Job Description:

The Data and Analytics organization at Neustar is the DNA of the company. The DNA encodes the essence of existence and character that drives continuous innovation with data, contin­uous insights with analytics and continuous evolution with cutting-edge data products and services. Our vision is to be the trailblazer in Connection Science driven information services that create meaningful value for our customers. Our mission is to enable cutting-edge data products & services delivered through superior data, unique insights and top-of-the-class technology solutions. We believe in developing a Collaborative, Creative, yet Competitive, Customer Centric culture. We are shaping the present and the future at Neustar and are seeking “TENXERS” who share the same DNA.

Job Description:

The Data Scientist will work on challenging problems extracting actionable information out of the many data sources available to Neustar, particularly geospatial data. They will assist in developing accurate and precise models of user behavior based on this geospatial data using various analytical tools, including data curation, data visualization, supervised, and unsupervised machine learning. The data sets under analysis are large, and growing larger still, and so the data scientist must be proficient in the design and development of CPU and memory efficient algorithms.

Application areas include Identity Resolution, Marketing Analytics Security and Fraud and other Business Solutions supported by our or our client’s data.

Data Scientists create prototypes of new algorithms and support Engineering teams in productizing these capabilities. Data Scientists work closely with various teams including data acquisition, data products, data sciences and various business units including marketing, security, and internet of things to ensure implementation of capabilities that enable the organization’s vision. The role is based out of India at the Neustar's offices in either Bangalore or Hyderabad.

Responsibilities:
Algorithm Development: Develop a deep understanding of all the data relevant to the problem to be addressed. Establish deterministic and probabilistic linkages between data sources and develop ways to extract and summarize the sought information in the data using a wide variety of statistical, data mining and machine learning techniques.
Prototyping: Create prototypes of productizable ways to perform the analysis at scale, provide documentation and help educate your colleagues in different function about the solution
Support Implementation: Closely work with product, engineering and client teams to incorporate Data Science capabilities into Neustar’s products and services
Skills and Experience:
Masters’s degree in Data Science, Statistics or a related field (we will consider applicants with a Bachelor’s degree and relevant work experience as well)
Solid understanding of fundamental data mining and statistics concepts and familiarity with real-world applications of these techniques
Solid knowledge of SQL in its various forms for traditional databases and distributed computing environments
Experience working with commercial and/or open source statistics and data mining packages
Experience working on large distributed datasets using HiveSQL, Spark, Python
Strong written and oral communication skills
Strong inter-personal collaboration skills. Being able to both work in groups or as an individual contributor
General curiosity, a willingness to experiment, pragmatism and the ability to handle ambiguity
Why work with us?
Because you love to build beautiful, innovative solutions that wow the customer
Because you believe in changing the status quo and are up for the challenge of your life
Because you know you can make a difference to people, places and things!
About Us

Every day, the world generates roughly 2.5 quadrillion bits of data. Neustar isolates certain elements and analyzes, simplifies and edits them to make precise and valuable decisions that drive results. As one of the few companies capable of knowing with certainty who is on the other end of every interaction, we’re trusted by the world’s great brands to make critical decisions some 20 billion times a day.

Neustar does not accept unsolicited resumes from external firms or agencies. Neustar will not be responsible for placement fees associated with unsolicited resumes.

DIVERSITY
Diversity, inclusion and teamwork are second nature to Neustar; and these values permeate our entire business structure. Neustar is committed to creating an environment where a wide spectrum of opinions and beliefs are actively sought, listened to and respected. Further, our talented workforce draws from the many geographic areas and markets in which Neustar operates worldwide, which represents a distinct competitive advantage. The rich and varied personal and professional backgrounds of our employees make Neustar a dynamic and rewarding company at which to build a career. We invite you to join us.

EOE of Minorities/Females/Vets/Disability
Neustar, Inc. considers all applicants for employment without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, or status as a Vietnam-era or special disabled veteran in accordance with federal law and other state and local requirements. Neustar, Inc., complies with applicable state and local laws prohibiting discrimination in employment and provides reasonable accommodation to qualified individuals with disabilities in accordance with the American with Disabilities Act (ADA) and applicable state and local laws.",3.7,"Neustar
3.7",Bengaluru,"Sterling, VA",1001 to 5000 employees,1996,Company - Private,Internet,Information Technology,₹50 to ₹100 billion (INR),"Adobe, Akamai, Oracle"
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelors degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. Youll also get to visit other locations in India and beyond, so youll need to go where this journey takes you. In return, youll get the chance to work with teams impacting entire cities, countries and the shape of things to come.

Were Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.0,"Siemens
4.0",Bengaluru,"Munich, Germany",10000+ employees,1843,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹500+ billion (INR),"GE, ABB, Philips"
Senior Data Scientist (Text Mining),-1,"Title Senior Data Scientist (Text Mining)

Category IT

Education Graduate or Post Graduate

Experience Relevant Work experience of 3 to 5 Years

Location Bangalore


Details

3 – 5 years of industry or research experience in text mining.

Lead and engage a team of engineers and curators to deliver text mining solutions to external or internal customers.

Lead internal R&D projects to envisage the development of new products and services.

Experience or thorough understanding of named entity recognition, semantic indexing and retrieval, text classification, relationship extraction, and sentiment analysis.

Keep up-to-date with scientific and business developments in the market.

Experience in working with text and data analytic platforms such as OpenNLP, LingPipe, UIMA, Solr, Lucene, MALLET, KNIME and WEKA.

Exposure to text mining and AI APIs like Alchemy, TensorFlow and Google Cloud Natural Language AP.

Experience or thorough understanding of applications of machine learning techniques such as CRFs, SVM.

Exposure to Semantic Web standards from W3C: RDF, RDFS, OWL, SPARQL etc.,

Large scale data visualizations on the lines of d3js, Graphviz.

Good understanding of biomedical databases, ontologies, and controlled vocabularies is a plus.

Good communication, writing and presentation skills.

Qualification

Post-Doc, PhD or Masters in Computer Science, Biomedical Informatics, Natural Language Processing, Bioinformatics, Artificial Intelligence or related disciplines.

Please submit your application for the above opening(s) to hiring.technology@molecularconnections.com.",2.8,"Molecular Connections
2.8",Bengaluru,"Bengaluru, India",1001 to 5000 employees,2001,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Analyst,-1,"We are looking for a passionate Data Analyst. The successful candidate will turn data into information, information into insight and insight into business decisions.

Job Description:
Proven working experience as a data analyst or business data analyst between 1 to 2 years
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings
Understanding of utility value chain
Energy domain experience
Billing/Invoicing Background Preferably knowledge of energy market
Good Communication skills
Good with the numbers
Good Email writing skills
Immediate Joiners preferred",4.8,"Proziod Analytics
4.8",Bengaluru,"Bengaluru, India",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
CIEL/SEL/2317: Data Scientist Machine Learning,-1,"Data Scientist Machine Learning/Python/C#
3+ years in a data processing & machine learning role with demonstrable experience with Cognitive computing, data integration, data mining, Natural Language Processing, Hadoop platforms, and automating machine learning components.
Min. 1 year of experience with below technologies is mandatory.
a. Python
b. R
c. Spark
d. SAS
e. HDInsights
f. Databricks
Strong Knowledge in Machine learning like Spark and Azure ML.
Strong experience in Azure Big Data Technologies like Azure Data Lake, HDInsights etc.
Strong experience in any database technology (SQL Server / Azure Cosmos DB)
Strong experience in at least one programming language (i.e. C#, Python, R).
Experience implementing and automating models created by data science teams (i.e. Spark, Scala, Hive, Python, R, etc.)
Experience with data modeling and normalization concepts.
Experience with data visualizations tools like SSRS, PowerBI& Tableau.
Experience architecting and building data marts, warehouses, etc.
Experience working with different query languages (i.e. PL-SQL, T-SQL).
Understanding and experience working with cloud infrastructure services like Azure, Amazon Web Services & Google Cloud. Azure preferred.
Experience working with code repositories and continuous integration (i.e. Git, Jenkins, etc.)
Understanding of development and project methodologies.
Ability to work collaboratively in teams with other specialized individuals.
Able to work in a fast-paced, technical environment",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
Data Science Lead,-1,"Job Title: Data Science Lead

GCL : D1

Location: TRIL GTC Chennai

Experience:

7-10 years

Job Summary

The Data Science Lead oversees and manages the activities of the Data Engineers & Junior Data Scientists and provides advanced expertise on statistical and mathematical concepts. The Data Scientist applies and inspires the adoption of advanced data science and analytics across the business.

The Data Scientist synthesizes and leverages the businesss dataset and data to enhance the business capabilities for overall goal achievement. The Data Scientist is instrumental in helping the business continue its evolution into an analytical and data-driven culture.

This role of the Data Scientist supports relevant stakeholders through quantitative analytics, and the application of appropriate advanced analytics for the businesss key initiatives.

Job Description

Role and Responsibilities
Managing a team of data scientists, machine learning engineers and network graph specialists
Lead and collaborate with a team of other data engineers and business subject matter experts to solve complex business problems using machine learning and statistics
Recommend which approaches will be effective in various situations and will be able to implement these approaches independently without guidance
Drive the collection of new data and the refinement of existing data sources.
Analyze and interpret the results of product experiments.
Essential Skills and experience
Must have Direct Hands-on, 3 to 7 years of experience, building complex systems using any Statistical Programming Language (R / Python / SAS)
Must have fundamental knowledge of Inferential Statistics
Should have worked on Predictive Modelling
Experience should include the following:
Multi-Dimensional Array Processing
Simulation & Optimization Techniques
Machine Learning Techniques (Supervised, Unsupervised)
Artificial Intelligence and Deep Learning
Natural Language Processing
Model Ensembling Techniques
Building Interactive Applications to demonstrate Data Science Use Cases
Prior experience in Healthcare Domain, is a plus
Should be strong in Pharma business and understand the relevant data
Knowledge of AZ brand and science is mandatory
Experience using Big Data, is a plus. Exposure to SPARK is desirable
Should have Excellent Analytical, Problem Solving ability. Should be able to grasp new concepts quickly
Should be well familiar with Agile Project Management Methodology
Should have experience of managing multiple simultaneous projects
Should have played a team lead role
Should have excellent written and verbal communication skills
Should be a team player with open mind
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.9,"AstraZeneca
3.9",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
AI Scientist 2,-1,"IQVIA is the leading human data science company focused on helping healthcare clients find unparalleled insights and better solutions for patients. Formed through the merger of IMS Health and Quintiles, IQVIA offers a broad range of solutions that harness the power of healthcare data, domain expertise, transformative technology, and advanced analytics to drive healthcare forward.

AI Scientist II Role

PURPOSE

The AI Scientist II will be part of a new stealth group building the next generation of smart machine cloud-based solutions. This provides an opportunity to get in on the ground floor level of something new and exciting for an industry working with the latest and greatest technologies.

RESPONSIBILITIES
• Participate in cutting edge research using tools such as Machine Learning, Natural Language Processing, Robotic Process Automation and Blockchain amongst other capabilities.
• Help develop software and algorithms and build new cognitive computing platforms for areas such as sensors and tracking systems, deep learning algorithms and models, workflow and automation through to new areas such as virtual assistants and AI in IoT to enhance our Artificial Intelligence functionality.
• Define and drive the analytical scope and method for projects, including formulating and shaping the capabilities through a full software development life cycle.
• Help the research and development of a local AI team, deliver practical AI components to be used within clinical processes.
• Work on world-class cutting-edge technologies in related fields, including but not limited to the following: deep learning, large-scale machine learning and machine learning platforms, Natural Language processing and Semantic Ontology, Robotic Process Automation and Blockchain.
REQUIRED KNOWLEDGE, SKILLS, AND ABILITIES
• Experience in some of the following areas:
o Optical Character Recognition utilizing character recognition tools to convert images, PDFs and other document types into digitally recognized structure with meta-tagging;
o Machine Learning - deep learning, online learning, transfer learning, reinforcement learning, structured/unstructured learning;
o Natural language processing - NLTK/OpenNLP, StanfordNLP, Translation, Semantic Ontology, Natural Language understanding/generation;
o Robotic Process Automation virtual worker process builds, script generation utilizing AI tool sets;
o Blockchain smart contracts, supply chain programming, encryption programming.
• Strong research and innovation skills and ability to solve difficult machine vision and learning problems and transferring business problems into AI use cases and requirements.
• Excellent prototyping skills in open-source with some examples of practical application.
• Excellent programming skills in languages such as Java, C#/C++, Spark, Flink, Tensorflow and Python.
• Hands-on experience with large-scale real-time machine learning/AI and with full software development life cycle.
• Excellent communication and teamwork skills.
• Flexibility and adaptability to work in a growing dynamic team in a highly visible role.
• Preferred pharmaceutical experience in research projects and teams.

MINIMUM REQUIRED EDUCATION AND EXPERIENCE

Masters degree in Computer Science, Applied Statistics, Engineering, Mathematics, Physics or other qualitative discipline with specialization and experience in Artificial Intelligence, Machine Learning, Natural Language Processing, Cognitive Science, Deep Learning or other related fields.

A minimum of three years of professional post-academic work experience with a Masters or additional years of experience at BSc level will be considered. Strong mathematical/computing science background with strong knowledge in at least one of the following fields: Cognitive Science, Advanced Semantic Design, Information Extraction, Information retrieval, Probabilistic Decision Marking, or similar.

DESIRED ADDITIONAL SKILLS AND ABILITIES
• Someone who is passionate about AI and can show examples of their skills utilizing open-source capabilities that they can show as part of that passion;
• The freedom to use your talent and background to help us make noise in the industry quickly.

EEO Minorities/Females/Protected Veterans/Disabled

Join Us

Making a positive impact on human health takes insight, curiosity, and intellectual courage. It takes brave minds, pushing the boundaries to transform healthcare. Regardless of your role, you will have the opportunity to play an important part in helping our clients drive healthcare forward and ultimately improve outcomes for patients.

Forge a career with greater purpose, make an impact, and never stop learning.",3.6,"IQVIA
3.6",Bengaluru,"Durham, NC",10000+ employees,2017,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹100 to ₹500 billion (INR),"PPD, INC Research, PRA Health Sciences"
Senior Data Scientist,-1,"Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore
Desired Skills and Experience
Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.
Responsibilities
The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data And Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Analyst - Credit and Risk,-1,"Work closely with business teams to identify specific insights that can drive business impact. You will be a part of the Credit and Risk team.
Hands-on experience on SQL
Ability to effectively engage with business stakeholders and translate business requirements into high impact reports and visualizations
Developing new capabilities for our clients beyond static reports and spreadsheets (focus on PowerBI, Data Studio and Tableau products.
Hands-on experience on integrating, querying and preparing datasets for reporting and analytics
Data mining within the organization as well as enrich data from 3rd party databases
Experience working in an agile development environment.
Work proactively with Product functions to translate insights into actionable items.
Requirements and qualifications
Experience of 2+ yrs of experience in Data Visualization & Reporting.
Bachelor Degree in Computer Science / IT / Electronics / Statistics / Mathematics
Role Category:
Credit & Risk

Location:
Mumbai, India, Asia

Employment Type:
Full time",3.0,"FLEXILOANS TECHNOLOGIES
3.0",Mumbai,"Mumbai, India",201 to 500 employees,2016,Company - Private,Lending,Finance,Unknown / Non-Applicable,"LendingKart, Capital Float, NeoGrowth Credit"
Senior Data Scientist,-1,"Your Day-to-day Will Involve
Using modeling and analytics to understand how business decisions impact our bottom line. This may include assessing risks of new products, determining fraud policies, or identifying inefficiencies in existing operations.
Ensuring the team is delivering on our KPIs by using various data mining and data visualization tools to monitor portfolio performance and identify improvement opportunities
Developing hypotheses and set up your own problem frameworks to test for the best solutions. You will also scope the operational feasibility, lead implementation efforts, and monitor the success of your solutions.
Leveraging data analysis tools and technologies. For example, using machine learning to determine how we identify fraud.
Creating new solutions rooted in empathy and research that assist all customers as they work to better manage their finances.
Collaborating in a team environment. As part of our crew, you will learn to energetically rally diverse groups in pursuit of a common goal.

The Ideal Candidate Is
Innovative & Curious - You have the desire and ability to connect and empathize with our customers. You have an entrepreneurial spirit and get excited about creating new businesses and reinventing current ones. You ask why, explore, and bring your unique perspective to the table.
Analytical& Action-Oriented - You are data driven and outcome focused. You grow comfortable with ambiguity, fueled by a hunger to learn and constantly seeking out new challenges. You have a desire to take action, try new things, and sometimes fail. You persevere but know when to change course and are up for juggling multiple deliverables.
Collaborative & Team-Oriented- You always keep the people around you in the loop and are excited to communicate complex ideas clearly to make sure your co-workers understand the why behind their work and their key priorities.
Inclusive- You will empathize with those around you and care about their success, as you bring people together around whats possible.
Basic Qualifications
Bachelors degree or higher in a quantitative field (Business, Math, Economics, Finance, Statistics, Science, Engineering)
At least 1 year of work experience in analysis or consulting
Experience with or willingness to learn tools such as SQL, R, Python, Tableau
We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors, which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.
PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"PayPal
3.5",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Analytical consultant/Data Scientist,-1,"Analytics/Data Scientist


We at o9 Solutions...

We help enterprises to digitally transform their supply chain with a cloud-based platform that connects the supply chain end-to-end. We do this with the latest available technologies like AI/ML and NLP. Headquartered in Dallas, we have offices in Europe, Japan, Korea and one here, in Bangalore. In the past 18 months, we expanded our value-adding activities to amongst others Google, Nike, Walmart and Starbucks. The US/EMEA/India team is expanding rapidly and we look forward to having you on board and support our growing organization!


What you really do:

Design and operationalize various kinds of descriptive, predictive and prescriptive analytics relevant in the planning space.
While the analysis can happen in R, excel, SQL or o9’s tool, ensure the results are presented in a usable fashion for consumption in the o9 platform.


You will:

Ability to work with and as a true team
Ability to analyse problems by synthesizing complex information, evaluating alternate methods and articulating the result with the relevant assumptions/reasons
Knowledge of statistical and machine learning algorithms
Experience in using R and/or Python
Experience in implementing planning applications will be a plus
Knowledge of SQL, experience with ETL tools like Informatica/SSIS will be a plus
Having an educational background in Operations Research/Management will be a plus.

What is required by the position?

Experience of applied analytics in the field of Supply chain, like building Demand forecasting models, applied ML methods in improving Supply/Inventory planning etc.
Expertise at the juncture of planning and analytics for very diverse problems like recommending optimal assortments/pricing/inventory levels/forecasts, demand supply balancing etc.
SW tools: o9’s planning platform, R, SSIS, SQL, Excel.


What you get:

Flexible working schedule
Possibility to travel and work with clients
Exposure to the biggest brands in the world
A flat organization with a very strong entrepreneurial culture
A great team to support you and that you can support
Great people and unlimited fun at work
Possibility to really make a difference in a scale-up environment

Beer Fridays",3.3,"o9 Solutions, Inc.
3.3",Bengaluru,"Dallas, TX",201 to 500 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),-1
Business Intelligence Analyst,-1,"47456

Job Summary
Join the Strategy and Market Intelligence team and work on top-of-mind questions directly supporting CEO and his staff. These challenging yet intriguing projects include identifying and sizing new markets for NetApp and developing target account segmentation for new product offerings with the goal of increasing market share. We are looking for self starters who can translate abstract business problems into more actionable, data driven models.
Job Requirements
The Market Intelligence Strategist collects and analyzes business and market data and turns it into insights to support strategy and business decision. Specifically, this person will need to:
Understand and synthesize key industry and technology trends including industry landscape and dynamics, major players and competitors
Perform research and data analysis to support the strategy development and strategy discussions.
Understand and perform statistical analysis on diverse datasets – structured and unstructured - to draw actionable insights
Independently lead initiatives for cross-functional alignment; work independently with senior executives to gain buy-in and support on project findings
Develop key messages and presentations to communicate strategy messages to internal and external audiences
Structure and execute operational and strategic initiatives by developing project plans, leading analysis and developing final findings, recommendations and drive results.
Have clear understanding of key business issues and technology offerings of both the R&D Group and Sales and Marketing Group to collaborate and support their top business initiatives
Education
Bachelor's degree in Engineering, Mathematics, Statistics, Economics or any other quantitative field. MBA (preferred)
3-5 years of experience either in consulting, technology firm, large B2B organization
Excellent analytical abilities: Data driven and understanding of key analytical techniques
Prior experience of working on analytical tools like Excel, SQL, Python, R and visualization tools like Tableau, PowerBI
Excellent data vizualization and presentation skills
Ability to quickly understand the key value drivers of a business
Preferred prior experience in consulting, data science, or business analytics role
Preferred familiarity with enterprise IT industry

Job Segment:
Business Intelligence, Engineer, Consulting, Statistics, Technology, Engineering, Research, Data

Apply now »",4.2,"NetApp
4.2",Bengaluru,"Sunnyvale, CA",10000+ employees,1992,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹500+ billion (INR),"Nimble Storage, Pure Storage"
Analytics Consultant,-1,"CAREERS

Analytics Consultant

Bengaluru, India
JOB DESCRIPTION

As an Analytics Consultant with Tredence you will work in a challenging environment with smart peer group. In your role, you will work hands on and provide thought leadership to real life business problems using analytical thinking and by applying complex mathematical techniques.
THE IDEAL CANDIDATE WILL

Solve business problems which involves:
Brainstorming with clients/onsite and internal teams to define a problem
Translate the business problem into an analytical problem
Identify internal and external data requirements for solving the analytical problem
Solving the analytical problem using concepts from mathematics, statistics, Artificial Intelligence and Machine learning
Translate the solution to a business solution and create artefacts that can help communicate the solution to clients like dashboards, power point slides, excel sheets etc.
Understand challenges faced by our clients in the context of their business and industry
Work hands on and provide thought leadership to real life business problem
Use analytical thinking and apply complex mathematical techniques
Work in a challenging environment with smart peer group
ELIGIBILITY CRITERIA

Bachelors in Engineering or Masters in Statistics/Economics
At least 5 years of working experience in analytics
Experience in statistical techniques such as Regression, Clustering & Time Series Forecasting, etc.
Strong analytical/logical thinking and communication skills
Proficient in:
SQL, R and/or Python
Visualization tools like Tableau or SpotFire
Send your CV to careers@tredence.com",3.7,"Tredence
3.7",Bengaluru,"San Jose, CA",501 to 1000 employees,2013,Company - Private,Consulting,Business Services,₹1 to ₹5 billion (INR),-1
Data Scientist,-1,"· Good programming skills in Python/C++. (Deep Learning)

· Experienced in open source computer vision libraryOpenCV for Video/Image Processing, YOLO.

· Experience with object detection, recognition, tracking, classification and scene understanding.

· Hands-on experience on machine learning/deep learning libraries tensorflow, keras, theano and sklearn.

· Hands-on experience on mysql, mangodb, oracle.

· Capable of preparing and installing solutions by designing system specifications and standards.

Job Types: Full-time, Internship

Salary: ₹15,000.00 /month

Experience:
artificial intelligence: 1 year (Required)
deep leaning: 1 year (Required)
image processing: 1 year (Required)
Education:
Bachelor's (Required)",-1,GreenTech Intelligent Transportation System LLP,New Delhi,-1,-1,-1,-1,-1,-1,-1,-1
SENIOR DATA SCIENTIST,-1,"Job Description:Ã¢â¬Â¢ Experience in Data Modelling, R, Python, SQL, Data Science, Machine Learning, Deep Learning, Statistics
Ã¢â¬Â¢ Have ability to solve Business problems using Data
Ã¢â¬Â¢ Should possess extensive knowledge of and experience in applying data mining and machine learning techniques on large amount of datasets
Ã¢â¬Â¢ High level of proficiency in statistical tools like R, Python
Ã¢â¬Â¢ Candidate will be expected to communicate analytical results in a way that is meaningful for business stakeholders and provides actionable insights.
Ã¢â¬Â¢ Have the ability to discover new opportunities where advanced analytical techniques can be leveraged for solving business problems
Good to have
Ã¢â¬Â¢ Expertise in programming languages like Java/C/C++/Python
Ã¢â¬Â¢ Experience with relational databases and SQL is good to have
Ã¢â¬Â¢ Relevant experience in Big Data platforms like Hadoop eco-system
Ã¢â¬Â¢ Come up with innovative algorithms and solutions",4.1,"Happiest Minds Technologies
4.1",Bengaluru,"Bengaluru, India",1001 to 5000 employees,2011,Company - Private,IT Services,Information Technology,₹5 to ₹10 billion (INR),-1
CIEL/SEL/2066: Advanced Analytics-Data Scientist,-1,"Data Scientist-Core: R/Python(NumPy, SciPy, SKLearn, etc)/Scala, Zeppelin/Jupyter, Linux
Secondary: SQL, Hive, Pig, HDFS",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
Hiring for Sr/Jr Data Scientist in Chennai,-1,"Role Description
Role involves a combination of hands-on contribution, customer engagement and technical team management.
Lead data science aspects of client engagements on their own end to end, effortlessly switching between roles of an Individual Contributor, team member and data science manager as demanded by each project
Work closely with project team, Customer stakeholders and internal Business Units in devising creative analytical approaches to solve business problems
Developing and enhancing algorithms and models to solve business problem
Maintaining all models along with developing and updating code and process documentation
Demonstrated analytic, quantitative, and programming skills
Proficiency in a structured programming language is a must - knowledge of one of statistical/general purpose scripting languages software such as R, python is mandatory.
Strong SQL, Microsoft Excel, PowerPoint skills
Experience in designing data science solution approaches to unstructured problems, conducting quantitative analyses and interpreting results
Excellent written and verbal communication skills
Organized, structured and reliable while being an effective problem solver
Proficiency in data science approaches, machine learning algorithms and statistical methods.Â
Qualification and Experience
8+ years exp of which 5 years of relevant data science experience including hands-on programming in one (or more) of the above languages. Minimum 5 years spent with Analytics teams of reputed consultants and IT/ITES companies doing statistical modelling using above tools
B.Tech from Tier-1 college (IITs, NITs, IIITs etc.)
M.S or M.Tech is preferred
00-11.00 Years
Bachelor Of Technology (B.Tech/B.E), Masters in Technology (M.Tech/M.E/M.Sc)",-1,Avenues Consulting,Bengaluru,"Mumbai, India",1 to 50 employees,-1,Unknown,-1,-1,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"ARE YOU READY TO WORK AT ALTISOURCE?
Are you looking for an opportunity to advance your career in data science?
Do you enjoy solving complex business problems using financial and sales data?
Are you excited to join a growing team and take on exciting challenges?
If so,Altisource would love to hear from you! Altisource is seeking a Senior Data Scientist with a demonstrated competency in developing efficient and effective solutions for diverse and complex business problems.

WHAT YOU GET TO DO
Help to conceive, build, and test new models and technologies using best in class tools and state of the art knowledge
Create and deliver strategic quantitative solutions leveraging consumer behavior data, knowledge systems, and modeling techniques
Build modeling solutions and create intellectual property leveraging concepts from statistics, optimization theory, econometrics, risk theory, and dynamic systems theory
Contribute as an active team member to product management, development and delivery of enterprise modeling products and solutions
Build solutions with real world impact, and help demonstrate that impact
WHAT ABOUT YOU? You have...
At least 5+ years of extensive hands-on work experiences in manipulating large data sets and building statistical and advanced machine learning models.
Solid knowledge in mortgage and financial / real estate industry. Previous modeling experiences in loan / mortgage (default, severity, prepayment etc.) is a must.
Masters or higher in Economics, Applied Statistics, Applied Mathematics, Operations Research, or similar disciplines with a heavy quantitative focus.
Strong knowledge and experience with modeling languages (Python, R or similar) and data extraction tools (SQL or similar). Skills in other tools or languages including Excel, Tableau, Amazon SageMaker, VBA Java, C, C++ are plus.
WORKING AT ALTISOURCE ADVANTAGES:

Prosperity
Competitive base salaries!
Bonus Potential – if you go above and beyond, you should be rewarded
Good Health
Comprehensive insurance plans like Medical, Personal Accident Benefit and Life Insurance
Wellness Programs (examples include eye examination, diabetes checkup camp, hemoglobin check and health talks)
And Happiness
10 paid holidays, plus 26 paid days off per year
Lots of employee engagement activities both offsite (examples include family cricket/football games, annual company celebrations and happy hours) and onsite (examples include office stress buster events, holiday parties, and quarterly Living our Values celebrations)
Opportunities to join our community service initiatives, including Habitat for Humanity.
OUR CORE VALUES

For our employees, customers, and shareholders, we commit to…
Act With Integrity – exhibit unwavering integrity, compliance and ethical conduct at all times
Energize People – enable exceptional people to energize their teams and drive results
Empower Innovation – reward the relentless creation of innovative and compliant solutions to achieve our mission and generate value for our customers
Exceed Customer Expectations – execute world-class solutions to deliver value and delight our customers
Win as a Team – embrace the passion, energy and power of our global teams to win as ""One-Altisource""
Enrich Communities – create positive impacts for the communities where we live and serve
Are you up to the challenge? What are you waiting for? Apply today!

Got a question? Contact our Talent Acquisition Team at working@altisource.com.

At Altisource we value diversity, and are proud to be an equal opportunity workplace. We do not discriminate against any employee or applicant for employment on the basis of race, religion, color, sex, national origin, gender identity and/or expression, sexual orientation, age, marital status, veteran status, or disability status.",3.2,"Altisource
3.2",Bengaluru,"Luxembourg, Luxembourg",5001 to 10000 employees,2009,Company - Public,Investment Banking & Asset Management,Finance,₹50 to ₹100 billion (INR),"Safeguard Global, Genpact Mortgage, Black Knight"
Director - Data Scientist/ Chief Data Scientist/Manager-Data Scientist,-1,"Share this job

Description

About Zycus

Headquartered in Princeton, U.S. in 1998, Zycus has grown every day to be established as an organization which now is a leading global provider of complete Source-to-Pay suite of procurement performance solutions.

We develop cloud-based (SaaS) Source-to-Pay solutions for large global enterprises, and have successfully deployed about 200 solutions to over 1000 Global clients. We are proud to have as our clients, some of the best-of- breed companies across verticals like Manufacturing, Automotives, Banking and Finance, Oil and Gas, Food Processing, Electronics, Telecommunications, Chemicals, Health and Pharma, Education and more.

With a team of 1000+employees, we are present in India with 3 development centers at Bengaluru, Mumbai & Pune and offices in the U.S., U.K., Australia, Dubai, Netherlands and Singapore.

Know more about the LEADER of: Gartner’s 2013, 2015 & 2017 Magic Quadrant for Strategic Sourcing Application Suites and The Forrester Wave™: eProcurement, Q2 2017

We are in process of launching Merlin A.I. Studio™.

The artificial intelligence (AI)-based platform will allow procurement teams to to build and deploy bots across the source-to-pay process.

The bots will be used by firms leveraging more than 1,100 APIs from Zycus’ solution suite.

“By deploying the intelligent bots from Merlin A.I. Studio™, procurement can put themselves in cruise control mode as the bots work towards accomplishing tasks with zero human intervention,” The Fortune 500-serving firm explained in its press release

“Be it running an RFI event, discovering contract risks, negotiating with suppliers or transnational procurement; all one needs to do is launch the bot and see the magic unfold.”

“It will empower procurement to transform their routine, repetitive & mundane procurement tasks, so that time, effort & resources can be optimized towards more strategic initiatives.”

Requirements

We are especially looking for applicants with a strong background in Analytics and Data mining (Web, Social and Big data), Machine Learning and Pattern Recognition, Natural Language Processing and Computational Linguistics, Statistical Modelling and Inferencing, Information Retrieval, Large Scale Distributed Systems and Cloud Computing, Econometrics and Quantitative Marketing, Applied Game Theory and Mechanism Design, Operations Research and Optimization, Human Computer Interaction and Information Visualization. Applicants with a background in other quantitative areas are also encouraged to apply. If you are passionate about research and developing innovative technologies of interest to Zycus and the research community at large, the BigData Experience Lab may be the right place for you.

All successful candidates are expected to dive deep into problem areas of Zycus’s interest and invent technology solutions to not only advance the current products, but also to generate new product options that can strategically advantage Zycus

Skills

Master’s or Ph.D. in statistics, mathematics, or computer science
Experience using statistical computer languages such as R, Python, SQL, etc.
Experience in statistical and data mining techniques, including generalized linear model/regression, random forest, boosting, trees, text mining, social network analysis
Experience working with and creating data architectures
Knowledge of machine learning techniques such as clustering, decision tree learning, and artificial neural networks
Knowledge of advanced statistical techniques and concepts, including regression, properties of distributions, and statistical tests
5-7 years of experience manipulating data sets and building statistical models
Experience using web services: Redshift, S3, Spark, DigitalOcean, etc.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.
Experience visualizing/presenting data.

Director – Data Scientist will report in to Senior Vice President Engineering & the roles & responsibilities are as below:

Work as the data strategist, identifying and integrating new datasets that can be leveraged through our product capabilities and work closely with the engineering team to strategize and execute the development of data products
Execute analytical experiments methodically to help solve various problems and make a true impact across various domains and industries
Identify relevant data sources and sets to mine for client business needs, and collect large structured and unstructured datasets and variables
Devise and utilize algorithms and models to mine big data stores, perform data and error analysis to improve models, and clean and validate data for uniformity and accuracy
Analyze data for trends and patterns, and Interpret data with a clear objective in mind
Implement analytical models into production by collaborating with software developers and machine learning engineers.
Communicate analytic solutions to stakeholders and implement improvements as needed to operational systems
Benefits

Along with a competitive compensation structure, Zycus believes in an open culture learning environment, where everyone gets a chance to share their ideas and deliver par excellence. Here's a sneak peek to our life at Zycus.",3.4,"Zycus
3.4",Bengaluru,"Princeton, NJ",501 to 1000 employees,1998,Company - Private,Computer Hardware & Software,Information Technology,₹500 million to ₹1 billion (INR),"SAP Ariba, GEP, Coupa Software Inc"
ML Engineer/Statistician/Data Scientist – Pre-IPO Unicorn,-1,"As a Data Scientist / ML specialist you will focus on building next-generation platform services to identify right business problems that will be more effectively solved with Machine Learning techniques

Then you will apply your algorithmic/statistical skills, analytical skills, knowledge of ML techniques and distributed systems to solve the problem in the simplest possible way.

Experience

3 to 12 years

Qualification

A Bachelor’s degree or a higher degree in Computer Science, Statistics, Mathematics or a related field.
A strong grounding in Data structures and algorithms, Database concepts
Solid understanding of mathematical underpinnings behind Machine Learning algorithms and proficiency in probability, statistics, linear algebra, calculus, and optimization.
Prior experience in building and deploying ML systems and familiarity with Machine learning algorithms
Experience with NLP, Distributed Systems, large scale computing, Big Data technologies like Hadoop and Spark are plus.

Responsibilities

Collaborate with product and business teams to understand all aspects of the problem
Deliver scalable, low latency, and high-performance ML solutions for different
Apply knowledge of ML, statistics, and advanced mathematics to conceptualize, experiment and design an intelligent system
Drive solutions and implementation leveraging different open source libraries and distributed systems
Work with engineers to build the system end-to-end including Big Data pipelines and ensure the serving system is scalable and highly performant.

We value intellectual curiosity, open communication and creative thinkers who know how to stand up and be counted. If this sounds like who you are, we should talk.

Write to deepa.m@careerxperts.com to set up this adventure! #HighBarOfEntry

Job Location

Bengaluru",-1,CareerXperts,Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
"Data Scientist[ Image Processing, Computer Vision,tensorRT,keras]",-1,"Job Description

Job Description

Need Data Scientist - for our Fortune Wireless Ecosystem, who can contribute in Image Processing & Neural Network domain

NOTE:
Need someone who can join within 30 days.
Work Location: Magarpatta,Pune

Essential Requirements

5+ years of experience in understanding the problem statement, data handling/triage, selecting and improving neural network models using deep learning frameworks to solve business problems
Thorough understanding and experience of DL/AI/ML lifecycle - full neural network pipeline, starting from data collection to model building to experimental framework to data analytics
Developed/optimized various models in image domain
Computer Vision - Experience with object detection, tracking, classification, recognition using deep neural network
Hands on experience of popular frameworks (Tensorflow, Keras, MxNet, Caffe. CNTK, Theano / Pytorch, python), their strength and applicable AI use-cases.
Experience in design and developing deep neural networks for large datasets
Proven record of improving current models for accuracy and speed for specific use case

Good to have

Published research papers on neural network
PhD/Masters in DL/ML/AI domain.
Demonstrated prowess in ML in public competitions: Kaggle or participation at other worldwide competitions, etc
GitHub code repository
To book your appointment, please call 9898791075.

Perks and Benefits

Training/certifications + 5 Days + Other Fringe Benefits

Salary: Not Disclosed by Recruiter

Keyskills
PytorchTensorflowObject DetectionArtificial IntelligenceNeural NetworksCaffeKerasComputer VisionDeep LearningPython
Desired Candidate Profile
Please refer to the Job description above

Education-

UG:B.Sc - Computers, B.Tech/B.E. - Computers

PG:MS/M.Sc(Science) - Any Specialization, Computers, M.Tech - Computers, MCA - Computers

Doctorate:Ph.D - Computers, Doctorate Not Required

Company Profile

eInfochips Limited

eInfochips, an Arrow company, is a leading global provider of product engineering and semiconductor design services. With over 500+ products developed and 40M deployments in 140 countries, eInfochips continues to fuel technological innovations in multiple verticals. The company€™s service offerings include digital transformation and connected IoT solutions across various cloud platforms, including AWS and Azure.

Along with Arrow€™s $27B in revenues, 19,000 employees, and 345 locations serving over 80 countries, eInfochips is primed to accelerate connected products innovation for 150,000+ global clients. eInfochips acts as a catalyst to Arrow€™s Sensor-to-Sunset initiative and offers complete edge-to-cloud capabilities for its clients through Arrow Connect.
Industry

Semiconductors / Electronics

Functional Area

IT Software - Application Programming, Maintenance

Role Category

Programming & Design

Role

Team Lead/Technical Lead

Employment Type

Full Time, Permanent",3.5,"e-Infochips
3.5",Pune,"Ahmadabad, India",1001 to 5000 employees,1994,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"We are building a world-class language-related product that has the potential to positively transform lives worldwide. We have a passionate team of data scientists, coders, and linguists who have been working on it.

We are looking for a Data Engineer who will identify and implement the best data-driven methodologies considering the product requirements.

Work location: Goregaon (West), Mumbai

Key responsibilities:

Create, build and design data management systems across an entire organization
Work with very large data sets (both structured and unstructured).
Help data scientist to easily retrieve the needed data for their evaluations and experiments.
Design, develop and implement R&D and pre-product prototype solutions
Must have strong engineering skills that will help engineering team to productivize NLP/ML algorithms
Implement scalable, maintainable, well documented and high-quality solutions.
Stay abreast of the new developments in Artificial Intelligence (AI)/Machine Learning (ML). Contribute to the research strategy and technical culture of the team


Skills Required:

BTech/MTech/ME/MCA from reputed Engineering college.
0-2 years of industry experience
Extremely curious and relentless at figuring out solutions to problems
Knowledge of Big Data platforms like Hadoop and its eco-system
Proficiency in programming languages like Java/C/C++/Python
Experience with cloud services
Exposure to NLP and its related services.
Experience with one or more visualization tools like Tableau, etc.
Experience with Docker, Kubernetes, Kafka, Elasticsearch, Lucene
Experience with relational or NoSQL databases such as MySQL, MongoDB, Redis, Neo4j.
Experience of handling various data types and structures: structured and unstructured data, validating and cleaning data, and measuring evaluation
Excellent understanding of machine learning techniques.",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Data Engineer - Data and Platform,-1,"Responsibilities: • Should have an idea about designing, deploying and operating highly available, scalable and fault-tolerant systems using Amazon Web Services (AWS) like Redshift, Lambda, Glue, S3, Ec2, Kinesis • Experience with Back-end engineering /API development using any of one high-level language like java, python, net, REST/SOAP-based web services understanding and implementation • Strong knowledge in OLTP/OLAP Systems, Dimensional Strategies - Star Schema, Snowflake Schema, and Ralph Kimball Methodology. • Develop ETL solution using SSIS/Talend/Informatica • Ability to integrate 3rd party API programmatically.Ability to access AWS programmatically via its API • Big data/Stream platform development experience Kafka • Write SQL code - Queries/Stored Procedures/Functions.Understand cloud-based solutions and help in designing data lake solutions • Experience in creating BI solutions using Tableau/PowerBI. • Experience in setting-up Elastic Logstash Kibana (ELK) stack. • Previously experience working with distributed architectures like Hadoop, Map-reduce, etc.
Woking Knowledge of frontend framework such as React /Angular • Application Security • Familiarity in Unix/Linux development environments & tools including scripting & process management.",3.6,"Quantiphi
3.6",Mumbai,"Marlborough, MA",501 to 1000 employees,2013,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Junior Data Scientist,-1,"Looking for a junior Data Scientist with 1 to 4 years experience
Job Type: Full-time
Salary: ₹20,000.00 to ₹40,000.00 /year
Experience:
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Secondary(10th Pass) (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Erdster Information Systems Private Limited,Coimbatore,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist 2,-1,"Experience Required: 8-year experience in Software development, having BE/BTech degree.
Deep understanding of statistics and ML algorithms work internally with proficiency in at least 2 supervised and unsupervised algorithms in each bucket.
Supervised algorithms : Regression [linear/polynomial], Decision Tree, Random Forest or classification [Logistic Regression, Naïve Bayes, SVM etc]
- Model design and implementation : Experience in deriving feature sets, model training and testing

- Preferred tools and programming languages: TensorFlow/Keras, Python

- Exposure to Deep Learning and NLP is an added advantage.",3.5,"PayPal
3.5",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Data Engineer - C10,-1,"The Data/Information Mgt Analyst 2 is a developing professional role. Applies specialty area knowledge in monitoring, assessing, analyzing and/or evaluating processes and data. Identifies policy gaps and formulates policies. Interprets data and makes recommendations. Researches and interprets factual information. Identifies inconsistencies in data or results, defines business issues and formulates recommendations on policies, procedures or practices. Integrates established disciplinary knowledge within own specialty area with basic understanding of related industry practices. Good understanding of how the team interacts with others in accomplishing the objectives of the area. Develops working knowledge of industry practices and standards. Limited but direct impact on the business through the quality of the tasks/services provided. Impact of the job holder is restricted to own team.

Responsibilities:
This function covers incumbents responsible for various data activities, which include database administration, data analysis, maintenance, data quality, and database management or database architecture / design engineering
Responsible for routine operational or administrative work
Day-to-day actions are focused on administering defined procedures, analyses and report preparation
Individuals will have their work thoroughly reviewed and checked by more senior incumbents and will have limited contact outside their immediate area
Daily deliverable of routine and defined outputs, while at the same time developing knowledge of the broader context in which the work is being performed
Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency.
Qualifications:
0-2 years relevant experience
Know-how on analytic tools (SAS E-miner, Knowledge Seeker, SPSS etc.)
Big data and machine learning experiences are (R, Python etc.)
The ability to engage resources outside of their direct control to achieve objectives
Education:
Bachelors/University degree or equivalent experience
This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.

-------------------------------------------------

Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - IN

------------------------------------------------------

Time Type :

------------------------------------------------------

Citi is an equal opportunity and affirmative action employer.
Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity.

Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE.

To view the ""EEO is the Law"" poster CLICK HERE. To view the EEO is the Law Supplement CLICK HERE.
To view the EEO Policy Statement CLICK HERE.
To view the Pay Transparency Posting CLICK HERE.",3.6,"Citi
3.6",Pune,"New York, NY",10000+ employees,1812,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Data Guru,-1,"Data Guru

Think of yourself as the Lead for managing the data science team, machine learning engineers, and big data specialists in planning projects, and building analytics systems and predictive models. You should have a strong problem-solving ability and a knack for statistical analysis.

You will be directly accountable for providing the business with analysis and intelligence on how the business is performing through close partnership with the site leads (Operations VPs). You will be accountable for providing meaningful analysis of a site, in order to produce measurable improvements for campaign performance, profitability, and efficiency. Your ultimate goal will be to help improve our business decisions by making the most out of our data.

As a Data Guru, you will make sure that all work quality standards and all work performed by your team are delivered and executed within mutually agreed target completion dates. You will utilize analytical, statistical, and programming skills to collect, analyze, and interpret large data sets, then use this information to develop data-driven solutions to business challenges. A key responsibility for your role is in producing the dashboard packages and data integration related to campaigns and/or key departments performance at your site. The expectation is that all dashboards are automated, with no manual intervention required, in producing reports once the ETL process is established.

As the Lead, you will be expected to conduct at least one performance monitoring session per direct report each week, covering deliverables, their performance, their upskilling requirements, and their personal development. Results of these sessions should be reported in your weekly status reports and logged in the Coaching tool.

So, do you have what it takes to become a Data Guru?
Requirements:
Proven experience as a Data Scientist or similar role
Solid understanding of machine learning
Knowledge of data management and visualization techniques
A knack for statistical analysis and predictive modeling
Able to lead data mining and collection procedures
Ensures data quality and integrity
Experience in interpreting and analyzing data problems
Able to conceive, plan and prioritize data projects
Qualifications:
Degree in Computer Science, Data Science, Mathematics or similar field
Good knowledge of R, Python and MATLAB
Experience with SQL and NoSQL databases
Strong organizational and leadership skills
Excellent communication skills
A business mindset
Works well with others and fosters teamwork
Integrity and good judgement
Flexible to shifting hours including working graveyard shift where necessary
Able to travel internationally, as needed
Candidates from BPO industry highly preferable.",4.5,"TaskUs
4.5",Indore,"Santa Monica, CA",10000+ employees,2008,Company - Private,Staffing & Outsourcing,Business Services,₹10 to ₹50 billion (INR),-1
Senior Managing Consultant - Data Scientist,-1,"Antuit is the leader in AI-powered solutions for Retail, Consumer Goods, and Manufacturing companies with a proven track record for delivering out-sized business results to industry leaders.

Our AI solutions, in the cloud, improved accuracy for demand forecasting, S&OP, DSD fulfillment, trade promotion, retail life cycle pricing, and personalized marketing.

Antuit’s executives, comprised of industry leaders from McKinsey, Accenture, IBM, and SAS, and our team of Ph.Ds., data scientists, technologists, and domain experts, are passionate about delivering real value to our clients. Antuit is funded by Goldman Sachs and Zodius Capital.

Description
Antuit is looking for a Senior Managing Consultant - Data Scientist, who has knowledge and experience in developing machine learning algorithms, particularly in Supply chain and forecasting.

The candidate should be able to design and implement the solution. The candidate should have excellent communication skills and be results driven with a customer centric approach to problem solving. This job also requires the ability to operate across geographic delivery environment. Excellent opportunity to learn and contribute to solving world-class data science problems.

Responsibilities and Duties
A key member of the Forecasting and Supply Chain team, this person will own end to end implementation of projects. Specific tasks include:
Understanding the project scope, deliverables and SLA from internal and external project stakeholders;
Work with client/engagement managers to identify requisite data sets, outline & communicate detailed project plan, timeline plus cost estimates for the requisite analysis;
Collaborate with business and clients to extract the data, ensure completeness of the data to execute the analysis;
Design the analytics solution in collaboration with other teams at Antuit and present the design to the clients;
Allocate tasks to the project team members, guide and enable them to succeed as per plan;
Track, validate, release the work by the project members and own the technical delivery of the project;
Present findings from the analysis and clearly articulate any recommendations to the clients – develop implementation plans to best help clients derive value from the recommendations;
Accountable for creating and managing an engaged, motivated, diverse workforce;
Develop customer centric culture;
Hygiene tasks i.e. leave management, rewards and recognition etc.
Qualifications and Skills

Experience / Education:
Master’s or PhD in Computer Science, Industrial Engineering, Applied Mathematics or in General Management;
A minimum of 13+ years’ experience, ideally in a consulting environment leading projects developing Data Science solutions;
Hands on expert level skills in SQL, Python, R, etc;
Experience in retail and/or consumer packaged goods preferred;
Highly technical:
Experience in solving forecasting, network design, assortment optimization, inventory optimization or dynamic allocation problems mandatory;
Prior experience consulting in a retail, CPG or manufacturing environment a plus;
Experience with Agile methodology and tools like Jira;
Experience with code management and migration tools like github, bitbucket and bamboo;
Experience with data flow tools like Airflow preferred;
Experience dealing with large data sets, application of analytics to generate and communicate insights;
Experience using business software such as Microsoft Word, Excel and power point;
Ability to lead project teams and own the delivery quality, cost and timelines;
Effective communication and presentation skills;
Strong management track record;
Strong inter-personal skills and leadership qualities;
EEOC
Antuit is an at-will, equal opportunity employer. We consider applicants for all positions without regard to race, color, religion, national origin or ancestry, gender identity, sex, age (40+), marital status, disability, veteran status, or any other legally protected status under local, state, or federal law.

To apply, please send your resume or CV to careers@antuit.com",4.0,"Antuit
4.0",Bengaluru,"Chicago, IL",201 to 500 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
AI/Machine Learning Engineer (Premium Colleges only),-1,"Requirements

We are looking for applicants with a strong background in Analytics and Data mining (Web, Social and Big data), Machine Learning and Pattern Recognition, Natural Language Processing and Computational Linguistics, Statistical Modelling and Inferencing, Information Retrieval, Large Scale Distributed Systems and Cloud Computing, Econometrics and Quantitative Marketing, Applied Game Theory and Mechanism Design, Operations Research and Optimization, Human Computer Interaction and Information Visualization. Applicants with a background in other quantitative areas are also encouraged to apply.

We are looking for someone who can create and implement AI solutions. If you have built a product like IBM WATSON in the past and not just used WATSON to build applications, this could be the perfect role for you.

All successful candidates are expected to dive deep into problem areas of Zycus’ interest and invent technology solutions to not only advance the current products, but also to generate new product options that can strategically advantage the organization.

Skills:
Experience in predictive modelling and predictive software development
Skilled in Java, C++, Perl/Python (or similar scripting language)
Experience in using R, Matlab, or any other statistical software
Experience in mentoring junior team members, and guiding them on machine learning and data modelling applications
Strong communication and data presentation skills
Classification (svm, decision tree, random forest, neural network)
Regression (linear, polynomial, logistic, etc)
Classical Optimization(gradient descent, newton raphson, etc)
Graph theory (network analytics)
Heuristic optimisation (genetic algorithm, swarm theory)
Deep learning (lstm, convolutional nn, recurrent nn)
Must Have:
Experience: 1-9 years
The ideal candidate must have proven expertise in Artificial Intelligence (including deep learning algorithms), Machine Learning and/or NLP
The candidate must also have expertise in programming traditional machine learning algorithms, algorithm design & usage
Preferred experience with large data sets & distributed computing in Hadoop ecosystem
Fluency with databases
Benefits",3.4,"Zycus
3.4",Bengaluru,"Princeton, NJ",501 to 1000 employees,1998,Company - Private,Computer Hardware & Software,Information Technology,₹500 million to ₹1 billion (INR),"SAP Ariba, GEP, Coupa Software Inc"
CIEL/SEL/1942: Jr data scientist,-1,"Job Description

Specific Job Experience or Skills Needed

Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desirable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model

Responsibilities
:
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
:• Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
Senior Data Analyst,-1,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

We Are looking for an analytically inclined , Insights Driven Data Analyst to make our organisation more data driven. In this role you will be responsible for creating dashboards to drive insights for product and business teams. Be it Day to Day decisions as well as long term impact assessment, Measuring the Efficacy of different products or certain teams, You'll be Empowering each of them. The growing nature of the team will require you to be in touch with all of the teams at upgrad. Are you the ""Go To"" person everyone looks at for getting Data, Then this role is for you.

Roles & Responsibilities
Lead and own the analysis of highly complex data sources, identifying trends and patterns in data and provide insights/recommendations based on analysis results
Build, maintain, own and communicate detailed reports to assist Marketing, Growth/Learning Experience and Other Business/Executive Teams
Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.
Analyze data and generate insights in the form of user analysis, user segmentation, performance reports, etc.
Facilitate review sessions with management, business users and other team members
Design and create visualizations to present actionable insights related to data sets and business questions at hand
Develop intelligent models around channel performance, user profiling, and personalization
Skills Required
Having 3-5 yrs hands-on experience with Product related analytics and reporting
Experience with building dashboards in Tableau or other data visualization tools such as D3
Strong data, statistics, and analytical skills with a good grasp of SQL.
Programming experience in Python is must
Comfortable managing large data sets
Good Excel/data management skills
Qualification – B.Tech/M.Tech/MCA (IT/Computer Science)

Years of Exp – 2-5",4.0,"upGrad Education Private Limited
4.0",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
Research Associate/Research Scientist (Downstream Process),-1,"Position: Research Associate/Research Scientist (Downstream Process)

Location: Bangalore, India

Contact: Please email admin@stringbio.com

No of Openings: 1

The candidate will be responsible for design, planning and execution of downstream processes. The employee will also be involved in compilation and interpretation of data from lab scale experiments. He/she will be responsible for inventory management which includes the amount and efficiency of product generation. He/she will be responsible for coordination of activities related to departmental audits, communicating with vendors for technical queries, preparation of BMR, SOP, technical presentations and data compilation. The candidate is someone who is enthusiastic about taking challenges and has an eagerness to learn new techniques.

POSITION RESPONSIBILITIES

Design, plan, test and improve downstream processing for a particular molecule.
Support and manage operations of separation, chromatography, TFF, filtration and drying systems.
Quantify, monitor and establish the yield and efficiency of unit operations
Optimize the process for specific target metrics
Monitor and support end to end execution at lab and pilot scale
Should be conversant with interpretation of analytical and process data and should be conversant with DSP scale-up principles.
Good communication skills.
Be a conscientious laboratory citizen.
Adhere to EH&S standards, and use knowledge of laboratory procedures to advance projects under shifting priorities and timelines.
The position is full-time.

CANDIDATE PROFILE

EDUCATION AND EXPERIENCE

M.Tech in Bio-Chemistry/Bio-Technology, MS/M.Sc(Science) in Biotechnology

>4 years’ work experience in downstream process

Experience in unit operations like separation, filtration, drying, centrifugation etc.

Proficiency with MS Office suite.

PERSONAL QUALITIES

Driven, dedicated team player with attention for detail

Ability to work independently and deliver on project objectives

Capacity to be proactive and take initiatives

Good organizational skills

Effective interpersonal skills

Strong oral and written communication skills

Creative, out of the box thinker with strong analytical and problem-solving capabilities

Ability to adapt to changing drivers.",4.7,"String Bio
4.7",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist Bangalore,-1,"Data Scientist

Exp: 3+ Years

We are hiring for the role of Data Scientist for a Sweden based company for their offices in Bangalore.
Bachelor in Engineering, Data Science, Maths, Stats or Computer Science
2+ years of related work experience in Data science field
Fluency in SQL for data access, manipulation, and validation
Proficiency in either R, Python or SAS for data analysis
Passion for data visualization and information design
Capable of clearly communicating complex analyses to a non-technical audience, including extensive experience presenting to leadership groups
Ability to initiate, refine, and complete projects with minimal guidance
Mail your resume to team@equinoxes.in",-1,Equinox e Services,Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Machine Learning Engineer (f/m/d),-1,"IMPACT DESCRIPTION
Are you a technology enthusiast and enjoy being challenged towards development of superior software using innovation? Have you been part of high performing teams delivering world-class products? Join us in our drive to make robust products with assured quality available to our customers.

You will be responsible for setting up the right code architecture, leveraging emerging tools and trends while keeping the vision of our product intact. You will be part of our core R&D team working in Pune, India.
YOUR PROFILE
WHAT YOU ALREADY KNOW

Strong fundamental understanding of machine learning algorithms, with good hold on under-the-hood mathematical and statistical concepts
Research oriented mindset : Should be able to review existing research publications for applicability in the current problem and also publish research papers at forums / events
Programming experience with Python
Experience with machine learning frameworks such as Tensorflow, Keras and commonly used python libraries
Able to build data pipelines to train and build your models
Able to deploy models in Docker containers
Able to do Linux shell scripting
Able to use at least one of the following database and data processing technologies such as MongoDB, Apache Hadoop and/or Apache Spark
Ability to provide a compelling story / narrative on work through dashboards and presentations

Experience:
2-3 Years
WHAT WE OFFER YOU
Beautiful Office Spaces
Our team has added a personal touch to our office spaces, which is a reflection of our work culture: unique, fresh and innovative.
A Young, global Team
We are employee driven. We have a diverse team, a flat structure and encourage a healthy balance between work and play.
Passion for Technology
We are enthusiastic about our work and go the extra mile. Jump headfirst into the deep end, ready to do what no one else has done.
We make a change
We clean up your code and get it to speed with the times, assuring good quality and robustness at all times.
We're empowering
We make your code visual and beautiful, making it easy to understand by anyone to make well informed decisions.
We love challenges
We revel in expectations and widening our horizons. We are always eager to learn, grow and trudge into new territories.
We have fun
We take pride in making work a place we look forward to coming to each day. We love our work and this shows in the work we do.
We are efficient
We do great work and utilize resources effectively, making our services accessible and affordable to our clients.
CONTACT US
Embold Software Pvt.Ltd
HR India
Office No. 302-303,
Third Floor, Pride House,
Pune University Road, Chattushringi,
Pune- 411016
India

E-Mail: hrindia@embold.io
ABOUT US
Our Vision is to change the Paradigm of Software Development by helping our users to create great software products.
We develop the infrastructure and tools that fuel the transformation of software development with the power of artificial intelligence and support our customers in dealing with complex challenges in their software development processes with our software analytics platform.",4.0,"Embold Technologies GmbH
4.0",Pune,"Frankfurt am Main, Germany",51 to 200 employees,2008,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Product Analytics Consultant,-1,"#LI-Post

HP is the worlds leading personal systems and printing company, we create technology that makes life better for everyone, everywhere. Our innovation springs from a team of individuals, each collaborating and contributing their own perspectives, knowledge, and experience to advance the way the world works and lives.

We are looking for visionaries, like you, who are ready to make a purposeful impact on the way the world works.

At HP, the future is yours to create

As part of the HP Store Analytics team, will support the HP Store Product analytics team, by providing analysis, insights and reporting of key operational metrics, as well as aligning with financial metrics and becoming an expert in day-to-day performance monitoring and measurement of the HP Store.

Actual performance and related benchmarks/metrics. Leads or participates in team projects and/or initiatives, facilitates information validation and team decision-making process.

If you are our Product Analytics Consultant in India, you will get an opportunity to work on below.

Key responsibilities include:
Collaborate with both front-line Product managers and IT to enhance ecommerce engine
Responsible to build scorecards, business analytics , feature innovation etc.
Manage complex data and business analyses to assist management in the development of marketing tactics and business plans
Identify metrics/benchmarks required to measure/evaluate business performance; compare actual performance to plan; identify and create action plans to address performance gaps.
Work independently and/or under the direction of management to support business requirements; collaborate cross-functionally to accomplish assigned objectives.
Contribute to assigned ad hoc priority projects with complex analyses; assist in the development of management recommendations.
Provide analytics support to Product team by driving requirement and feasibility study and ROI analysis
Are you a high-performer? We are looking for an individual with:

Education and Experience Required
Masters degree or university-level equivalent in Software Engineering or Product Analytics
7-10 years experience in Product Engineering , Analytics, or planning related functional area
Knowledge and Skills Required
Strong analytical thinking, technical analysis, and data manipulation skills.
Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Adwords, etc.
Ability to learn and draw on new analytical techniques to develop creative approaches to business analysis.
Hands on experience with one or more querying databases (SQL , PL/SQL) and using statistical languages: Python,R etc.
Hands on experience in visualization /presenting data for stakeholders using: Tableau, Power BI etc.
A drive to learn and master new technologies and techniques
Strong verbal and written communication skills; advanced English language competency
Ability to work with cross-functional teams
Ability to identify and summarize relevant trends from internal, market and industry data
#LI-Post",4.0,"HP Inc.
4.0",Bengaluru,"Palo Alto, CA",10000+ employees,1939,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Science Specialist / Sr. Data Scientist,-1,"Function : Clustr

Experience : 8-12 yrs

Why should you join us?

Work in an exciting start-up that builds first-of-its-kind product and services

Access to a unique dataset covering > 85% of SMEs with unmatched diversity and complexity

Opportunity to build truly state-of-the-art algorithms and insight engines that consume and digest complex “Big” data and extract value out of them

Learning and exposure to multiple engineering areas (including Big Data technologies, DevOps) surrounded by a top-quality team

Accelerate your career in a fast-paced, open, non-hierarchical working environment

The Data Science team at Clustr builds algorithms and Machine Learning models that sit at the core of the company’s value proposition. This is a team of intellectuals with high aptitude, hacker attitude, strong curiosity about data, great comfort with Math, good coding discipline and excellent communication skills.

What will you be doing?

Data Science Specialist will be involved in all stages of the DS-based solution development cycle, working with various stakeholders in framing, designing and executing DS solutions considering both functional and non-functional aspects

Data Science Specialist would be in-charge of: translating a business problem to a DS problem, scope definition, data cleaning, explorations, feature engineering, feature selection, modeling, building prototype, documentation of an algorithm and insights. You would be involved in building scalable Machine Learning models for various problems in the areas of information extraction, entity resolution and linking knowledge base curation, machine translation, information retrieval and others

Involvement in all stages of the development cycle - building scalable machine learning models for various problems in the areas of information extraction, entity resolution and linking, knowledge base curation, machine translation, information retrieval and others

Who are we looking for?

D. or MS/M. Tech with 4+ years of experience or BE/B. Tech with 8+ years of experience in Data Science, Machine Learning, or NLP

Experience of working on production-grade Machine Learning-based solutions would be a plus

Prior publication record at AI/ML conferences would be a plus

Ability to formulate a business problem as a DS/ML problem, hypothesize, design, iterate and productionize solutions

Ability to scale and deploy DS-based solutions in production

Strong communication skills and ability to work with stakeholders across business, PM, and Engineering

Excitement & curiosity around data in general “Hacker” attitude with “go-getter” mind-set

High level of comfort with Math and ability to quickly master deep Mathematical concepts

In-depth understanding of Machine Learning techniques

Experience with Text Mining including hands-on knowledge of at least a few of the following areas: Information extraction, Natural Language processing, Knowledge graphs, Semantic Search, Information Retrieval, Probabilistic graphical models, Deep learning and Bayesian Learning techniques

Very good coding skills in any of these languages: R, Python, Matlab, Java, C and Machine Learning libraries like scipy, numpy, pyspark, tensorflow etc

Basic knowledge of Big Data stack: Spark, Cassandra, Map-Reduce, S3

Train/Mentor other team members

Keep abreast of the current state-of-the-art in Machine Learning and NLP areas

Prior experience with start-up environment preferred
Ready to join Clustr?
If you fit the bill, email your resume to careers@clustr.co.in with the position name in subject line",4.5,"HP Inc.
4.0",Bengaluru,"Bengaluru, India",1 to 50 employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Science Engineer,-1,"You can send your CV to careers@intellipredikt.com
Job_ID : IPTB_PE_102

Job Title: Data Science Engineer

Status: OPEN

Job Description: Data scientist is responsible for data exploration, machine learning, IP generation, anomaly detection/ prediction and data visualization of massive dataset using common tools.

Qualification: MS or PhD in Data Analytics areas

Experience: 1 to 5 years of experience in data analytic's for anomaly detection and prediction",5.0,"IntelliPredikt Technologies
5.0",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"Through the Amazon Marketplace, Amazon provides individuals or enterprises the opportunity to sell their goods on the Amazon platform. Worldwide, more than a million sellers use this Marketplace and thereby contribute to the success of Amazon. Amazon is growing its Marketplace aggressively worldwide. In this context, Amazon India Seller Services is setting up a new service to help with driving selection improvement on Amazon.

In order to drive improvement in the Amazon selection, this program will contribute in identification and on-boarding of new selection and drive efficiency of the existing selection.

About the Role: We are looking for a hands-on, detail oriented and highly motivated data analyst to help create data backed insights that will drive selection improvement . The candidate should be comfortable interfacing with technology systems and be able to analyze data and gather actionable conclusions. Operating in a rapidly changing environment will require the candidate to be adept at dealing with ambiguous, new and challenging situations. The candidate will be comfortable in executing repeatable processes.



Basic Qualifications

· Bachelor's degree in Computer Science, Engineering, Operations Research, Math, or related discipline.
· Minimum 2+ years of experience as an Analyst role preferred.
· Highly proficient in Microsoft Office and Windows based applications.
· SQL Knowledge and Hands-on experience is a must.
· Demonstrated Analytical ability, results-oriented environment with external customer interaction.
· Excellent written and verbal communication and presentation skills and the ability to express thoughts logically and succinctly.
· Entrepreneurial drive and demonstrated ability to achieve stretch goals in an innovative and fast-paced environment.

Preferred Qualifications


· Experience with E-Commerce, Retail and Business Analytics would be an advantage.
· Understanding of data warehousing, data modeling concept and building new DW tables
· Advanced SQL skills, fluent in R and/or Python, advanced Microsoft Office skills, particularly Excel and analytical platforms",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Staff Machine Learning Engineer,-1,"Business Title
Staff Machine Learning Engineer

17-Apr-2020

Requisition Number
22965BR

Job Description and Requirements
Overview

Join a new and growing team at Synopsys focused on advancing state-of-the-art in Machine Learning. The team is working on developing Chip Design Solutions that will change the way how Chips are designed. Our focus is to develop ML driven technologies that could improve Quality of Results as well as Time to Results.

Ongoing research and development involve following technologies …
• Deep Learning
• Reinforcement Learning
• Bayesian Optimization, Gaussian Processes
• Unsupervised Learning
• Probabilistic Modeling
• Bayesian Network Modeling

Minimum Qualifications
• Exceptional team player
• Research oriented mindset : Should be able to review existing research publications in the relevant area and provide feedback on applicability in the current problem
• Strong understanding of Machine Learning fundamentals
• Strong analytical and communication skills
• Prior experience in some of the Machine Learning research areas listed above
• Proficiency in developing code in Python, TensorFlow, PyTorch, C++
• Object Oriented Software architecture Design

Education Requirements Required: Bachelor's, Computer Engineering and/or Computer Science and/or Electrical Engineering
Preferred: Master's, Computer Engineering and/or Computer Science and/or Electrical Engineering

Hiring Location
INDIA - Bangalore

Hire Type
Employee

Job Category
Engineering

Country
India",4.0,"Synopsys
4.0",Bengaluru,"Mountain View, CA",10000+ employees,1986,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),"Cadence Design Systems, Mentor Graphics, Ansys"
CIEL/STF/2137: Data Scientist,-1,"Strong problem-solving skills with an emphasis on data transformation.
Work Experience of 3-6 years
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
Senior Data Scientist- AI,-1,"Description:
Background:
Lymbyc is the first and currently the only player, in the predictive engine-based self-service analytics product space for end business users. We have created the world’s first data scientist, Leni, capable of understanding plain English queries from user, and autonomously being able to take decisions ranging from data selection to algorithm selection and finally visualisation and narratives, without any human intervention. And now we are embarking on bringing explainable component to our AI based solutions, to make the business decisions simpler, easier and adaptable to larger stakeholders.

By way of our acquisition, we at Lymbyc now are working full tilt with LTI’s global reach to take Leni to the world’s major businesses.

Description:
We need ace data scientists who can develop best in class predictive models, machine learning models and deep learning models and at the same time they should be able to explain the decisions taken by the models automatically through plain simple English language. The explainable elements should not be limited to the numbers and formulas, there must be a bit of personalization also to understand the context of the problem.

Roles and Responsibilities:
Passion for learning new technologies and be up to date with the scientific research community.
Work in technical teams in development, deployment, and application of machine learning solutions, leveraging technical components and explaining the modelling decisions
Take responsibility for insights, reports and explanability of the decisions taken by predictive models
Responsible for taking an idea from concept to production thoroughly with feedback from all stakeholders.

Qualification:
Masters’ in Computer Science/M. tech/PhD/Statistics/Econometrics/Applied Mathematics/Applied Statistics/Operations Research is a must
Hands on Experience with data mining or machine learning, deep learning, computer vision, natural language processing
Hands on Experience in developing deep learning models and explaining the results of deep learning models in a business-friendly manner

Skills Required:
Must have minimum of 5-7 years of industry experience in developing data science models.
Deep understanding and experience in the field of Machine Learning, Deep Learning and statistical learning
The person should be excellent at Classification (logistic regression, svm, decision tree, random forest, neural network), Regression (linear regression, decision tree, random forest, neural network), Classical optimisation (gradient descent, newton rapshon, etc), Graph theory (network analytics), Heuristic optimisation (genetic algorithm, swarm theory)
Should be strong at Deep leaning (CNN, LSTM, RNN, Bi-LSTM)
Must have thorough mathematical knowledge of correlation/causation, decision trees, classification and regression models, recommenders, probability and stochastic processes, distributions, priors and posteriors.
Skilled at scientific programming languages such as Python, R, Matlab and writing deployable code into production.
Understand the model lifecycle of cleansing/standardizing raw data, feature creation/selection, writing complex transformation logic to generate independent and dependent variables, model selection, tuning, A/B testing and generating production ready code.
Knowledge of Numerical optimization, Linear/Non-linear/Integer programming, Statistics, Combinatorial optimization is a plus.
Familiarity with R, Apache Spark (Scala, Python), PyMC3/theano/tensorflow/Keras and other scientific python/R modules is a must.
AI skillsets – hands-on Machine learning and Deep Learning algorithms and platforms, neural networks in any, or all the following areas, specifically, in Data & Analytics use cases
Language – Natural Language Processing, machine translation, emotion detection, language detection, classification
Vision – computer vision, object recognition/tracking, face/gender/age/emotion recognition, OCR/handwriting recognition
Knowledge and experience in some of the key AI platforms will be important, e.g. IBM Watson, Microsoft Azure, Google Api.Ai, Facebook Wit.Ai, Chatbots using Microsoft Bot Framework
Knowledge and experience of key machine learning and deep learning framework, e.g. Keras, TensorFlow, Caffe, CNTK, Jiraffe, MXNet and PyTorch commercial technologies/platforms, etc",3.5,"Lymbyc Solutions
3.5",Bengaluru,"Bengaluru, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Science (Jupyter/Azure ML/MatLab),-1,"Accenture Technology powers our clients businesses with innovative technologiesestablished and emergingchanging the way their people and customers experience work, life and entertainment. Join Accenture Technology and youll translate the operational needs of the worlds governments and leading businesses into the innovative technical solutions that will enable them to better serve their customersyour friends, family and neighbors.Youll deliver everything from point solutions for a single business function to large, long-term outsourcing services, to complex systems integration installations spanning multiple businesses and functions. Youll create custom-designed solutions or integrate our technology platforms with their operations.

Role :Digital Data Engineering Practitioner
Role Description :Develop analytics based solutions that produce quantitative and qualitative business insights. Work with partners as necessary to integrate systems and data quickly and effectively, regardless of technical challenges or business environments.
Must Have Skills :Data Science (Jupyter/Azure ML/MatLab)
Good To Have Skills :Python Scripting,R Programming,Spark Programming
Job Requirements : Role: Data Scientist
Must Have:
1 Exp in Data science frameworks Jupyter notebook, AWS Sagemaker etc
2 Exp querying databases and using statistical computer languages: R, Python, SLQ, etc
3 Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis,
4 Exp with distributed data/computing tools: Map/Reduce, Flume, Drill, Hadoop, Hive, Spark, Gurobi, MySQL

Good to Have:
1 Coding knowledge and experience with several languages: C, C, Java, JavaScript, NodeJS
2 Experience using cloud services: RDS, Athena, Redshift, Kinesis, S3, AWS glue
3 Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks
4 Exp in visualizing/presenting data for stakeholders using: AWS Quicksight, Tableau, Periscope, Business Objects, D3, ggplot",3.9,"Accenture
3.9",Hyderabad,"Dublin, Ireland",10000+ employees,1989,Company - Public,Consulting,Business Services,₹500+ billion (INR),"Cognizant Technology Solutions, EY, McKinsey & Company"
Data Scientist Intern,-1,"Pursuing Masters or equivalent advanced degree from a top tier Technology school
Record of delivering large analytical solutions with business impact
Experience on R/SAS/Matlab and SQL
Excellent Microsoft Office skills, including a strong working knowledge of Excel
Problem solving ability and passion for big data
Excellent communication and data presentation skills
Fluent written and spoken English
Amazon's looking for Data Scientist to optimize one of the most complex logistics systems in the world. Academic and/or practical background in Computer Science, Engineering, Operations Research, or Process Control are particularly relevant for this position. Experience in the integration of model-based engineering tools and/or multidisciplinary analysis & optimization is also a plus.

Major Responsibilities:
Use data analyses and statistical techniques to develop solutions to improve customer experience and to guide business decision making
Identify predictors and causes of business related problems and implement novel approaches related to forecasting and prediction
Identify, develop, manage, and execute analyses to uncover areas of opportunity and present written business recommendations
Collaborate with multiple teams as a leader of quantitative analysis and where you develop solutions that utilize the highest standards of analytical rigor and data integrity
Analyze and solve business problems at their root
Masters or equivalent advanced degree in Computer Science, Computer Engineering, Statistics, Mathematics or related technical discipline. Hands-on experience and project based learning in computer science, engineering or mathematics is preferred.
Academic experience in manipulating/transforming data, model selection, model training, cross-validation and deployment at scale.
Academic or Project Experience with Machine and Deep Learning toolkits such as MXNet, TensorFlow, Caffe and PyTorch.
Academic Experience with Big Data platforms like Apache Spark and Hadoop.
Familiarity with data processing with Python, R & SQL.
Familiarity with AWS services related to AI/ML highly desirable, particularly Amazon EMR, AWS Lambda, SageMaker, Machine Learning, IoT, Amazon DynamoDB, Amazon S3, Amazon EC2 Container Service, Green Grass etc.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Analyst,-1,"Responsibilities:
We are looking to add a Data Analyst who will partner with teams across the entire organization to ensure the highest quality of data across all workflows and to derive insights from this data to take our product to the next level. Do you have strong SQL skills and an excellent attention to detail? Are you passionate about adding product value through data discovery? If so, then this may be the role for you!

As a Data Analyst, you will directly support the growth and development of the products that our customers use every day. Daily we are aggregating billions of events from our data partners and from our customers for whom we are building world-class sales and marketing insights.

You'll work closely with the Data Science so that our modeling process has optimal data inputs, our Technical Success team to optimize customer on-boarding quality, with the Product team while building additional datasets that can be leveraged in new features and offerings, and collaborate with the Engineering team while building out and optimizing data pipelines.

You will work in a challenging, dynamic, fast paced environment with a mindset to contribute beyond basic responsibilities and constantly look for better ways to deliver top quality insights and solutions. Other responsibilities include:
• Working with different teams at 6sense to build reporting to gain deeper insights into our data

• Diving into and discovering new potential for existing data

• Providing recommendations and solutions on how to deal with problem data inputs

• Building out new methods/testing procedures for improving and ensuring data quality

Qualifications:
• 5+ years of data analysis experience

• You know SQL in and out, window functions and all

• Have worked with BI tools like Tableau, Domo, Qlikview, etc.

• You love to tell data driven stories

• Able to prioritize and execute tasks in a high-pressure, constantly changing environment

Good to have:
• Experience working Presto

• Experience with the Hadoop ecosystem including Hive

• Development experiences with various databases and DBMSs

• Proficient with data processing flowcharting techniques",4.9,"6sense
4.9",Pune,"San Francisco, CA",51 to 200 employees,2013,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Lead Data Scientist,-1,"Your Day-to-day Will Involve
Using modeling and analytics to understand how business decisions impact our bottom line. This may include assessing risks of new products, determining fraud policies, or identifying inefficiencies in existing operations.
Ensuring the team is delivering on our KPIs by using various data mining and data visualization tools to monitor portfolio performance and identify improvement opportunities
Developing hypotheses and set up your own problem frameworks to test for the best solutions. You will also scope the operational feasibility, lead implementation efforts, and monitor the success of your solutions.
Leveraging data analysis tools and technologies. For example, using machine learning to determine how we identify fraud.
Creating new solutions rooted in empathy and research that assist all customers as they work to better manage their finances.
Collaborating in a team environment. As part of our crew, you will learn to energetically rally diverse groups in pursuit of a common goal.

The Ideal Candidate Is
Innovative & Curious - You have the desire and ability to connect and empathize with our customers. You have an entrepreneurial spirit and get excited about creating new businesses and reinventing current ones. You ask why, explore, and bring your unique perspective to the table.
Analytical& Action-Oriented - You are data driven and outcome focused. You grow comfortable with ambiguity, fueled by a hunger to learn and constantly seeking out new challenges. You have a desire to take action, try new things, and sometimes fail. You persevere but know when to change course and are up for juggling multiple deliverables.
Collaborative & Team-Oriented- You always keep the people around you in the loop and are excited to communicate complex ideas clearly to make sure your co-workers understand the why behind their work and their key priorities.
Inclusive- You will empathize with those around you and care about their success, as you bring people together around whats possible.
Basic Qualifications
Bachelors degree or higher in a quantitative field (Business, Math, Economics, Finance, Statistics, Science, Engineering)
At least 1 year of work experience in analysis or consulting
Experience with or willingness to learn tools such as SQL, R, Python, Tableau
We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors, which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.
PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities.",3.5,"PayPal
3.5",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Data Engineer,-1,"Location: Bangalore- India
Job ID: 19WD35705

Position Overview
As a Data Engineer, you will be responsible for building the data foundations that enable data driven marketing at Autodesk

Responsibilities
Build ETLs and data processing workflows for various projects
Setup reliable data ingestion pipelines for new data sources and integrate them with other data sets
Provide engineering support to investigate, identify and setup new tools and processes for data warehousing, data quality, reporting, business intelligence, data governance and data cataloging
Build data quality tracking mechanisms and address inevitable disruptions in data ingestion and processing
Assist in building a comprehensive data catalog and implement data governance strategies, as required by the business
Address questions and concerns from downstream data consumers
Continue to adapt to changes based on emergence of new technologies, new competitors, artificial intelligence and alternative sources of data
Qualifications
Bachelors or master’s degree in Computer Science, Engineering, Statistics, Informatics, Information Systems or in another quantitative fields
2 years of experience in data engineering or data warehousing
Intermediate to advanced SQL skills
Excellent programming skills in Python, Java, or Scala. (Python preferred)
Experience working with relational databases, query authoring as well as working familiarity with a variety of databases
Optional Experience building products in a cloud-based environment, especially AWS and its services like EC2, Lambda, API Gateway, S3, EMR, RDS, Cloudwatch etc
Optional Experience working on or integrating a diverse set of in-house or acquired technologies
Optional Experience working on Spark or a similar distributed processing platform
Optional Experience working on orchestration tools like Airflow
Optional Working knowledge of the Agile development process
The Ideal Candidate
Strong technical aptitude and strong interest to learn best of class technologies around data warehousing, data wrangling, data quality and data governance
Excellent problem solving and analysis skills
Excellent written and verbal communication skills, empathy, initiative and ownership
Superb analytical skills, technical aptitude, influencing skills and attention to detail
Eager to learn new things and passionate about technology
Flexible and be able to embrace change effectively
Ability to work effectively in teams
Process focused",4.0,"Autodesk
4.0",Bengaluru,"San Rafael, CA",5001 to 10000 employees,1982,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),-1
Data Scientist - Machine Learning/Artificial Intelligence/ Python -BFSI,-1,"Experience 4 - 10 Years
Salary 8 LPA - 16 LPA
Job Location Bengaluru

Industry:
IT-Software / Software Services

Keywords:
Data Scientist

About Job:
Core Responsibility :
Strong experience in delivering projects in using Python.
Strong experience in developing models using Image Processing and Computer Vision algorithms
Designing, developing, and deploying deep learning models on AWS environment.
Experience and Skills :
4 - 6 years- experience in Designing and Deploying Deep Learning Solutions
Excellent knowledge of Deep Learning Architectures/Convolutional Neural Networks
Excellent knowledge of Supervised Learning, Adversarial Learning
Excellent Python Coding Skills with at least 4 years of Python coding
Robust working knowledge with deep learning frameworks (like Tensorflow, Keras, PyTorch)
Hands on experience on Image Processing and Computer Vision algorithms
Experience with GPU/CUDA programming
Deep knowledge of mathematics, probability, statistics and algorithms
Understanding of data structures, data modelling and software architecture
Excellent communication skills
Ability to work in a team
Outstanding analytical and problem-solving skills
Must Have :
Aware of the Software Development Life Cycle and Quality concepts
Excellent experience in Python programming language for data analysis.
Excellent verbal and written communications skills; Strong interpersonal skills
Managing available resources such as cloud services, data
Good to Have :
Experience with System Development Life Cycle methodologies (CMMI)",4.0,"Careerera
4.0",Bengaluru,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
Senior Data Scientist / Algorithms Specialist,-1,"Job Description:
Should possess strong design and architecture skills.
Deliver solutions for Fortune 100 customers using an Agile Development model
Understanding and working to come up with solutions to problems, design and architect, Building and collaborating with business and technical teams to deliver software.
Positions : 10

Skillset:
At least 4+ years of solid experience in the software industry
Experience working in / Understanding of Big data a technologies – worked in Hadoop, MapR and Map/Reduce, Pig, Hive
Played pivotal roles as an engineer and architect across domains
Understanding of Big data a technologies – Hadoop, MapR and Map/Reduce, Pig, Hive
NoSQL solutions like Hbase, Cassandra, MongoDB, CouchDB, and be comfortable with commercial solutions too
Expertise in SQL databases (e.g. MySQL or Oracle), Analytics platforms (e.g. Pentaho, BO or similar) and OLAP technologies
Solid technology stack in J2EE and .Net (desirable but not essential)
Be very comfortable with Agile methodologies in order to be able to arrive at difficult engineering decisions quickly.
Good to have experience with MPP databases like Netezza, ETL tools like Informatica, and BI tools like SAS etc.
Good to have knowledge of web Analytics and exposure working with data sources clickstream data etc.
Proven ability to lead a team of engineers

Other Skillset:
Passion for technology and willingness to learn is required
Have ability to work in a fast paced and dynamic work environment and be able to produce efficient and robust solution
High energy, confidence, and agility to drive a team.
A creative thinker who can bring in new ideas and innovations to the company.
Job Type: Full-time

Required experience:
Hadoop, MapR : 2 years

Required education:
Bachelor’s",4.3,"AmyLogic
4.3",Bengaluru,"Jaipur, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist- AI,-1,"Description:
Lymbyc is the first and currently the only player, in the predictive engine-based self-service analytics product space for end business users. We have created the world’s first data scientist, Leni, capable of understanding plain English queries from user, and autonomously being able to take decisions ranging from data selection to algorithm selection and finally visualisation and narratives, without any human intervention. And now we are embarking on bringing explainable component to our AI based solutions, to make the business decisions simpler, easier and adaptable to larger stakeholders.

By way of our acquisition, we at Lymbyc now are working full tilt with LTI’s global reach to take Leni to the world’s major businesses.

Descriptions

We need ace data scientists who can develop best in class predictive models, machine learning models and deep learning models and at the same time they should be able to explain the decisions taken by the models automatically through plain simple English language. The explainable elements should not be limited to the numbers and formulas, there must be a bit of personalization also to understand the context of the problem.

Roles and Responsibilities:
Passion for learning new technologies and be up to date with the scientific research community.
Work in technical teams in development, deployment, and application of machine learning solutions, leveraging technical components and explaining the modelling decisions
Take responsibility for insights, reports and explanability of the decisions taken by predictive models
Responsible for taking an idea from concept to production thoroughly with feedback from all stakeholders.

Qualification:
Masters’ in Computer Science/M. tech/PhD/Statistics/Econometrics/Applied Mathematics/Applied Statistics/Operations Research is a must
Hands on Experience with data mining or machine learning, deep learning, computer vision, natural language processing
Hands on Experience in developing deep learning models and explaining the results of deep learning models in a business-friendly manner

Skills Required:
Must have minimum of 3-5 years of industry experience in developing data science models.
Deep understanding and experience in the field of Machine Learning, Deep Learning and statistical learning
The person should be excellent at Classification (logistic regression, svm, decision tree, random forest, neural network), Regression (linear regression, decision tree, random forest, neural network), Classical optimisation (gradient descent, newton rapshon, etc), Graph theory (network analytics), Heuristic optimisation (genetic algorithm, swarm theory)
Should be strong at Deep leaning (CNN, LSTM, RNN, Bi-LSTM)
Must have thorough mathematical knowledge of correlation/causation, decision trees, classification and regression models, recommenders, probability and stochastic processes, distributions, priors and posteriors.
Skilled at scientific programming languages such as Python, R, Matlab and writing deployable code into production.
Understand the model lifecycle of cleansing/standardizing raw data, feature creation/selection, writing complex transformation logic to generate independent and dependent variables, model selection, tuning, A/B testing and generating production ready code.
Knowledge of Numerical optimization, Linear/Non-linear/Integer programming, Statistics, Combinatorial optimization is a plus.
Familiarity with R, Apache Spark (Scala, Python), PyMC3/theano/tensorflow/Keras and other scientific python/R modules is a must.
AI skillsets – hands-on Machine learning and Deep Learning algorithms and platforms, neural networks in any, or all the following areas, specifically, in Data & Analytics use cases
Language – Natural Language Processing, machine translation, emotion detection, language detection, classification
Vision – computer vision, object recognition/tracking, face/gender/age/emotion recognition, OCR/handwriting recognition
Knowledge and experience in some of the key AI platforms will be important, e.g. IBM Watson, Microsoft Azure, Google Api.Ai, Facebook Wit.Ai, Chatbots using Microsoft Bot Framework
Knowledge and experience of key machine learning and deep learning framework, e.g. Keras, TensorFlow, Caffe, CNTK, Jiraffe, MXNet and PyTorch commercial technologies/platforms, etc",3.5,"Lymbyc Solutions
3.5",Bengaluru,"Bengaluru, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"GRM Actuarial East & West Predictive Modeling Team is searching for a highly motivated Senior Data Scientist who is eager to make an impact on the very complex and evolving global insurance industry. The East & West Predictive Modeling Team is responsible for developing statistical models and tools that will help Libertys non-US operations improve their business results and meet their strategic priorities. You will provide highly technical analytical assessments of business issues to a mixture of technical and non-technical audiences so good communication skills are essential

Responsibilities:
Collaborate with business partners to develop predictive models that will drive strategic decision making.
Utilizes advanced analytics techniques to solve business problems. May regularly utilize, update and adapt predictive modeling tools
Work extensively with key stakeholders across East & West to understand business needs, vet opportunities, and deliver modeling solutions and tools to drive business results.
Drive projects execution and implement a robust plan for monitoring and measuring success.
Understand the business issues and data challenges in the country markets to deliver actionable insights, recommendations and business processes.
Manage and prioritize multiple moderate-to-highly complex projects including gathering business requirements, developing project goals, coordinating project timelines, developing models and communicating project status and deliverables with customers and management.
Build strong relationships and lead frequent two-way communication with in-country analytics team members and functional subject matter experts.
Help identify and model best practices which will enhance the predictive modeling and analytical capabilities of modeling groups across East & West operations.
Present findings, share insights, and make recommendations that impact profitability, growth and/or customer satisfaction.
Effectively communicate results in written, oral and presentation formats.
Expected global travel: 20-30%
Qualifications:
Masters Degree in Mathematics, Economics, Statistics or any other quantitative field plus a minimum of 4-5 years of applied business/non-academic experience preferred; Ph.D. plus a minimum of 2-4 years of experience preferred.
Proficient in predictive analytics including real-world experience in model development, validation, testing and monitoring.
Proficient with at least one language for data analysis and modeling, such as R, Python or SAS.
Experience with very large analysis datasets and Enterprise-scale database systems.
Proficient in predictive modeling including experience in the following: generalized linear models, survival models, random forests, clustering, and Bayesian approaches to data analysis.
Knowledge of insurance principles, underwriting and the various functions of an insurance organization, including Finance, Underwriting, Sales and Claims desirable.
Strong organizational skills, ability to balance multiple projects and adapt to changing needs.
Ability to perform high-level work both independently and collaboratively as a project team member or leader.
Ability to establish and build effective relationships within the organization.
Strong verbal and written communication skills, interpersonal skills, and ability to clearly and effectively communicate technical results to a non-technical business audience.
Powered by JazzHR",3.6,"Liberty Insurance Pte Ltd
3.6",Mumbai,"Singapore, Singapore",201 to 500 employees,-1,Company - Private,Insurance Operators,Insurance,Unknown / Non-Applicable,-1
"Data Scientist, Smart MFG & AI",-1,"Req. ID: 181176

Micron Technology’s vision is to transform how the world uses information to enrich life and our commitment to people, innovation, tenacity, collaboration, and customer focus allows us to fulfill our mission to be a global leader in memory and storage solutions. This means conducting business with integrity, accountability, and professionalism while supporting our global community.

Do you believe that data provides groundbreaking insight? Do you see data as an asset that builds a competitive advantage? Great…so do we!

Micron Technology operates in a highly competitive industry where innovation depends on hardworking minds extracting fresh insights from an ever-expanding data universe. We are seeking an experienced Data Engineer capable of designing and implementing large data solutions from data streams and intelligent systems, including transforming, supporting, configuring and enhancing existing data solutions. Are you experienced in applying Data Engineering and Machine learning to Big Data, never-before-solved problems for industrial manufacturing at scale? Does this sound like the right team for you? Apply today!

As a Big Data Engineer at Micron Technology Inc., you will be a key member of a multi-functional team responsible for developing and growing Micron’s methods and systems for extracting new insight for our expanding data streams. You will be collaborating with data scientists, engineers, technicians and data mining teams to design and implement systems to extract data from Micron’s business systems, transforming it into an actionable format, and as needed, creating dynamic presentation layers for use by high-level engineers and managers throughout the company. You will be creating new solutions, as well as, supporting, configuring, and improving existing solutions.

Responsibilities and Tasks

Understand the Business Problem and the Relevant Data

Maintain an intimate understanding of company and department strategy
Translate analysis requirements into data requirements
Identify and understand the data sources that are relevant to the business problem
Develop conceptual models that capture the relationships within the data
Define the data-quality objectives for the solution
Be a subject matter expert in data sources and reporting options
Architect Data Management Systems
Use understanding of the business problem and the nature of the data to select appropriate data management system (Big Data, OLTP, OLAP, etc.)
Design and implement optimum data structures in the appropriate data management system (Hadoop, Teradata, SQL Server, etc.) to satisfy the data requirements
Plan methods for archiving/deletion of information

Develop, Automate, and Orchestrate an Ecosystem of ETL Processes for Varying Volumes of Data

Identify and select the optimum methods of access for each data source (real-time/streaming, delayed, static)
Determine transformation requirements and develop processes to bring structured and unstructured data from the source to a new physical data model
Develop processes to efficiently load the transform data into the data management system
Prepare Data to Meet Analysis Requirements
Work with the data scientist to implement strategies for cleaning and preparing data for analysis (e.g., outliers, missing data, etc.)
Develop and code data extracts
Follow standard methodologies to ensure data quality and data integrity
Ensure that the data is fit to use for data science applications

Qualifications and Experience:
0-7 years of experience developing, delivering, and/or supporting data engineering, advanced analytics or business intelligence solutions
Ability to work with multiple operating systems (e.g., MS Office, Unix, Linux, etc.)
Experienced in developing ETL/ELT processes using Apache Ni-Fi and Snowflake
Significant experience with big data processing and/or developing applications and data sources via Hadoop, Yarn, Hive, Pig, Sqoop, MapReduce, HBASE, Flume, etc.
Understanding of how distributed systems work
Familiarity with software architecture (data structures, data schemas, etc.)
Strong working knowledge of databases (Oracle, MSSQL, etc.) including SQL and NoSQL.
Strong mathematics background, analytical, problem solving, and organizational skills
Strong communication skills (written, verbal and presentation)
Experience working in a global, multi-functional environment
Minimum of 2 years’ experience in any of the following: At least one high-level client, object-oriented language (e.g., C#, C++, JAVA, Python, Perl, etc.); at least one or more web programming language (PHP, MySQL, Python, Perl, JavaScript, ASP, etc.); one or more Data Extraction Tools (SSIS, Informatica etc.)
Software development
Ability to travel as needed

Education:
B.S. degree in Computer Science, Software Engineering, Electrical Engineering, Applied Mathematics or related field of study.

M.S. degree preferred.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

For US Sites Only: To request assistance with the application process and/or for reasonable accommodations, please contact Micron’s Human Resources Department at 1-800-336-8918 or 208-368-4748 and/or by completing our General Contact Form

Keywords: Hyderabad || Telangana (IN-TG) || India (IN) || SGA || Experienced || Regular || Manufacturing/Production Operations || #LI-NB1 || Tier 4 ||",-1,Micron,Hyderabad,"Scottsdale, AZ",1 to 50 employees,-1,Company - Private,Healthcare Product Manufacturing,Manufacturing,Unknown / Non-Applicable,-1
Software Developer 4 - Speech Scientist,-1,"Description

SHIFT: Day Job

SCHEDULE:

Design, develop, troubleshoot and debug software programs for databases, applications, tools, networks etc.

As a member of the software engineering division, you will take an active role in the definition and evolution of standard practices and procedures. You will be responsible for defining and developing software for tasks associated with the developing, designing and debugging of software applications or operating systems.

Work is non-routine and very complex, involving the application of advanced technical/business skills in area of specialization. Leading contributor individually and as a team member, providing direction and mentoring to others. BS or MS degree or equivalent experience relevant to functional area. 7 years of software engineering or related experience.

Qualifications

We are looking for someone who is:

·Experienced with speech recognition. Knowledge of Kaldi is a plus.

·Strong background in language modeling and machine learning. Relevant Master’s degree or PHD preferred.

·Familiar with deep learning technologies and frameworks such as tensorFlow and PyTorch.

·Eager to advance the state of the art for speech recognition.

·Able to adapt to a fast-paced work environment and can quickly adjust to changing priorities.

·Detail oriented with a focus on quality of the product, data, and code.

·An experienced software development with 5+ years of professional development in at least one object-oriented programming language (C++, Java, C#). Python is a plus.

·Familiar with cloud platforms and cloud services development.

·Has excellent communication skills with an ability to explain and write specifications that embody complex concepts to stakeholders within the team.

·Can tackle hard problems with tenacity and positivity.

Expected engineering tasks include:

·Working closely together with software engineers and other speech scientists to build production-grade large vocabulary speech recognition language and acoustic models.

·Research and implement new approaches and benchmark solutions against state of the art.

·Data cleanup and curation as needed for modeling.

·Maintain and contribute to training recipes, optimization efforts and performance tuning to meet accuracy, memory and run-time demands

·Continuous improvement and maintenance of training and testing toolchains

·Explore new prototyping frameworks, libraries and technologies by developing and implementing prototypes, algorithms and experiments which serve as proof-of-concepts

·Advise and mentor junior research scientists, interns or students

]]>",3.6,"Oracle
3.6",Bengaluru,"Redwood City, CA",10000+ employees,1977,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹500+ billion (INR),"SAP, Salesforce, Microsoft"
Staff Research Scientist,-1,"Company Description

FireEye is the leader in intelligence-led security-as-a-service. Working as a seamless, scalable extension of customer security operations, FireEye offers a single platform that blends innovative security technologies, nation-state grade threat intelligence, and world-renowned Mandiant® consulting. With this approach, FireEye eliminates the complexity and burden of cyber security for organizations struggling to prepare for, prevent, and respond to cyber attacks. FireEye has over 7,500 customers across 67 countries, including more than 50 percent of the Forbes Global 2000.
Job Description

We are seeking Sr. Research Scientist with the passion and experience necessary to solve the malware problem across multiple platfrorms including both mobile and desktop. The candidate will work for FireEye’s security research team, which is a group of top notch security researchers specializing in areas from Machine Learning to reverse engineering advanced malware.

Responsibilities:
Perform leading edge malware research, analysis (data-mining) and generate content for use in our products.
Enhance FireEye’s security content infrastructure, process workflow, and the malware intelligence portal.
Run the FireEye’s security content release process, controlling content selection, packaging, and coordination with DEV/QA/Customer-Support teams.
Qualifications

Requirements:
At least 5 years direct or equivalent experience in areas of malware-analysis, software/security-content build/release, networking/system administration or software development
BS/MS in computer science or equivalent experience
Knowledge in Malware Analysis and Reverse Engineering
Proficiency with network traffic analysis tools such as wireshark and tcpdump
Knowledge in Security and Malware detection technologies
Solid programming skills with scripting languages such as Perl or Python is required
Working knowledge of databases such as Postgres or MySQL
Working knowledge of Rapid Web development frameworks/languages and environments such as PHP etc
Deep working knowledge of networking concepts: TCP/IP, HTTP, HTTPS, FTP, IRC, RPC, DNS etc
Host based IDS/IPS knowledge and experience a definite plus
Additional Qualifications:
Strong problem solving, troubleshooting and analysis skills
Experience working in fast-paced development environments
Excellent written & verbal communication skills
Excellent inter-personal and teamwork skills
Self-driven, proactive, hardworking, team-player with a good sense of humor",3.2,"FireEye, Inc.
3.2",Bengaluru,"Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Data Scientist (Bangalore, India)",-1,"CORESIGHT RESEARCH:
The Coresight Research team, based in New York, London, Hong Kong, and India is a think tank that follows emerging retail and tech trends, specializing in the ways retail and technology intersect, and builds collaborative communities. The team, led by Deborah Weinswig, an award-winning retail and technology analyst, delivers cutting-edge research on topics such as the evolving retail landscape, changing consumer behavior, disruptive retail technologies and the future of supply chains in sectors such as apparel, beauty, grocery, and furniture. More information can be found at Coresight.com.

POSITION OVERVIEW:
The team focuses on leveraging data and analytics to innovatively bring better products to our clients in the retail and technology industries. Based in Mangalore / Hyderabad and reporting into the Head of India and the Head of Data, the Data Scientist will be responsible for developing data dashboards and maintaining reports using various technologies.

RESPONSIBILITIES:
Demonstrate a deep knowledge of and ability to operationalize, leading data technologies and best practices (via various mechanisms: SQL reports, CSV / Excel extracts, Tableau, PowerBI).
Responsible for developing algorithms to automate collection process and adding new features to the current database.
Establish methodologies for quickly rolling out new data analysis capabilities for standalone data-driven products and service to support our associates.
Build architecture and dashboards to support team’s data collection and presentation process
Formulate best practices for the data team; work close with data strategy head to identify areas for performance and improvement.
Identify avenues and methods for relevant data extraction and communicate to stakeholders
Should have experience in using data languages such as R / Python and have experience in web scrapping / writing web crawler.
Have end-to-end responsibility for leading projects focused on well-written documentation, extracting, merging, analyzing and managing large sets of data across multiple, disparate databases.
Develop a proficiency in the retrieval and manipulation of data from spreadsheets, a data warehouse or database environment.
Make decisions independently on analytical problems and methods and able to transform unstructured raw data in to formats suitable for modeling.
Responsible for building up the data science team in India and training those junior data analysts.
Be able to work in teams and collaborate with stakeholders to define requirements
Be able to identify and suggest novel areas of future work for themselves or the team
REQUIREMENTS:
Bachelors Degree/Masters Degree (preferably from a computer application background)
5+ years of experience in similar role
Candidate with Machine Learning and Data Analytics experience
Candidate with programming experience of automating data collection process will be a plus
Strong analytical skills and data modelling skills
Strong writing and oral communication skills
Strong investigative skills - specialists require tenacity and patience to thoroughly review digital assets and have sharp intuitions about data architecture, website layouts, design and functionality
Ability to seamlessly navigate various programs and tools utilized as part of the collection process
The ability to think and work through gaps of knowledge, by being comfortable approaching researchers and managers and asking informed questions whenever there are ambiguities during collection assignments
Impeccable attention to detail as the specificity of data points and high volume of data being collected requires collectors to be meticulous and precise
Extremely detail-oriented/self-motivated/strong time management skills
Ability to work with team members located in different time zones
Open to receive and act on constructive criticism.
Excellent self-organization skills.
Ability to work collaboratively in an open team environment.
A positive attitude and a commitment to bringing fresh ideas to the team.
Coresight Research offers a competitive salary, an entrepreneurial work environment, and realistic growth potential. We value a culture of inclusion and diversity within our workforce. We are committed to maintaining a workplace free from prohibited employment conduct, including discrimination or harassment on the basis of race, color, national origin, sex, age, religion, disability, genetic information, sexual orientation, gender identity or expression, marriage and civil partnership, pregnancy and maternity and any other characteristic protected by law. Coresight Research is an equal opportunity employer.",2.9,"Coresight Research, Inc.
2.9",Mangalore,"New York, NY",1 to 50 employees,2018,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
Data Science part time job/internship,-1,"About the company:
We are a Singapore based software company, working on digitizing business cards for businesses and corporates. Our mobile app can be used for sending e-cards, contacts management, and lead generation.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Design, build and refine our data and analytics infrastructure scaling to terabytes of data 2. Grow our analytical capabilities with faster, more reliable data pipelines, and better tools 3. Design and develop a real-time events pipeline for data ingestion for real-time dashboarding 4. Develop complex and efficient functions to transform raw data sources into powerful and reliable components of our data lake 5. Collaborate with various cross-functional teams: infrastructure, network, and database

Who can apply:
Only those students or freshers can apply who:
are available for the part time job/internship (it may be part time in-office or part time at home/work from home online)
have relevant skills and interests
can start the part time job/internship between 2nd Apr'20 and 22nd May'20
are available for duration of 3 months
have already graduated or are currently in any year of study
are from Delhi, Ghaziabad, Bangalore, Mumbai, Noida, Gurgaon and neighboring cities
Females willing to start/restart their career may also apply

Number of internships/jobs available: 1

Additional details:
An incentive of Rs.10,000 will be provided based on performance and regular attendance.

Categories: Data Science",4.0,"DUIT Technologies
4.0",New Delhi,"Singapore, Singapore",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
"Sr Data Scientist - Computer Vision, Deep Learning",-1,"What's the role?


As a Senior Data Scientist within Quality Testing and Statistics (QTST), you are passionate about statistical sampling and analytic methods, measurements and machine learning models. You will work with map and location experts, engineering teams and fellow data scientists to develop testing plans, quality benchmarks, and predictive models to deliver analytic insights and solutions enabling the highest levels of quality throughout HERE’s offerings.

• Subject Matter Expert (SME) for sampling and test designs, statistics, analytics, training data, and predictive modeling.• Create summary results and reports with graphs, tables, and charts; provide interpretations to project leaders.• Develop sampling plans for data collection, quality evaluation, and the production of training data. Design and create estimators for the evaluation of map quality along various customer use-cases. Design and analyze A/B experiments that validate different optimization and solution approaches, and to calibrate model parameters.• Build and test statistical and machine learning models to support improvement of a wide variety of data-driven processes for map-making data evaluation and decisions. Develop code, databases, tools, and outputs in the R programming environment.• Work with map experts, engineering teams, and other analytic teams. Provide support to the statistical and analytical needs of various departments within the company.

Who are you?
MS or PhD degree in Statistics, Mathematics, Econometrics, or related fields.
5+ years of related work experience
Proficiency of sampling methods, and analytic methods such as regression, classifiers, clustering, association rules, decision trees, etc.
Proficiency with analysis and programming in R, or any similar package (Python, SAS, etc).
Knowledge and experience with using GIS tools for spatial data analysis.
Knowledge of tools such as Pig, Hive, etc. for working with big data in Hadoop or Spark for data extraction/prep for analysis.
Application of statistics in quality area or Six Sigma will be a plus.
Excellent oral and written communication skills.
What we Offer

We will support you in delivering your day to day tasks and achieving your personal goals and develop your skills. Personal development is highly encouraged at HERE. You can take different courses and trainings at our online University and join cross-functional team projects within our Talent Platform. Our office is located with easy access by public transportation options. So, what are you waiting for? Apply now and make HERE your destination. We are just getting started...!

HERE is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, age, gender identity, sexual orientation, marital status, parental status, religion, sex, national origin, disability, veteran status, and other legally protected characteristics.

Make HERE your destination, we are just getting started! Apply now!

Who are we?


Ever checked in somewhere on social media? Ever tracked your online orders? You might be using HERE Technologies every single day without even realizing it. You can find us everywhere: in vehicles, smartphones, drones or third-party apps. We believe that with the right people, we will continue to be a game-changer in the technology industry and improve the daily lives of people around the world. Find out more by clicking the video below or going HERE.",3.7,"HERE Technologies
3.7",Mumbai,"Amsterdam, Netherlands",5001 to 10000 employees,1984,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Google, TomTom, Apple"
Junior Data Scientist,-1,"Job Profile: Junior Data Scientist

Work Location: Visakhapatnam, IN

Educational Qualifications: B.E/B.Tech/M.E/M.Tech

Experience: 1-4 years of work experience in machine learning and data mining domain, where you have been actively involved in industry research.

We will be willing to take exceptionally qualified freshers too.

Job Description:

You should be self-motivated to solve interesting research problems that have a huge business and revenue potential.

Strong communication skills are needed.

You should be able to explain and discuss deeply technical stuff on a day to day basis.

The ability to understand others, as well as having the communication skills to discuss science on a daily basis is an absolute requirement.

As a data scientist, you’d be working towards developing cutting edge products and solutions that are based on state of the art machine learning algorithms and challenging problems in the web-analytics domain.

A real opportunity to expand your skill-sets and a chance to learn and use the latest advances and approaches in machine learning and data mining on real world datasets

Detailed Description:

In this role, you will be required to have the following skills:

Intermediate to advanced knowledge of machine learning, probability theory, statistics and algorithms. You will be required to discuss and use various algorithms and approaches on a daily basis.

Extremely strong programming skills: Since most of the core R&D teams’ work involves solving problems in the big-data domain, preparing datasets for algorithmic exploration is a significant part of the job. You should have strong programming skills (preferably in python), in order to play around with the raw data, and also for deploying various algorithms

Strong analytical skills: We seek individuals who try to look at a problem from various angles, and who have deep analytical skills to understand, grasp and discuss deeply technical and significantly complicated problems, and the solutions that the R&D team is working on.

Job Types: Full-time, Fresher, Walk-In

Experience:
work: 1 year (Preferred)
4 total work: 1 year (Preferred)
Education:
Bachelor's (Preferred)
Work Remotely:
No",-1,SAPIENTIAL TECHNOLOGIES PVT LTD,Visakhapatnam,-1,-1,-1,-1,-1,-1,-1,-1
"Data Scientist, Data Engineer, Deep Learning,",-1,"Opening for Data Scientist At Bangalore (Hebbal )

Experience- Min 2 Years
Location - Bangalore (Hebbal )

Role & Responcibility -

2 - 4 years of experience applying ML / Deep Learning algorithms and techniques to real-world data sets
Expert knowledge of Core Python
Proficiency in Machine learning algorithms (SVM, Decision Trees, PCA, Clustering etc.)
Knowledge and Experience of Deep Learning Algorithms (CNN, RNN, LSTM etc.)
Major ML frameworks: TensorFlow, PyTorch, Keras, Scikit-Learn
Strong analytical thinking
Designs scalable processes to collect, manipulate, present, and analyze large datasets in a production-ready environment
Strong written and oral skills (in English)
Demonstrated participation on platforms like Kaggle is a plus
Prefer great appreciation or expertise in Security products such as End point detection, protection and response, Managed detection and response etc
Kindly revert your Opinion
00-6.00 Years",-1,TechPro HR Consultancy,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Associate Data Scientist - MFG,-1,"Noodle's Data Scientists build advanced AI models that change the way our clients do business by empowering them to make better decisions. Our solutions impact small and large businesses ranging from media, to retail companies, to airlines, to e-commerce, financial services, to government agencies. Members of our Data Science team are passionate about problem solving with applied data science and work with clients to explore, specify, and communicate high-value, AI- based solutions. We geek out about AI technology.

As a Data Scientist at Noodle.ai, you will collaborate with the Noodle Client Service team, Data Engineers, SW Engineers, UX Designers, and industry-specific experts from our client companies to build a deep understanding of our clients' business context and then develop, test, and deploy advanced AI models. As we grow, you will also develop reusable IP to help us move faster, dive deeper, and work more efficiently by generalizing the models, methodologies, and supporting infrastructure that you build. As one of the early hires to join the Noodle.ai team, you will have a significant impact on the future of Enterprise Artificial Intelligence.

Qualifications:

Must haves
1+ years of experience in applied artificial intelligence technologies including machine learning, predictive data analytics, and/or data science
BE/B.Tech or Advanced degree in a relevant field (Computer Science, Operations Research, Statistics, Mathematics, Electrical Engineering, or other Computational Science)
Proficient in python
Experience with spark
Knowledge of data science/machine learning concepts
Demonstrated ability to iteratively conceptualize, design and build data-driven analytical models
Strong capabilities in modern analytics languages/tools
Collaborative, open, and respectful working style
Passion for learning and a desire to grow – Noodlers are life-long learners!
Nice to haves
Experience applying advanced AI techniques (g., machine learning, predictive analytics. optimization, semantic analysis, time-series analysis, advanced visualization) to real-world problems
Experience with R
Experience manipulating and preparing large, heterogeneous data sets (""Big Data"") to support advanced analytics
Demonstrated energy and passion that extends beyond your field of study – Are you a computer scientist who writes poetry? A mathematician who loves psychology? An engineer passionate about public policy? We want to build something with
Experience with (and excitement for) interdisciplinary collaboration",4.5,"Noodle.ai
4.5",Bengaluru,"San Francisco, CA",201 to 500 employees,2016,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),-1
Machine Learning Engineer - Engineering Function (Bengaluru / Remote),-1,"Following a year of rapid growth in our open-source ML projects and winning top tier customers across sectors to support strategic AI platform initiatives, Seldon expanding to find our first technical hire in Bengaluru, India!

We're looking for our first technical base on the ground to help solidify our India operation from day zero. Seldon is looking for a Machine Learning Engineer to join our Solutions Team.

About Seldon
Seldon is a London based scale-up that builds open source and enterprise machine learning frameworks that power massive scale deployments of production AI systems. Our open source frameworks benefits from over 200,000 installations, and power our enterprise product Seldon Deploy, which is currently being used by some of the leading global organisations across industries such as automotive, pharma, finance, etc.

About the role
Your role at Seldon will primarily involve:
Supporting production systems at scale based on our open source and enterprise machine learning products in Kubernetes
Triaging production client deployments to ensure success for large scale production machine learning systems in critical environments
Submit bugs and patches to our open source and enterprise products to resolve issues
Contributing to our open source projects to extend their functionality
Architecting solutions for critical industry machine learning systems
Identifying & documenting best practices for ML Engineering
Optimising the performance of machine learning systems
Designing and delivering high impact solutions with top tier organisations
Contributing to global open source projects and technology conferences
Growing within a scaling startup crafting a role of your own
Required skills:
A degree or higher level academic background in a scientific or engineering subject.
Strong computer science foundations.
Strong System architecture knowledge/experience.
Familiarity with linux based development.
Experience architecting/applying technology to solve real world challenges.
Experience delivering production-level client-facing projects.

Nice-to-have skills:
Experience with Kubernetes and the ecosystem of Cloud Native tools.
Experience using machine learning tools in production.

Benefits:
Share options to align you with the long-term success of the company.
Exciting phase of fast-paced start-up challenges with an ambitious team and unlimited potential for professional growth.
Access to discounted lunches, gyms, shopping and cinema tickets.
Healthcare benefits.
Flexible work-from-home policy.

About our tech stack
Some of our high profile technical projects:
We are core authors and maintainers of Seldon Core, the most popular Open Source model serving solution in the Cloud Native (Kubernetes) ecosystem
We built and maintain the black box model explainability tool Alibi
We are co-founders of the KFServing project, and collaborate with Microsoft, Google, IBM, etc on extending the project
We are core contributors of the Kubeflow project and meet on several workstreams with Google, Microsoft, RedHat, etc on a weekly basis
We are part of the SIG-MLOps Kubernetes open source working group, where we contribute through examples and prototypes around ML serving
We run the largest Tensorflow meetup in London
And much more

Some of the technologies we use in our day-to-day:
Go is our primary language for all-things backend infrastructure including our Kubernetes Operator, and our new GoLang Microservice Orchestrator)
Python is our primary language for machine learning, and powers our most popular Seldon Core Microservices wrapper, as well as our Explainability Toolbox Alibi
We leverage the Elastic Stack to provide full data provenance on inputs and outputs for thousands of models in production clusters
Metrics from our models collected using Prometheus, with custom Grafana integrations for visualisation and monitoring
Our primary service mesh backend leverages the Envoy Proxy, fully integrated with Istio, but also with an option for Ambassador
We leverage gRPC protobufs to standardise our schemas and reach unprecedented processing speeds through complex inference graphs
We use React.js for our all our enterprise user products and interfaces
Kubernetes and Docker to schedule and run our services (Oliver,our Head of Engineering, gave a great talk at KubeCon on how we use these technologies)
AWS for most of our infrastructure
React for internal web dashboards
We also have two physical datacenter sites with actual cables to connect to various third parties

Logistics
Our interview process is normally a phone interview, a coding task, and 2-3 hours of onsite interviews. We promise not to ask you any brain teasers or trick questions. We might design a system together on a whiteboard, the same way we often work together, but we won’t make you write code on one. Our recruitment process has an average length of 3 weeks.",5.0,"Seldon
5.0",Bagalur,"Shoreditch, United Kingdom",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"Work in the fascinating world of Markets IT within Data Engineering & Data Analytics. Help us counteract financial crime by utilizing the latest technologies to detect and uncover unusual activity in trading data.

We are at the start of a journey. We want to create a Centre of Excellence in India. Do you have what it takes to join the journey with us?

Are you passionate about data engineering and big data technologies: Hadoop, Spark, Hive, Airflow, Elastic Search, Docker, Kubernetes, Scala, Python, and Functional Programming?

Do you have a strong interest in Data Science and Financial Markets?

Are you keen to be a key player at the start of something transformative within Danske?

We are seeking skilled Data/Software Engineers to join our team.

Our goal is to create the next generation of analytics tooling focused on the world of fraud, regulatory compliance, and Financial Crime.

Enjoy vibrant and exciting work with challenging tasks, trending technology and all the flexibility you expect of a modern IT organization.

You will work in a team of highly skilled engineers in Bengaluru.

We work closely with our business, regulatory compliance, 3rd party vendors as well as our fellow engineers in Copenhagen and London.

We believe in software development organizations where our engineers are trusted and empowered to take full responsibility for their stack.

We would expect the right person to be competent with:
Scala but we will also consider highly skilled Java Engineers that have a good understanding of functional programming
Python
Experience of building data processing pipelines for use in production batch systems, including either traditional ETL pipelines and/or analytics pipelines
Experience in manipulating data through cleansing, parsing, standardizing, etc, especially in relation to improving data quality/integrity
Test-Driven Development & Automated testing
Experience with large scalable system development and deployment
Working within a Scrum team
Solid understanding of the JVM
Data Structures & Concurrency
Linux

Programming experience:
Scala
Java
Python
Tools and infrastructure experience:
Hadoop
Apache Spark (Scala)
Apache Airflow (Python)
Elastic Search
Bamboo, Go.CD, other CI/CD pipelining tools
Git
Linux
REST and JSON
Gradle",2.5,"Danske IT and Support Services
2.5",Bengaluru,"Copenhagen, Denmark",1001 to 5000 employees,2012,Subsidiary or Business Segment,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Neustar is an information services and technology company and a leader in identity resolution providing the data and technology that enables trusted connections between companies and people at the moments that matter most. More information is available at https://www.home.neustar.

Job Requisition:

R-2927 Data Engineer (Open)

Primary Location:

BANGALORE

Job Description:

Data Engineer

Fueled by start-up energy, Neustar was literally born to manage large datasets. As the original administrator of the North American Numbering Plan (NANP), we were hip to big data long before it was cool. In managing this massive database of phone numbers, we learned the power of being a neutral steward of data by giving competing telephone companies equal access to everybody’s digits. In the following years, we built upon this foundation of data expertise.

As the first real-time provider of cloud-based information services and data analytics, we enable marketing and IT security professionals to promote and protect their businesses. With a commitment to privacy and neutrality, Neustar operates complex data registries and uses its expertise to deliver actionable, data-driven insights that help clients make high-value business decisions in real time, one customer interaction at a time. Our vision is to be the single most trusted source of commercial insight and analysis for our Clients.

More information is available at www.neustar.biz.

Neustar is a place where the entrepreneurial spirit is strong. We embrace innovation and encourage the development of bold new ideas. This is deeply rooted in our culture and comes through in everything we do. Our world-class technology, innovative solutions and experienced employee base have been catalysts for customer success for more than a decade – infusing voice, video and data transactions with true innovation and unparalleled performance.

Description

We’re looking for someone who wants the challenge of working on implementing solutions for on boarding large volumes of data feeding into the front end application.

Responsibilities/Key Tasks
Play a key role in end to end data on boarding and in creating a data pipeline for the end application.
In depth analysis of source data to provide insights for data mapping & business rules setup.
Develop , code & implement the data pipeline
Work closely with technical product managers, solution architects and other internal stakeholders to address issues in data pipeline and to make sure data is ingested accurately and on time.
Assist and shadow rest of the team members and accomplish the tasks in a timely manner
Work in a high paced and rewarding environment with bleeding edge technologies and innovative concepts
Qualifications/Educational Requirements
Bachelor’s Degree, with 3 - 5 years related IT experience.
Adept at data pre-processing & complex data transformations using Hive programming.
Experience in working with HiveQL and performance tuning of Hive queries.
Extensive experience on distributed systems frameworks like Hadoop including hands on experience on HDFS, MapReduce etc.
Proficient in working with large scale multi-node clusters with technologies like HDFS/ Hive etc.
Excellent SQL skills and in-depth understanding of relational databases.
Adept at working on UNIX environments and exposure to shell scripting.
Knowledge of database design principles like OLAP, OLTP and ETL.
Excellent understanding of Oracle and MySql relation databases.
Experience in Python and Java will be an advantage.
Familiarity with big data platforms like Qubole/AWS will be an advantage.
Experience in working with cloud based services like AWS.
Work with an innovative bend of mind to develop creative solutions for data on boarding
Interpersonal Skills
""Self-starter"" attitude
Ability to work closely with fellow Developers and Managers to understand requirements
An effective communicator, able to clearly articulate; clear, succinct and persuasive at all levels
Good written skills
Job Qualifications: (professional and/or technical certifications, education)
BE/B.TECH degree in Computer Science or equivalent
ME/M.TECH degree in Computer Science or equivalent
Neustar does not accept unsolicited resumes from external firms or agencies. Neustar will not be responsible for placement fees associated with unsolicited resumes.

DIVERSITY
Diversity, inclusion and teamwork are second nature to Neustar; and these values permeate our entire business structure. Neustar is committed to creating an environment where a wide spectrum of opinions and beliefs are actively sought, listened to and respected. Further, our talented workforce draws from the many geographic areas and markets in which Neustar operates worldwide, which represents a distinct competitive advantage. The rich and varied personal and professional backgrounds of our employees make Neustar a dynamic and rewarding company at which to build a career. We invite you to join us.

EOE of Minorities/Females/Vets/Disability
Neustar, Inc. considers all applicants for employment without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, or status as a Vietnam-era or special disabled veteran in accordance with federal law and other state and local requirements. Neustar, Inc., complies with applicable state and local laws prohibiting discrimination in employment and provides reasonable accommodation to qualified individuals with disabilities in accordance with the American with Disabilities Act (ADA) and applicable state and local laws.",3.7,"Neustar
3.7",Bengaluru,"Sterling, VA",1001 to 5000 employees,1996,Company - Private,Internet,Information Technology,₹50 to ₹100 billion (INR),"Adobe, Akamai, Oracle"
Junior Data Analyst,-1,"Role: Hiring Junior Data Analyst

Location: Gurgaon, India

GroundTruth is the leading global location platform that leverages data and insights to drive business performance. Using its proprietary Blueprints technology, GroundTruth is able to learn about mobile users and reach them at the right place and right time, ultimately helping companies make smarter marketing decisions, increase sales, and grow their businesses. Since its foundation in 2009, GroundTruth has launched several innovative products and won numerous awards, including Inc. 5000’s Fast Growing Private Companies and Deloitte's Fast 500 Technology companies. Today, we're proud to employ over 400 employees across three continents and serve millions of marketers across 21 countries. Learn more: www.groundtruth.com

This will be an exciting and challenging role that will enable you to work with very large data sets, expose you to cutting edge analysis techniques, work with the latest components in cloud architecture and gain experience in the usage of location data to drive businesses. As an early member you will have significant opportunities for growth within the organization. A successful applicant will be passionate about technology and developing a deep understanding of human behavior in the real world. They would also have excellent communication skills, be able to synthesize and present complex information and be a fast learner.

You will:

• Learn about location-driven marketing and how companies are using location signals to drive their business

• Work closely with marketing, growth strategy and sales teams based out of our offices in USA, UK, Germany

• Develop re-usable tools and templates to quickly create data driven narratives

• Gather requirements, design analyses, identify data sources and define measurement metrics to present insights and recommendations for ready consumption

• Be responsible for managing your work pipeline and creating re-usable analysis and documentation

You have:

• BA/BSc/B.E./BTech degree in Computer Science, Statistics, Mathematics, Economics, Physics or related fields

• 1-2 years of experience in working with data and conducting statistical and/or numerical analysis

• Strong understanding of how data can be stored and accessed in different structures

• Experience with writing computer programs to solve problems

• Strong understanding of data operations such as sub-setting, sorting, merging, aggregating and CRUD operations

• Ability to write SQL code and familiarity with R/Python, Linux shell commands

• Be willing and able to quickly learn about new businesses, database technologies and analysis techniques

• Ability to tell a good story and support it with numbers and visuals

• Strong oral and written communication

•

How you can impress us:

• Experience working with large datasets

• Experience with AWS analytics infrastructure (Redshift, S3, Athena, Boto3)

• Experience building analytics applications leveraging R, Python, Tableau, Looker or other • Experience in geo-spatial analysis with POSTGIS, QGIS

We operate in a fast paced, dynamic environment where everyone on the team is committed to the success and growth of GroundTruth. Our culture is highly entrepreneurial and our success comes from our employees who voice their opinions and ideas to facilitate growth to our bottom line. We reward hard work, support career development, offer comprehensive benefits, and foster a fun and friendly work environment.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",3.3,"GroundTruth
3.3",Gurgaon,"New York, NY",201 to 500 employees,2009,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"The thrill of working at a start-up that is starting to scale massively is something else.

Simpl (getsimpl.com) was formed in 2015 by Nitya Sharma, an investment banker from Wall Street and Chaitra Chidanand, a tech executive from the Valley, when they teamed up with a very clear mission - to make money simple, so that people can live well and do amazing things. Simpl is the payment platform for the mobile-first world, and we’re backed by some of the best names in fintech globally (folks who have invested in Visa, Square and Transferwise), and has Joe Saunders, Ex Chairman and CEO of Visa as a board member.

Everyone at Simpl is an internal entrepreneur who is given a lot of bandwidth and resources to create the next breakthrough towards the long term vision of “making money Simpl”. Our first product is a payment platform that lets people buy instantly, anywhere online, and pay later. In the background, Simpl uses big data for credit underwriting, risk and fraud modelling, all without any paperwork, and enables Banks and Non-Bank Financial Companies to access a whole new consumer market.

We are looking to hire a data analyst (Can be considered for a lead role depending on fit) who can work closely with product, investment, operations and marketing team on analytics.

The candidate would be a business aware self-starter responsible for enabling data driven decisions by setting up a reporting framework for daily/weekly metrics, helping with ad-hoc analysis and any fundamental research exercise.

This Role Requires Applicant To
Have passion for sourcing, manipulating and visualizing data
Apply direction and confidence to design qualitative and quantitative analysis
Stand before stakeholders, including senior leaders to clearly communicate strategic findings and recommendations
Partner with key members from technical and non-technical teams to build and enable high quality decisions
Prioritize and manage multiple priorities simultaneously
Advocate for working backwards from the customer
All basic qualifications, plus the following:
Degree in Computer Science, Engineering, Statistics, Mathematics, Statistics or a related field
SQL, Python/R (EDA experience), Visualisation tools (Qlik/Tableau) is must
Experience with AWS solutions
Experience working in very large data warehouse environments
Experience conducting large scale data, regression, and predictive analysis to support business decision making
Strong verbal/written communication and data visualization skills, including an ability to effectively communicate with both business and technical teams
We promise a culture of ownership coupled with competitive compensation and generous equity",4.3,"Simpl
4.3",Bengaluru,"Bengaluru, India",51 to 200 employees,2015,Company - Private,Financial Transaction Processing,Finance,Unknown / Non-Applicable,-1
Applied Scientist II,-1,"Amazon is looking for a passionate, talented, and inventive Scientist with a strong machine learning background to help build industry-leading Speech and Language technology. Our mission is to push the envelope in Automatic Speech Recognition (ASR), Natural Language Understanding (NLU), and Audio Signal Processing, in order to provide the best-possible experience for our customers.
As a Speech and Language Scientist, you will work with talented peers to develop novel algorithms and modeling techniques to advance the state of the art in spoken language understanding. Your work will directly impact our customers in the form of products and services that make use of speech and language technology. You will leverage Amazons heterogeneous data sources and large-scale computing resources to accelerate advances in spoken language understanding.

We are hiring in the area of speech recognition (ASR).



Basic Qualifications


· MS or PhD in Electrical Engineering, Computer Sciences, or Mathematics with specialization in speech recognition, natural language processing, or machine learning.
· Familiar with programming languages such as C/C++, Java, Perl or Python.



Preferred Qualifications

· Experience in building speech recognition and natural language processing systems (e.g. commercial speech products or government speech projects)
· Solid Machine Learning background and familiar with standard speech and machine learning techniques.
· Scientific thinking and the ability to invent, a track record of thought leadership and contributions that have advanced the field
· Solid software development experience
· Good written and spoken communication skills.


Amazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
"Data Scientist (SQL, Python, Statistics and Machine Learning)",-1,"Springer Nature opens the doors to discovery for researchers, educators, clinicians and other professionals. Every day, around the globe, our imprints, books, journals, platforms and technology solutions reach millions of people. For over 175 years our brands and imprints have been a trusted source of knowledge to these communities and today, more than ever, we see it as our responsibility to ensure that fundamental knowledge can be found, verified, understood and used by our communities – enabling them to improve outcomes, make progress, and benefit the generations that follow.

Visit: group.springernature.com and follow @SpringerNature

.sfpanel .content {padding: 0 40px !important;}

Springer Nature is seeking a highly motivated Data Scientist for its highly-regarded Analytics Centre of Excellence serving the Research division that includes Nature, Springer, BioMedCentral and Scientific American.

As a Data Scientist, you’ll be analyzing big data from very highly trafficked websites and content. You will provide actionable analysis and insight into the behavior of researchers in both their roles as authors and users of scientific information, as well as general trends in the world of research. You will help drive change that improves their experience with Springer Nature, supporting our purpose to advance discovery.

Roles and Responsibilities
Write code for gathering, analysing and blending data
Running experiments and creating models and data summaries to produce business and customer insights
Create reports and presentations giving recommendations on how to further improve Springer Nature’s products, services and platforms
Build strong and proactive relationships with relevant business stakeholders and senior management, providing insights and analytics to support in achieving the strategic goals of the business
Increase the adoption of data science, standardise analytics tools across the organization, improve data management and reporting, and make data-led insight accessible to the business
Being an advocate for a data-driven culture, share thought leadership on tools and best practices
Introducing compelling data visualizations and interactive dashboards that allow good monitoring and decision-making in a timely manner
Leading the journey towards more advanced and predictive analytics using statistical modelling, machine learning and AI
Role Requirements:
University degree with a strong analytical/quantitative background or equivalent experience Demonstrable experience in cleansing and combining data using software and tools like SQL, Big Query, Python/R, Tableau
Demonstrable experience writing working code for data science or similar, in either R or Python
Excellent statistical and machine learning skills
Excellent communication skills with the ability to tell compelling stories from the data
Demonstrable experience in identifying patterns and connecting different pieces of information to deliver unobvious insights, drawing information from diverse and varied sources of data.
Excellent analytical and problem solving capabilities
Well organized and accurate with good time management
Good networker, able to build up effective relations with internal business partners
Visit the Springer Nature Editorial and Publishing website at www.springernature.com/editorial-and-publishing-jobs for more information about our Research E&P career opportunities.",3.2,"Springer Nature
3.2",Pune,"Heidelberg, Germany",10000+ employees,2015,Company - Private,Publishing,Media,Unknown / Non-Applicable,-1
Data Science Engineer,-1,"Overview:
Will be responsible for promoting data science topics through the local entities; helping entities in integrating data science in their organisation; industrialize data science projects focusing on production, maintenance, monitoring, availability, performance; and manage an innovative set of data science tools (Smart Data Studio), used by data scientists across the group.

Key responsibilities:
Follow and manage the engineering aspects of industrialised Data Science projects: platforms, production constraints, connections, factory compatibility
Advise and support Smart Data Studio users
Help users regarding level 2 and level 3 issues
Help users regarding industrialized data science good practices
Contribute to documentation creation and update (wikis, tutorials, …)
Contribute to tools upgrade
Support Data Science tools development and benchmarking
Help product owner and developers to define functionalities, and prioritise the Smart Data Studio roadmap
Contribute to data science tools benchmarking and evaluation
Contribute to data science tools enhancements and new functionalities

Key skills:
Must have knowledge of machine learning (scikit-learn, MLLib, vowpal wabbit), coding (Python, Scala, R), spark (Python and/or Scala), GNU/Linux, Hadoop (administration and/or development with PIG, HIVE)
Added advantage: Knowledge of H2O, Dato, Data Science challenges track record, Git, Jenkins
Passion for learning new tools, languages and frameworks
Ability to be creative and innovation-minded
Fast adaptation to changing requirements
To work with minimal direct guidance, self-motivated and proactive
Practical, hands on approach to get results
Willing and capacity to teach and transfer knowledge to the team
English - Fluent in speaking and writing
Ability to work in a multi-cultural environment
Strong oral and written communication skills
3-5 years of relevant experience
Experienced in working in an international environment and open to overseas travel",3.4,"AXA Business Services
3.4",Bengaluru,"Bengaluru, India",1001 to 5000 employees,1999,Company - Private,Insurance Operators,Insurance,Unknown / Non-Applicable,-1
Data Scientist Intern,-1,"Location: Bangalore, India.

Dasceq: Data – Science – Equilibrium
Transforming Collections with AI/ML and Big Data
In the digital age, businesses have access to more data than ever before, and this data can be leveraged to drive decision-making for improved growth and seamless consumer experience including collections. Since being founded in 2017, our team of data scientists and domain experts at Dasceq (Data – Science – Equilibrium) have created a AI platform to boost collections efficiency and amount collected. We are leading edge AI Startup converging Machine learning, AI with deep collection and servicing experience leveraging AI/ML and Big Data to create a unique platform for Collections. Our next generation product is enabling clients to improve consumer experience and ROI. Dasceq’s next-gen SaaS AI platform optimizes collections with data-driven insights.

We experiment and innovate leveraging the latest technologies to engineer breakthrough AI product, customer experiences, and bring simplicity and humanity to collections. At Dasceq Center for Artificial Intelligence and Innovation, you’ll be part of an elite team accelerating adoption of AI, ML and Big Data for Fortune enterprises in USA.

Do you have it in you to join Dasceq? We are a committed and passionate team of hard working individuals who are making a difference for our clients, our industry and our team members. We are looking for passionate individuals who are great performers and willing to be part of team passionate about building production-quality applications using cutting-edge machine learning algorithms? They must be Self Starter, Hard Workers, Great Team Spirit and a willing to become experts in their domain? If the answer is YES then APPLY

We are looking for a Data Scientist who will work in our AI/Data Science Innovation Team and will leverage data to gain insights by analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action.
They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations.
They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.
Responsibilities for Data Scientist:
Data mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Qualifications for Data Scientist
Has a bachelor’s degree in Computer Science, Economics, Statistics or another quantitative field, and is familiar with data science algorithms.
Strong problem-solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets and experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
We’re looking for someone of experience manipulating data sets and building statistical models, has a master’s or PHD in Statistics, Mathematics, Computer Science or another quantitative field, and is familiar with the following software/tools:
Coding knowledge and experience with several language C++, python, R, SQL.
Experience querying databases and using statistical computer languages: R, Python, SQL, etc.
Experience visualizing/presenting data for stakeholders using: BI tools.
Only those candidates can apply who for internship:
Have a great attitude, willing to learn and work hard and excel in career.
Are available for full time (in-office) internship at our Jaynagar Office in Bengaluru
can start the internship between 1st March19 and 15th Mar’19
are available for duration of 6 months
have relevant skills and interests
Other requirements:
Should have an ability to work in a team with good communication skills
Should have the ability to meet routine production deadlines
Should be well versed with computer concepts of the internet, networking, browser, website, apps, MS Office, etc.
Should have basic knowledge of Excel, Word, Presentation, Google Sheets, and Google Docs
Should have a strong attitude to learn and logical reasoning
Open to work long hours and weekend as needed (one to two weekend a month).
Perks:
Certificate
Letter of recommendation
Job offer (On successful conversion to a permanent employee, the candidate can expect a salary of Rs. 2 to 3 Lac/annum)
Daily Lunch and Snacks Provided
Bi-Weekly Team Events and Office Party.

Required for Interview:
Current and past jobs pay slip and appointment letter (pdf)
All diploma and certificate copies (pdf)
Three References
* Women willing to start/restart their career can also apply",2.0,"Dasceq
2.0",Bengaluru,"Irving, TX",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Revenue Operations Data Analyst,-1,"Revenue Operations Data Analyst

Job Description :


6sense is a Predictive Intelligence Engine that is reimagining how B2B companies do sales and marketing. It works with big data at scale, advanced machine learning and predictive modeling to find buyers and predict what they will purchase, when and how much.

6sense helps B2B marketing and sales organizations fully understand the complex ABM buyer journey. By combining intent signals from every channel with the industry's most advanced AI predictive capabilities, it is finally possible to predict account demand and optimize demand generation in an ABM world. Equipped with the power of AI and the 6sense Demand Platform™, marketing and sales professionals can uncover, accelerate, and capture buyer demand to drive more revenue.

The Fit: We are looking for a person who enjoys data research and understands the value that high quality sales and marketing data provides to an organization. A person who is details oriented, disciplined, and can interact well with their US based colleagues. Also, a person who is willing to learn Salesforce and other related sales and marketing technology.

Business Acumen Fit (combined internship + work experience):
1-3 years of sales/marketing operations or data support. Preferably, 1+ years with an enterprise software or SaaS startup.
High quality analysis and presentation skills.
Strong English written and verbal communications skills.
Internal customer focused. We are extremely customer centric and will go that extra mile to win a customer and more importantly woo them. We want the RevOps Data Analyst to exhibit this ""customer first"" mentality with internal stakeholders.
Strong team player. We have cross geographic teams and are in different time zones. Need leaders who can coordinate and work with people across cultures, time zones and ethnicities.
Ability to work in a fast-paced, team environment.
4-year BA/BS degree or equivalent practical experience.
Technical Fit (combined internship + work experience):
Willingness to learn or has current knowledge of administering Salesforce (and other related systems)
Experience with Microsoft Excel (E.g. Pivot Tables, vLookups, Matching, Formatting, etc.)
Experience maintaining data within Salesforce (E.g. Directing on the record, Data Loader, etc.)
Experience with data quality tools (E.g. Data deduplication, Merging, Conversion, List loading, etc.)
Experience with RingLead, Cloudingo, Validity, etc. is preferred.",4.9,"6sense
4.9",Pune,"San Francisco, CA",51 to 200 employees,2013,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Because you belong at Twilio.

The Who, What, Why and Where

Twilio is growing rapidly and seeking Data Engineers at multiple levels to be a key member of the Consumer Trust Team in Bangalore, India. You will be joining one of the first teams of engineers in our new Bangalore office, with an opportunity to help define our technical and team culture in India. You will also help us build solutions that prevent fraud and abuse, ensuring that Twilio is the leader in trusted communications. A successful candidate will be a self-starter, embody a growth mindset, collaborate effectively, can mentor junior engineers and operate highly resilient services.

Who?

Twilio is looking for a strong data engineer who lives the Twilio Magic and has a demonstrated track record of working with data, specifically; sourcing and integrating data from multiple disparate backend data sources, developing reporting infrastructures and applying a deep analytics background to assess business performance and deliver actionable insights to improve efficiency and increase productivity. You should also have::
BA/BS in Computer Science, Engineering or related field
Relevant work experience in a role requiring application of analytic skills to integrate data into operational planning/business planning
Knowledge and expertise with database modeling and data warehousing principles
Fluent in writing and optimizing SQL, data mining using SQL with demonstrated strength in writing complex, high-optimized queries across large data sets,
Familiar with AWS services, especially S3, Redshift, big data services and DevOps tools
Hands on experience with Lucene / SOLR / ElasticSearch, Kafka, Google Big Query
Proficiency in at least one scripting language, Python, R, or similar.
Advanced ability to draw insights from data and clearly communicate them (verbal/written) to the stakeholders and senior management as required
Demonstrated ability to manage and prioritize workload and roadmaps
Excellent problem solving, critical thinking, and communication skills.
Strong belief in automation over toil.
Nice to have:
Hands-on experience with Big Data technologies (e.g Hadoop, Hive, Spark) is a big plus
Extensive knowledge of BI and Visualization platforms i.e. Tableau and AWS Quicksight
Strong expertise in troubleshooting complex production issues.
What?

As a Data Engineer you will:
Design, develop, and maintain data pipelines, warehouses, and reporting systems to support Twilio's products, including fraud and abuse detection systems/ tools.
Design, develop, and maintain data pipelines, warehouses, and reporting systems to support Twilio's product engineering operational data: incidents, deployments, performance, utilization, defects, change failure rate, test data, infrastructure costs.
Build the data products that technical users will depend on for business intelligence and ad-hoc access.
Build scalable solutions and self-serve platforms that will provide data and KPIs to inform business decision making.
Identify, develop, manage, and execute analyses to uncover areas of opportunity and present written business recommendations that will help improve the controllership and help achieve the goals of the team.
Develop and maintain documentation relating to all assigned systems and projects
Develop high-trust relationships and processes with partner teams and stakeholders to identify and address insight requirements
Participate in workstreams planning process including inception, technical design, development, testing and delivery of BI solutions.
Be able to adapt to prioritizing multiple issues in a high-pressure environment.
Be able to understand complex architectures and be comfortable working with multiple teams.
Why?

Twilio has democratized communications channels like voice, text, chat, and video by virtualizing the world's telecommunications infrastructure through APIs that are simple enough for any developer to use, yet robust enough to power the world's most demanding applications.

The Consumer Trust Team is central to Twilio's continued growth. Our mission is to prevent consumer harm by offering products and services that protect our customers and help them authenticate their users. We also ensure that every call, email and message that is made using our service is wanted, safe and legal. To do this we need to continue to develop and evolve our products and services and ensure they are able to scale; driving Twilio to new heights of scale.

Twilio is a company that is empowering the world's developers with modern communication in order to build better applications. Twilio is truly unique; we are a company committed to your growth, your learning, your development, and your entire employee experience. We only win when our employees succeed and we're dedicated to helping you develop your strengths. We have a cultural foundation built on diversity, inclusion, and innovation and we want you and your ideas to thrive at Twilio.

Where?

This position will be located in our office in Bangalore, India. You will enjoy our office perks: catered meals, snacks, game room, ergonomic desks, massages, bi-weekly All Hands and more. What you will also get to experience is a company that believes in small teams for maximum impact; seeks well-rounded talent to ensure a full perspective on our customers' experience, understands that this is a marathon, not a sprint; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves.

About Us

Millions of developers around the world have used Twilio to unlock the magic of communications to improve any human experience. Twilio has democratized communications channels like voice, text, chat, video and email by virtualizing the world's communications infrastructure through APIs that are simple enough for any developer to use, yet robust enough to power the world's most demanding applications. By making communications a part of every software developer's toolkit, Twilio is enabling innovators across every industry — from emerging leaders to the world's largest organizations — to reinvent how companies engage with their customers.",3.9,"Twilio
3.9",Bengaluru,"San Francisco, CA",1001 to 5000 employees,2008,Company - Public,Internet,Information Technology,₹100 to ₹500 billion (INR),-1
User & Business Monetization - Associate Data Scientist,-1,":

At Truecaller, we have an ocean of data to mine, we believe in working hard & smart, learning every day in this constantly evolving
space while adding value to our users and business.
We focus on measurable and impactful work and don’t forget have a lot of fun along the way. If this sounds like you, we want to talk to you!

Job Description:
We are looking for a data scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter
decisions to deliver even better products. translating a business problem to a DS problem, scope definition, data cleaning, explorations, feature engineering, feature selection, modelling, building prototype, documentation of an algorithm and insights, will
also help with data collection and algorithm quality monitoring.

Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems
integrated with our products.

Classifying based on a variety of data and meta data, anomaly detection systems, recommendation systems, internal A/B testing
procedures, improve and extend the features used by our existing classifiers.

Responsibilities :
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company’s data with other sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems,Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner,Creating automated anomaly detection systems and constant
tracking of its performance

Communication between teams and ability to transfer knowledge in a readable/understandable manner for everyone.

Skills and Qualifications :
Good understanding of machine learning techniques and algorithms, such as Neural Networks, K-Means, k-NN, Naive
Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as Spark, sklearn, GGplot, Advanced Excel, NumPy, MatLab, etc.
Great communication skills
Experience with data visualisation tools, such as tableau, Google Data Studio etc.
Proficiency in using query languages such as SQL, Hive, Spark, Cassandra
Experience with NoSQL databases, such as MongoDB, Cassandra, Hive, Hadoop
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personalityMaster’s/PGDDS in Computer Science, Statistics, Mathematics,
Engineering, Operations Research or related fields
1-3Y Exp in an Analytics/Data Science or similar roles, self- curated projects

Personality

Well-structured
Proactive
Team player
Polite and respectful
Honest and trustworthy
Never give up
Taking ownership
We offer

At Truecaller we have built a dynamic and diverse culture where we are keen to take ownership of what we are doing, learn and develop ourselves and are willing to share their knowledge with others. We love to experiment with new tools and technologies to push the envelope and be able to deliver the best product to our users and we believe that failure is halfway to success. At Truecaller you will find challenges and a team with passion for what we do.

Applying

This position is located in Bengaluru, India.

We only accept applications in English.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, or marital status.",-1,True Caller,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Science Associate,-1,"ZS is a professional services firm that works side by side with companies to help develop and deliver products that drive customer value and company results. From R&D to portfolio strategy, customer insights, marketing and sales strategy, operations and technology, we leverage our deep industry expertise and leading-edge analytics to create solutions that work in the real world. Our most valuable asset is our people—a fact that’s reflected in our values-driven organization in which new perspectives are integral and new ideas are celebrated. ZSers are passionately committed to helping companies and their customers thrive in industries ranging from healthcare and life sciences, to high-tech, financial services, travel and transportation, and beyond.

ZS’s India Capability & Expertise Center (CEC) houses more than 60% of ZS people across three offices in New Delhi, Pune and Bengaluru. Our teams work with colleagues across North America, Europe and East Asia to create and deliver real world solutions to the clients who drive our business. The CEC maintains standards of analytical, operational and technological excellence across our capability groups. Together, our collective knowledge enables each ZS team to deliver superior results to our clients.

ZS's Business Consulting group partners with clients to design and deliver solutions to help them tackle a broad range of business challenges. Our teams work on multiple projects simultaneously, leveraging advanced data analytics and problem-solving techniques. Our recommendations and solutions are based on rigorous research and analysis underpinned by deep expertise and thought leadership.

DATA SCIENCE ASSOCIATE

Data Science Associates (DSAs) design, develop and execute high-impact analytics solutions for large, complex, structured and unstructured data sets (including big data) to help clients make better fact-based decisions.

Responsibilities:
Develop advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner;
Execute statistical and data mining techniques (e.g. hypothesis testing, machine learning and retrieval processes) on large data sets to identify trends, figures and other relevant information;
Collaborate with clients and other ZS stakeholders to effectively integrate and communicate analysis findings;
Contribute to the evaluation of emerging datasets and technologies that may contribute to our analytical platform.

Qualifications:
Bachelor's or master's degree in Computer Science (or Statistics), and strong academic performance with analytic and quantitative cousework is required;
Knowledge of big data/advanced analytics concepts and algorithms (e.g. text mining, social listening, recommender systems, predictive modeling, etc.);
Knowledge of programming (e.g. Java/Python/R);
Exposure to tools/platforms (e.g. Hadoop eco system and database systems);
Excellent oral and written communication skills;
Strong attention to detail, with a research-focused mindset;
Excellent critical thinking and problem solving skills;
High motivation, good work ethic and maturity.

ZS is a global consulting firm; fluency in English is required, additional fluency in at least one European or Asian language is desirable.
Candidates must possess work authorization for their intended country of employment. An on-line application, including a cover letter expressing interest and a full set of transcripts (official or unofficial), is required to be considered.
ZS offers a competitive compensation package with salary and bonus incentives, plus an attractive benefits package.

NO AGENCY CALLS, PLEASE.

Connect with ZS in India on social media:
Like ZS in India on Facebook
Follow ZS in India on Twitter and Instagram
Follow ZS on LinkedIn for more job opportunities
Subscribe to the ZS in India YouTube channel
Explore the Life at ZS blog

ZS has been recognized globally for its expertise in consulting and its flexible work environment. View ZS’s accolades.",3.8,"ZS Associates
3.8",Pune,"Evanston, IL",5001 to 10000 employees,1983,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Research Associate / Scientist,-1,"Position: Research Associate / Scientist

Location: Bangalore, India

Contact: Please email admin@stringbio.com

No of Openings: 1

The incumbent will be responsible for managing all scientific experiments related to plant growth, developmental trials, documentation, data analysis and product specs. Candidate with strong knowledge of the agricultural market are preferred. Candidate is someone who is enthusiastic about taking scale up challenges, exhibits meticulous attention to detail, and an eagerness to learn new techniques. The candidate will work very closely with the String team and outside partners/collaborators.

POSITION RESPONSIBILITIES

Design, set up, execution and analysis of experiments related to application of agricultural products in various crops.
Developing robust protocols for testing efficiency of different agricultural products for improving plant growth and productivity.
Optimizing agricultural products for performance and stability.
Plan and implement greenhouse/ field experiments.
Collaborate with interdisciplinary teams and work closely with multi-disciplinary teams/ along with project partners to assist in University trails or other field experiments.
Data collection, analysis and interpretation of data generated from field/ wet lab experiments.
Assist scientists/other team members in the various ongoing research activities.
Manage and deliver against project goals and timelines.
Maintain accurate and timely records of laboratory work. Evaluate data, prepare technical reports and make scientific presentations.
Be a conscientious laboratory citizen, adhere to EH&S standards, and use knowledge of laboratory procedures to advance projects under shifting priorities and timelines.
The position is full-time.

CANDIDATE PROFILE

EDUCATION AND EXPERIENCE

PhD in any stream of Agricultural Sciences/ Horticulture/ Plant Biotechnology or
MSc in Agricultural Sciences/ Horticulture/Biotechnology with minimum of at least 3-5 years relevant experience, preferably with a research and development organization implementing agriculture related projects.
Ability to independently plan and carry out research on various project and work towards attainment of project objectives.
Sound knowledge of experimental designs, statistical analysis, proficiency in computation skills for document processing, and preparing presentations.
Excellent communication, with fluency in written and spoken English, and the ability to work in a multi-cultural environment.

PERSONAL QUALITIES

Driven, dedicated team player with attention for detail.
Ability to work independently and deliver on project objectives.
Capacity to be proactive and take initiatives.
Good organizational skills.
Effective interpersonal skills.
Strong oral and written communication skills.
Creative, out of the box thinker with strong analytical and problem-solving capabilities.
Ability to adapt to changing drivers.",4.7,"String Bio
4.7",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"Strong background in statistics and machine learning, with direct experience in machine learning-related field (e.g., information retrieval, deep learning, natural language processing, computer vision, analytics, etc.).

Hands-on experience applying advanced statistical learning techniques to different types of data.

Strong programming skills in at least two languages: DotNet, Python, R, Scala

Experience with large data sets in a distributed computing environment such as Hadoop or Spark.

Ability to lead discussion with the business teams, understand the business problem, identify the key challenges, formalize problem algorithmically, and prototype solutions.

Analyze, advise and recommend various models with reasoning and predictable outcomes

Consistent track record of documenting, synthesizing, and communicating results.

Overall Experience of 7-10 years in which at least 3-5 years of experience with machine learning, Data Science, Information retrieval, deep learning, Natural Language Processing, Text Mining, Data Mining, Regression, Classification, etc.

May need to work frequently during US- MT hours for business discussions

Proactiveness and leadership skills are essential for this individual contributor role.

Relevant technical and delivery experience within, or working as a consultant/advisor to, hospitality industry will be an added advantage.

Education: Ph.D with Bachelors/ master’s in computers/Statistics/Mathematics.

Technologies: Azure ML studio/AI, SQL server

Contact Details

Email: careers@evoketechnologies.com
Phone: 040-33509000

To apply for this position, send your resume to careers@evoketechnologies.com mentioning the job code ‘SDS01’.",3.9,"Evoke Technologies
3.9",Hyderabad,"Dayton, OH",501 to 1000 employees,2003,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Machine Learning Engineer,-1,"Description

Unbxd is an AI-driven eCommerce Search Platform that understands shopper intent and connects them to the products they are most likely to buy — across site search, navigation and recommendation purchase journeys.

The platform combines AI-based automation, powerful merchandising controls, and extensive user experience capabilities to enhance the onsite shopper experience and increase revenue for online retailers.

Your Role

As part of our Data Science team, you will solve some of the most challenging and impactful problems in Information Retrieval, NLP, Machine Learning, Deep Learning and Recommender Systems. In close coordination with the Data Scientists, you will design and develop Machine Learning models that will understand a user’s intent across modalities and devices, enabling them to make the right purchasing decisions. You will have the opportunity to build models across different verticals (fashion, home, electronics, autos, etc) to drive better user conversion and user engagement.

What you’ll do

Be a thought leader in identifying the right set of problems that will delight our customers.

Design and implement state of the art Machine Learning and AI algorithms into our products.

Integrating ML components into a fully functional software system.

Writing well-designed, testable, efficient code.

Become an expert in IR, NLP and help make an impact on the broader community as an Unbxd Brand Ambassador.

About You

Must have:

You have BS/BTech/MS/MTech (with 2+ years relevant experience) in Computer Science, Information Technology, Mathematics, Statistics or similar fields.

You are extremely strong in Algorithms, Data Structures and basic probability.

You have strong technical and programming skills(Python/R/Java).

You have strong problem solving and analytical skills.

You have basic understanding and demonstrable strong interest in two or more of Machine Learning, Information Retrieval, Natural Language Processing, Deep Learning, Recommender Systems or related fields.

You have an understanding of the full software development lifecycle.

You can work independently with little supervision to research and test innovative solutions

You have strong communication skills to influence and make the team around you better

You have demonstrated the ability to quickly prototype ideas to solve complex problems

You are able to prioritize and handle multiple tasks and changing priorities

Good to have:

You have hands-on implementation experience with building machine learning models into products.

You have hands-on experience with some ML frameworks like TensorFlow, PyTorch, Keras, Sklearn, nltk or similar.

You are familiar with Big Data technologies

You have experience working with Solr or other search platforms",3.7,"Unbxd Inc
3.7",Bengaluru,"Bengaluru, India",51 to 200 employees,2011,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Computer Vision/Deep Learning Research Scientist,-1,"Job Title : Computer Vision/Deep Learning Research Scientist
Job Location : Bangalore, India
Job Description :

- A world-class research lab that excels at novel product development through fundamental architecture research. -
Looking for highly qualified, dynamic researchers for path breaking research in Architectures for Computer Vision and Deep Learning.
Next generation image processing and associated real-time, low-power programmable/accelerator hardware architectures for Computer Vision and Deep Learning is the focus of this research thrust.
Optimized implementations of geometric methods in Computer Vision Multi view Geometry, SLAM, SfM etc, Inertial visual sensor fusion, real-time image-based rendering techniques, 3D reconstruction, Deep Learning based recognition methods in Computer Vision will all be explored. - This will be done in collaboration with teams across the globe evaluating, researching and co-developing new algorithms and hardware architectures for emerging new world applications like Augmented Reality AR, Virtual Reality VR and drones.
All Research Scientists will advance the state-of-the-art in deep collaboration with product architecture/design teams while also contributing to scientific literature/conferences and developing Intellectual Property.
Main responsibilities
Hardware-oriented Computer-Vision/Deep-Learning Research Scientists will be responsible for power/area/performance driven architecture, microarchitecture development and optimization.
Activities include Logic design, RTL-to-GDS synthesis, layout optimizations and FPGA emulation.
Algorithm/software-oriented Computer-Vision/Deep-Learning Research Scientists be responsible for research and development of new algorithms and their optimization for high performance and quality, and highly efficient mapping and implementation to hardware.
Qualification :

Candidate Should hold -
PhD or advanced MS in EE/CS
Research background
Job Posted : 2017-09-13",-1,Approgence,Bengaluru,"Irvine, CA",1 to 50 employees,2006,Company - Private,IT Services,Information Technology,₹500 million to ₹1 billion (INR),-1
Data Scientist II,-1,"Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.
Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop – Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",3.8,"General Mills
3.8",Mumbai,"Minneapolis, MN",10000+ employees,1866,Company - Public,Food & Drink Manufacturing,Manufacturing,₹500+ billion (INR),-1
Assistant Manager - Data Scientist,-1,"With a startup spirit and 90,000 curious and courageous minds, we have the expertise to go deep with the world’s biggest brands—and we have fun doing it. Now, we’re calling all you rule-breakers and risk-takers who see the world differently, and are bold enough to reinvent it. Come, transform with us.
Are you the one we are looking for?
We are inviting applications for the role of AM, Data scientist
Role involves to think strategically about data as a core enterprise asset and assist in all phases of the advanced analytic development process
Support advanced analytical and data mining efforts which could include but not limited to clustering, segmentation, logistic and multivariate regression, decision/CART trees, neural networks, time-series analysis, sentiment analysis, topic modeling, random forests, and Bayesian analysis
Responsibilities
The scope of work includes Forecast, Prediction Models, Outlier Reporting, Payment Integrity violation identification, Adhoc analysis
Implementation of Supervised and Unsupervised model development techniques
Work with Data engineers to supervise and help institutionalize models and dashboards for Analytics team of leading Healthcare client
Develops ML models using identified features and packages
Responsible for maintenance and performance monitoring of the production environment for the Advanced Analytics team
Lead the design of complex and large-scale datasets to be used for statistical modeling and data mining.
Slice and dice through the database and come up with actionable analytical insights
Facility with one or more quantitative data analysis languages such as R, SciPy, NumPy, SQL, Python, SAS, SPSS
Experience with relational database management systems (Oracle, Teradata, SQL Server, DB2..)
Works with key stakeholders to generate and test hypotheses
Experience with contemporary big data technologies (Hadoop, HIVE, PIG, MapReduce)
Facility with one or more data analytical methods such as regression, decision trees, experimental designs, support vector machines, machine learning and text mining
Proficiency with Microsoft Office Suite
Work in a dynamic and fast-paced environment without compromising the quality
Conduct explanatory data analysis and prepare data sources to be analyzed.
Excellent domain knowledge on US Healthcare is must
Qualifications we seek in you
Minimum qualifications
Bachelors or Master’s degree with specialization in statistics, applied mathematics, economics, finance, computer science or Information systems/science; Preference given to candidates with demonstrated academic achievement in core subjects and proficiency in quantitative subject matter (Advanced Statistics coursework, Predictive Modeling projects). Familiarity with PBM or Healthcare industry.
Relevant Healthcare domain experience
Preferred qualifications
Solid communication skills with exposure to direct client communication is preferred

Genpact is an Equal Opportunity Employer and considers applicants for all positions without regard to race, color, religion or belief, sex, age, national origin, citizenship status, marital status, military/veteran status, genetic information, sexual orientation, gender identity, physical or mental disability or any other characteristic protected by applicable laws. Genpact is committed to creating a dynamic work environment that values diversity and inclusion, respect and integrity, customer focus, and innovation. For more information, visit www.genpact.com. Follow us on Twitter, Facebook, LinkedIn, and YouTube.",3.6,"Genpact
3.6",Gurgaon,"New York, NY",10000+ employees,1997,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"Accenture, IBM, Capgemini"
Senior Data Scientist,-1,"The Data Sciences team at Flipkart is on a mission to build systemic intelligence across
Flipkart products and the overarching ecosystem. Being India’s largest online
marketplace and the most used e-commerce app in India, places Flipkart in a unique
position and gives this team a distinctive opportunity — to decipher the richest
possible data about Indian consumers. Add the dimension of a vast product selection
and a proliferating seller base to that and what you get is a multitude of disruptive
possibilities.
In a nutshell, the terabytes of daily data compounded in Flipkart’s data centers offer a
dynamic mix of numerical, structured, unstructured, image- and audio-based statistics,
all set to define shopping in the future.

What this job entails:
The pool of data available at Flipkart forms the foundation to solve some present and
predictable challenges for shoppers in India. As a Data Scientist you will be working on:
Product discovery along with personalization and intent modeling
Demand shaping and planning
Heterogeneous networks for consumer, product and seller interactions
Customer insights
Catalog enhancement and product insights
Customer emotion detection and right response matching
Fulfillment automation
Optimization of last mile delivery
Fraud modeling",4.1,"Flipkart
4.1",Bengaluru,"Bengaluru, India",10000+ employees,2007,Company - Private,Internet,Information Technology,₹500+ billion (INR),"eBay, Snapdeal"
Data Engineer,-1,"Why you'll love Cisco


We change the world, you will become passionate about your employer and the brand you represent. Everything is converging on the Internet, making networked connections more meaningful than ever before in our lives. Our employees' groundbreaking ideas impact everything. Here, that means we take creative ideas from the drawing board to dynamic solutions that have real world impact. You'll collaborate with Cisco leaders, partner with mentors, and develop incredible relationships with colleagues who share your interest in connecting the unconnected. You'll be part a team that cares about its customers, enjoys having fun, and you'll take part in changing the lives of those in our local communities. Come prepared to be encouraged and inspired.

What You'll Do


Cisco Advanced Analytics team in Growth Marketing is looking for a Data Engineer eager to provide the engineering muscle for Machine Learning Development, Deployment and Integration into the business.

You will be responsible for:
Working with a technical leader to lead major engineering initiatives to support decision-making by the business
You will look after Data Management that drives ML models in production
Identify ways to drive ML output into Business Workflows
Partnering with Modeling and IT teams as well as with Business stakeholders
Who You'll Work With
You will report to a manager within Advanced Analytics and work directly with a Team Leader in the Engineering Center of Excellence
You will work closely with Modelers, Business Stakeholders, Analytics Translators as well as IT
Who you are:


You like working with Data and love getting the business to adopt Data Insights. Minimum qualifications are:
Experience with data modeling, data warehousing, and building ETL pipelines
Experience in SQL, Python, and Unix/Bash scripting
Writing complex, highly optimized SQL queries across large data sets
Experience with scripting in Python and Unix/Bash environments
Experience in communicating complex technical concepts to a broad variety of audiences
Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy.
Preferred Qualifications:

BS/MS in Computer Science/Engineering.
4-7 years of experience in a Data Engineering or similar role
Knowledge of software engineering standard methodologies across development lifecycles – including agile methodologies, coding standards, code reviews, source management, build processes, testing and operations.
Why Cisco


#WeAreCisco, where each person is unique, but we bring our talents to work as a team and make a difference. Here’s how we do it.

We embrace digital and help our customers implement change in their digital businesses. Some may think we’re “old” (30 years strong!) And only about hardware, but we’re also a software company. And a security company. A blockchain company. An AI/Machine Learning company. We even invented an intuitive network that adapts, predicts, learns and protects. No other company can do what we do – you can’t put us in a box!

But “Digital Transformation” is an empty buzz phrase without a culture that allows for innovation, creativity, and yes, even failure (if you learn from it.)

Day to day, we focus on the give and take. We give our best, we give our egos a break, and we give of ourselves (because giving back is built into our DNA.) We take accountability, we take results-oriented steps, and we take the difference to heart. Because without diversity of thought and a dedication to equality for all, there is no moving forward.

So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool.",4.2,"Cisco Systems
4.2",Bengaluru,"San Jose, CA",10000+ employees,1984,Company - Private,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Alcatel-Lucent, Juniper Networks"
Data Engineer (ETL),-1,"We are looking for a Data Engineer who will work on the collecting, storing, processing, and analyzing of huge sets of data (ETL). The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Roles & Responsibilties
Design, develop and support data platform with large dataset for realtime and batch processing.
Implement ELT/ETL processes from a wide variety of data sources using best practices while working with other technology teams
Work with business and product teams to understand their data needs, gather requirements and delivering dataset
Work on automating/improving existing data sets, ETL/ELF pipelines
Identify the opportunities to improve data storage and query performance and implement them
Basic Qualifications

• Comprehensive knowledge of the Data Collection, Transformation, Storage and Query technologies' landscape.

• Hands on expert experience with at least a few of these systems.

• 2-4 years of strong hands-on development experience

• 1+ years experience of hands-on big data experience

• Should be able to write high quality code - preferably in Java/Python/Ruby

• Should have excellent written and verbal communication skills

• Data modelling, SQL and Databases knowledge

• Good understanding of HDFS, Hive, Spark, Kafka

Good to Have

• Exposure to Amazon Web Services

• Exposure of BI tools like Tableau/Qliksense/Superset

• Experience of building applications with streams and complex event processing

• Should be able to prioritize in fast-moving complex environment and produce solutions despite complex requirements",3.8,"Doubtnut
3.8",Gurgaon,"Gurgaon, India",51 to 200 employees,2016,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Deputy Manager - Data Scientist,-1,"Job Summary

Experience:
6 - 9 Years

Location:
Mumbai

Designation:
Deputy Manager - Data Scientist

Degree:
BE-Comp/IT, BE-Other, BTech-Comp/IT, BTech-Other, ME-Comp/IT, ME-Other, MTech-Comp/IT, MTech-Other, PG-Other, PhD-Comp/IT

Educational Level:
Graduate/Bachelors

Industrial Type:
IT-Software/Software Services

Functional Area:
IT Software - Application Programming / Maintenance

Key Skills:
Data Scientist

Job Post Date:
Wednesday, April 15, 2020

Company Description

We are capability centre based in Mumbai, initially started as a back-office operational support to the UK business unit.

However, over the recent years, we have significantly increased the breadth and depth of our capabilities and offerings to keep pace with the changing needs of the Group. These include Digital & Knowledge Services, Finance and Actuarial, Information Technology (IT), Customer Service, Risk and Audit.

Our core purpose is to be a strategic partner to company, enabling growth by delivering change and driving synergies through a highly capable and agile workforce.

With our diversified service offerings we provide our people with exciting opportunities to grow personally and professionally.

Company is a leading savings and investments business serving around 5.5 million retail customers and more than 800 institutional clients.

It-s innovative asset management and customer solutions are supported by extensive investment capabilities, an international distribution network and two strong brands.

Job Description

6 – 9 years’ experience as Data Scientist
Must have deep experience in Machine Learning
Excellent Python skills
Exposure to advanced deep learning techniques such as LSTM. CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow, keras, pytorch, deepai or equivalent.
Experience of working in multiple text mining / NLP solution
Should have experience of deploying and putting into production ML based solution
Good SQL expertise",3.8,"Sampoorna Computer People
3.8",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Sr Data Scientist - Fraud,-1,"Neustar, Inc. is a leading global information services provider driving the connected world forward with trusted, holistic identity resolution. More information is available at https://www.home.neustar.

Job Requisition:

R-1663 Sr Data Scientist - Fraud (Open)

Primary Location:

BANGALORE

Job Description:

Neustar, Inc. (NYSE: NSR) is a trusted, neutral provider of real-time information and analytics to the communications services, financial services, retail, educational, and media and advertising sectors. Neustar applies its advanced, secure technologies to help its clients promote and protect their businesses. More information is available at www.neustar.biz.

The Data and Analytics organization at Neustar is the DNA of the company. The DNA encodes the essence of existence and character that drives continuous innovation with data, continuous insights with analytics and continuous evolution with cutting-edge data products and services. Our vision is to be the trailblazer in Connection Science driven information services that create meaningful value for our customers. Our mission is to enable cutting-edge data products & services delivered through superior data, unique insights and top-of-the-class technology solutions. We believe in developing a Collaborative, Creative, yet Competitive, Customer Centric culture. We are shaping the present and the future at Neustar and are seeking “TENXERS” who share the same DNA.

Job Description:

The Sr. Data Scientist will lead a group of Data Scientists that works on challenging problems extracting actionable information out of the many data sources available to Neustar. They will focus on Security and Fraud, and their group will be involved in projects from end-to-end, including data ingestion and curation, hypothesis development, feature engineering, and model development and evaluation. The team will be integral to the development of an automated real time anomaly and fraud detection systems.

Apart from Security and Fraud, other application areas include Identity Resolution and other Business Solutions supported by our or our client’s data. The Sr. Data Scientist is expected to be working hands-on herself/himself while guiding the work of and mentoring junior team members.

Data Scientists create prototypes of new algorithms and support Engineering teams in productizing these capabilities. Data Scientists work closely with various teams including data acquisition, data products, data sciences and various business units including marketing, security, and internet of things to ensure implementation of capabilities that enable the organization’s vision. The role is based out of India at the Neustar's offices in either Bangalore or Hyderabad.

Responsibilities:
Group Leadership: Mentoring and supporting the career and capability growth of her/his team members. Setting and monitoring project schedules, communicating progress to the larger team. Provide technical leadership and foster a climate of open creative collaboration with his/her team and with other colleagues.
Algorithm Development: Develop a deep understanding of all the data relevant to the problem to be addressed. Establish deterministic and probabilistic linkages between data sources and develop ways to extract and summarize the sought information in the data using a wide variety of statistical, data mining and machine learning techniques.
Prototyping: Create prototypes of productizable ways to perform the analysis at scale, provide documentation and help educate your colleagues in different function about the solution
Support Implementation: Closely work with product, engineering and client teams to incorporate Data Science capabilities into Neustar’s products and services
Skills and Experience:
Masters’s degree in Data Science, Statistics or a related field
At least three years of experience working on data-intensive analytics solutions
Evidence of technical and team leadership in a previous position
Solid understanding of fundamental data mining and statistics concepts and familiarity with real-world applications of these techniques
Solid knowledge of SQL in its various forms for traditional databases and distributed computing environments
Experience working with commercial and/or open source statistics and data mining packages
Experience working on large distributed datasets using HiveSQL, Spark, Python
Strong written and oral communication skills
Strong inter-personal collaboration skills. Being able to both work in groups or as an individual contributor
General curiosity, a willingness to experiment, pragmatism and the ability to handle ambiguity
Why work with us?
Because you love to build beautiful, innovative solutions that wow the customer
Because you believe in changing the status quo and are up for the challenge of your life
Because you know you can make a difference to people, places and things!
About Us

Every day, the world generates roughly 2.5 quadrillion bits of data. Neustar isolates certain elements and analyzes, simplifies and edits them to make precise and valuable decisions that drive results. As one of the few companies capable of knowing with certainty who is on the other end of every interaction, we’re trusted by the world’s great brands to make critical decisions some 20 billion times a day.

Neustar does not accept unsolicited resumes from external firms or agencies. Neustar will not be responsible for placement fees associated with unsolicited resumes.

DIVERSITY
Diversity, inclusion and teamwork are second nature to Neustar; and these values permeate our entire business structure. Neustar is committed to creating an environment where a wide spectrum of opinions and beliefs are actively sought, listened to and respected. Further, our talented workforce draws from the many geographic areas and markets in which Neustar operates worldwide, which represents a distinct competitive advantage. The rich and varied personal and professional backgrounds of our employees make Neustar a dynamic and rewarding company at which to build a career. We invite you to join us.

EOE of Minorities/Females/Vets/Disability
Neustar, Inc. considers all applicants for employment without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, or status as a Vietnam-era or special disabled veteran in accordance with federal law and other state and local requirements. Neustar, Inc., complies with applicable state and local laws prohibiting discrimination in employment and provides reasonable accommodation to qualified individuals with disabilities in accordance with the American with Disabilities Act (ADA) and applicable state and local laws.",3.7,"Neustar
3.7",Bengaluru,"Sterling, VA",1001 to 5000 employees,1996,Company - Private,Internet,Information Technology,₹50 to ₹100 billion (INR),"Adobe, Akamai, Oracle"
Scientific Research Data Scientist R&D,-1,"We are looking for self-motivated scientists & engineers to join a supercharged workplace and build a first-generation analytical product. If you are a geek about anything – algorithms, math, machine learning, data wrangling/visualizing, high performance computing, scientific computing & tools, or anything else you can convince us about – we want to talk to you!

Experience
4 - 7 Years of Experience

Qualification

Bachelors or Masters in CS / Electronics from a premier institute with 4-7 years of industry experience
Solid design, excellent programming and debugging skills on a Unix-based OS (Ubuntu, Fedora, OSX) and fluency with a DVCS like Git.
Programming Languages: Python, C++
Deal-clinchers

Any of these – more the better!
Skilled with python packages: scikit-learn, pandas, numpy and scipy
Understanding of common algorithms and their application in solving real-world problems
Strong mathematical background in linear algebra, optimization and descriptive & inferential statistics
Understanding of machine learning concepts like generalization, regularization, linear models, neural network and expertise with using data to build systems based on machine learning techniques
Responsibilities

Individual technical contributor with self-drive to understand problem statements and make design decisions – ‘own’ what you do, make your calls, and defend them
Build a first generation analytical software product – design, code, test (unit & functional) and maintain the software, while proving that your implementations ‘work’
Implement software engineering processes and discipline for fast and reliable development of high-quality software product – make the software ‘elegant’
Work as a team player in a high performance environment that rewards ownership – make your opinion count within the team and the organization
Write to deepa.m@careerxperts.com to get started!

Job Location
Bengaluru",-1,CareerXperts,Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Microsoft Modern Data Platform,-1,"Accenture Technology powers our clients businesses with innovative technologiesestablished and emergingchanging the way their people and customers experience work, life and entertainment. Join Accenture Technology and youll translate the operational needs of the worlds governments and leading businesses into the innovative technical solutions that will enable them to better serve their customersyour friends, family and neighbors.Youll deliver everything from point solutions for a single business function to large, long-term outsourcing services, to complex systems integration installations spanning multiple businesses and functions. Youll create custom-designed solutions or integrate our technology platforms with their operations.

Role :Application Lead
Role Description :Lead the effort to design, build and configure applications, acting as the primary point of contact.
Must Have Skills :Microsoft Modern Data Platform
Good To Have Skills :Industry Strategy
Job Requirements : 1: Responsibilities -
a: Develop database solutions to store and retrieve company information
b: Methodologies used:Data Ingestion, ComsumptionStorage,Transformation,Visualization
c: Migrate data from legacy systems to new solutions
d: Knowledge of data mining and segmentation techniques
e: Define security and backup procedures
f: Proven work experience as a Data Architect, Data Scientist, Data Analyst or similar role

2: Professional Experience -
a: Candidates should have minimum 10 years of IT experience
b: Candidates should have 6 years of extensive database experience with a good knowledge of Business Intelligence, SQL Server, Data Warehousing Concepts Knowledge on internal working of YARN and HDFS
c:Should have Minimum 2 years of experience on Hadoop and strong knowledge of Hadoop HDInsight ecosystem Pig, Hive,MapReduce,HBase,Azure Blob Storage,SQOOP
d:Should have experience in Azure Analytics components like DocDB,Azure SQL Data Warehouse, Azure SQL DB and Azure Data Factory",3.9,"Accenture
3.9",Bengaluru,"Dublin, Ireland",10000+ employees,1989,Company - Public,Consulting,Business Services,₹500+ billion (INR),"Cognizant Technology Solutions, EY, McKinsey & Company"
Senior Research Data Scientist,-1,"dunnhumby is looking for a talented Senior Research Data Scientist!

You will apply machine learning techniques and algorithms to create dunnhumby
science solutions that can be delivered across our clients and engineered into science modules.

What you'll be doing:
Create
new solutions that can be captured as science modules and applied across
clients, and articulate how these solutions can distil complex problems into
compelling insights that resonate with clients.
Research
the latest machine learning approaches, and share the knowledge across the
team.
Use
programming skills, such as Python, Spark and sci-kit learn, in order to
develop efficient and scaleable science code for science modules
Perform
exploratory data analysis to characterise and visualise datasets
Develop
mathematical models for business problems to enable statistical and machine
learning techniques to be applied
Help
identify new opportunities within the Data Science space for future dunnhumby
solutions.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Lead
by example by following Quality Assurance processes, ways of working and coding
standards.
Ensure
smooth running of your projects & support junior team members with their
projects.
Ensure
clear and effective communication across your projects and build strong
relationships within the team and with internal stakeholders.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Technology and Product teams
Global Client Lead and Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Data Science Teams within our Retailer / Manufacturer
Partners
What you'll need:
Master’s
degree or equivalent in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related
field.
Experience of a wide range of machine learning
techniques including regularised regression, clustering and tree-based
ensembles, and ability to implement them through libraries.
Experience with open source machine learning packages, such as Pandas, scikit-learn, TensorFlow.
Experience
with handling large data volumes with modern data processing tools,
e.g. by using Hadoop / Spark / SQL Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and Testing
Statistical Modelling
Programming (Python, SQL, R,…)
Data Interpretation/ Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship building and management
Presentation skills
A plus if you also have:
PhD in Computer Science, Artificial Intelligence, Machine Learning, Applied Statistics, Physics, Engineering or related field.",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
"Data Scientist, Analytics",-1,"Full Time HyderabadPositions: 3

This position is a generalist role and could involve analytics, modeling, business operations and/or partnerships among other things. You must have flexibility to adapt to changing priorities, business and organizational needs. In addition, you must have the ability to operate independently in a fast-paced, small but growing environment and work proactively with various teams across the organization, including engineering, product, business, customer support, human resources, finance and legal.

Responsibilities
Apply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with our core/business products
Partner with Product and Engineering teams to solve problems and identify trends and opportunities
Inform, influence, support, and execute our product decisions and product launches.
The Data Scientist Analytics role has work across the following four areas:
Data Infrastructure
Working in hadoop and hive primarily, sometimes mysql, oracle, and vertica
Authoring pipelines via SQL and python based ETL framework
Building key data sets to empower operational and exploratory analysis
Automating analyses
Product Operations
Setting goals
Designing and evaluating experiments monitoring key product metrics, understanding root causes of changes in metrics
Building and analyzing dashboards and reports
Exploratory Analysis
Proposing what to build in the next roadmap
Understanding ecosystems, user behaviors, and long-term trends
Identifying levers to help move key metrics
Evaluating and defining metrics
Building models of user behaviors for analysis or to power production systems
Product Leadership
Influencing product teams through presentation of work
Communicating of state of business, experiment results, etc to product teams
Spreading best practices to analytics and product teams
Requirements
4+ years’ experience doing quantitative analysis.
BA/BS in Computer Science, Math, Physics, Engineering, Statistics or other technical field. Advanced degrees preferred.
Experience in SQL or other programming languages.
Development experience in at least one scripting language (PHP, Python, Perl, etc.).
Ability to initiate and drive projects to completion with minimal guidance
Ability to communicate the results of analyses in a clear and effective manner
Basic understanding of statistical analysis.
Experience with a statistical package such as R, MATLAB, SPSS, SAS, Stata, etc.
Experience with an Internet-based company.
Experience with data sets and distributed computing (Hive/Hadoop).
Minimum Qualification
4+ years’ experience doing quantitative analysis.
BA/BS in Computer Science, Math, Physics, Engineering, Statistics or other technical field. Advanced degrees preferred.
Experience in SQL or other programming languages.
Development experience in at least one scripting language (PHP, Python, Perl, etc.).
Ability to initiate and drive projects to completion with minimal guidance
Ability to communicate the results of analyses in a clear and effective manner
Basic understanding of statistical analysis.
Experience with a statistical package such as R, MATLAB, SPSS, SAS, Stata, etc.
Experience with an Internet-based company.
Experience with data sets and distributed computing (Hive/Hadoop).",-1,Dotbits,Hyderabad,"Sunnyvale, CA",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"A New Social Future


How is it that in a world that's evolving so quickly that social products still feel the same? Strangely enough, we're still using products that were invented in the 2G era. There seems to be an emptiness with the current experience and today's products are built to force humanity to be superficial.

We'd like to change that.

With the advancements in technology, so much more is possible today that wasn't even possible, just a few years ago. We believe the timing couldn't be better.

6 Principles


We’re thoughtful about why we do things and here are 6 principles guiding our thinking:
Advancements in Tech & AI: Allowing more bits to be pushed to users in real-time and thus allowing far richer, more personalised experiences.
Bits Cheaper than Atoms: Today, bringing rich, luxurious experiences to the masses is faster, more efficient and cheaper online than it is offline.
Self Worth Moving Online: 40% of people's waking life is now spent on their smartphones. The next generation is far more comfortable online than offline.
Vertical Communities: We don't live our lives in one massive community. We're specific in the activities we engage in (art, gaming, fitness etc).
New Business Models: Putting customer at the centre. These won't be ad-driven in the traditional sense. Think micro-transactions, subscriptions and more.
Consumers as Owners: It's a bit strange that consumers aren't part of the value chain. Turning customers into owners is a fascinating thought.
Build Magical Things


It’s so clear to us that technology evolves but people stay the same. We’re solving for a core human need - social connection and with all the evolution in technology, today we can solve for that in brand new ways.

At our core, we’re a creative company. Ideas and pixels is where we live and we love building magical products that make our users feel ‘wow’ inside. It’s not just about features, it’s also about how they make people feel. We build at the intersection of the scientific and the romantic.

And it all starts with people, the right team that cares deeply about our mission, values and our users. At hike, you'll have the chance to do the best work of your life.

Come join us and shape the future of social.

The Hike Code


We’re on a journey to build something new, something different and making anything innovative & new requires the ability to surrender to the unknown. The Hike Code is our value system. It is our guide to navigate through the unknown to build incredible products. Here they are:
Top Talent in Every Role: We look for people with an incredible intellect. Both skills and values are important to us.
Pro-Sports Team: Strengths based, results driven with a ""team-first"" attitude
Customer at the Centre: Everything we do is inspired by how can we better solve for our customer.
Constant Innovation: It's our DNA to walk into the unknown in search of having meaningful impact.
Act Like Owners: We own the output of what we do, even if it's explicitly not our job.
Thoughtful Decision Making: Clear Mind + Obsession to Simplify + Data Driven. We strive to be thoughtful.
Always be Hustling: We understand that success is not one big leap but tiny gains compounding over time #ABH.
Be Open Minded & Coachable: We have a quest to continuously #RiseUp to be the best version of ourselves.
Role


If you've made it till here, you're probably still interested in the role :)

As a Data Analyst, you will:
Perform quantitative analyses that translate data into actionable insights and provide analytical, data-driven decision-making support for key projects.
Provide reporting and performance monitoring to product teams using data drawn from diverse sources.
Own and evangelize data-driven experimentation in the team to improve the product offerings, and document it.
Enable product reviews, deep dives and analyses through the effective use of data and communicate and report insights and recommendations to shape product strategy.
Ensure that any data required for carrying out the other responsibilities for the product/features you’re working on is properly instrumented and logged.
Requirements

Sounds Like You?
You have a Bachelor’s degree in Math, Statistics, Comp Science, Engineering, or other technical field required; advanced degrees strongly preferred.
You are hands on with Python/ Java Programming language.
You have a very good understanding of mobile and Internet products, growth strategies and business dynamics.
You are comfortable manipulating, transforming, and analysing complex, high-volume, high-dimensionality data from varying sources.
You have 3+ years experience performing quantitative analysis, preferably for an Internet or technology company.
You have hands-on working experience on SQL queries.
You have experience in reporting and dashboards involving very large datasets and multiple data sources, with the ability to interpret data and produce meaningful insights.
You have good understanding of statistical analysis, data warehousing, data modelling.
You have experience with statistical packages such as SPSS, SAS etc. and BI/visualisation tools such as Tableau, Google Analytics etc.
You have ability to execute research projects and craft actionable recommendations.
You have proven ability to work in a fast-paced environment, meet changing deadlines and priorities on multiple simultaneous projects.
You have excellent organisational, communication, presentation and interpersonal skills.
You enjoy working in both individual and team settings.
Benefits
A flat and transparent culture
Flexible working hours - No fixed Checkin/Checkout
Unlimited Snacks, food, and drinks on the house
Tools of the trade - MacBook, Latest Softwares
Monthly Communication Reimbursement
Best learning and development opportunities
A chance to have a big impact early in your career
At Hike, we value diversity. We are an equal opportunity employer: we do not discriminate on the basis of race, color, religion, gender, ethnicity or disability status.",4.3,"Hike
4.3",New Delhi,"New Delhi, India",51 to 200 employees,2012,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,"Facebook, Google, WhatsApp"
Senior Data Scientist,-1,"We are looking for a strong Senior Analyst/Senior Data Scientist, who will guide model development. The person will be part of data science team that continuously interacts with underwriting analysts and developers that drive solutions to the complex business problems, in credit and risk domains.

Roles and Responsibilities:
In addition to the responsibility of analyst/Data Scientist, additional responsibilities:

Good understanding of the underlying business and workings of cross functional teams for successful execution.
Good written and oral communication, and ability to convey technical details to teams working across multiple time zones.
Mentor a small team of analysts.

Qualification & Experience:
4+ years of experience in the field of credit rist analytics, marketing analytics backgrounds
Proven experience working in teams with end to end real time implementation
Strong with programming languages like Python and data processing using SQL or equivalent and ability to experiment with newer open source tools
Strong with analytical and statistical packages like R, Python Scikit-Learn
Familiarity with deep learning, xgboost, scikit, apache spark, GPU based machine learning
Good communication skills and ability to articulate complex scientific and technical matters to the business group
Ability to successfully interact with business and software teams for execution
Experience in newer machine learning algorithms
Experience with NoSQL and distributed data processing technologies such as Hadoop is also desirable
Experience in risk and credit score domains are a big plus
Bachelor or Master in Operations Research, Computer Engineering or in closely related Quantitative Disciplines from a premier institution.
Interested? Please send your resume to careersindia@applieddatafinance.com.",4.5,"Applied Data Finance
4.5",Chennai,"San Diego, CA",51 to 200 employees,2014,Company - Private,Lending,Finance,Unknown / Non-Applicable,Avant
Ads -Data Scientist,-1,":

The Data Scientist is responsible for collecting, organizing, analyzing and interpreting Truecaller data and drawing insightful conclusions with the aim of enhancing BU’s road map, business plan and customer experience. The individual will work in close collaboration with the Product, Engineering and platform team in order to identify and follow up on metrics, evaluate A/B tests and user behavior and identify product insights. The role requires working both independently and proactively with identifying improvement opportunities as well as being involved in separate projects. The Data Scientist will act as an advisor to the BU's Product improvement, strategy building and Management Team by identifying and communicating data insight.

Key responsibilities:
Collecting, organizing, analyzing and interpreting all data and drawing insightful conclusions from it that enables us to work in a smarter way
Create visual interpretations from data and explain graphs and charts with insightful notes and summaries
Analyzing users data and assist product development in finding new innovative ways of presenting and making use of data
Support our management team in identifying, measuring and following up on key metrics
Providing regular, accurate and comprehensive statistical reports
Providing objective insight and analysis to influence decision making
Constantly asking the right but difficult questions on why, what and how and also help us answering those questions
Ensuring quality of data and actively working on cleaning data to make sure of top notch relevance and accuracy
Actively keep up to date on external market and data research and work towards adding data points from external sources to our own data in order to create a value added analysis

Required minimum competencies:
3 to 5 Years Experience in an Analytics/Data Science or similar roles, self- curated projects

Familiarity with database modeling and data warehousing principles with a working knowledge of SQL
Familiarity with data modeling on Hadoop clusters, the tools in Big Query, Hive, Spark Kafka ecosystem, stream processing to support the day-to-day work
Extensive experience with analytical and quantitative problem solving
Experience with analysis tools, open source or commercially available libraries and toolsets
Excellent communication skills
Great attention to detail and analytical skills
A passion for numbers, data and finding patterns
Ability to excel with challenging tasks with a calm and positive attitude
Working knowledge of data mining algorithms including decision trees, probability networks, association rules, clustering, regression, neural networks and reinforcement learning
Experience from working with mobile applications and big data is a great advantage
Programming knowledge in at least one language in addition to SQL
Global / multinational experience

Applying:
This position is located in Bengaluru, India.
We only accept applications in English.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, or marital status.",-1,True Caller,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
CIEL/SEL/1882: Data scientist,-1,"Experience in
Python
&
R
programming
Â· Experience in
Machine Learning / Deep Learning
Â· Experience with common data science packages such as
NumPy, MatLab, Keras, Tensorflow, PyTorch, scikit learn
etc
Â· Should proactively fetch information from various sources and analyze it for better understanding and build AI tools that automate certain processes.
Â· The primary focus will be in applying data mining techniques, doing statistical analysis, and building high-quality prediction systems integrated within the products",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
Senior Data Scientist,-1,"We required Senior Data Scientist who will work as leader, set the direction for the team, deciding on the best methodology to address complex business problem, generating models pipelines and pulling useful insights to make decisions.
One will be an expert in data science, machine learning and statistics, with extensive hands-on experience and the ability to balance technical and business considerations to make the right decisions. They will be a self-starter, with strong attention to detail, an ability to work in a fast-paced and ever-changing environment. They will have excellent oral and written communication skills to communicate effectively with both technical and non-technical stakeholders.

Responsibilities
Work closely with business of Finance, Retail, Automotive etc. to understand requirements effectively
Applying Statistical, Data Science, Machine Learning or other innovative methods to specific business problems and data
Provide technical leadership, research new machine learning approaches to drive continued scientific innovation.
Working with other engineers to solve technical problems.
Skills and Experience
M.S. or Bachelor in Computer Science, Machine Learning, Statistics, Applied Mathematics or related discipline
PhD in quantitative field (Computer Science, Mathematics, Machine Learning, AI, Math, Statistics, or equivalent) is big plus
Extensive knowledge and practical experience in machine learning, statistics, NLP, deep learning, information retrieval
Good communication skills and ability to work with a team
Ability to manage and quantify improvement in customer experience or value for the business resulting from research outcomes
Are you ready ?

What are you waiting for, if above mentioned job details match to skills, send us your updated resume at hello@crossml.com",-1,CrossML,Chandigarh,-1,-1,-1,-1,-1,-1,-1,-1
Applied Scientist Intern,-1,"Excited by Big Data, Machine Learning and Predictive Software? Interested in creating new state-of-the-art solutions using Machine Learning and Data Mining techniques on Terabytes of Data?
At Amazon, we are developing state-of-the-art large-scale Machine Learning Services and Applications on the Cloud involving Terabytes of data. We work on applying predictive technology to a wide spectrum of problems in areas such as Amazon Retail, Seller Services, Customer Service, Alexa, Chatbots and so on. We are looking for talented and experienced Machine Learning Scientists (Masters/Ph.D. in a related area preferred) who can apply innovative Machine Learning techniques to real-world e-Commerce problems. You will get to work in a team dedicated to advancing Machine Learning technology at Amazon and converting it to business-impacting solutions.
Major responsibilities
- Use machine learning, data mining and statistical techniques to create new, scalable solutions for business problems
- Analyze and extract relevant information from large amounts of Amazons historical business data to help automate and optimize key processes
- Design, develop and evaluate highly innovative models for predictive learning
- Establish scalable, efficient, automated processes for large scale data analyses model development, model validation and model implementation
- Research and implement novel machine learning and statistical approaches




Basic Qualifications

- A Masters and/or PhD in Computer Science, Machine Learning, Operational research, Statistics or in a highly quantitative field
- Experience in predictive modelling and analysis, predictive software development
- Strong problem-solving ability
- Good skills with Java/Scala or C++, Perl/Python (or similar scripting language)
- Experience in using R, Matlab, or any other statistical software
- Strong communication and data presentation skills



Preferred Qualifications

- Experience handling gigabyte and terabyte size datasets
- Experience working with distributed systems and grid computing
- Knowledge of the latest and state of the art ML technology
- Publications or presentation in recognized Machine Learning and Data Mining journals/conferences",4.2,"Amazon
4.2",Hyderabad,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Lead Data Scientist,-1,"Lead Data Scientist(Job Number: 20000743)

Description

Brillio is forging ahead aggressively amidst the current COVID-19 situation and continues to hire for various roles globally - with all interviewing and on-boarding done virtually. Brillio has invested in the right capabilities to adapt to the new normal and empower its employees to operate seamlessly. All the new joiners, along with the Brillio family, will temporarily work remotely until it is safe to return to our offices. Read Brillio’s Chief Operating and Delivery Officer, Aftab Ullah’s statement about Brillio's hiring plans in the leading publications - The Times of India and The Week’s latest stories about the positive hiring sentiments of tech firms.

As a Brillian what your day would look like:
o Take ownership of large-scale data science engagements and drive end-to-end solutions that have efficient and productionable algorithms, and communicate relevant insights to stakeholders through storyboards/presentations

o Engage and mentor those around you in advanced statistical analysis concepts and foster data driven thinking

o Stay abreast with current technical and industry development and constantly strive to devise innovative statistical models for data analysis

o Communicate with multi-disciplinary teams, internal and external stakeholders define problems, uncover insights hidden in large data sets that drive impactful business decisions

o Actively participate in external forums and industry conclaves

To succeed, you’d have technical experience and expertise in –

A. For you to be successful, you must:
o Build partnerships within and outside the team regardless of formal authority

o Create value by anticipating and meeting needs of customers and delivering high-quality results and be accountable for outcomes

o Disseminate personal knowledge, share own experiential learning with others and empower others by mentoring those around you

o Be open and flexible to accommodate and implement new ideas, understand business complexities, nurture innovation and challenge the status quo persistently

o Be subject matter expert in chosen area of specialty through continuous learning

o Have an eye for detail to ensure accurate conclusions in data analysis and presentations

B. For you to be successful, you must: -

o Critical Thinking in order to drive end-to-end solutions to ambiguous problem; with excellent sense of risk and resource management

o Strong analytical skills with the ability to collect, organize, review significant amounts of information

o Strong problem-solving skills with an emphasis on product development

o Experience using statistical computer languages (R, Python, SAS) to manipulate data and draw insights from large data sets

o Expertise in basic statistical concepts such as properties of distributions, statistical tests and their proper usage

o Expertise in advanced machine learning techniques such as Clustering, Regression/Classification, Time Series Analysis, Network Analysis, Popular Deep Learning architectures and theory, simulation, scenario analysis

o Experience with some optimization techniques (Linear Programming, Genetic Algorithm, Sim. Annealing, MC Simulation)

o Clear, professional written and verbal communication skills, ability to easily communicate complex ideas

o Experience with any distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, etc. or AWS/Azure

o Experience with machine learning on big data

C. It would be exceptional, if you also have this:
o Expertise in Image, Video, Speech, Sound, Text domain

o Working knowledge of concepts and application of Design of Experiments

o Depth across areas within the domain or industry

Primary Location: IN-KA-Bangalore
Employee Status: Regular",3.1,"Brillio
3.1",Bengaluru,"Santa Clara, CA",1001 to 5000 employees,2014,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),-1
Data Science AI ML NLP Consultant,-1,"“AI-ML-NLP-0519”

For one of our prestigious multinational clients, we are looking for AI/ML/NLP Professionals for immediate hiring. Our client is an established name in the space of software development and consultancy. This position is based at Gurgaon – Delhi NCR, India.

WHAT IS IN IT FOR YOU?

The company is known for software consulting services and is a respected name in the software industry. You will get to work in a very energetic environment with lot of dynamism. They cater to mainly US customers, and provide their services through onsite/offshore model. The work environment is conducive to innovation, and provides continuous growth opportunities.

JOB DESCRIPTION

Work on Data Science projects in the area of NLP, ML, and Cognitive analysis.

Key Responsibilities:
Understand Customer Problem and Data Requirements.
Translate Customer requirements into a Data Science Problem.
Propose a Data Science solution which may involve use of Machine Learning (Supervised & Unsupervised) and other algorithmic models
Prepare Data followed by Model development
Model Testing and Deployment
Qualifications and skills:
Engineering Degree is a MUST
2 to 4 years experience in AI/ML/NLP/Cognitive Analysis
Coding of Machine Learning models in R and/or Python language
Experience in extracting data from a variety of data sources
Proven expertise in analyzing & visualizing data
Experience in deploying on AWS, Google Cloud Platform or - Microsoft Azure will be preferred.
Quick learner of newer models, libraries and modeling techniques
Excellent communication and presentation skills
About the client

Our client is an established Software development and consultancy organization with its headquarters in US. They are a respected name in Insurance and Healthcare software and services. They have a large spectrum of customers all over US, and have development centers in India. They believe in hiring smart people and giving them a chance to grow at a rapid pace.

Come, be part of a winning team.",3.9,"ChampionsIT
3.9",Gurgaon,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
"QA Lead for Machine Learning( Engineer,Sr Staff/Mgr)",-1,"Job Id
E1981981
Job Title QA Lead for Machine Learning( Engineer,Sr Staff/Mgr)

Post Date 05/04/2020

Company
Qualcomm Technologies, Inc.

Job Area Engineering - Software

Location India - Hyderabad

Job Overview Join a new and growing team at Qualcomm focused on advancing state-of-the-art in Machine Learning. The team uses Qualcomm chips extensive heterogeneous computing capabilities and engineers them to allow the running of trained neural networks on device without a need for connection to the cloud. Our inference engine is designed to help developers run neural network models trained in a variety of frameworks on Snapdragon platforms at blazing speeds while still sipping the smallest amount of power. See your work directly impact billions of mobile devices around the world.
In this position, you will lead 20+ member strong technical team and responsible for the QA (test development and execution) and CI/CD infrastructure of Qualcomm ML Software. You will work with neural network frameworks like Caffe, Caffe2 and TensorFlow and develop the validation framework to gauge functionality, performance, precision and power of SNPE (Snapdragon Neural Processing Engine). You will work with the latest and greatest DNNs emerging from the research community. You will also have to keep up with the fast pace development happening in the industry and academia to continuously enhance our benchmarking and validation infrastructure from software engineering as well as machine learning standpoint. In addition, youd be responsible to ensure to setup the CI/CD infrastructure that integrates/validates/releases all the changes for a smooth nightly quality assurance. The team strives to minimize manual interventions and looks to use state of the art in the field of DevOps to achieve the most resilient and reliable infrastructure for this. Youll be required to not only maintain/enhance the existing infrastructure but also bring in your ideas to remove any inefficiencies in the process. You are responsible for SNPE, ANN (Android Neural Network) and other product releases from Qualcomm across multiple chipsets.

Minimum Qualifications Experience with at least one machine learning framework like TensorFlow, Caffe, Pytorch, etc.
Well versed in version control tools, CI tools like git, repo, Jenkins
Expert in DevOps fundamentals, lives by Infrastructure-as-code principles
Strong understanding of Deep Learning fundamentals
Strong development skills in Python
Excellent communication skills (verbal, presentation, written)
Ability to collaborate across a globally diverse team and with stakeholders/ leads across geographies
12 to 14 years of relevant work experience in software test development and DevOps
3 to 4 years of experience in leading the teams technically and handling line management responsibilities

"" id=""hdnMinimumQualifications"">Live and breathe quality software development with excellent analytical, and debugging skills
Experience with at least one machine learning framework like TensorFlow, Caffe, Pytorch, etc.
Well versed in version control tools, CI tools like git, repo, Jenkins
Expert in DevOps fundamentals, lives by Infrastructure-as-code principles
Strong understanding of Deep Learning fundamentals
Strong development skills in Python
Excellent communication skills (verbal, presentation, written)
Ability to collaborate across a globally diverse team and with stakeholders/ leads across geographies
12 to 14 years of relevant work experience in software test development and DevOps
3 to 4 years of experience in leading the teams technically and handling line management responsibilities

Preferred Qualifications Experience with ML Application development
Experience with Docker and orchestration frameworks like ansible, chef etc..
Experience in Android(AOSP) or embedded Linux application development
Development experience in C++

Education Requirements Bachelors/Masters",3.9,"Qualcomm
3.9",Hyderabad,"San Diego, CA",10000+ employees,1985,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Intel Corporation, MediaTek, Broadcom"
Machine Learning Engineer (Data Science Engineer),-1,"We are looking for Machine Learning Engineers/ Data Scientists to join our talented software team in building high performing, low latency, enterprise grade and cloud-based product suite. You will play a key role in building our innovative product pipeline. Using your deep understanding of modern web architectures and Cloud platforms, programming expertise and operational experience, you will help building successful SaaS products at Pype.

Please join our ML team and work together in breaking barriers and bringing AI to the construction software industry. Applicants should have a strong computer science background with good analytical, problem solving skills apart from good foundations in Machine learning with bent towards NLP/Image Understanding. Working proficiency with Python is mandatory. Knowledge of distributed systems like Hadoop/Spark is a plus.

Roles & Responsibilities

Formulate, code and evaluate machine learning models required for the product/application
Production deployment with required optimization, vectorization and system integration
Verification/validation and continuous integration of advanced variations
Identify/adopt feedback loops to maintain high fidelity data governance across the product portfolios

Qualifications:
Bachelor’s/Master’s degree in Computer Science or equivalent area from reputed institutes
Around 2-6 years of experience in applied or theoretical Machine learning roles in the industry or research institutes
Good grasp of Linear Algebra, Probability and Statistics
Working knowledge and inclination towards Statistical pattern recognition, Machine learning, Neural Nets, Image Processing
Experience with Python/Scikit-Learn/TensorFlow/OpenCV
Ability to work with a team in an Agile environment
To apply send your resume to hr-india@pype.io",4.1,"Pype
4.1",Bengaluru,"Herndon, VA",1 to 50 employees,2013,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
"AI/Machine learning Engineer (only from IIT, NIT)",-1,"Requirements

We are looking for applicants with a strong background in Analytics and Data mining (Web, Social and Big data), Machine Learning and Pattern Recognition, Natural Language Processing and Computational Linguistics, Statistical Modelling and Inferencing, Information Retrieval, Large Scale Distributed Systems and Cloud Computing, Econometrics and Quantitative Marketing, Applied Game Theory and Mechanism Design, Operations Research and Optimization, Human Computer Interaction and Information Visualization. Applicants with a background in other quantitative areas are also encouraged to apply.

We are looking for someone who can create and implement AI solutions. If you have built a product like IBM WATSON in the past and not just used WATSON to build applications, this could be the perfect role for you.

All successful candidates are expected to dive deep into problem areas of Zycus’ interest and invent technology solutions to not only advance the current products, but also to generate new product options that can strategically advantage the organization.

Skills:
Experience in predictive modelling and predictive software development
Skilled in Java, C++, Perl/Python (or similar scripting language)
Experience in using R, Matlab, or any other statistical software
Experience in mentoring junior team members, and guiding them on machine learning and data modelling applications
Strong communication and data presentation skills
Classification (svm, decision tree, random forest, neural network)
Regression (linear, polynomial, logistic, etc)
Classical Optimization(gradient descent, newton raphson, etc)
Graph theory (network analytics)
Heuristic optimisation (genetic algorithm, swarm theory)
Deep learning (lstm, convolutional nn, recurrent nn)
Must Have:
Experience: 3-9 years
The ideal candidate must have proven expertise in Artificial Intelligence (including deep learning algorithms), Machine Learning and/or NLP
The candidate must also have expertise in programming traditional machine learning algorithms, algorithm design & usage
Preferred experience with large data sets & distributed computing in Hadoop ecosystem
Fluency with databases
Benefits",3.4,"Zycus
3.4",Bengaluru,"Princeton, NJ",501 to 1000 employees,1998,Company - Private,Computer Hardware & Software,Information Technology,₹500 million to ₹1 billion (INR),"SAP Ariba, GEP, Coupa Software Inc"
Senior Data Scientist,-1,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.

What is the Data Scientist – Mathematical Finance – Client Analytics group responsible for?
Works individually in support of a Fintech (Wealth Management) initiative typically involving delivering against pre-defined timelines, providing support for solving complex problems by developing a variety of mathematical models and applying statistical techniques and perform ad-hoc statistical and data mining analysis as required.
Designs, develops and programs methods, processes, and systems to consolidate and analyze structured or unstructured, diverse “big data” sources to generate actionable insights and solutions for on-going research and product enhancement. Interacts with data management, data engineering, product, technology and service teams to identify questions and issues for data analysis and experiments.
Develops and codes software programs, algorithms and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources. Ability to Identify meaningful insights from large data and metadata sources; interprets and communicates insights and findings from analysis and experiments to business leaders (or organizations through out the enterprise).
What are the ongoing responsibilities of an Data Scientist – Mathematical Finance?
Mathematical Modelling:
Demonstrates Expertise in advanced mathematics, especially mathematical finance.
Demonstrates a good grasp of probability distributions and stochastic calculus.
Designs and validates mathematical models to find interlinkages and applications of academic models within a business context.
Works on mathematical optimization modules similar to Traveling salesman problems under multivariate constraints. Familiarity with Lagrangian multivariate optimization problems a plus.
Analyzes and interprets the results of research experiments through statistical models Solves analytical problems utilizing large structured, semi-structured and un-structured data in a distributed processing environment.
Data Analysis:
Collects data from disparate systems, analyzes and delivers the data as intelligence that is actionable.
Uses distributed and parallel processing frameworks like Spark for the analysis.
Statistical Analysis (Data Mining and Advanced Analytical Techniques)
Develops predictive, statistical, behavioral, or other models using supervised and un-supervised machine learning / statistical modeling techniques.
Performs ad hoc statistical and data mining analyses.
Training, Research and Development.
What ideal qualifications, skills & experience would help someone to be Successful?
Master’s degree in Mathematical Finance / Quantitative Finance / Financial Engineering highly preferred.
Ph.D / Master’s / Bachelor’s degree in Mathematics, Statistics, Econometrics, Engineering or related disciplines, from Tier-1 or Tier -2 Institutes.
4-6 years of experience in data science.
Certifications in Financial Mathematics or related subjects from institutes such as IIQF, IFMR, TIFR etc would be highly valued.
Experience:
4-6 years of experience in data science.
Understanding and prior experience with financial markets (Mandatory).
Knowledge of and Experience with Stochastic calculus, Simulations, Linear Algebra, statistical modeling, Time series analysis (especially state space models) (Mandatory)
Knowledge and experience of key machine learning and deep learning framework, e.g. Keras, TensorFlow.
Hands on Experience in Python (Mandatory)
Proven Experience in Statistical and Mathematical modelling.
Experience in SQL
Other Skills:
Proven ability to take initiative and work under pressure in a changing/growing environment.
Should be self-driven and be able to work in an unstructured environment.
Proven ability to work with ambiguous (not well defined) challenges.
Excellent written and verbal communication skills.
Displays curiosity to learn and learns independently.
Ability to translate business challenges into analytical problems.
Able to cultivate interpersonal customer and co-worker relationships.
Ability to articulate and explain statistical / machine learning techniques to business partners.
Ability to work individually or as a team as task requires.
What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8","Hyderabad,India","San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
Data Analyst,-1,"Discussions with SMEs to understand the requirement.
Worked with different lines of business in consumer banking like mortgage, credit cards, loans and ready credit.
Preparing Business Requirement Document/Functional Requirements documents/Minor Development Documents (MDD)
Preparing the data enrichment rules
working with SMEs to get the sign offs for the changes
Data quality checks on feeds received
Good working knowledge in SQL, Data Analysis, Feed Analysis, Data Mapping, Data Reconciliation
Responsible for mapping the attributes required for Optima Retail Reporting with the country specific attributes for the regulatory reports such as CCAR14Q/FDIC/BASEL.
Working with business users across countries and products on the map-gap analysis performed to document the gaps.
Hands on experience in data analysis, data validation, data profiling and data reconciliation.
Responsible for data profiling, data reconciliation, full report validation, production parallel stages validations and UAT testing of the engagement.
Responsible for enhancements and to explain the same to technology team assist UAT testing and provide business approval on resolution.
Liaison with technical teams to resolve business related queries.
co-ordinate with offshore for completing day to day deliverables.
Job Segment:
Database, Consulting, SQL, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
Data Analyst,-1,"We are looking for a Data Scientist who will support our client’s product, sales, leadership and marketing teams with insights gained from analyzing data. You should be using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action.

You must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations.

You must have a proven ability to drive business results with their data-based insights. You must be comfortable working with a wide range of stakeholders and functional teams. You will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.

Technologies experience

Strong problem-solving skills preferably with an emphasis on service, platform, product enabled solutions.
Experience using statistical computer languages (R, Python, etc.) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, k-NN, Naive Bayes, SVM, Decision Forests etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
Coding knowledge and experience with several languages: C, C++, Java, JavaScript, etc.
Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.
Experience querying databases and using statistical computer languages: R, Python, Scala,SLQ, etc.

Responsibilities

Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Work with stakeholders to identify and leveraging data to drive business solutions.
Mine and analyze data from databases to drive optimization, techniques and business strategies.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation and other business outcomes.
Coordinate with different functional teams of client to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model",3.8,"LTI
3.5",Mumbai,"Bengaluru, India",10000+ employees,1999,Company - Public,IT Services,Information Technology,₹50 to ₹100 billion (INR),"Infosys, Tata Consultancy Services, Wipro"
Senior Data Scientist,-1,"Company Description

Tesco Bengaluru: We are a multi-disciplinary team creating a sustainable competitive advantage for Tesco by standardising processes, delivering cost savings, enabling agility, providing cutting-edge technological solutions and empowering our colleagues to do ever more for our customers. With cross-functional expertise in Global Business Services and Retail Technology & Engineering, a wide network of teams and strong governance we reduce complexity thereby offering high quality services for our customers. Tesco Bengaluru, established in 2004 to enable standardisation and build centralised capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 4,40,000 colleagues.
Tesco Technology consists of people from a number of different backgrounds, but having a common purpose to serve our shoppers a little better every day with our retail technological solutions. We shared a common interest in harnessing innovations in technology to enhance their shopping experience at Tesco stores. Whether making products, software or systems, our teams focuses on various aspects from taking strategic ownership of the architecture to delivering technological solutions such as design, testing, deployment, infrastructure, operation and security of the systems to ensure agile, smooth and safe operations. These help us to deliver the maximum business impact. Teams refine their internal processes to best fit their own needs, working to build core capabilities in application and services. We collaborate globally across teams to build end-to-end customer-facing solutions, as well as to share knowledge, experience, tools and techniques.
Job Description

A Data Scientist is someone who can obtain explore and model data by blending maths algorithms and a scientific mindset in order to support and automate decision making across the business. In this job you will
Utilise an advanced knowledge level of the Data Science Toolbox to participate in the entire Data Science Project Lifecycle and execute end-to-end Data Science project
Work end-to-end on Data Science developments contributing to all aspects of the project lifecycle
Understand difficult business problems and prototype solutions
Analyse and link complex datasets so that they may be learned from or optimised
Scientifically analyse and evaluate the effectiveness of different approaches to guide future development and track the value created by the team
Build mathematical models on top of big data architectures to gain deep insights into opportunities to improve the customer experience and the Tesco business
Partner with technology teams to productionize developments
Communicate complex solutions in a clear understandable way to non-experts
Promote data science across Tesco and promote Tesco across the external Data Science community
Other non technical skills
Have excellent written and verbal communication skills and clearly articulate your ideas.
Learn new areas/disciplines quickly.
Are a team player and work collaboratively with other members of the team.
Seek help and guidance when appropriate.
Are self-organised and can plan your work in line with the team plan and priorities.
Take an active part in the Data Science community building and knowledge sharing with peers.
Demonstrate empathy and listening skills to understand the needs of your stakeholders and customers and strong persuasion skills to influence others.
Encourage collaboration and communication between teams.
Keep up-to-date with data trends and developments showing a strong interest and commitment to Tesco your work and Data Science
Have great presentation skills and can present your ideas/ thoughts/plans with clarity and confidence.
Demonstrate ownership responsiveness and commitment towards your work.
Demonstrate strong data-based decision-making skills especially when multiple trade-offs are involved and fast decision-making is required.
Have great coaching skills and mentor junior colleagues and peers in your team.
Confidently and competently represent the team when needed.
Collaborate with external suppliers and solution providers.
Use the Tesco leadership skills to encourage and get the best out of the people you work with.
Customer Commercial & Critical Thinking
Have an analytical thought process and ability to process complex information.
Understand key user personas customers and stakeholders for your project and their pain points really well.
Keep customers as focus of analysis insight and recommendation.
Help define business objectives/customer needs by capturing the right requirements from the right customers.
Can take defined problems and identify resolution paths and opportunities to solve them; which you validate by defining hypotheses and driving experiments
Have an understanding of the commercial impact of your recommendations and insight
Can identify unstructured problems and articulate opportunities to form new analytics project ideas
Functional (e.g.quantitative techniques)
Contribute to all aspects of the Data Science project lifecycle
Understand and monitor data quality to improve confidence in the data used for analysis
Use and understand the key performance indicators (KPIs) and diagnostics to measure performance against business goals
Compile integrate and analyze data from multiple sources to identify trends expose new opportunities and answer ongoing business questions
Execute hypothesis-driven analysis to address business questions issues and opportunities
Build validate and manage advanced models (e.g. explanatory predictive) using statistical and/or other analytical methods
Are familiar working within Agile Project Management methodologies / structures
Analyse results using statistical methods and work with senior team members to make recommendations to improve customer experience and business results
Have the ability to conceptualize formulate prototype and implement algorithms to capture customer behavior and solve business problems
Analyse results using statistical methods to make recommendations to improve customer experience and business results
Skilled at managing processing and optimising performance and reliability of automated data streams and analytical workflows
Domain
Advanced knowledge level of the Data Science Toolbox
Familiar with configuring Data Science analytics environments (technology software etc)
Understanding of ETL principles (Data munging joins etc)
Experience working in Hadoop / Big Data environments and common Data Science toolkits

Qualifications

Machine Learning, Python, Scala, Data Structures and Algorithms",-1,Tesco Technology,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer:

Pluto7 is a services and solutions company focused on building ML, Ai, Analytics, solutions to accelerate business transformation. We are a Premier Google Cloud Partner, servicing Retail, Manufacturing, Healthcare, and Hi-Tech industries and Pluto7 has been awarded as ""2019 Google Cloud Specialization Partner of the Year for Data and Analytics"" . Were seeking passionate people to work with us to change the way data is captured, accessed and processed, to make data-driven insightful decisions.

Must have skills :
Hands-on experience in database systems (Structured and Unstructured).
Programming in Python, R, SAS.
Overall knowledge and exposure on how to architect solutions in cloud platforms like GCP, AWS, Microsoft Azure.
Develop and maintain scalable data pipelines, with a focus on writing clean, fault-tolerant code.
Hands-on experience in data model design, developing BigQuery/SQL (any variant) stored.
Optimize data structures for efficient querying of those systems.
Collaborate with internal and external data sources to ensure integrations are accurate, scalable and maintainable.
Collaborate with business intelligence/analytics teams on data mart optimizations, query tuning and database design.
Execute proof of concepts to assess strategic opportunities and future data extraction and integration capabilities..
Data extraction, Data cleansing and transformation.
Strong knowledge on REST APIs, Http Server, MVC architecture.
Knowledge on continuous integration/continuous deployment.
Preferred but not required:
Machine learning and Deep learning experience
Certification on any cloud platform is preferred.
Experience of data migration from On-Prem to Cloud environment.
Exceptional analytical, quantitative, problem-solving, and critical thinking skills
Excellent verbal and written communication skills
Work Location: Bangalore",4.2,"Pluto7
4.2",Bengaluru,"Milpitas, CA",51 to 200 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Scientist DA4AD,-1,"Responsibilities
Selecting features, building and optimizing classifiers using machine learning and Deep Learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance

Skills
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, CNNs, etc.
Very good experience with common data science toolkits of Python like numpy, pandas, pyTorch. Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools like matplotlib, Tableau
Proficiency in using query languages such as SQL
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality

Responsibilities
Selecting features, building and optimizing classifiers using machine learning and Deep Learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance

Skills
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, CNNs, etc.
Very good experience with common data science toolkits of Python like numpy, pandas, pyTorch. Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools like matplotlib, Tableau
Proficiency in using query languages such as SQL
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality",4.2,"Daimler
4.2",Bengaluru,"Stuttgart, Germany",10000+ employees,1886,Company - Public,Transportation Equipment Manufacturing,Manufacturing,₹500+ billion (INR),"Audi, Porsche, BMW"
Machine Learning Engineer – CV (Research),-1,"Palpx is looking for an expert in machine learning to join our tech team. You will be involved in implementing machine learning systems for computer vision systems as per the requirements given. Write scripts to carry out experiments, data cleaning, and data collection. Deploy and create services in the cloud.

Roles and Responsibilities:
Quickly write scripts for performing machine learning experiments.
Work with large video and image datasets. Write scripts to curate, generate, format, clean the data set.
Create workflows and tools to label and annotate data.
Implement deployable training and inference systems.
Containerize the application and deploy it in a horizontally scalable manner.
Monitor and perform maintenance if required.
Create documentation for the system.
Create a unit test plan. Perform unit testing.
Maintain Code Base.

Requirements:
Masters in Computer Science from reputed educational institutions.
2 to 5 years working knowledge in computer vision-based production implementations.
Specialized knowledge and experience with scalable machine learning systems, algorithms, and data structure.
Proficiency in Computer Vision related machine learning and deep learning algorithms.
Expertise in Python, R, Matlab, OpenCV, Tensorflow, Theano, Caffe, PyTorch, Keras, AWS/Azure or GCP, Docker, Kubernetes, and Git.

Location

Bangalore

Department

Research & Development

Employment Type

Full time",5.0,"Palpx
5.0",Bengaluru,"Kochi, India",1 to 50 employees,2017,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Lead Data Scientist,-1,"How will you create an impact within Flutura?

You will play a strategic role in helping us to continuously improve our products and business decisions with your strong problem-solving ability and knack for statistical analysis.

You will be challenged to

· Implement methodologies to standardize end to end data science project life cycle

· Implement state of the art data mining algorithms in production environment

· Building an End to End Data Science Framework designed to handle large volume data sets

· Lead Data Exploration and Statistical Inferences on datasets, Storytelling to communicate insights and findings in a simplified way

· Effective multitasking and delivery on time with quality

· Provide timely communications on significant issues or developments

· Evangelize new product features

· Manage a team of data scientists, machine learning engineers and big data specialists

· Work with cross functional teams for assessing data science use cases and product market fitment

The core competency you should possess

Technical/Functional Skills:

· Minimum 8 years of total experience with recent & relevant experience of at least 4 years as a data scientist

· Should have managed a team directly atleast for 2 years

· Solid understanding of Statistics, Machine Learning, Deep Learning and Artificial Intelligence Technologies

· Hands On experience in Python, R, Pyspark and equivalent programming languages

· Expertise in building, productionizing and scaling analytics solutions for big data problems

· Experience in building and scaling models for time series (such as sensors etc.) data is a priority

· Experience with SQL and NoSQL databases

· Familiarity with agile execution of data science projects

Desired Characteristics:
Strong oral and written communication skills
Strong interpersonal and leadership skills
Ability to influence others and lead small teams
Lead initiatives of moderate scope and impact
Ability to coordinate several projects simultaneously
Effective problem identification and solution skills
Proven analytical and organizational ability
Education:
Qualification: BE/B.Tech, ME/M.Tech, MS, MCA (with an aggregate of 75% and above)
Stream (Preferable): Computer Science, Data Science, Mathematics or similar field
Job Type: Full-time

Salary: ₹1,800,000.00 to ₹2,200,000.00 /year

Experience:
Tead Lead: 2 years (Required)
Work Remotely:
Temporarily due to COVID-19",3.7,"Flutura Decision Sciences & Analytics
3.7",Bengaluru,"Bengaluru, India",51 to 200 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),"Mu Sigma, Analytics Quotient, PTC"
Data Scientist / Engineer,-1,"Division : Machine Learning /AI
Education :MSc(IT/Maths) /BCA /MCA /BE(IT)
Relevant Exp : 2 years
At : Ahmedabad

ML Engineer with atleast 2 year experience in design and development of machine learning algorithms and active involvement in deep learning systems. To do this job successfully, you need exceptional skills in statistics, mathematics and programming. Your ultimate goal will be to shape and build efficient self-learning applications.

key Skills & Attributes
Python
PyTorch
Numpy
SciPy
Matplotlib
Pandas
MySql
Statastics
Lineer Algebra",-1,FrankPro Consulting [OPC],Ahmedabad,"Ahmedabad, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst/Scientist,-1,"We are looking for a Data Analyst/Scientist to analyze large amounts of raw information to find patterns/outliers that will help improve our company. We will rely on you to build data products to extract valuable business insights. In this role, you should be highly analytical with a knack for analysis, math, and statistics. Critical thinking and problem-solving skills are essential for interpreting data. We also want to see a passion for machine-learning and research. Your goal will be to help our company analyze trends to make better decisions.

Responsibilities

Identify valuable data sources and automate collection processes
Undertake preprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns
Build predictive models and machine-learning algorithms
Combine models through ensemble modeling
Present information using data visualization techniques
Propose solutions and strategies to business challenges
Collaborate with engineering and product development teams

Requirements

5+ years of experience
Proven experience as a Data Scientist or Data Analyst
Experience in data mining
Understanding of machine-learning and operations research
Working knowledge of Machine Learning algorithms ( GLM, GBM, XGBoost)
Knowledge of deep learning models and frameworks
Knowledge of SQL and Python; familiarity with Scala, Java or C++ is an asset
Experience using business intelligence tools (e.g. Tableau, Data Studio) and data frameworks (e.g. Hadoop, Spark)
Familiarity with Python libraries (Pandas, Celery, MultiProcessing)
Familiarity with machine learning frameworks (like H2O, scikit-learn)
Analytical mind and business acumen
Strong math skills (e.g. statistics, algebra)
Problem-solving aptitude
Excellent communication and presentation skills
BSc/BA in Computer Science, Engineering or relevant field; graduate degree in Data Science or other quantitative field is preferred",-1,hudsondata.com,Gurgaon,-1,-1,-1,-1,-1,-1,-1,-1
Data Analyst/Scientist,-1,"Founded in 1987 and listed on NASDAQ, our client is headquartered in the USA and has an annual turnover of over USD 2+ Billion. They are a leading provider of technology solutions for small, medium, enterprises throughout the North America, Europe and Asia. Their comprehensive expertise and proven experience in advanced technologies and consulting & implementation services makes them the preferred partner for many global MNC customers

As a Data Analyst/ Scientist you will be responsible for reviewing, analysing and for gaining insights from the data stored in the BI data cubes as well as position BI for future uses such as machine learning and predictive analytics of sales behaviors.

Ket Responsibilities and Qualifications/Skills
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Excellent understanding of machine learning techniques and algorithms, etc.
Experience with common data science toolkits
Great communication skills
Experience with data visualization tools such as Power BI
Experience with MS SQL databases and Analytics / OLAP Cube Development (Microsoft SSAS and MDX)
Proficiency in using query languages such as SQL
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality
Location: Gurgaon, India

Employment Term: Dedicated & Full Time",5.0,"itForte
5.0",Gurgaon,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Chief Data Scientist - ML/AI,-1,"Icertis, the leading enterprise contract management platform in the cloud, solves the hardest contract management problems on the easiest to use platform. With Icertis, companies accelerate their business by increasing contract velocity, protect against risk by ensuring regulatory and policy compliance, and optimize their commercial relationships by maximizing revenue and reducing costs. The AI-infused Icertis Contract Management (ICM) platform is used by companies like Airbus, Cognizant, Daimler, Microsoft and Sanofi to manage 6.5 million contracts in 40+ languages across 90+ countries.

Contracts have always been the foundation of commerce - determining, influencing and guarding the balance between risk and reward. This is the first time in history that almost all contracts have been digitized and the risks and rewards expressed in legal language can now potentially be enshrined in computer readable logic. This role at Icertis is to bring thought leadership to computational law and its journey towards autonomous contracts. With insights into the contracting processes of some of the largest organizations in the world, this role will be responsible for evolving new tenets of contracting and reinforcing existing ones. The Chief Data Scientist will study current trends and data, evolve new methodologies and platform features to set the direction of Icertis enterprise contract management intelligence. The role reports to the CTO.
Role Requirements
You have demonstrated skills to go deep into a domain and transform business processes in that domain by applying the right AI techniques. You are a respected and recognized leader in the field, and have deep knowledge of machine learning and NLP techniques. You bring teams together, break new ground and provide thought leadership in areas that have the potential to make deep impact to how we live and work. Research or application background in computational law or related domains is a big plus. You bring the right values and team work to build a world class analytics team
Responsibilities
Deeply understand the mechanics of the enterprise contract management lifecycle
Help define and own the direction of the Icertis platform for applying AI to contracting processes
Establish Icertis’ s thought leadership in this area
Build a strong team of data scientists and engineers to help realize the Icertis vision of transforming the foundation of commerce through AI/ML
Provide pragmatic solutions to tough contracting problems using AI working with a team of data scientists and engineers
Qualifications
Holds a PhD degree in a quantitative discipline: computer science, applied mathematics, statistics, engineering or equivalent
5+ years of industry experience
5+ years of hands-on data science and NLP experience
Knowledge of machine learning techniques (regression, classification, clustering, dimension reduction, etc.) and their real-world advantages/drawbacks
Deep knowledge of Machine Learning, NLP related mathematical domains such as statistics (distributions, tests), calculus, linear algebra, probability, etc.
Icertis is not open to 3rd party solicitation or resumes for our posted FTE positions. Resumes received from 3rd party agencies that are unsolicited will be considered complimentary.

Icertis, Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.",4.2,"Icertis
4.2",Pune,"Bellevue, WA",1001 to 5000 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Selectica, SAP Ariba"
Technical Team Member Distributed Data Science & Machine Learning,-1,"Position: Technical Team Member – Distributed Data Science & Machine Learning (Full Time)
Location: Kolkata, India
Status: Open

Overview
Agnik, is a global connected car technology company (www.agnik.com) operating in 38 countries headquartered in USA with major consumer brands like Vyncs (https://www.vyncs.com) and several B2B products. Agnik is looking for several full-time members of its Technical Team for Distributed Data Science and Machine Learning in its New Town, Kolkata office. If you want to join a top notch technical team that develops novel algorithms/systems and very well familiar with statistics, machine learning, image analysis, and distributed systems then send a copy of your complete resume to jobs@agnik.com with a subject line “Technical Team Member - Distributed Data Science & Machine Learning”.

Responsibilities
As an employee of Agnik’s Distributed Data Science & Machine Learning Technical team Member, the primary focus of this position would be to design, develop, and implement novel data analysis and machine learning algorithms for connected car and mobility applications. Successful candidates must be knowledgeable and passionate about latest developments in field of machine learning and data science, should be a hands on developer. The position does not require extensive travel.

Duties Include
Develop real-time and off-line data analysis and machine learning algorithms/systems for embedded systems, mobile platforms, and cloud-based distributed environments.
Dealing with big data management problems in real-time applications.
Writing and reviewing code using Java/C#/C language for embedded and in-cloud environments for predictive modeling, control, and scene analysis.
Developing geo-spatial data management and analysis software.

Required Qualifications

B.Tech/BS/M.Tech/MS/PhD. from a reputed University in Computer Science, Electrical/Electronic engineering (or other engineering/Science) with relevant experience.
1 – 5 years of experience in building data analysis, signal processing, and machine learning applications using Java/C/Python language, web-services in dot net environment, relational/non-relational databases, and developing distributed systems.
Ability to communicate in fluent English. Effective communications skills and strong interpersonal skills, both orally and in written form.
Distributed data management environments such as Hadoop and Spark.
Ability to juggle multiple projects simultaneously.
Attention to details, ability to prioritize and meet aggressive deadlines.

Salary

Commensurate with qualifications. Benefits, possible overseas trip.

Location

New Town, Kolkata",4.8,"Agnik
4.8",Kolkata,"Columbia, MD",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,₹10 to ₹50 million (INR),-1
Data Scientist : Manager,-1,"7-12 years overall experience with minimum 4-6 years in Analytics delivery experience with hands on quantitative research + statistics +Presentation
Passionate about solving business problems, providing business Insights, and statistics, well versed with multivariate/ forecasting/ and who is capable of proactively suggesting clients and helping analysts to apply them to solve biz. problems
Need to have data mining skills (including data auditing, aggregation, validation and reconciliation), advanced modelling techniques, testing and creating and explaining results in clear and concise reports.
Advance statistical tools (Regression, Forecasting etc.), Machine Learning, Analytical tools (Clustering, Basket analysis, Decision trees, Random forest etc.)
Apply advanced statistical and predictive modeling techniques to build, maintain, and improve decision systems.
Broad understanding and experience with real-time analytics and business intelligence platforms such as Tableau/Power BI etc.
Should be able to work with SQL databases and several programming languages and statistical software packages such as Python, R, Java, MatLab or SPSS
A degree in a relevant subject is highly desirable e.g mathematics, data analysis, natural science, process analysis etc
Certifications in advance analytics skills is good to have
Experience on HR & Operations analytics preferred.
Should be ready to work in a dynamic and changing environment with changing requirements from time to time.
Strong communication skills, both verbal and written",3.8,"Mindtree
3.8",Bengaluru,"Bengaluru, India",10000+ employees,1999,Company - Public,IT Services,Information Technology,₹50 to ₹100 billion (INR),"Infosys, Tata Consultancy Services, Wipro"
Associate Architect - Data Science,-1,"Icertis, the leading enterprise contract management platform in the cloud, solves the hardest contract management problems on the easiest to use platform. With Icertis, companies accelerate their business by increasing contract velocity, protect against risk by ensuring regulatory and policy compliance, and optimize their commercial relationships by maximizing revenue and reducing costs. The AI-infused Icertis Contract Management (ICM) platform is used by companies like Airbus, Cognizant, Daimler, Microsoft and Sanofi to manage 6.5 million contracts in 40+ languages across 90+ countries.

Responsibilities:
· Partner with Business Stakeholders to translate business objectives into clearly defined analytical Projects
· Own the end-end process, from recognizing the problem to implementing the solution.
· Identify opportunities for text analytics and NLP to enhance core product platform, select best ML technique to the specific business problem and then build model to solve the problem
· Define the variables and their inter-relationships and extract the data from our data repositories, leveraging infrastructure including Cloud computing solutions and relational database environments.
· Build predictive models that are accurate and robust and that help our customers to utilize the core platform to the maximum extent.
· Guide and mentor team members on the technical activities of the project

Skills and Qualifications:
· 8+ years of experience.
· An advanced degree in predictive analytics, machine learning, artificial intelligence; or a degree in programming and significant experience with text analytics/NLP. He shall have a strong background in machine learning (unsupervised and supervised techniques). In particular, excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, logistic regression, MLPs, RNNs, etc.
· Experience with text mining, parsing, and classification using state-of-the-art techniques.
· Experience with information retrieval, Natural Language Processing, Natural Language Understanding and Neural Language Modeling.
· Ability to evaluate quality of ML models and to define the right performance metrics for models in accordance with the requirements of the core platform.
· Experience in the Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK, Gensim, etc.
· Excellent verbal and written communication skills, particularly possessing the ability to share technical results and recommendations to both technical and non-technical audiences.
· Ability to perform high-level work both independently and collaboratively as a project member or leader on multiple projects.
· Ability to own solutions for design and architecture and negotiate requirements with global customers
· Experience with Enterprise Software Design is a plus
Icertis is not open to 3rd party solicitation or resumes for our posted FTE positions. Resumes received from 3rd party agencies that are unsolicited will be considered complimentary.

Icertis, Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.",4.2,"Icertis
4.2",Pune,"Bellevue, WA",1001 to 5000 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Selectica, SAP Ariba"
Data Scientist - Bangalore,-1,"Data Scientist

We are looking for a Data Scientist to help us create machine learning products. Data Scientist responsibilities include understanding the business problem and experimenting with different modelling architectures to create the best possible setup from model performance as well as computational performance. To do this job successfully, you need exceptional skills in Machine Learning and Programming. Your ultimate goal will be to find the best data-based solution for the problem at hand

Job Description:
Understanding business objectives and developing models that help to achieve them, along with metrics to track their progress
Develop and maintain robust data processing pipelines and reproducible modelling pipelines
Build mathematical models to solve various problems ranging from Time Series forecasting to Neural Networks and ensure seamless deployment in production pipelines.
Explore data and communicate insights clearly to non-technical as well as technical audience
Analyze experimental results, iterate and refine models to create significant business impact
Follow strict coding standards and other software engineering best practices and be the proponent of the culture in the organization.

Requirements

Bachelor’s Degree in a Quantitative discipline
4-6 years’ experience in data science/Analytics roles
Expert Proficiency in Time Series Forecasting – Classical & Machine Learning
Proven experience as a Data Scientist or similar role
Expert ability to write robust code in Python
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn , StatsModels )
Should be proficient in evaluation metrics (MAPE, F1, RMSE, Confusion Matrix)
Should possess strong problem-solving skills
Excellent verbal and written communication skills
You take complete ownership of your work and are self-driven.

Good to Have

Deep Learning Frameworks like Tensorflow, PyTorch etc.
Familiarity in working with Azure, AWS, GCP etc.
Experience with NoSQL databases, such as MongoDB, Cassandra
Experience with containerizing applications using Docker",4.7,"Thoucentric
4.7",Bengaluru,"Bengaluru, India",51 to 200 employees,2015,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Data Analyst,-1,"Our Team

PharmEasy was founded in 2015 with the sole purpose to make healthcare easily available, accessible and affordable to all through the extensive use of new-age cutting-edge technology. Today, we are one of India's largest healthcare aggregators connecting lakhs of patients to licensed pharmacies & diagnostic centres online for all their medical needs. We are particularly catering to the chronic-care segment, and offer a range of services including medicine delivery, tele-consultation, sample collection for diagnostic tests as well as subscription-based services for all these categories.

Our highly efficient and technology led Consumer and Supply-chain platforms ensure that medicines are delivered from a licensed pharmacy within six hours of the validation of prescriptions submitted by our customers. And such customer promises are improving with the increasing scale of our business, and continuous product innovation.

By extensively leveraging the latest in hardware and software technology, we are also committed to eradicate fake medicines from the Pharma ecosystem that contribute to roughly 30% of drug volumes in India. Our product innovations have allowed for complete data transparency in the entire Pharma supply-chain to empower even the end-users to validate the authenticity and genuineness of the medicines for every medicine sold, using constructs such as unique barcoding of information like expiry dates, origination of drugs etc.

With our scalable technology and processes, we are now reliably delivering healthcare services and medicines to every single pin code in the country.

Analytics @ Pharmeasy:
Pharmeasy wants to enable data driven decision-making for achieving the core business objective of the company to make healthcare accessible & affordable to everyone. This would essentially require rigorous efforts being put into all domains of analytics from data collection to data extraction to data cleaning to data wrangling to descriptive analytics and eventually drawing business insights and communicate the same to the relevant business teams. We want to make analytics an integral part of every decision making at Pharmeasy because in today’s world subjectivity is something that is limited to academia and data can answer most of the questions.

Responsibilities :
A Data Analyst would be responsible for supporting the Business Teams for any kind of Data Reporting and Adhoc Data Analysis. The role would include extraction, cleaning, reporting, analysis and visualization of data.

Creating Dashboards/Reports and communicating the same to business team

Identification, Reporting & Tracking of Key Business Metrics at hourly, daily, weekly, monthly frequency

Coordination with Business Teams to identify new reporting requests and enhancing the existing one, business users to be communicated and explained the details if need arises

Testing all new reports/deliverables and periodically reviewing them for maintaining data quality

Data validation and attention to detail is required as the individual will be accountable for quality of all the numbers delivered through dashboards or otherwise

What are we looking for ?

1 to 3 years of work experience in the relevant field, preferably in a consumer facing company

Well versed in MS Excel (vlookup, hlookup, if-else, index, match, countif, sumifs, string operations, Pivot Table & Pivot Table Chart etc.)

Proficient in writing SQL queries and the candidate should be able to handle complex queries

Structured thought process and problem solving skills are a must have

Prioritization of tasks, organised work ethics, high work efficiency are expected

VBA, Macros are an advantage and good-to-have",3.8,"PharmEasy
3.8",Bengaluru,"Mumbai, India",1001 to 5000 employees,2015,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Analyst / Data Scientist | Internship | Tech-Savvy|,-1,"Job role:
As a data analyst, you will be responsible for compiling actionable insights from data and assisting program, sales and marketing managers build data-driven processes. Your role will involve driving initiatives to optimize for operational excellence and revenue.

Job Location: Indore | Full-Time Internship | Stipend - Performance Based |

About the company:
Anaxee Digital Runners is building India's largest last-mile verification & data collection network of Digital Runners (shared feet-on-street, tech-enabled) to help Businesses & Consumers reach remotest parts of India, on-demand. KYC | Field Verification | Data Collection | eSign | Tier-2, 3 & 4

Sounds like a moonshot? It is. We want to make REACH across India (remotest places), as easy as ordering pizza, on-demand. Already serving 11000 pin codes (57% of India) | Website: www.anaxee.com

Important: Check out our company pitch (6 min video) to understand this goal - https://www.youtube.com/watch?v=7QnyJsKedz8

Responsibilities:
Ensure that data flows smoothly from source to destination so that it can be processed
Utilize strong database skills to work with large, complex data sets to extract insights
Filter and cleanse unstructured (or ambiguous) data into usable data sets that can be analyzed to extract insights and improve business processes
Identify new internal and external data sources to support analytics initiatives and work with appropriate partners to absorb the data into new or existing data infrastructure
Build tools for automating repetitive tasks so that bandwidth can be freed for analytics
Collaborate with program managers and business analysts to help them come up with actionable, high-impact insights across product lines and functions
Work closely with top management to prioritize information and analytic needs

Requirements:
Bachelors or Masters (Pursuing or Graduated) in a quantitative field (such as Engineering, Statistics, Math, Economics, or Computer Science with Modeling/Data Science), preferably with work experience of over [X] years.
Ability to program in any high-level language is required. Familiarity with R and statistical packages are preferred.
Proven problem solving and debugging skills.
Familiar with database technologies and tools (SQL/R/SAS/JMP etc.), data warehousing, transformation, and processing. Work experience with real data for customer insights, business, and market analysis will be advantageous.
Experience with text analytics, data mining and social media analytics.
Statistical knowledge in standard techniques: Logistic Regression, Classification models, Cluster Analysis, Neural Networks, Random Forests, Ensembles, etc.",4.0,"Anaxee Digital Runners Pvt Ltd
4.0",Indore,"Indore, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Principal Data Scientist & Software Development Manager,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.4,"Nanobi Data & Analytics
3.4",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Tvarit opens up a new Artificial Intelligence division with the vision to help
manufacturing companies
transform their businesses by leveraging AI. We strive to achieve efficient processes
management for
factories and plants, increasing the yield, increasing the accuracy and reliability by
bringing
data-driven decisions, shorten the time frame of delivery, and hence direct reflection
in terms of
profit to the enterprise. This is a chance for you to get in on the ground floor of an
exciting AI
company.

You will be responsible for building AI / Machine Learning applications for our
manufacturing clients.
We expect you have strong programming skills, and background of statistical engineering,
data mining.
You should have a strong growth mindset and a strong work ethic.

Key responsibilities:
Work with manufacturing clients, understanding various problems and failures in
different kinds of
high tech machines
Working with manufacturing machines data formats, data collection via API (REST for
e.g.), data
cleaning and defining performance measures based on pre-processing of data
Define set of features on the basis of hundreds of sensors signals coming from the
single machine,
work on building time series forecasting and other cross metric ML models
Develop evaluation techniques to gauge the performance and accuracy of the models
you build
Write production ready code in Python / R for above models, further write unit
tests, integration
tests, end to end tests

Your background:


Know how of machine learning algorithms e.g., ARIMA, Linear Regression, Neural
Networks and relevant
maths such as linear algebra, probability, statistics
Strong hands­-on skills with time series databases InfluxDB, SQL, Postgres etc
Proven ability to deliver complex metrics solutions and applications from end to end
and required
CI/CD tooling like Github, Docker, Travis, Jenkins
Ability to write code in a scripting language (Python, Perl, Bash etc)
Strong coding ability. While theoretical knowledge of algorithms is appreciated, it
is also
important that you're able to write clean, efficient code in Python (with a focus on
testability and
using OOP) on a Linux platform.

Our Team Culture:


We provide hands-­on statistical solutions for automotive and manufacturing industry
in Germany to
highlight trends and generate insights
We have closely worked with Deutsche Bahn, Linde, Liebherr creating AI for machines
health and work
closely with their backend databases and data engineering teams
We act as primary point of contact for business forecasting, delivering
metrics/analytics that drive
the organization and help senior management taking data driven business decisions
To apply, please send an email, including your resume as an attachment, to careers@tvarit.com

Location: Mumbai",4.0,"Tvarit
4.0",Mumbai,"Frankfurt am Main, Germany",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Specialist I - Data Science,-1,"Job Title
Specialist I - Data Science
Job Description


Job Title

Specialist I - Data Science

Job Description

Key areas of responsibilities
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase system reliability
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate who is a driven professional & has a strong background in the following:
Overall 7+ yrs exp with minimum 3+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Strong programming skills in Java, R and Python
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics.
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Good understanding and minimum 2+ years of hands on experience in developing models using Artificial Intelligence,
Machine Learning and/or Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.8,"Philips
3.8",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"IIITM-K invites the applications from suitable candidates for the following posts under Centre for Excellence in Artificial General Intelligence and Neuromorphic Systems Project. The appointment will be initially for a period of one year and will be extended based on the performance and project funding

Machine Learning Engineer

No. of post: 1 Post

Qualification: MSc Mathematics or M.Tech/MSc in CS/ECE/AI or Ph.D. in CSE/ECE/AI. Final year MSc/M.Tech students from IIITs or IITs, who are awaiting results are also eligible to apply. Must be familiar with Tensorflow and Keras libraries. Hands-on experience in machine learning/deep learning projects will be given preference. Freshers and those about to graduate by June 2020
can apply. Maximum work experience of not more than five years.

Remuneration: Rs. 25000 to Rs 30000 per month, depending on the experience and qualification (consolidated).

Experience:0-1 Year

Location:Thiruvananthapuram

Education:MSc Mathematics or M.Tech/MSc

Company:Indian Institute Of Information Technology & Management

SALARY:Rs. 25000 to Rs 30000 per month

Last Date: Last Date to Apply is Over. : 2020-Mar-16

Key Skills: Good Communication skills

Company details

Indian Institute Of Information Technology & Management

INDIAN INSTITUTE OF INFORMATION TECHNOLOGY & MANAGEMENT - KERALA IIITM-K, TECHNOPARK, THIRUVANANTHAPURAM 695581 KERALA, INDIA (An Autonomous Institution under Govt. of Kerala)",4.2,"Indian Institute Of Information Technology & Management
4.2",Thiruvananthapuram,"Gwalior, India",1 to 50 employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",-1,Accrete.AI,Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst – Junior and Senior (Hiring Now),-1,"Career Positions:
Responsible for Market Research, Database reporting & e-mail Campaigns.
Build and Develop a plan to research Company’s portfolio.
Creating the list of prospects.
Research on identifying business needs and opportunities of prospect companies.
Interpreting data accurately, database creation for various campaigns & client communication for lead generation and demand creation.
Researching the target audience and driving the lead generation campaigns.
Managing the Campaigns with periodical follow-ups & report creations.
Working closely with Sales Team to understand their research projects.
Comfortable using Excel, Word, and PowerPoint – Should be able to create presentations.
Prepare Market research reports using Web tools/domains such as Hoovers, Linkedin, Jigsaw, ZoomInfo, Lead411 etc.
Tracking the market trends thereby generating & analyzing reports.
Executing direct marketing campaigns like email campaigns, event-specific campaigns, webinars etc.
Competitor Analysis
Preparing MIS and sales report using CRM

Relevant Experience:
1 to 3 years

Education:
Any Graduate (B.E / B.Tech preferred)
Post Graduation – MBA (preferred).

Location:
Gurugram – (a two-minute walk from Sikandarpur Metro Station)",4.7,"KEY IDEAS INFOTECH
4.7",Gurgaon,"New Delhi, India",1 to 50 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"Postman is the only complete API development environment. Today we have 10 million developers and over 500K companies using our comprehensive set of built-in tools to support every stage of the API life cycle. With Postman you can design, mock, debug, test, document, monitor, and publish your APIs all in one place.

We are looking for a Senior Data Analyst in Data team to help us scale our analysis processes and deliver more value to the organisation.

About the team

Data team at Postman acts as a central hub for asking analysis questions. We are a small team of engineers and analysts who believe in impact driven work.

We believe in democratisation of data and work towards building data products so that decision making through data is as self-served as possible.

We are major supporters of knowledge distribution, be it factual or philosophical. We don’t shy away from getting our hands dirty whenever it comes to anything data.

Do come prepared because you will be in for one of the craziest ride of your lifetime.

Responsibilities:
Work closely with Data Engineering and partner teams to author and develop core data sets, within our Data Warehouse and BI tool, to empower operational and exploratory analyses
Work with partner teams to define goals and identify metrics for improving existing features and new releases
Build dashboards and reports to drive awareness and understanding of metrics and experiment results
Deep-dive into domain heavy problems and own the implementation of end-to-end solution
Help us in defining the information architecture of Postman eco-system
Help us in solving problems at scale such as Forecasting, Experimentation etc.
Requirements
You have 3+ years of experience as a Data Analyst or similar experience across college projects
The ability to clearly and effectively communicate the results of complex analyses
At least 1 BI tool experience such as Looker, Tableau, Power BI etc.
You have curiosity about how things work
Benefits

This position will be located in our beautiful office at 100 ft road, Indiranagar in Bangalore. You will enjoy our incredible perks: home-cooked meals, snacks, game room, flexible hours, ergonomic workstations and cuddles from our endearing Chief Happiness Officer, Cooper.

What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world.

Be a part of something big.",4.4,"Postman
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:
Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:
As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus

Requirements

Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.

Good to have

Previously worked in a SaaS company

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.2,"Whatfix
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning/Data Scientist,-1,"Key Responsibilities:
Apply deep advanced analytical skills to explore complex datasets for knowledge discovery and predictive modeling activities.
Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas.
Inspire and influence others for continous improvement in every aspect
Be hands on in development and execution of predictive analytics and machine learning.

Job Requirements :
Minimum two years of experience with Machine Learning technologies
Expert in building custom ML algorithms leveraging statistical concepts and ML tools
Apply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.
Understanding & working knowledge in Natural Language Processing & Conceptual modelling.
Proficiency in statistical analysis tools (R, Python and SAS).
Extensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).
Research and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)
Awareness/Experience with big data tools (Hadoop, HDFS & Spark).
Experience on AWS/Google machine learning services is a plus.
Experience with any of these is a plus: scikit-learn, Pandas, R, ggplot, D3, and Spark (open source preferred)",2.8,"Forgeahead
2.8",Pune,"Pune, India",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Web Analytics Manager,-1,"Location: Goregaon (W) – Mumbai

Shift timings: 10am to 7pm (weekend all yours)

Roles & Responsibilities:
Analyze website data, conduct tests for opportunities in improvement of conversion and analyze test results.
Develop various measurement tools and analyze business requirements and implement appropriate plans.
Analyze functionality of all current and future websites and develop new objective for the same.
Identify risks and gaps in all channels of traffic on the website and analyze various risks and provide optimal solutions for the same.
Monitor all investigation on sites and resolve the tracking-issues as and when required in a Web-Analytics manner.
Maintain records of web usage and traffic to site and prepare reports in user usability trends.
Perform usability tests and evaluate customer experience for projects and ensure accuracy for the same.
Manage various web analytical tools and prepare reports for metrics evaluation.
Perform analysis on volume and navigation behavior to gather appropriate information on web site user.
Monitor and incorporate data in visitor behavior and ensure optimization of business processes.
Ensure appropriate implementation of software application to aid various businesses-goals.
Assist other departments to develop test scripts and perform troubleshoot on various issue in websites.
Analyze data captured on other software and tools to understand customer journey and various touchpoints and devise a plan to improve up-selling and conversion.
Expertise:
Expertise in Tag-Management tools like GTM, Tealium, Ensighten, DTM etc.
Strong understanding of data layer creation of any web-asset (Website/Web-App)
Expert in Google Analytics - Custom dimension & metric creation, attribution-modelling, cohort-analysis and goal-funneling.
Experience in A/B & Multivariant testing tools like Unbounce, Optimizely, Zoho, CrazyEgg, Google-Analytics, Clicktale etc... and well versed right implementation & metrics to be measured for the same.
Education:
Bachelor’s degree in Engineering from a reputed institute with good grades.
Google Analytics Certification.
MBA in Marketing (Preferred).",3.2,"Crimson Interactive
3.2",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Finance Data Engineer - Finance Platforms & Data,-1,"Our Data, Platform, Infrastructure and Risk engineers work with multiple Finance businesses to drive consistency, efficiency and reuse across Finance & Risk Engineering solutions via the delivery of common services, tools, frameworks, and practices.
With increasing complexity and volumes in Finance, we continuously need to scale our data. Cutting across all areas of Finance, our Data Engineering team is designing our common datastores in the Data Lake. We are a dynamic team of talented junior and senior developers, technical architects, and functional analysts who work in concert to deliver high profile projects using OO technologies.

HOW YOU WILL FULFILL YOUR POTENTIAL
• Work in a dynamic, fast-paced environment that provides exposure to all areas of Finance
• Build strong relationships with business partners
• Understand business needs, facilitating and developing process workflow, data requirements, and specifications required to support implementation
• Develop technical specifications, high level/detailed design, testing strategies, and implementation plans from business requirements
• Manage end-to-end systems development cycle from requirements analysis, coding, testing, UAT and maintenance

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelors degree in Computer Science, Mathematics, Electrical Engineering or related technical discipline
• Experience in software development, including a clear understanding of data structures, algorithms, software design and core programming concepts
• Comfortable multi-tasking, managing multiple stakeholders and working as part of a team
• Excellent communication skills including experience speaking to technical and business audiences and working globally
• Expertise in Java development & Relational Databases
• Can apply an entrepreneurial approach and passion to problem solving and product development
• Strong problem solving and analytical skills

Preferred Qualifications
• Strong programming experience in at least one compiled language (e.g. C, C++, Java)
• In-depth knowledge of relational and columnar SQL databases, including database design
• Experience with continuous delivery and deployment
• Proficient at working with large and complex code bases
• Comfortable working in highly dynamic and rapid development environment (Agile development experience)
• Technologies: Web/RESTful service development: HTML 5, JavaScript/AngularJS, JSON
• Technologies: Linux and shell scripting, TDD (JUnit), build tools (Maven/Gradle/Ant), Scala, Spark, Tableau

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",3.9,"Goldman Sachs
3.9",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Scientist II,-1,":

Job Overview
General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills.

:

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Education

Minimum Degree Requirements: Bachelors
Preferred Major Area of Study Computer Information / Computer Science
Min Preferred Professional Certifications Data Science / Mathematics / Statistics

Experience

Minimum years of related experience required: 3 years
Preferred years of experience: 5 years

Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc

Exploratory Data Analysis Yes Yes

Machine Learning Algorithms Yes Yes
Any one algo Yes Should have in-depth knowledge and implementation of atleast one algorithm

Deep Learning No No Knowledge would be a plus

Visualization
Tableau, Spotfire, BI No Yes Knowledge would be a plus

Soft Skills
Story telling
Ability to understand business use case and convert into data science parlance
Ability to explain model output to business and why should they trust in the model",-1,"General Mills Services, Inc.",Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"ML Practice forms the core of our platform. If solving a problem of unstructured data and building trainable trends is what your forte is, lets talk. The scope of the structure data will be overplayed on subject of Talent Attraction and Engagement.",4.0,"Uncap Research Labs
4.0",Gurgaon,"Gurgaon, India",1 to 50 employees,2018,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),-1,"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Engineer,-1,"About Us:

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.

Morgan Stanley is seeking an experienced and ambitious candidate to join their global Level3 operations team who are responsible of providing best in class operational support follow the sun model to Postgres Database as a Service Infrastructure. The applications onboarding Postgres DBaaS are across trading, wealth management, primary brokerage, Morgan Stanely java, network service, change management, Tech info risk etc. Our India DBA teams are based in Mumbai and Bengaluru.

Job Responsibilities:

• As part of our L3 team, you will represent the Postgres DBaaS in all dialogue and decisions around the architecture, deployment, and/or management of database environments.
• Candidate will contribute in the definition of operational best practices and automation of operational tasks related to the existing Postgres DBaaS plant, as well as provide training, guideline and establish procedures for L1 and L2 teams globally.
• Performance tuning and troubleshooting user issues with deep dive-in issues
• Candidates must be well organized, have strong communication and interpersonal skills,should be confident working independently.
• Ability to diagnose problems and triage / resolve issues across various tiers (application, network, database, server, or storage tiers)
• Ability to implement automation to reduce manual administrative tasks through use of jobs, scripts, Ansible playbooks.
• Ability to proactively identify, troubleshoot and resolve live database systems issues.
• Knowledge of disaster recovery principles and practices, including planning, testing, backup/restore
• Hands-on experience on database administration, backup recovery and troubleshooting in co-location environments.
• Ability to thrive in a fast-paced, deadline-sensitive environment.
• Responsible for configuring, integrating, and maintaining all Development, QA, Staging and Production PostgreSQL databases within the organization.
• Responsible for all backup, recovery, and upgrading of all of the PostgreSQL databases.
• Monitoring databases to optimize database performance and diagnosing any issues.
• Develop, implement, maintain policies and procedures and document database architecture to ensure the security and integrity of the databases.
• Implement data models, database designs, data access, table maintenance and code changes together with our development team.
• Experience in code migration, database change management through various stages of development life cycle.
• Work with development and operations teams to tune production queries for optimal performance.
• Implement and monitor replication for high availability and disaster recovery scenarios.
• Review new database schema changes.
• Monitor and manage database indexes for optimal performance.
• Automate the configuration management of database and Big Data systems.
• Performing schema management, database sizing, maintaining privileges.
• Installing and monitoring PostgreSQL database using the standard DB- monitoring tools .
• Maintaining and implementing custom vacuum strategies at table and db level for efficient DB-performance.
• Monitoring the DB growth for every month in DWH databases, prior exposure related to capacity planning on large DW plant.
• Monitoring the bloat report on every table and performing maintenance with minimal downtime.
• Performing minor and major level upgrades using minimal downtime by prior testing in sand-boxes with accurate time notifications.
• Plans and coordinates the administration of PostgreSQL databases to ensure accurate, appropriate, and effective use of data, including database definition, structure, documentation and follow existing operational guidelines.
• Reviews database design and integration of systems, and makes recommendations regarding enhancements and/or improvements.
• Establish and maintain security and integrity controls.
• Provides appropriate consulting, interfacing, and standards relating to database management, and monitors transaction activity and utilization.
• Prepares and/or reviews activity, progress, and performance reports.
• Plans and configures the physical database environment. Evaluates and recommendation about metadata management, security tools ,DB-archival and recovery strategy guidelines.
• Develops project plans for implementing database environments. Provides input to technical projects and oversees the tactical aspects of all database related tasks.
• Diagnoses, resolves and implements preventive measures to prevent problems for availability, recoverability and performance of all supported database environments.
• Recommends and oversees implementation of database level configuration changes to optimize performance. Ensures maintenance of physical integrity of all production databases.
• Install, configure, test, monitor, upgrade, and tune new and existing PostgreSQL databases.
• Tuning autovacuum parameters to ensure up to date table stats and reclaim space consumed by dead tuples.
• Contributed to decreasing need for downtime by developing and automating procedures for automated monitoring and proactive intervention.
• Hands-On exposure managing standby replication methodologies like Streaming/Synchronous replication and hot standby for disaster recovery.
• Hands on exposure Installing and configuring HADR/Replication Clusters for High Availability .
• Proactive in updating the latest security patches to database, which are provided by PostgreSQL open source community.
• Performs quality control audits to ensure accuracy, completeness, and proper usage of data in tables and various support tools, such as database dictionaries.
Exp-3-6 years
Primary Skills:

• Bachelor's in Engineering degree in computer science or related field.
• 3 years of experience as a Postgres DBA
• Strong experience with Postgres V9.4, V10 and V11
• Strong troubleshooting/performance tuning skills required. Must be able to improve SQL performance
• Proficient in Postgres RDBMS installation/configuration, patching, troubleshooting, performance tracking/tuning, back-up/recovery, remote monitoring skills with hands-on experience in large and very dynamic environments
• Experience in Perl/Python scripting in UNIX environment
• Strong communication skills and ability to work effectively across multiple business and technical teams.
• Experience in change control
Experience in Anisble, Python Programming will be a plus.",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Applied Data Scientist,-1,"dunnhumby is looking for
a talented Senior
Applied Data Scientist!

You will lead and execute projects to distil complex problems into compelling
insights, using the best of dunnhumby science and make recommendations that
resonate with clients and lead them to action.

What you'll be doing:
Build
strong relationships with internal contacts & external clients to ensure
full understanding of client challenges, growth strategy and agreed measures of
success for the project.
Investigate
and implement the most appropriate analytical technique for each project, role
modeling the re-use & further development of global solutions or code
written by others.
Deploy,
and mentor the team to deploy, data science algorithms and market products on
chosen tech stack for efficient and cost-effective delivery.
Lead
and execute projects that distil complex problems into compelling insights that
resonate with clients and lead them to action.
Spot
opportunities to grow client engagement by proactively solving client’s
strategic questions, using a mix of products and advanced data science
techniques that support executive decision making and call to action.
Participate
in client meetings as required to present methodology and solutions through
effective story telling techniques.
Work
closely with global products team to provide market feedback for enhancing an
existing product offering or augmenting the catalogue with a market-based
product that can become global offering.
Ensure
smooth running of your projects and support junior team members with their
projects.
Lead
by example by following dunnhumby Quality Assurance processes, ways of working
and coding standards.
Provide
advice and support to colleagues to resolve challenges and support code
reviews.
Who you’ll get to work with:

Within dunnhumby you’ll
work with
Applied and Research Data Scientist teams
Client / Commercial teams
Global Capability teams
Data Science Engineering teams
Externally, you’ll
frequently be in contact with:
Senior Retail/Customer Packaged Goods Analysts and Insights
contacts
What you'll need:
Bachelor’s degree or equivalent in
Mathematics, Economics, Applied Statistics, Computer Science, Physics,
Engineering or related field.
Experience focussing on
the practical & pragmatic use of data and a passion for connecting your
work directly to the customer experience, making a real and tangible impact.
Experience with handling
large data volumes with modern data processing tools, e.g. by using Hadoop /
Spark / SQL / Python.
Analytical Techniques
Analytical Technology
Desk Research
Prototyping
Quality Assurance and
Testing
Statistical Modelling
Programming (Python,
SQL, R, …)
Data Interpretation/
Insight Analysis
Data Visualisation
Insight Storytelling
Client relationship
building and management
Presentation skills
A plus if you also have:
Master’s degree or equivalent in in Computer Science, Artificial Intelligence,
Machine Learning, Applied Statistics, Physics, Engineering or related field.
Programming experience
on any standard data mining and modelling packages such as Python and R.
Experience of applying advanced statistical
models and machine learning algorithms to solve a variety of",3.7,"dunnhumby
3.7",Gurgaon,"Hammersmith, United Kingdom",1001 to 5000 employees,1989,Company - Private,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Machine Learning Engineer,-1,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.6,"Diamondpick
4.6",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst – PB APAC Products #149382,-1,"Support the Products management team to ensure the APAC
product business is organised and managed effectively, has a strategic plan and
maintains/develops positive relationships with business partners based on
sophisticated data analytics.
Work
directly with Asia senior management and their teams to conceptualize and
launch insightful dashboards/provide ad-hoc analysis on topics spanning
across Relationship Managers performance and productivity/ Clients/
Products/ Human Capital
Support
production of daily/weekly/monthly reports ensuring accuracy and
timeliness around different dimensions such as costs/clients/products/markets;
Highlight key wins/ areas of focus for the business supplemented by
commentaries substantiating the data, providing more transparency on the
financial gaps and driver
Drive
data/reporting aligned operational improvement through reengineering and
automation; constantly revisit book of work to find opportunities
Collaborate
with platform teams in Asia to support data collection, integration, and
retention requirements
Interpret
data and analyze results; Identify, analyze, and interpret trends or
patterns in complex data sets using standard statistical tools and
techniques
Communicate
concisely and meaningfully the analysis outcome to business associates,
finance functions in Onshore locations to facilitate fact based decision
making
Bachelor’s
degree in Mathematics, Computer Science, Information Management or
Statistics
Proficiency
of Private Banking business
3-5
years of relevant experience in data analytics, predictive analytics,
Strong analytical skills with the ability to collect, coordinate, analyze,
and disseminate significant amounts of information with attention to
detail and accuracy
Progressive
experience in data visualization tools such as Tableau, QlikView, Power BI
etc; and reporting packages such as Business Objects
Excellent
skills on MS Excel, Macro VBA, database query languages (SQL)
Outstanding
written and verbal communication and presentation skills and ability to
collaborate with Management
You
are ambitious, dedicated, hardworking and can work on own initiative
whilst also working collaboratively and deliver on time with a high level
of integrity, sense of urgency, attention to detail and quality standards",3.7,"Credit Suisse
3.7",Mumbai,"ZÜRICH, Switzerland",10000+ employees,1856,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"UBS, J.P. Morgan, Goldman Sachs"
Big Data Engineer,-1,"About the Draup:
DRAUP is a stealth-mode start-up, incubated at Zinnov, and working on Big Data and Machine Learning. We are building an Enterprise Sales Enablement platform, which will enable huge multi-corporations to be able to sell better. We are a 10-month-old team creating a new product led by very experienced Serial Entrepreneurs with more than 12 years of experience in the sales industry with a good track record of creating and selling off a very successful start-up.

The Big Data Engineer at Draup is responsible for building scalable techniques and processes for data storage, transformation and analysis. The role includes decision-making and implementation of the optimal, generic, and reusable data-platforms. You will work with a very proficient, smart and experienced team of developers, researchers and co-founders directly for all application use cases.

Experience:
B.E / B.Tech / M.E / M.Tech / M.S in Computer Science or software engineering.
Experience of 2-6 Years working with Big Data technologies.
Open to embrace the challenge of dealing with terabytes and petabytes of data on a daily basis. If you can think out of the box have good code discipline, then you fit right in.
Responsibilities:
Develop, maintain, test and evaluate big data solutions within the organisation.
Build scalable architectures for data storage, transformation and analysis.
Design and develop solutions which are scalable, generic and reusable.
Build and execute data warehousing, mining and modelling activities using agile development techniques.
Leading big data projects successfully from scratch to production.
Creating a platform on top of stored data sources using a distributed processing environment like Spark for the users to perform any kind of ad-hoc queries with complete abstraction from the internal data points.
Solve problems in robust and creative ways.
Collaborate and work with Machine learning and harvesting teams.
Skills:
Proficient understanding of distributed computing principles.
Must have good programming experience in Python.
Proficiency in Apache Spark (PySpark) is a must.
Experience with integration of data from multiple data sources.
Experience in technologies like SQL and NoSQL data stores such as Mongodb.
Good working Knowledge of MapReduce, HDFS, Amazon S3.
Knowledge of Scala would be preferable.
Should be able to think in a functional-programming style.
Should have hands-on experience in tuning software for maximum performance.
Ability to communicate complex technical concepts to both technical and non-technical audiences
Takes ownership of all technical aspects of software development for assigned projects.
Benefits:
Expertise in big data infrastructure, distributed systems, data modelling, query processing and relational.
Involved in the design of big data solutions with Spark/HDFS/MapReduce/Storm/Hive.
Worked with different types of file-storage formats like Parquet, ORC, Avro, Sequence files, etc.
Strong knowledge of data structures and algorithms.
Understands how to apply technologies to solve big data problems and to develop innovative big data solutions.
Someone with entrepreneurial mind-set delivering quick and efficient solutions with good design and architectural patterns will be preferred.",3.8,"Zinnov
3.8",Bengaluru,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),-1
Applied Scientist I,-1,"Basic Qualifications:
Very good English skills (including the ability to read and write technical papers in English)
Bachelors (BS/BE) in Computer Science or related field
Publications in top-tier NLP and or ML/DL conferences or journals
Skills with programming language like R, Python and/or Scala or similar scripting language
At least 5+ years of hands-on-experience in predictive modeling and analysis
At least 5+years of algorithmic development experience
At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the world’s largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·
Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
Perform analysis of data and metrics relevant to ad content generation and policing
Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs
Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
5+ years of extensive experience applying theoretical models in an applied environment.
Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
Strong fundamentals in problem solving, algorithm design and complexity analysis
Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
Experience with defining organizational research and development practices in an industry setting.
Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization
To apply for this job email your details to hr@claimgenius.com",-1,Claim Genius,Nagpur,"Iselin, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.4,"Postdot Technologies
4.4",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer (Python + ML/AI),-1,"Senior Data Model Engineer (Python + ML/AI)
With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.


Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What part will you play?
Implements innovative Products and Solution Development processes and tools by utilizing his/her expertise in the field of responsibility.
Use your skills to move the world forward
B.E in computer science with 4 – 7 years of experience on Data Science and Machine Learning
You Experience in research and development processes (Software based solutions and products) ; in commercial topics; in implementation of strategies, POC’s
You should have Experience in expert functions like Software Development / Architecture, Software Testing
Exposure to and working experience in the relevant Siemens sector domain (Industry, Energy, Healthcare, Infrastructure and Cities) required.
International experience with global projects and collaboration with intercultural team is preferred 4 - 7 years’ experience on developing software solutions with various Application programming languages.
You should have Strong experience in Data Engineering and Analytics
You should have Strong command of Python language + Data Science Ecosystem (Pandas, Scikit-learn, TensorFlow, NumPy etc.)
You should be Expert in Data Engineering and building data pipelines, implementing Algorithms in a distributed environment
You should have Very good experience with data science and machine learning
You should have Experience with developing and deploying web applications on the cloud with solid understanding of one or more of the following like Flask, DJango
Drive adoption of Cloud technology for data processing and warehousing
You should have Experience in working with multiple databases, especially with NoSQL world
You should have Strong understanding/expertise in building REST APIs/ Micro services architecture
You should have Experience or knowledge on Java would be added advantage
Understanding of Webserver, Load Balancer and deployment process / activities
Advanced level knowledge of software development life cycle.
Advanced level knowledge of software engineering process.
Excellent command over English in written, spoken communication and strong presentation skills.
Experience in Jira, Confluence will be an added advantage.
Experience with Agile/Lean development methods using Scrum
Experience in Rapid Programming techniques and TDD
Takes strong initiatives and highly result oriented
Good at communicating within the team as well as with all the stake holders
Strong customer focus and good learner.
Highly proactive and team player
Ready to travel for Onsite Job assignments (short to long term)
This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

Make your mark in our exciting world at Siemens.

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: Internet of Things

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Junior Data Analyst - Technology & Digital,-1,"QUALIFICATIONS
Bachelor's degree in engineering or computer science with excellent academic record required; advanced graduate degree (e.g., MCA, M.Tech etc.) is preferred
Minimum 1 year of professional work experience is required in a data management capacity
Experience in agile ways of working is a plus
Ability to work with cross-functional teams
Strong ETL background (SSIS/ODI/Informatica/DataStage/Snaplogic) required
Strong analytical and problem-solving skills and SQL proficiency
Good understanding of data warehousing concepts
Good experience of data integration with Salesforce
WHO YOU'LL WORK WITH

You will join our Gurugram office and will be a member of our Technology & Digital (T&D) team. Our broader team, the ClientLink data team, is responsible for managing the quality and integrity of the firm’s client contact database.

T&D works with agile methodologies and has its own development credo based on recognized best practices. Our team creates solutions so that colleagues are informed and engaged as the firm grows and changes rapidly. The solutions also ensure that colleagues are aligned with firm culture, values and strategy, are able to efficiently participate in firm governance, and be more productive and effective.

WHAT YOU'LL DO
You will shape the future of what data-driven organizations look like, drive processes for extracting and using that data in creative ways, and create new lines of thinking within an infinite number of clients and situations.
In this role, you will focus on importing and updating contact data, extracting lists, reporting on general data maintenance tasks. You will manipulate data and intelligently develop table structures and algorithms to comply with firms' rapidly-evolving databases. You will provide information to the relationship management product team on interesting trends, patterns, and spikes that could help shape product enhancements.
You will provide peer-level support and mentor junior colleagues on day-to-day operations. Lastly, you will contribute to operational efficiency, e.g., managing data quality/standards on the ClientLink database.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Scientist / Machine Learning Engineer,-1,"Synkrama Technologies is seeking an experienced Senior Data Scientist with an engineering aptitude to create and deliver data solutions to our organization. You will work closely with the Data Engineering team and the business to build and operationalize analytics and machine learning models. Your responsibility will be to help make our vision of embedding analytics throughout the business a reality.

Collaborate with Data Science & Data Engineering teams to develop data products and solutions
Work closely with the business to understand problems and translate into analytical solutions
Build and validate robust advanced machine learning/ ML models
Build end-to-end machine learning (ML) pipelines in production environments
Work with large, complex data sets coming from disparate sources
WHAT YOU’LL DO

Research, develop, prototype and productize machine learning products using various AI approaches (supervised and, and unsupervised learning, deep learning, recommender systems, computer vision, natural language processing, etc.)
Continue to invest and expand our core skill sets in the areas of artificial intelligence techniques, such as recommender systems, NLP, computer vision, deep learning etc.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to identify business opportunities and build ML solutions. Work closely with technology partners to test and implement solutions.
Your passion for machine learning, curiosity, problem solving, and innovation will empower you continuously learn something new, stay up-to-date with research and prototype new ideas quickly.

REQUIREMENTS
2+ years of experience developing ML/AI models and performing complex analyses.
Real world experience building and orchestrating ML pipelines
Expertise in Python/R and SQL
Experience operating in Cloud environment, e.g. GCP or AWS
Experience with algorithm tuning and scaling for deployment
Preferred experience with CI/CD , Docker & Kubernetes
Familiarity with machine learning frameworks and libraries, ideally with good proficiency in at least one (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.).
Mastery of the entire ML pipeline with strong proficiency in several techniques for each step of the ML product development.
Experience with working in an agile team environment
Experience with communicating and presentation highly quantitative concepts to a non-quant audience.
EDUCATION

Masters or PhD in a STEM Field with a focus in statistical analysis and machine learning.

Proficiency in English Language is must.

If interested then please send your resume and cover letter to hr@synkrama.com",-1,Synkrama Technologies,India,-1,-1,-1,-1,-1,-1,-1,-1
